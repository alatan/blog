<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>软件开发学习记录</title>
    <link>https://moge.fun/</link>
    <description>Recent content on 软件开发学习记录</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-CN</language>
    <lastBuildDate>Wed, 01 Feb 2023 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://moge.fun/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>AI 应用总结</title>
      <link>https://moge.fun/ai/</link>
      <pubDate>Wed, 01 Feb 2023 00:00:00 +0000</pubDate>
      <guid>https://moge.fun/ai/</guid>
      <description>行业 外贸 外贸商品的各场景图片生成 比如一个U盘在各种电脑上面的图片
服装行业 电商服装行业画重点：打板、爆品复刻、反推拆解图 他说的是把图案直接生成衣服样子的图 裁剪图，单块的，把每一块拼起来就是衣服 打板行业痛点，时间长，成本高，有个衣服设计想法出来单个需要 5 千的成本 假模特也可以变真人模特，前视图，左，右，后试图，pose，CNet，lora，线稿
可落地尝试 创意服装二维码 照相馆 摄影 手绘效果 模特换脸 餐饮品牌营销公司 生成菜品的宣传图 菜品模型没有标品，肯定是要调教的
室内设计 毛胚房变装修效果图，室内设计应用场景
视频宣传片 安全教育宣传片（文案，卡通人物，生成视频） 实现 工具 AI绘画 https://www.openflowai.net/ Stable Diffusion(SD) Mid Journey（MJ） controlnet 线稿 AI视频 runway pika 生成视频(chatgpt做脚本) sd出图 需要选checkpoint lora embedding 然后结合 controlnet 可以快速出替换 gpts的应用市场里，有直接文本生提示词的，还是分好镜的 你去找“小说文本提示词大师”这类的应用就好 gpts有hunt可以搜搜 方式论 关键词生产 可以找一些参考对象 生成后 ps 再优化下 </description>
    </item>
    <item>
      <title>性能测试</title>
      <link>https://moge.fun/pts/</link>
      <pubDate>Sun, 10 May 2020 00:00:00 +0000</pubDate>
      <guid>https://moge.fun/pts/</guid>
      <description>˚ 测试指标 业务指标：如并发用户数、TPS（系统每秒处理事务数）、成功率、响应时间。 资源指标：如CPU资源利用率、内存利用率、I/O、内核参数（信号量、打开文件数）等。 应用指标：如空闲线程数、数据库连接数、GC/FULL GC次数、函数耗时等。 前端指标：如页面加载时间、网络时间（DNS、连接时间、传输时间等）。 工具 APM工具（如ARMS）进行中间件、数据库、应用层面的问题定位。 </description>
    </item>
    <item>
      <title>秒杀(限时抢购)系统设计</title>
      <link>https://moge.fun/flashsale/</link>
      <pubDate>Thu, 07 May 2020 00:00:00 +0000</pubDate>
      <guid>https://moge.fun/flashsale/</guid>
      <description>参考文章 高性能秒杀系统设计 秒杀架构实践 百万级用户的抽奖系统 </description>
    </item>
    <item>
      <title>单点登录</title>
      <link>https://moge.fun/sso/</link>
      <pubDate>Wed, 06 May 2020 00:00:00 +0000</pubDate>
      <guid>https://moge.fun/sso/</guid>
      <description> 单点登录（Single Sign On），简称为 SSO，是比较流行的企业业务整合的解决方案之一。SSO的定义是在多个应用系统中，用户只需要登录一次就可以访问所有相互信任的应用系统。
参考文章 单点登录 单点登录总结 </description>
    </item>
    <item>
      <title>Nacos解析</title>
      <link>https://moge.fun/nacos/</link>
      <pubDate>Sat, 11 Apr 2020 00:00:00 +0000</pubDate>
      <guid>https://moge.fun/nacos/</guid>
      <description>临时实例和持久化实例。 在定义上区分临时实例和持久化实例的关键是健康检查的方式。 临时实例使用客户端上报模式，而持久化实例使用服务端反向探测模式。 临时实例需要能够自动摘除不健康实例，而且无需持久化存储实例，那么这种实例就适用于类 Gossip 的协议。 右边的持久化实例使用服务端探测的健康检查方式，因为客户端不会上报心跳，那么自然就不能去自动摘除下线的实例。 实现对比 Zookeeper：保证CP，放弃可用性；一旦zookeeper集群中master节点宕了，则会重新选举leader，这个过程可能非常漫长，在这过程中服务不可用。 Eureka：保证AP，放弃一致性；Eureka集群中的各个节点都是平等的，一旦某个节点宕了，其他节点正常服务（一旦客户端发现注册失败，则将会连接集群中其他节点），虽然保证了可用性，但是每个节点的数据可能不是最新的。 Nacos：同时支持CP和AP，默认是AP，可以切换；AP模式下以临时实例注册，CP模式下服务永久实例注册。 健康检查 客户端健康检查 客户端健康检查主要关注客户端上报心跳的方式、服务端摘除不健康客户端的机制。
服务端健康检查 而服务端健康检查，则关注探测客户端的方式、灵敏度及设置客户端健康状态的机制。
从实现复杂性来说，服务端探测肯定是要更加复杂的，因为需要服务端根据注册服务配置的健康检查方式，去执行相应的接口，判断相应的返回结果，并做好重试机制和线程池的管理。
这与客户端探测，只需要等待心跳，然后刷新 TTL 是不一样的。同时服务端健康检查无法摘除不健康实例，这意味着只要注册过的服务实例，如果不调用接口主动注销，这些服务实例都需要去维持健康检查的探测任务，而客户端则可以随时摘除不健康实例，减轻服务端的压力。
Nacos实现配置管理和动态配置 添加对应spring-cloud-starter-alibaba-nacos-config依赖 使用原生注解@Value()导入配置 使用原生注解@RefreshScope刷新配置 根据自己业务场景做好多环境配置隔离(Namespace)、不同业务配置隔离(Group) 切记：命名空间和分组的配置一定要放在bootstrap.yml或者bootstrap.properties配置文件中 参考文章 Nacos 注册中心的设计原理详解 Nacos 实现原理详解 Nacos 使用 </description>
    </item>
    <item>
      <title>Spring Cloud Alibaba</title>
      <link>https://moge.fun/springcloudalibaba/</link>
      <pubDate>Fri, 10 Apr 2020 00:00:00 +0000</pubDate>
      <guid>https://moge.fun/springcloudalibaba/</guid>
      <description>组件 Spring Cloud - Gateway 网关 Spring Cloud - Ribbon 实现负载均衡 Spring Cloud - Feign 实现远程调用 Spring Cloud - Sleuth 实现调用链监控 Spring Cloud Alibaba - Nacos 实现注册中心/配置中心 Spring Cloud Alibaba - Sentinel 实现服务容错(限流，降级) Spring Cloud Alibaba - Seata 实现分布式事务 Nacos Nacos 是一个 Alibaba 开源的、易于构建云原生应用的动态服务发现、配置管理和服务管理平台。
Nacos 这个名字怎么读呢？它的音标为 /nɑ:kəʊs/。这个名字不是一个标准的单词，而是以下单词的首字母缩写：Name and Config Service。
Nacos Discovery 使用 Spring Cloud Alibaba Nacos Discovery，可基于 Spring Cloud 的编程模型快速接入 Nacos 服务注册功能。
配置中心 Nacos Config 使用 Spring Cloud Alibaba Nacos Config，可基于 Spring Cloud 的编程模型快速接入 Nacos 配置管理功能。</description>
    </item>
    <item>
      <title>Spring Cloud Hystrix 解析</title>
      <link>https://moge.fun/springcloud-hystrix/</link>
      <pubDate>Sat, 04 Apr 2020 00:00:00 +0000</pubDate>
      <guid>https://moge.fun/springcloud-hystrix/</guid>
      <description>参考文章 Hystrix原理与实战 Hystrix原理与实战 Hystrix 源码分析及实践 </description>
    </item>
    <item>
      <title>Spring Cloud Eureka 解析</title>
      <link>https://moge.fun/springcloud-eureka/</link>
      <pubDate>Fri, 03 Apr 2020 00:00:00 +0000</pubDate>
      <guid>https://moge.fun/springcloud-eureka/</guid>
      <description>先来一波问题，然后看看Enueka是通过什么方式处理的。
Eureka注册中心使用什么样的方式来储存各个服务注册时发送过来的机器地址和端口号？ 各个服务找Eureka Server拉取注册表的时候，是什么样的频率？ 各个服务是如何拉取注册表的？ 对于一个有几百个服务，部署上千台机器的大型分布式系统来说，这套系统会对Eureka Server造成多大的访问压力？ Eureka Server从技术层面是如何抗住日千万级访问量的？ 基本知识点，各个服务内的Eureka Client组件，默认情况下，每隔30秒会发送一个请求到Eureka Server，来拉取最近有变化的服务信息
Eureka Server设计精妙的注册表存储结构 维护注册表、拉取注册表、更新心跳时间，全部发生在内存里！这是Eureka Server非常核心的一个点。 Eureka Server端优秀的多级缓存机制 尽可能保证了内存注册表数据不会出现频繁的读写冲突问题。 并且进一步保证对Eureka Server的大量请求，都是快速从纯内存走，性能极高。 总结 通过上面的分析可以看到，Eureka通过设置适当的请求频率拉取注册表30秒间隔，发送心跳30秒间隔），可以保证一个大规模的系统每秒请求Eureka Server的次数在几百次。 同时通过纯内存的注册表，保证了所有的请求都可以在内存处理，确保了极高的性能 另外,多级缓存机制，确保了不会针对内存数据结构发生频繁的读写并发冲突操作，进一步提升性能。 参考文章 Eureka 原理 Eureka 原理解析 深入学习 Eureka 原理 微服务注册中心如何承载大型系统的千万级访问 </description>
    </item>
    <item>
      <title>Spring Cloud</title>
      <link>https://moge.fun/springcloud/</link>
      <pubDate>Thu, 02 Apr 2020 00:00:00 +0000</pubDate>
      <guid>https://moge.fun/springcloud/</guid>
      <description>Spring 以 Bean（对象） 为中心，提供 IOC、AOP 等功能。 Spring Boot 以 Application（应用） 为中心，提供自动配置、监控等功能，专注于快速方便的开发单个微服务。 Spring Cloud 以 Service（服务） 为中心，关注全局的微服务协调整理治理框架，它将SpringBoot开发的一个个单体微服务整合并管理起来，为各个微服务之间提供，配置管理、服务发现、断路器、路由、微代理、事件总线、全局锁、决策竞选、分布式会话等等集成服务SpringBoot可以离开SpringCloud独立使用开发项目， 但是SpringCloud离不开SpringBoot ，属于依赖的关系。 Spring Cloud是目前最常用的微服务开发框架，Spring Cloud是一系列框架的有序集合。它利用Spring Boot的开发便利性巧妙地简化了分布式系统基础设施的开发，如服务发现注册、配置中心、消息总线、负载均衡、熔断保护、数据监控等，都可以用Spring Boot的开发风格做到一键启动和部署。Spring Cloud并没有重复制造轮子，它只是将各家公司开发的比较成熟、经得起实际考验的服务框架组合起来，通过Spring Boot风格进行再封装屏蔽掉了复杂的配置和实现原理，最终给开发者留出了一套简单易懂、易部署和易维护的分布式系统开发工具包。
版本对应 Spring Cloud Version Spring Boot Version Spring Cloud Alibaba Version Spring Cloud 2020.0.1 2.4.x 2021.1 Spring Cloud Hoxton 2.2.x, 2.3.x 2.2.x Spring Cloud Greenwich 2.1.x 2.1.x Spring Cloud Finchley 2.0.x 2.0.x(停止维护，建议升级) Spring Cloud Edgware 1.5.x 1.5.x(停止维护，建议升级) Spring Cloud Dalston 1.5.x 1.5.x(停止维护，建议升级) SpringCloud的基础功能 服务治理： Spring Cloud Eureka 服务容错保护： Spring Cloud Hystrix 客户端负载均衡： Spring Cloud Ribbon 基于Ribbon和Hystrix的声明式服务调用组件： Spring Cloud OpenFeign 整合了ribbon，具有负载均衡的能力。 整合了Hystrix，具有熔断的能力。 API网关服务：Spring Cloud Zuul 分布式配置中心： Spring Cloud Config 服务治理-Eureka 为了解决微服务架构中的服务实例维护问题(ip地址)， 产生了大量的服务治理框架和产品。 这些框架和产品的实现都围绕着服务注册与服务发现机制来完成对微服务应用实例的自动化管理。</description>
    </item>
    <item>
      <title>Dubbo总结</title>
      <link>https://moge.fun/dubbo/</link>
      <pubDate>Wed, 01 Apr 2020 00:00:00 +0000</pubDate>
      <guid>https://moge.fun/dubbo/</guid>
      <description>Apache Dubbo 是一款微服务开发框架，它提供了 RPC通信 与 微服务治理 两大关键能力。这意味着，使用 Dubbo 开发的微服务，将具备相互之间的远程发现与通信能力， 同时利用 Dubbo 提供的丰富服务治理能力，可以实现诸如服务发现、负载均衡、流量调度等服务治理诉求。同时 Dubbo 是高度可扩展的，用户几乎可以在任意功能点去定制自己的实现，以改变框架的默认行为来满足自己的业务需求。
服务是 Dubbo 中的核心概念，一个服务代表一组 RPC 方法的集合，服务是面向用户编程、服务发现机制等的基本单位。
Dubbo 开发的基本流程是：用户定义 RPC 服务，通过约定的配置 方式将 RPC 声明为 Dubbo 服务，然后就可以基于服务 API 进行编程了。对服务提供者来说是提供 RPC 服务的具体实现，而对服务消费者来说则是使用特定数据发起服务调用。
服务发现 服务发现，即消费端自动发现服务地址列表的能力，是微服务框架需要具备的关键能力，借助于自动化的服务发现，微服务之间可以在无需感知对端部署位置与 IP 地址的情况下实现通信。
实现服务发现的方式有很多种，Dubbo 提供的是一种 Client-Based 的服务发现机制，通常还需要部署额外的第三方注册中心组件来协调服务发现过程，如常用的 Nacos、Consul、Zookeeper 等，Dubbo 自身也提供了对多种注册中心组件的对接，用户可以灵活选择。
服务发现的一个核心组件是注册中心，Provider 注册地址到注册中心，Consumer 从注册中心读取和订阅 Provider 地址列表。 因此，要启用服务发现，需要为 Dubbo 增加注册中心配置：
以 dubbo-spring-boot-starter 使用方式为例，增加 registry 配置
1 2 3 4 # application.properties dubbo registry address: zookeeper://127.0.0.1:2181 服务流量管理 流量管理的本质是将请求根据制定好的路由规则分发到应用服务上，如下图所示： Dubbo提供了支持mesh方式的流量管理策略，可以很容易实现 A/B测试、金丝雀发布、蓝绿发布等能力。</description>
    </item>
    <item>
      <title>幂等</title>
      <link>https://moge.fun/idempotence/</link>
      <pubDate>Sun, 01 Mar 2020 00:00:00 +0000</pubDate>
      <guid>https://moge.fun/idempotence/</guid>
      <description>幂等就是：一个操作不论执行多少次，产生的效果和返回的结果都是一样的。
业务场景 查询操作 查询一次和查询多次，在数据不变的情况下，查询结果是一样的。select是天然的幂等操作。
删除操作 删除操作也是幂等的，删除一次和多次删除都是把数据删除。(注意可能返回结果不一样，删除的数据不存在，返回0，删除的数据多条，返回结果多个)
新增操作 唯一索引或唯一组合索引来防止新增数据存在脏数据（当表存在唯一索引，并发时新增报错时，再查询一次就可以了，数据应该已经存在了，返回结果即可）
防止页面重复提交（token机制） 业务要求：页面的数据只能被点击提交一次 发生原因：由于重复点击或者网络重发，或者nginx重发等情况会导致数据被重复提交 处理流程： 用户访问页面时，浏览器自动发起获取token请求。 服务端生成token，保存到redis中，然后返回给浏览器。 用户通过浏览器发起请求时，携带该token。 在redis中查询该token是否存在，如果不存在，说明是第一次请求，做则后续的数据操作。 如果存在，说明是重复请求，则直接返回成功。 在redis中token会在过期时间之后，被自动删除。 解决办法： 集群环境：采用token加redis（redis单线程的，处理需要排队） 单JVM环境：采用token加redis或token加jvm内存 token特点：要申请，一次有效性，可以限流。 redis要用删除操作来判断token，删除成功代表token校验通过，如果用select+delete来校验token，存在并发问题，不建议使用。 对外提供接口的api保证幂等 如银联提供的付款接口：需要接入商户提交付款请求时附带：source来源，seq序列号，source+seq在数据库里面做唯一索引，防止多次付款，(并发时，只能处理一个请求)。
对外提供接口为了支持幂等调用，接口有两个字段必须传，一个是来源source，一个是来源方序列号seq，这个两个字段在服务提供方系统里面做联合唯一索引，这样当第三方调用时，先在本方系统里面查询一下，是否已经处理过，返回相应处理结果；没有处理过，进行相应处理，返回结果。注意，为了幂等友好，一定要先查询一下，是否处理过该笔业务，不查询直接插入业务系统，会报错，但实际已经处理了。
解决方案 悲观锁 获取数据的时候加锁获取
1 select * from table_xxx where id=&amp;#39;xxx&amp;#39; for update; 注意：id字段一定是主键或者唯一索引，不然是锁表，会死人的，悲观锁使用时一般伴随事务一起使用，数据锁定时间可能会很长，根据实际情况选用。
乐观锁 乐观锁只是在更新数据那一刻锁表，其他时间不锁表，所以相对于悲观锁，效率更高。
乐观锁的实现方式多种多样可以通过version或者其他状态条件：
通过版本号实现 1 2 3 update table_xxx set name=#name#,version=version+1 where version=#version#; -- 优化后的 update table_xxx set name=#name#,version=version+1 where id=#id# and version=#version#; 通过条件限制 1 2 3 update table_xxx set avai_amount=avai_amount-#subAmount# where avai_amount-#subAmount# &amp;gt;= 0; -- 优化后的 update table_xxx set avai_amount=avai_amount-#subAmount# where id=#id# and avai_amount-#subAmount# &amp;gt;= 0 要求：quality-#subQuality# &amp;gt;= ，这个情景适合不用版本号，只更新是做数据安全校验，适合库存模型，扣份额和回滚份额，性能更高</description>
    </item>
    <item>
      <title>分布式ID</title>
      <link>https://moge.fun/distributedid/</link>
      <pubDate>Thu, 06 Feb 2020 00:00:00 +0000</pubDate>
      <guid>https://moge.fun/distributedid/</guid>
      <description>在复杂分布式系统中，往往需要对大量的数据和消息进行唯一标识。
概括下来，那业务系统对ID号的要求有哪些呢？
全局唯一：不能出现重复的ID号，既然是唯一标识，这是最基本的要求。 趋势递增：在MySQL InnoDB引擎中使用的是聚集索引，由于多数RDBMS使用B-tree的数据结构来存储索引数据，在主键的选择上面我们应该尽量使用有序的主键保证写入性能。 单调递增：保证下一个ID一定大于上一个ID，例如事务版本号、IM增量消息、排序等特殊需求。 信息安全：如果ID是连续的，恶意用户的扒取工作就非常容易做了，直接按照顺序下载指定URL即可；如果是订单号就更危险了，竞对可以直接知道我们一天的单量。所以在一些应用场景下，会需要ID无规则、不规则。 高可用：平均延迟和TP999延迟都要尽可能低；可用性5个9； 高QPS。 UUID UUID是通用唯一识别码（Universally Unique Identifier)的缩写，开放软件基金会(OSF)规范定义了包括网卡MAC地址、时间戳、名字空间（Namespace）、随机或伪随机数、时序等元素。利用这些元素来生成UUID。
UUID是由128位二进制组成，一般转换成十六进制，然后用String表示。在java中有个UUID类,在他的注释中我们看见这里有4种不同的UUID的生成策略:
randomly 基于随机数生成UUID，由于Java中的随机数是伪随机数，其重复的概率是可以被计算出来的。这个一般我们用下面的代码获取基于随机数的UUID: time-based 基于时间的UUID,这个一般是通过当前时间，随机数，和本地Mac地址来计算出来，自带的JDK包并没有这个算法的我们在一些UUIDUtil中，比如我们的log4j.core.util，会重新定义UUID的高位和低位。 DCE security:DCE安全的UUID。 name-based：基于名字的UUID，通过计算名字和名字空间的MD5来计算UUID。 UUID的优点 通过本地生成，没有经过网络I/O，性能较快 无序，无法预测他的生成顺序。(当然这个也是他的缺点之一) UUID的缺点 128位二进制一般转换成36位的16进制，太长了只能用String存储，空间占用较多。 不能生成递增有序的数字 适用场景 UUID的适用场景为不担心过多的空间占用，以及不需要生成有递增趋势的数字。在Log4j里面他在UuidPatternConverter中加入了UUID来标识每一条日志。
数据库主键自增 大家对于唯一标识最容易想到的就是主键自增，这个也是我们最常用的方法。例如我们有个订单服务，那么把订单id设置为主键自增即可。
优点 简单方便，有序递增，方便排序和分页
缺点 分库分表会带来问题，需要进行改造。 并发性能不高，受限于数据库的性能。 简单递增容易被其他人猜测利用，比如你有一个用户服务用的递增，那么其他人可以根据分析注册的用户ID来得到当天你的服务有多少人注册，从而就能猜测出你这个服务当前的一个大概状况。 数据库宕机服务不可用。 适用场景 根据上面可以总结出来，当数据量不多，并发性能不高的时候这个很适合，比如一些to B的业务，商家注册这些，商家注册和用户注册不是一个数量级的，所以可以数据库主键递增。如果对顺序递增强依赖，那么也可以使用数据库主键自增。
Redis Redis中有两个命令Incr，IncrBy,因为Redis是单线程的所以能保证原子性。
优点 性能比数据库好，能满足有序递增。
缺点 由于redis是内存的KV数据库，即使有AOF和RDB，但是依然会存在数据丢失，有可能会造成ID重复。 依赖于redis，redis要是不稳定，会影响ID生成。 适用 由于其性能比数据库好，但是有可能会出现ID重复和不稳定，这一块如果可以接受那么就可以使用。也适用于到了某个时间，比如每天都刷新ID，那么这个ID就需要重置，通过(Incr Today)，每天都会从0开始加。
雪花算法-Snowflake Snowflake是Twitter提出来的一个算法，其目的是生成一个64bit的整数
1bit:一般是符号位，不做处理 41bit:用来记录时间戳，这里可以记录69年，如果设置好起始时间比如今年是2018年，那么可以用到2089年，到时候怎么办？要是这个系统能用69年，我相信这个系统早都重构了好多次了。 10bit:10bit用来记录机器ID，总共可以记录1024台机器，一般用前5位代表数据中心，后面5位是某个数据中心的机器ID 12bit:循环位，用来对同一个毫秒之内产生不同的ID，12位可以最多记录4095个，也就是在同一个机器同一毫秒最多记录4095个，多余的需要进行等待下毫秒。 上面只是一个将64bit划分的标准，当然也不一定这么做，可以根据不同业务的具体场景来划分，比如下面给出一个业务场景：
服务目前QPS10万，预计几年之内会发展到百万。 当前机器三地部署，上海，北京，深圳都有。 当前机器10台左右，预计未来会增加至百台。 这个时候我们根据上面的场景可以再次合理的划分62bit,QPS几年之内会发展到百万，那么每毫秒就是千级的请求，目前10台机器那么每台机器承担百级的请求，为了保证扩展，后面的循环位可以限制到1024，也就是2^10，那么循环位10位就足够了。
机器三地部署我们可以用3bit总共8来表示机房位置，当前的机器10台，为了保证扩展到百台那么可以用7bit 128来表示，时间位依然是41bit,那么还剩下64-10-3-7-41-1 = 2bit,还剩下2bit可以用来进行扩展。
适用场景 当我们需要无序不能被猜测的ID，并且需要一定高性能，且需要long型，那么就可以使用我们雪花算法。比如常见的订单ID，用雪花算法别人就发猜测你每天的订单量是多少。
一个简单的Snowflake 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 public class IdWorker{ private long workerId; private long datacenterId; private long sequence = 0; /** * 2018/9/29日，从此时开始计算，可以用到2089年 */ private long twepoch = 1538211907857L; private long workerIdBits = 5L; private long datacenterIdBits = 5L; private long sequenceBits = 12L; private long workerIdShift = sequenceBits; private long datacenterIdShift = sequenceBits + workerIdBits; private long timestampLeftShift = sequenceBits + workerIdBits + datacenterIdBits; // 得到0000000000000000000000000000000000000000000000000000111111111111 private long sequenceMask = -1L ^ (-1L &amp;lt;&amp;lt; sequenceBits); private long lastTimestamp = -1L; public IdWorker(long workerId, long datacenterId){ this.</description>
    </item>
    <item>
      <title>分布式事务</title>
      <link>https://moge.fun/distributedtransaction/</link>
      <pubDate>Wed, 05 Feb 2020 00:00:00 +0000</pubDate>
      <guid>https://moge.fun/distributedtransaction/</guid>
      <description>数据库事务-本地事务 传统的单服务器，单关系型数据库下的事务，就是本地事务。本地事务由资源管理器管理，JDBC事务就是一个非常典型的本地事务。
事务ACID特性的实现思想 原子性：是使用 undo log来实现的，如果事务执行过程中出错或者用户执行了rollback，系统通过undo log日志返回事务开始的状态。 持久性：使用 redo log来实现，只要redo log日志持久化了，当系统崩溃，即可通过redo log把数据恢复。 隔离性：通过锁以及MVCC,使事务相互隔离开。 一致性：通过回滚、恢复，以及并发情况下的隔离性，从而实现一致性。 分布式事务 分布式事务是指事务的参与者、支持事务的服务器、资源服务器以及事务管理器分别位于不同的分布式系统的不同节点之上。
微服务架构下的分布式事务 用户下单购买礼物，礼物数据库、金币数据库、订单数据库在不同节点上，用本地事务是不可以的，那么如何保证不同数据库（节点）上的数据一致性呢？这就需要分布式事务啦
分库分表下的分布式事务 随着业务的发展，数据库的数据日益庞大，超过千万级别的数据，我们就需要对它分库分表（以前公司是用mycat分库分表，后来用sharding-jdbc）。一分库，数据又分布在不同节点上啦，比如有的在深圳机房，有的在北京机房~你再想用本地事务去保证，已经无动于衷啦~还是需要分布式事务啦。 比如A转10块给B，A的账户数据是在北京机房，B的账户数据是在深圳机房。流程如下：
分布式事务理论（CAP和BASE） 如果说到事务，ACID是传统数据库常用的设计理念，追求强一致性模型，关系数据库的ACID模型拥有高一致性+可用性，所以很难进行分区，所以在微服务中ACID已经是无法支持，我们还是回到CAP去寻求解决方案，不过根据上面的讨论，CAP定理中，要么只能CP，要么只能AP，如果我们追求数据的一致性而忽略可用性这个在微服务中肯定是行不通的，如果我们追求可用性而忽略一致性，那么在一些重要的数据（例如支付，金额）肯定出现漏洞百出，这个也是无法接受。所以我们既要一致性，也要可用性。
都要是无法实现的，但我们能不能在一致性上作出一些妥协，不追求强一致性，转而追求最终一致性，所以引入BASE理论，在分布式事务中，BASE最重要是为CAP提出了最终一致性的解决方案，BASE强调牺牲高一致性，从而获取肯用性，数据允许在一段时间内不一致，只要保证最终一致性就可以了。
这就是分布式事务等理论基础，即实现最终一致性。
分布式事务的几种解决方案 2PC(二阶段提交)方案/XA 事务的提交分为两个阶段：准备阶段和提交执行方案。
二阶段提交成功的情况 准备阶段，事务管理器向每个资源管理器发送准备消息，如果资源管理器的本地事务操作执行成功，则返回成功。 提交执行阶段，如果事务管理器收到了所有资源管理器回复的成功消息，则向每个资源管理器发送提交消息，RM 根据 TM 的指令执行提交。 二阶段提交失败的情况 准备阶段，事务管理器向每个资源管理器发送准备消息，如果资源管理器的本地事务操作执行成功，则返回成功，如果执行失败，则返回失败。 提交执行阶段，如果事务管理器收到了任何一个资源管理器失败的消息，则向每个资源管理器发送回滚消息。资源管理器根据事务管理器的指令回滚本地事务操作，释放所有事务处理过程中使用的锁资源。 二阶段提交优缺点 单点问题：如果事务管理器出现故障，资源管理器将一直处于锁定状态。 性能问题：所有资源管理器在事务提交阶段处于同步阻塞状态，占用系统资源，一直到提交完成，才释放资源，容易导致性能瓶颈。 数据一致性问题：如果有的资源管理器收到提交的消息，有的没收到，那么会导致数据不一致问题。 TCC（Try、Confirm、Cancel） TCC 采用了补偿机制，其核心思想是：针对每个操作，都要注册一个与其对应的确认和补偿（撤销）操作。
TCC（Try-Confirm-Cancel）模型 TCC（Try-Confirm-Cancel）是通过对业务逻辑的分解来实现分布式事务。针对一个具体的业务服务，TCC 分布式事务模型需要业务系统都实现一下三段逻辑：
try阶段： 尝试去执行，完成所有业务的一致性检查，预留必须的业务资源。
Confirm阶段： 该阶段对业务进行确认提交，不做任何检查，因为try阶段已经检查过了，默认Confirm阶段是不会出错的。
Cancel 阶段： 若业务执行失败，则进入该阶段，它会释放try阶段占用的所有业务资源，并回滚Confirm阶段执行的所有操作。
TCC优缺点 TCC方案让应用可以自定义数据库操作的粒度，降低了锁冲突，可以提升性能，但是也有以下缺点：
应用侵入性强，try、confirm、cancel三个阶段都需要业务逻辑实现。 需要根据网络、系统故障等不同失败原因实现不同的回滚策略，实现难度大，一般借助TCC开源框架，ByteTCC，TCC-transaction，Himly。 在 Try 阶段，是对业务系统进行检查及资源预览，比如订单和存储操作，需要检查库存剩余数量是否够用，并进行预留，预留操作的话就是新建一个可用库存数量字段，Try 阶段操作是对这个可用库存数量进行操作。 基于 TCC 实现分布式事务，会将原来只需要一个接口就可以实现的逻辑拆分为 Try、Confirm、Cancel 三个接口，所以代码实现复杂度相对较高。
TCC 需要事务接口提供 try, confirm, cancel 三个接口，提高了编程的复杂性。依赖于业务方来配合提供这样的接口，推行难度大，所以一般不推荐使用这种方式。</description>
    </item>
    <item>
      <title>分布式锁</title>
      <link>https://moge.fun/distributedlock/</link>
      <pubDate>Tue, 04 Feb 2020 00:00:00 +0000</pubDate>
      <guid>https://moge.fun/distributedlock/</guid>
      <description>基于数据库 基于数据库表数据记录做唯一约束 上面这种简单的实现有以下几个问题：
这把锁强依赖数据库的可用性，数据库是一个单点，一旦数据库挂掉，会导致业务系统不可用。 这把锁没有失效时间，一旦解锁操作失败，就会导致锁记录一直在数据库中，其他线程无法再获得到锁。 这把锁只能是非阻塞的，因为数据的insert操作，一旦插入失败就会直接报错。没有获得锁的线程并不会进入排队队列，要想再次获得锁就要再次触发获得锁操作。 这把锁是非重入的，同一个线程在没有释放锁之前无法再次获得该锁。因为数据中数据已经存在了。 不过这种方式对于单主却无法自动切换主从的mysql来说，基本就无法现实P分区容错性，（Mysql自动主从切换在目前并没有十分完美的解决方案）。可以说这种方式强依赖于数据库的可用性，数据库写操作是一个单点，一旦数据库挂掉，就导致锁的不可用。这种方式基本不在CAP的一个讨论范围。 基于Redis 使用redis的setNX()用于分布式锁。（原子性）
1 2 3 4 setnx key value Expire_time 获取到锁 返回 1 ， 获取失败 返回 0 * 返回1，说明该进程获得锁，SETNX将键 lock.id 的值设置为锁的超时时间，当前时间 +加上锁的有效时间。 * 返回0，说明其他进程已经获得了锁，进程不能进入临界区。进程可以在一个循环中不断地尝试 SETNX 操作，以获得锁。 1 2 3 4 5 6 7 8 9 10 11 12 protected boolean getLock(String lockKey, int time,TimeUnit timeUnit) { // 使用redis的setNX命令实现分布式锁 boolean isSuccess = redisTemplate.opsForValue().setIfAbsent(lockKey, &amp;#34;lock&amp;#34;); // 防止进程中断导致redis分布锁死锁，检查是否设置了超时时间。 Long timeLeft = redisTemplate.getExpire(lockKey); if (isSuccess || timeLeft &amp;lt; 0) { // 设置失效时间（最好与该任务执行频率时间一致）：如果执行期间宕机，5分钟后也能被另一机器获得lock redisTemplate.</description>
    </item>
    <item>
      <title>分布式概览</title>
      <link>https://moge.fun/distributed/</link>
      <pubDate>Mon, 03 Feb 2020 00:00:00 +0000</pubDate>
      <guid>https://moge.fun/distributed/</guid>
      <description>分布式理论基础 CAP CAP 理论是分布式中基础理论，有三个重要指标：一致性、可用性、分区容错性。
一致性（Consistency）：一致性意思就是写操作之后进行读操作无论在哪个节点都需要返回写操作的值 可用性（Availability）：非故障的节点在合理的时间内返回合理的响应 分区容错性（Partition Tolerance）：当网络出现分区后，系统依然能够继续履行职责 在分布式的环境下，网络无法做到100%可靠，有可能出现故障，因此分区是一个必须的选项，如果选择了CA而放弃了P，若发生分区现象，为了保证C，系统需要禁止写入，此时就与A发生冲突，如果是为了保证A，则会出现正常的分区可以写入数据，有故障的分区不能写入数据，则与C就冲突了。因此分布式系统理论上不可能选择CA架构，而必须选择CP或AP架构。
BASE（最终一致性） BASE是对CAP 理论中强一致性和可用性权衡的结果，其来源于对大规模互联网系统分布式实践的总结，是基于CAP定理逐步演化而来的，其核心思想是即使无法做到强一致性(Strong consistency)，每个应用都可以根据自身的业务特点，采用适当的方式来使系统达到最终一致性(Eventual consistency)。
BASE理论是对CAP的延伸和补充，是对CAP中的AP方案的一个补充，即在选择AP方案的情况下，如何更好的最终达到C。
BASE是基本可用，柔性状态，最终一致性三个短语的缩写，核心的思想是即使无法做到强一致性，但应用可以采用适合的方式达到最终一致性。
多数情况下，其实我们也并非一定要求强一致性，部分业务可以容忍一定程度的延迟一致，所以为了兼顾效率，发展出来了最终一致性理论BASE
BA-基本可用(Basically Available)：基本可用是指分布式系统在出现故障的时候，允许损失部分可用性，即保证核心可用。 S-软状态(Soft State)：软状态是指允许系统存在中间状态，而该中间状态不会影响系统整体可用性。分布式存储中一般一份数据至少会有三个副本，允许不同节点间副本同步的延时就是软状态的体现。 E-最终一致性(Eventual Consistency)：最终一致性是指系统中的所有数据副本经过一定时间后，最终能够达到一致的状态。弱一致性和强一致性相反，最终一致性是弱一致性的一种特殊情况。 一致性算法 分布式架构的核心就在一致性的实现和妥协，那么如何设计一套算法来保证不同节点之间的通信和数据达到无限趋向一致性，就非常重要了。
参考文章 分布式架构知识体系 通过一个订单查看微服务整个流程 分布式整体概览从CAP说起 学习资料 分布式系统合集 </description>
    </item>
    <item>
      <title>微服务介绍</title>
      <link>https://moge.fun/microservices/</link>
      <pubDate>Sun, 02 Feb 2020 00:00:00 +0000</pubDate>
      <guid>https://moge.fun/microservices/</guid>
      <description>微服务架构（MicroServices Architecture，MSA）：微服务架构可以看做是面向服务架构和分布式服务架构的拓展，使用更细粒度的服务（所以叫微服务）和一组设计准则来考虑大规模的复杂系统架构设计。系统中的各个微服务可被独立部署，各个微服务之间是松耦合的。每个微服务仅关注于完成一件任务并很好地完成该任务。在所有情况下，每个任务代表着一个小的业务能力。
常见的微服务组件及概念 服务注册：服务提供方将自己调用地址注册到服务注册中心，让服务调用方能够方便地找到自己。 服务发现：服务调用方从服务注册中心找到自己需要调用的服务的地址。 负载均衡：服务提供方一般以多实例的形式提供服务，负载均衡功能能够让服务调用方连接到合适的服务节点。并且，节点选择的工作对服务调用方来说是透明的。 服务网关：服务网关是服务调用的唯一入口，可以在这个组件是实现用户鉴权、动态路由、灰度发布、A/B 测试、负载限流等功能。 配置中心：将本地化的配置信息（properties, xml, yaml 等）注册到配置中心，实现程序包在开发、测试、生产环境的无差别性，方便程序包的迁移。 API 管理：以方便的形式编写及更新 API 文档，并以方便的形式供调用者查看和测试。 集成框架：微服务组件都以职责单一的程序包对外提供服务，集成框架以配置的形式将所有微服务组件（特别是管理端组件）集成到统一的界面框架下，让用户能够在统一的界面中使用系统。 分布式事务：对于重要的业务，需要通过分布式事务技术（TCC、高可用消息服务、最大努力通知）保证数据的一致性。 调用链：记录完成一个业务逻辑时调用到的微服务，并将这种串行或并行的调用关系展示出来。在系统出错时，可以方便地找到出错点。 支撑平台：系统微服务化后，系统变得更加碎片化，系统的部署、运维、监控等都比单体架构更加复杂，那么，就需要将大部分的工作自动化。现在，可以通过 Docker 等工具来中和这些微服务架构带来的弊端。 例如持续集成、蓝绿发布、健康检查、性能健康等等。严重点，以我们两年的实践经验，可以这么说，如果没有合适的支撑平台或工具，就不要使用微服务架构。 微服务架构的优点 降低系统复杂度：每个服务都比较简单，只关注于一个业务功能。 松耦合：微服务架构方式是松耦合的，每个微服务可由不同团队独立开发，互不影响。 跨语言：只要符合服务 API 契约，开发人员可以自由选择开发技术。这就意味着开发人员可以采用新技术编写或重构服务，由于服务相对较小，所以这并不会对整体应用造成太大影响。 独立部署：微服务架构可以使每个微服务独立部署。开发人员无需协调对服务升级或更改的部署。这些更改可以在测试通过后立即部署。所以微服务架构也使得 CI／CD 成为可能。 Docker 容器：和 Docker 容器结合的更好。 DDD 领域驱动设计：和 DDD 的概念契合，结合开发会更好。 微服务架构的缺点 微服务强调了服务大小，但实际上这并没有一个统一的标准：业务逻辑应该按照什么规则划分为微服务，这本身就是一个经验工程。有些开发者主张 10-100 行代码就应该建立一个微服务。微服务的目标是充分分解应用程序，以促进敏捷开发和持续集成部署。 微服务的分布式特点带来的复杂性：开发人员需要基于 RPC 或者消息实现微服务之间的调用和通信，而这就使得服务之间的发现、服务调用链的跟踪和质量问题变得的相当棘手。 分区的数据库体系和分布式事务：更新多个业务实体的业务交易相当普遍，不同服务可能拥有不同的数据库。CAP 原理的约束，使得我们不得不放弃传统的强一致性，而转而追求最终一致性，这个对开发人员来说是一个挑战。 测试挑战：传统的单体WEB应用只需测试单一的 REST API 即可，而对微服务进行测试，需要启动它依赖的所有其他服务。这种复杂性不可低估。 跨多个服务的更改：比如在传统单体应用中，若有 A、B、C 三个服务需要更改，A 依赖 B，B 依赖 C。我们只需更改相应的模块，然后一次性部署即可。但是在微服务架构中，我们需要仔细规划和* 调每个服务的变更部署。我们需要先更新 C，然后更新 B，最后更新 A。 部署复杂：微服务由不同的大量服务构成。每种服务可能拥有自己的配置、应用实例数量以及基础服务地址。这里就需要不同的配置、部署、扩展和监控组件。此外，我们还需要服务发现机制，以便服* 可以发现与其通信的其他服务的地址。因此，成功部署微服务应用需要开发人员有更好地部署策略和高度自动化的水平。 总结（问题和挑战）：API Gateway、服务间调用、服务发现、服务容错、服务部署、数据调用。 不过，现在很多微服务的框架（比如 Spring Cloud、Dubbo）已经很好的解决了上面的问题。</description>
    </item>
    <item>
      <title>高并发系统设计</title>
      <link>https://moge.fun/3h/</link>
      <pubDate>Sat, 01 Feb 2020 00:00:00 +0000</pubDate>
      <guid>https://moge.fun/3h/</guid>
      <description>软件开发通常会提到一个名词 “三高”，即高并发、高性能、高可用。
具体的指标定义，如：高并发方面要求QPS 大于10万；高性能方面要求请求延迟小于 100 ms；高可用方面要高于 99.99%。
高并发 高并发（High Concurrency）是互联网分布式系统架构设计中必须考虑的因素之一，它通常是指，通过设计保证系统能够同时并行处理很多请求。高并发相关常用的一些指标有响应时间（Response Time），吞吐量（Throughput），每秒查询率QPS（Query Per Second），并发用户数等。
系统拆分 将一个系统拆分为多个子系统，用 dubbo 来搞。然后每个系统连一个数据库，这样本来就一个库，现在多个数据库，不也可以扛高并发么。
读写分离 读写分离，这个就是说大部分时候数据库可能也是读多写少，没必要所有请求都集中在一个库上吧，可以搞个主从架构，主库写入，从库读取，搞一个读写分离。读流量太多的时候，还可以加更多的从库。
分库分表 分库分表，可能到了最后数据库层面还是免不了抗高并发的要求，好吧，那么就将一个数据库拆分为多个库，多个库来扛更高的并发；然后将一个表拆分为多个表，每个表的数据量保持少一点，提高 sql 跑的性能。
缓存 缓存，必须得用缓存。大部分的高并发场景，都是读多写少，那你完全可以在数据库和缓存里都写一份，然后读的时候大量走缓存不就得了。毕竟人家 redis 轻轻松松单机几万的并发。所以你可以考虑考虑你的项目里，那些承载主要请求的读场景，怎么用缓存来抗高并发。
消息队列 MQ，必须得用 MQ。可能你还是会出现高并发写的场景，比如说一个业务操作里要频繁搞数据库几十次，增删改增删改，疯了。那高并发绝对搞挂你的系统，你要是用 redis 来承载写那肯定不行，人家是缓存，数据随时就被 LRU 了，数据格式还无比简单，没有事务支持。所以该用 mysql 还得用 mysql 啊。那你咋办？用 MQ 吧，大量的写请求灌入 MQ 里，排队慢慢玩儿，后边系统消费后慢慢写，控制在 mysql 承载范围之内。所以你得考虑考虑你的项目里，那些承载复杂写业务逻辑的场景里，如何用 MQ 来异步写，提升并发性。MQ 单机抗几万并发也是 ok 的，这个之前还特意说过。
ElasticSearch Elasticsearch，简称 es。es 是分布式的，可以随便扩容，分布式天然就可以支撑高并发，因为动不动就可以扩容加机器来扛更高的并发。那么一些比较简单的查询、统计类的操作，可以考虑用 es 来承载，还有一些全文搜索类的操作，也可以考虑用 es 来承载。
高性能 性能体现了系统的并行处理能力，在有限的硬件投入下，提高性能意味着节省成本。同时，性能也反映了用户体验，响应时间分别是100毫秒和1秒，给用户的感受是完全不同的。 高可用 表示系统可以正常服务的时间。一个全年不停机、无故障；另一个隔三差五出线上事故、宕机，用户肯定选择前者。另外，如果系统只能做到90%可用，也会大大拖累业务。 高扩展 表示系统的扩展能力，流量高峰时能否在短时间内完成扩容，更平稳地承接峰值流量，比如双11活动、明星离婚等热点事件。
常用指标 吞吐量 在了解qps、tps、rt、并发数之前，首先我们应该明确一个系统的吞吐量到底代表什么含义，一般来说，系统吞吐量指的是系统的抗压、负载能力，代表一个系统每秒钟能承受的最大用户访问量。
一个系统的吞吐量通常由qps（tps）、并发数来决定，每个系统对这两个值都有一个相对极限值，只要某一项达到最大值，系统的吞吐量就上不去了。
系统吞吐量几个重要参数：QPS（TPS）、并发数、响应时间。
QPS（TPS）：（Query Per Second）每秒钟request/事务 数量 并发数： 系统同时处理的request/事务数 响应时间： 一般取平均响应时间 理解了上面三个要素的意义之后，就能推算出它们之间的关系：</description>
    </item>
    <item>
      <title>业务架构合集</title>
      <link>https://moge.fun/businessdesign/</link>
      <pubDate>Fri, 03 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://moge.fun/businessdesign/</guid>
      <description>业务场景 对账系统 有赞零售财务中台架构设计与实践 百万TPS支付账务系统的设计与实现 高效的风控规则引擎 最佳实践 最佳实践 服务化 架构设计 如何进行系统分析与设计 系统架构 领域驱动分层架构与对象模型 常见的软件架构套路 项目结构 互联网分层架构的本质 项目应该如何正确分层 分层架构 技术选型 技术选型 DevOps </description>
    </item>
    <item>
      <title>Java架构演变历史</title>
      <link>https://moge.fun/javaarchhistory/</link>
      <pubDate>Thu, 02 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://moge.fun/javaarchhistory/</guid>
      <description>Java网站架构演变过程，大致分为5个阶段，分别为单体架构、集群架构、分布式架构、SOA架构和微服务架构。
单体架构 应用、数据库、文件都部署在一台机器上。简单来讲其实就是我们熟知的SSM架构(Spring+SpringMVC+MyBatis)，把所有的业务模块都放在一个应用中开发，这里面又衍生出三层架构，即表示层、业务逻辑层和数据库访问层，虽然在软件设计中划分了经典的三层模型，但是对业务场景没有划分，一个典型的单体应用就是将所有的业务场景的表示层、业务逻辑层和数据访问层放在一个工程项目中，最终经过编译、打包，部署在一台服务器上。
单体架构优点 部署简单: 由于是完整的结构体，可以直接部署在一个服务器上即可。 技术单一: 项目不需要复杂的技术栈，往往一套熟悉的技术栈就可以完成开发。 用人成本低: 单个程序员可以完成业务接口到数据库的整个流程。 单体架构缺点 系统启动慢： 一个进程包含了所有的业务逻辑，涉及到的启动模块过多，导致系统的启动、重启时间周期过长; 系统错误隔离性差、可用性差：任何一个模块的错误均可能造成整个系统的宕机; 可伸缩性差：系统的扩容只能只对这个应用进行扩容，不能做到对某个功能点进行扩容; 线上问题修复周期长：任何一个线上问题修复需要对整个应用系统进行全面升级。 集群架构（cluster） 不同服务器部署同一套应用程序对外提供服务，实现服务的负载均衡或者互备(热备，主从)。同一种组件的多个实例，形成逻辑上的整体。单个节点可以提供完整服务，集群是物理形态。
集群架构相关技术点 应用和数据分离(大量用户高并发的访问导致系统性能越来越差，数据存储空间开始出现不足) 缓存的使用(QPS持续提高，为了降低接口访问时间、提高服务性能和并发，根据二八定律可以将80%的数据缓存) 负载均衡器的代理服务器 数据库读写分离 反向代理和CDN加速 负载平衡 集群就是把一个的事情交给多个人去做，假如要做1000个产品给一个人做要10天，我叫10个人做就是一天，这就是集群，负载均衡的话就是用来控制集群，他把做的最多的人让他慢慢做休息会，把做的最少的人让他加量让他做多点。
分布式架构 服务的不同模块部署在不同的机器上，单个节点不能提供完整服务，需要多节点协调提供服务(相同组件部署在不同节点，节点间通过交互信息协作提供服务)，分布式强调的是工作方式。
分布式相关技术点 业务分库分表 业务模块拆分成子项目 NoSQL和搜索引擎对可伸缩的分布式特性具有更好的支持，应用服务器通过一个统一的数据访问模块访问各种数据，减轻应用程序管理诸多数据源的麻烦。 SOA架构 面向服务的设计架构，其中包含多个服务，服务之间通过相互依赖最终提供一系列的功能。一个服务通常以独立的形式存在于操作系统进程中。各个服务之间通过网络调用。
中心化实现：ESB(企业服务总线)，各服务通过ESB进行交互，解决异构系统之间的连通性，通过协议转换，消息解析，消息路由把服务提供者的数据传送到服务消费者。 去中心化实现：微服务 微服务架构(在SOA上做的升华) 微服务就是一个独立的职责单一的服务应用程序，微服务架构强调业务需要彻底组件化和服务化，原有的单个业务系统会拆分为多个可独立开发，设计，运行的小应用。这些小应用通过服务完成交互和集成。
优点 每个服务直接足够内聚，代码容易理解 开发效率高，一个服务只做一件事，适合小团队开发 松耦合，有功能意义的服务。 可以用不同语言开发，面向接口编程。 易于第三方集成 微服务只是业务逻辑的代码，不会和HTML,CSS或其他界 可以灵活搭配，连接公共库/连接独立库 缺点 分布式系统的责任性 多服务运维难度加大。 系统部署依赖，服务间通信成本，数据一致 ，系统集成测试，性能监控。 服务间通信成本 数据一致性 系统集成测试 性能监控 Service Mesh 架构（集中管理微服务中非业务相关内容，让微服务更加专注于业务处理） 最初，流量管理和控制能力（比如图例中的熔断、服务发现）是和业务逻辑耦合在一起，即便以引用包的方式被调用，依然解决不了异构系统无法重用的问题。 流控功能和业务耦合相当不美好，于是出现了提供这些功能的公共库和框架。但这些库通常比较复杂，无论是学习使用，与业务系统整合、维护都会带来很大的成本。 为避免花费太多时间开发和维护这些通用库，人们希望流量控制能力可以下沉到网络通讯栈的层面，但几乎无法实现。 于是另一种思路出现，就是将这些功能独立成一个代理，由它先接管业务服务的流量，处理完成后再转发给业务服务本身，这就是 Sidecar 模式。 为统一管理 Sidecar，该模式进一步进化，形成网络拓扑，增加了控制平面，演变成 Service Mesh（最后的网格图中，绿色代表业务服务，蓝色代表 sidecar 服务）。 业务系统的核心价值应该是业务本身，而不是服务，微服务只是一种实现手段，实现业务才是目标。现有的微服务架构下，为解决可能出现的网络通信问题，提升系统的弹性，开发人员不得不花费大量时间和精力去实现流量控制相关的非业务需求，不能聚焦在业务本身。</description>
    </item>
    <item>
      <title>Java知识大纲</title>
      <link>https://moge.fun/javaoutline/</link>
      <pubDate>Wed, 01 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://moge.fun/javaoutline/</guid>
      <description>基础 数据结构与算法 数组、链表、二叉树、队列、栈的各种操作（性能，场景） 二分查找和各种变种的二分查找 各类排序算法以及复杂度分析（快排、归并、堆） 各类算法题（手写） 理解并可以分析时间和空间复杂度。 动态规划（笔试回回有。。）、贪心。 红黑树、AVL树、Hash树、Tire树、B树、B+树。 图算法（比较少，也就两个最短路径算法理解吧） 操作系统 进程通信IPC（几种方式），与线程区别 OS的几种策略（页面置换，进程调度等，每个里面有几种算法） 互斥与死锁相关的 linux常用命令（问的时候都会给具体某一个场景） Linux内核相关（select、poll、epoll） 网络基础 OSI7层模型（TCP4层） 每层的协议 url到页面的过程 HTTP http/https 1.0、1.1、2.0 get/post 以及幂等性 http 协议头相关 网络攻击（CSRF、XSS） TCP/IP 三次握手、四次挥手 拥塞控制（过程、阈值） 流量控制与滑动窗口 TCP与UDP比较 子网划分（一般只有笔试有） DDos攻击 (B)IO/NIO/AIO 三者原理，各个语言是怎么实现的 Netty Linux内核select poll epoll 数据库 索引（包括分类及优化方式，失效条件，底层结构） sql语法（join，union，子查询，having，group by） 引擎对比（InnoDB，MyISAM） 数据库的锁（行锁，表锁，页级锁，意向锁，读锁，写锁，悲观锁，乐观锁，以及加锁的select sql方式） 隔离级别，依次解决的问题（脏读、不可重复读、幻读） 事务的ACID B树、B+树 优化（explain，慢查询，show profile） 数据库的范式。 分库分表，主从复制，读写分离。 Nosql相关（redis和mem***d区别之类的，如果你熟悉redis，redis还有一堆要问的） 编译原理 Java Java基础 把我之后的面经过一遍，Java感觉覆盖的就差不多了，不过下面还是分个类。 Java基础（面向对象、四个特性、重载重写、static和final等等很多东西） 集合（HashMap、ConcurrentHashMap、各种List，最好结合源码看） 并发和多线程（线程池、SYNC和Lock锁机制、线程通信、volatile、ThreadLocal、CyclicBarrier、Atom包、CountDownLatch、AQS、CAS原理等等） JVM（内存模型、GC垃圾回收，包括分代，GC算法，收集器、类加载和双亲委派、JVM调优，内存泄漏和内存溢出） IO/NIO相关 反射和***、异常、Java8相关、序列化 设计模式（常用的，jdk中有的） Web相关（servlet、cookie/session、Spring&amp;lt;AOP、IOC、MVC、事务、动态***&amp;gt;、Mybatis、Tomcat、Hibernate等） 并发编程 JVM 性能优化 性能指标体系 JVM调优 Tomcat调优 MySQL调优 故障排除 最佳实践 重构 设计模式 开发框架 Spring体系 MyBatis 常见业务 支付幂等性 减库存 秒杀 分布式锁 redis实现的分布式锁。 应该保证互斥性（在任何时候只有一个客户端持有锁。使用setnx）。 不能死锁（设置过期时间）。 保证上锁和解锁是同一个客户端（设置不同的value值）。 业务时间太长。导致锁过期（设置看门狗。自动续锁）。 锁的重入性（使用redis的hset）。 分布式事务 分布式缓存 中间价 消息队列 缓存 本地缓存 分布式缓存 ELK 数据库 分库分表 数据同步 数据库连接池 分布式 CAP原理和BASE理论。 Nosql与KV存储（redis，hbase，mongodb，mem***d等） 服务化理论（包括服务发现、治理等，zookeeper、etcd、springcloud微服务、） 负载均衡（原理、cdn、一致性hash） RPC框架（包括整体的一些框架理论，通信的netty，序列化协议thrift，protobuff等） 消息队列（原理、kafka，activeMQ，rocketMQ） 分布式存储系统（GFS、HDFS、fastDFS）、存储模型（skipList、LSM等） 分布式事务、分布式锁等 四大理论 拜占庭将军问题 CAP 理论 ACID 理论 BASE 理论 八大协议/算法 Paxos 算法 Raft 算法 一致性 Hash 算法 Gossip 协议算法 Quorum NWR 算法 FBFT 算法 POW 算法 ZAB 协议 大数据与数据分析： hadoop生态圈(hive、hbase、hdfs、zookeeper、storm、kafka) spark体系 语言：python、R、scala 搜索引擎与技术 工具 版本管理 Git 项目管理 Maven/Gradle 代码质量管理 Sonar 持续集成部署 Jenkins&amp;amp;GitLab CI/CD 监控系统 测试 Postman Jmeter VisualVM </description>
    </item>
    <item>
      <title>SpringBoot总结</title>
      <link>https://moge.fun/springboot/</link>
      <pubDate>Wed, 03 Apr 2019 00:00:00 +0000</pubDate>
      <guid>https://moge.fun/springboot/</guid>
      <description>使用了特定的方式来进行配置，从而使开发人员不再需要定义样板化的配置，简化Spring应用的初始搭建以及开发过程。简单理解，就是SpringBoot其实不是什么新的框架，它默认配置了很多框架的使用方式，就像Maven整合了所有的Jar包，Spring Boot整合了所有的框架。
SpringBoot 的启动过程 开始源码分析，先从 SpringBoot 的启动类的 run() 方法开始看，以下是调用链：SpringApplication.run() -&amp;gt; run(new Class[]{primarySource}, args) -&amp;gt; new SpringApplication(primarySources)).run(args)。
一直在run，终于到重点了，我们直接看 new SpringApplication(primarySources)).run(args) 这个方法。
1 2 3 public static ConfigurableApplicationContext run(Class&amp;lt;?&amp;gt;[] primarySources,	String[] args) { return new SpringApplication(primarySources).run(args); } 上面的方法主要包括两大步骤：
创建 SpringApplication 对象。 运行 run() 方法。 创建 SpringApplication 对象 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 public SpringApplication(ResourceLoader resourceLoader, Class.</description>
    </item>
    <item>
      <title>SpringMVC总结</title>
      <link>https://moge.fun/springmvc/</link>
      <pubDate>Tue, 02 Apr 2019 00:00:00 +0000</pubDate>
      <guid>https://moge.fun/springmvc/</guid>
      <description>SpringMVC 执行流程 用户请求发送到前端控制器DispatcherServlet。 前端控制器DispatcherServlet接收到请求后，DispatcherServlet会使用HandlerMapping来处理，HandlerMapping会查找到具体进行处理请求的Handler对象。 HandlerMapping找到对应的Handler之后，并不是返回一个Handler原始对象，而是一个Handler执行链，在这个执行链中包括了拦截器和处理请求的Handler。HandlerMapping返回一个执行链给DispatcherServlet。 DispatcherServlet接收到执行链之后，会调用Handler适配器去执行Handler。 Handler适配器执行完成Handler（也就是我们写的Controller）之后会得到一个ModelAndView，并返回给DispatcherServlet。 DispatcherServlet接收到Handler适配器返回的ModelAndView之后，会根据其中的视图名调用视图解析器。 视图解析器根据逻辑视图名解析成一个真正的View视图，并返回给DispatcherServlet。 DispatcherServlet接收到视图之后，会根据上面的ModelAndView中的model来进行视图中数据的填充，也就是所谓的视图渲染。 渲染完成之后，DispatcherServlet就可以将结果返回给用户了。 </description>
    </item>
    <item>
      <title>Spring总结</title>
      <link>https://moge.fun/spring/</link>
      <pubDate>Mon, 01 Apr 2019 00:00:00 +0000</pubDate>
      <guid>https://moge.fun/spring/</guid>
      <description>Spring 是一种轻量级开发框架，旨在提高开发人员的开发效率以及系统的可维护性。
我们一般说 Spring 框架指的都是 Spring Framework，它是很多模块的集合，使用这些模块可以很方便地协助我们进行开发。这些模块是：核心容器、数据访问/集成、Web、AOP（面向切面编程）、工具、消息和测试模块。比如：Core Container 中的 Core 组件是Spring 所有组件的核心，Beans 组件和 Context 组件是实现IOC和依赖注入的基础，AOP组件用来实现面向切面编程。
Spring 官网列出的 Spring 的 6 个特征:
核心技术 ：依赖注入(DI)，AOP，事件(events)，资源，i18n，验证，数据绑定，类型转换，SpEL。 测试 ：模拟对象，TestContext框架，Spring MVC 测试，WebTestClient。 数据访问 ：事务，DAO支持，JDBC，ORM，编组XML。 Web支持 : Spring MVC和Spring WebFlux Web框架。 集成 ：远程处理，JMS，JCA，JMX，电子邮件，任务，调度，缓存。 语言 ：Kotlin，Groovy，动态语言。 IOC IOC容器初始化过程 BeanFactory和ApplicationContext是Spring中两种很重要的容器，前者提供了最基本的依赖注入的支持，后者在继承前者的基础上进行了功能的拓展，增加了事件传播，资源访问，国际化的支持等功能。同时两者的生命周期也稍微有些不同。
Spring IOC容器初始化过程分为Resource定位，载入解析，注册。IOC容器初始化过程中不包含Bean的依赖注入。Bean的依赖注入一般会发生在第一次通过getBean向容器索取Bean的时候。
关键步骤 IOC容器初始化入口是在构造方法中调用refresh开始的。 通过ResourceLoader来完成资源文件位置的定位，DefaultResourceLoader是默认的实现，同时上下文本身就给除了ResourceLoader的实现。 创建的IOC容器是DefaultListableBeanFactory。 IOC对Bean的管理和依赖注入功能的实现是通过对其持有的BeanDefinition进行相关操作来完成的。 通过BeanDefinitionReader来完成定义信息的解析和Bean信息的注册。 XmlBeanDefinitionReader是BeanDefinitionReader的实现了，通过它来解析xml配置中的bean定义。 实际的处理过程是委托给BeanDefinitionParserDelegate来完成的。得到Bean的定义信息，这些信息在Spring中使用BeanDefinition对象来表示。 BeanDefinition的注册是由BeanDefinitionRegistry实现的registerBeanDefiition方法进行的。内部使用ConcurrentHashMap来保存BeanDefiition。 Spring解决循环依赖的过程总结 Spring在初始化Bean的时候，会先初始化当前Bean所依赖的Bean，如果两个Bean互相依赖，就产生了循环依赖，Spring针对循环依赖的办法是：提前曝光加上三个缓存singletonObjects、earlySingletonObjects、singletonFactories。
假设当前Bean是A，A依赖的Bean是B，B又依赖A。
提前曝光的意思就是，当前Bean A实例化完，还没有初始化完就先把当前Bean曝光出去，在B初始化需要依赖A的时候，就先拿到提前曝光的A，这样就可以继续将B初始化完成，然后返回A继续进行初始化。
循环依赖解决只针对单例Bean。
总结 Spring启动。 加载配置文件，xml、JavaConfig、注解、其他形式等等，将描述我们自己定义的和Spring内置的定义的Bean加载进来。 加载完配置文件后将配置文件转化成统一的Resource来处理。 使用Resource解析将我们定义的一些配置都转化成Spring内部的标识形式：BeanDefinition。 在低级的容器BeanFactory中，到这里就可以宣告Spring容器初始化完成了，Bean的初始化是在我们使用Bean的时候触发的；在高级的容器ApplicationContext中，会自动触发那些1. lazy-init=false的单例Bean，让Bean以及依赖的Bean进行初始化的流程，初始化完成Bean之后高级容器也初始化完成了。 在我们的应用中使用Bean。 Spring容器关闭，销毁各个Bean。 SpringBean生命周期 手动或者自动的触发获取一个Bean，使用BeanFactory的时候需要我们代码自己获取Bean，ApplicationContext则是在IOC启动的时候自动初始化一个Bean。 IOC会根据BeanDefinition来实例化这个Bean，如果这个Bean还有依赖其他的Bean则会先初始化依赖的Bean，这里又涉及到了循环依赖的解决。实例化Bean的时候根据工厂方法、构造方法或者简单初始化等选择具体的实例来进行实例化，最终都是使用反射进行实例化。 Bean实例化完成，也就是一个对象实例化完成后，会继续填充这个Bean的各个属性，也是使用反射机制将属性设置到Bean中去。 填充完属性后，会调用各种Aware方法，将需要的组件设置到当前Bean中。BeanFactory这种低级容器需要我们手动注册Aware接口，而ApplicationContext这种高级容器在IOC启动的时候就自动给我们注册了Aware等接口。 接下来如果Bean实现了PostProcessor一系列的接口，会先调用其中的postProcessBeforeInitialization方法。BeanFactory这种低级容器需要我们手动注册PostProcessor接口，而ApplicationContext这种高级容器在IOC启动的时候就自动给我们注册了PostProcessor等接口。 如果Bean实现了InitializingBean接口，则会调用对应的afterPropertiesSet方法。 如果Bean设置了init-method属性，则会调用init-method指定的方法。 接下来如果Bean实现了PostProcessor一系列的接口，会先调用其中的postProcessAfterInitialization方法。BeanFactory这种低级容器需要我们手动注册PostProcessor接口，而 ApplicationContext这种高级容器在IOC启动的时候就自动给我们注册了PostProcessor等接口。 到这里Bean就可以使用了。 容器关闭的时候需要销毁Bean。 如果Bean实现了DisposableBean，则调用destroy方法。 如果Bean配置了destroy-method属性，则调用指定的destroy-method方法。 AOP Spring AOP流程大致上可以分为三个阶段：标签解析和AutoProxyCreator的注册、AOP代理的创建、代理的使用。</description>
    </item>
    <item>
      <title> MyBatis总结</title>
      <link>https://moge.fun/mybatis/</link>
      <pubDate>Sun, 03 Mar 2019 00:00:00 +0000</pubDate>
      <guid>https://moge.fun/mybatis/</guid>
      <description>
接口层-和数据库交互的方式 MyBatis和数据库的交互有两种方式：
使用传统的MyBatis提供的API； 使用Mapper接口； 参考文章 常见问题 </description>
    </item>
    <item>
      <title>Redis概览</title>
      <link>https://moge.fun/redis/</link>
      <pubDate>Sat, 02 Mar 2019 00:00:00 +0000</pubDate>
      <guid>https://moge.fun/redis/</guid>
      <description>Redis是一款内存高速缓存数据库。Redis全称为：Remote Dictionary Server（远程数据服务. ，Redis是一种支持key-value等多种数据结构的存储系统。可用于缓存，事件发布或订阅，高速队列等场景。支持网络，提供字符串，哈希，列表，队列，集合结构直接存取，基于内存，可持久化。
单线程的redis为什么这么快 纯内存操作 单线程操作，避免了频繁的上下文切换 采用了非阻塞I/O多路复用机制 基础数据类型 Redis所有的key（键. 都是字符串。我们在谈基础数据结构时，讨论的是存储值的数据类型，主要包括常见的5种数据类型，分别是：String、List、Set、Zset、Hash
结构类型 结构存储的值 结构的读写能力 String字符串 可以是字符串、整数或浮点数 对整个字符串或字符串的一部分进行操作；对整数或浮点数进行自增或自减操作； List列表 一个链表，链表上的每个节点都包含一个字符串 对链表的两端进行push和pop操作，读取单个或多个元素；根据值查找或删除元素； Set集合 包含字符串的无序集合 字符串的集合，包含基础的方法有看是否存在添加、获取、删除；还包含计算交集、并集、差集等 Hash散列 包含键值对的无序散列表 包含方法有添加、获取、删除单个元素 Zset有序集合 和散列一样，用于存储键值对 字符串成员与浮点数分数之间的有序映射；元素的排列顺序由分数的大小决定；包含方法有添加、获取、删除单个元素以及根据分值范围或成员来获取元素 持久化 为了防止数据丢失以及服务重启时能够恢复数据，Redis支持数据的持久化，主要分为两种方式，分别是RDB和AOF; 当然实际场景下还会使用这两种的混合模式
RDB 持久化 RDB 就是 Redis DataBase 的缩写，中文名为快照/内存快照，RDB持久化是把当前进程数据生成快照保存到磁盘上的过程，由于是某一时刻的快照，那么快照中的值要早于或者等于内存中的值。
触发方式 手动触发 save命令：阻塞当前Redis服务器，直到RDB过程完成为止，对于内存 比较大的实例会造成长时间阻塞，线上环境不建议使用 bgsave命令：Redis进程执行fork操作创建子进程，RDB持久化过程由子进程负责，完成后自动结束。阻塞只发生在fork阶段，一般时间很短 bgsave命令具体流程如下：
redis客户端执行bgsave命令或者自动触发bgsave命令； 主进程判断当前是否已经存在正在执行的子进程，如果存在，那么主进程直接返回； 如果不存在正在执行的子进程，那么就fork一个新的子进程进行持久化数据，fork过程是阻塞的，fork操作完成后主进程即可执行其他操作； 子进程先将数据写入到临时的rdb文件中，待快照数据写入完成后再原子替换旧的rdb文件； 同时发送信号给主进程，通知主进程rdb持久化完成，主进程更新相关的统计信息（info Persitence下的rdb_*相关选项. 。 自动触发 在以下4种情况时会自动触发
redis.conf中配置save m n，即在m秒内有n次修改时，自动触发bgsave生成rdb文件； 主从复制时，从节点要从主节点进行全量复制时也会触发bgsave操作，生成当时的快照发送到从节点； 执行debug reload命令重新加载redis时也会触发bgsave操作； 默认情况下执行shutdown命令时，如果没有开启aof持久化，那么也会触发bgsave操作； RDB优缺点 优点 RDB文件是某个时间节点的快照，默认使用LZF算法进行压缩，压缩后的文件体积远远小于内存大小，适用于备份、全量复制等场景； Redis加载RDB文件恢复数据要远远快于AOF方式； 缺点 RDB方式实时性不够，无法做到秒级的持久化； 每次调用bgsave都需要fork子进程，fork子进程属于重量级操作，频繁执行成本较高； RDB文件是二进制的，没有可读性，AOF文件在了解其结构的情况下可以手动修改或者补全； 版本兼容RDB文件问题； AOF 持久化 Redis是“写后”日志，Redis先执行命令，把数据写入内存，然后才记录日志。日志里记录的是Redis收到的每一条命令，这些命令是以文本形式保存。PS: 大多数的数据库采用的是写前日志（WAL.</description>
    </item>
    <item>
      <title>缓存概览</title>
      <link>https://moge.fun/cache/</link>
      <pubDate>Fri, 01 Mar 2019 00:00:00 +0000</pubDate>
      <guid>https://moge.fun/cache/</guid>
      <description>缓存问题 Redis最常用的一个场景就是作为缓存，在实践中可能会有哪些问题？比如一致性, 穿击, 穿透, 雪崩, 污染等。
缓存穿透 缓存穿透是指缓存和数据库中都没有的数据，而用户不断发起请求。由于缓存是不命中时被动写的，并且出于容错考虑，如果从存储层查不到数据则不写入缓存，这将导致这个不存在的数据每次请求都要到存储层去查询，失去了缓存的意义。
在流量大时，可能DB就挂掉了，要是有人利用不存在的key频繁攻击我们的应用，这就是漏洞。如发起为id为“-1”的数据或id为特别大不存在的数据。这时的用户很可能是攻击者，攻击会导致数据库压力过大。
解决方案：
接口层增加校验，如用户鉴权校验，id做基础校验，id&amp;lt;=0的直接拦截； 从缓存取不到的数据，在数据库中也没有取到，这时也可以将key-value对写为key-null，缓存有效时间可以设置短点，如30秒（设置太长会导致正常情况也没法使用. 。这样可以防止攻击用户反复用同一个id暴力攻击 布隆过滤器。bloomfilter就类似于一个hash set，用于快速判某个元素是否存在于集合中，其典型的应用场景就是快速判断一个key是否存在于某容器，不存在就直接返回。布隆过滤器的关键就在于hash算法和容器大小。 缓存击穿 缓存击穿是指缓存中没有但数据库中有的数据（一般是缓存时间到期)，这时由于并发用户特别多，同时读缓存没读到数据，又同时去数据库去取数据，引起数据库压力瞬间增大，造成过大压力。
解决方案
设置热点数据永远不过期。 接口限流与熔断，降级。重要的接口一定要做好限流策略，防止用户恶意刷接口，同时要降级准备，当接口中的某些服务不可用时候，进行熔断，失败快速返回机制。 加互斥锁. 缓存雪崩 缓存雪崩是指缓存中数据大批量到过期时间，而查询数据量巨大，引起数据库压力过大甚至down机。和缓存击穿不同的是，缓存击穿指并发查同一条数据，缓存雪崩是不同数据都过期了，很多数据都查不到从而查数据库。
解决方案：
缓存数据的过期时间设置随机，防止同一时间大量数据过期现象发生。 如果缓存数据库是分布式部署，将热点数据均匀分布在不同的缓存数据库中。 设置热点数据永远不过期。 缓存污染（或满了) 缓存污染问题说的是缓存中一些只会被访问一次或者几次的的数据，被访问完后，再也不会被访问到，但这部分数据依然留存在缓存中，消耗缓存空间。
缓存污染会随着数据的持续增加而逐渐显露，随着服务的不断运行，缓存中会存在大量的永远不会再次被访问的数据。缓存空间是有限的，如果缓存空间满了，再往缓存里写数据时就会有额外开销，影响Redis性能。这部分额外开销主要是指写的时候判断淘汰策略，根据淘汰策略去选择要淘汰的数据，然后进行删除操作。
缓存淘汰策略 不淘汰 noevictionv4.0后默认的。 对设置了过期时间的数据中进行淘汰 随机：volatile-random ttl：volatile-ttl 越早过期的数据越优先被选择。 lru：volatile-lru LRU算法：LRU 算法的全称是 Least Recently Used，按照最近最少使用的原则来筛选数据。这种模式下会使用 LRU 算法筛选设置了过期时间的键值对。 lfu：volatile-lfu LFU 算法：LFU 缓存策略是在 LRU 策略基础上，为每个数据增加了一个计数器，来统计这个数据的访问次数。当使用 LFU 策略筛选淘汰数据时，首先会根据数据的访问次数进行筛选，把访问次数最低的数据淘汰出缓存。如果两个数据的访问次数相同，LFU 策略再比较这两个数据的访问时效性，把距离上一次访问时间更久的数据淘汰出缓存。 全部数据进行淘汰 随机：allkeys-random lru：allkeys-lru lfu：allkeys-lfu 数据库和缓存一致性 方案：队列 + 重试机制 流程如下所示
更新数据库数据； 缓存因为种种问题删除失败 将需要删除的key发送至消息队列 自己消费消息，获得需要删除的key 继续重试删除操作，直到成功 然而，该方案有一个缺点，对业务线代码造成大量的侵入。于是有了方案二，在方案二中，启动一个订阅程序去订阅数据库的binlog，获得需要操作的数据。在应用程序中，另起一段程序，获得这个订阅程序传来的信息，进行删除缓存操作。
方案：异步更新缓存(基于订阅binlog的同步机制) MySQL binlog增量订阅消费+消息队列+增量数据更新到redis</description>
    </item>
    <item>
      <title>Kafka</title>
      <link>https://moge.fun/mq-kafka/</link>
      <pubDate>Tue, 05 Feb 2019 00:00:00 +0000</pubDate>
      <guid>https://moge.fun/mq-kafka/</guid>
      <description>Kafka 是一个分布式消息引擎与流处理平台，经常用做企业的消息总线、实时数据管道，有的还把它当做存储系统来使用。早期 Kafka 的定位是一个高吞吐的分布式消息系统，目前则演变成了一个成熟的分布式消息引擎，以及流处理平台。
使用消息队列不可能是单机的（必然是分布式or集群）
Kafka天然是分布式的，往一个topic丢数据，实际上就是往多个broker的partition存储数据
数据写到消息队列，可能会存在数据丢失问题，数据在消息队列需要持久化
Kafka会将partition以消息日志的方式(落磁盘)存储起来，通过 顺序访问IO和缓存(等到一定的量或时间)才真正把数据写到磁盘上，来提高速度。
想要保证消息（数据）是有序的，怎么做？
Kafka会将数据写到partition，单个partition的写入是有顺序的。如果要保证全局有序，那只能写入一个partition中。如果要消费也有序，消费者也只能有一个。
Kafka术语 Producer：生产者，消息产生和发送端。 Broker：Kafka 实例，多个 broker 组成一个 Kafka 集群，通常一台机器部署一个 Kafka 实例，一个实例挂了不影响其他实例。 Consumer：消费者，拉取消息进行消费。 一个 topic 可以让若干个消费者进行消费，若干个消费者组成一个 Consumer Group 即消费组，一条消息只能被消费组中一个 Consumer 消费。 Topic：主题，服务端消息的逻辑存储单元。一个 topic 通常包含若干个 Partition 分区。 Partition：topic 的分区，分布式存储在各个 broker 中， 实现发布与订阅的负载均衡。若干个分区可以被若干个 Consumer 同时消费，达到消费者高吞吐量。一个分区拥有多个副本（Replica），这是Kafka在可靠性和可用性方面的设计，后面会重点介绍。 message：消息，或称日志消息，是 Kafka 服务端实际存储的数据，每一条消息都由一个 key、一个 value 以及消息时间戳 timestamp 组成。 offset：偏移量，分区中的消息位置，由 Kafka 自身维护，Consumer 消费时也要保存一份 offset 以维护消费过的消息位置。 Kafka特点 高吞吐、低延时：这是 Kafka 显著的特点，Kafka 能够达到百万级的消息吞吐量，延迟可达毫秒级； 持久化存储：Kafka 的消息最终持久化保存在磁盘之上，提供了顺序读写以保证性能，并且通过 Kafka 的副本机制提高了数据可靠性。 分布式可扩展：Kafka 的数据是分布式存储在不同 broker 节点的，以 topic 组织数据并且按 partition 进行分布式存储，整体的扩展性都非常好。 高容错性：集群中任意一个 broker 节点宕机，Kafka 仍能对外提供服务。 Kafka消息发送机制 异步发送 Kafka 自从 0.</description>
    </item>
    <item>
      <title>ZooKeeper</title>
      <link>https://moge.fun/zookeeper/</link>
      <pubDate>Mon, 04 Feb 2019 00:00:00 +0000</pubDate>
      <guid>https://moge.fun/zookeeper/</guid>
      <description>简介 ZooKeeper主要服务于分布式系统，可以用ZooKeeper来做：统一配置管理、统一命名服务、分布式锁、集群管理。 使用分布式系统就无法避免对节点管理的问题(需要实时感知节点的状态、对节点进行统一管理等等)，而由于这些问题处理起来可能相对麻烦和提高了系统的复杂性，ZooKeeper作为一个能够通用解决这些问题的中间件就应运而生了。 ZooKeeper数据结构 ZooKeeper的数据结构，跟Unix文件系统非常类似，可以看做是一颗树，每个节点叫做ZNode。每一个节点可以通过路径来标识，结构图如下： 那ZooKeeper这颗&amp;quot;树&amp;quot;有什么特点呢？？ZooKeeper的节点我们称之为Znode，Znode分为两种类型：
短暂/临时(Ephemeral)：当客户端和服务端断开连接后，所创建的Znode(节点)会自动删除 持久(Persistent)：当客户端和服务端断开连接后，所创建的Znode(节点)不会删除 监听器 在上面我们已经简单知道了ZooKeeper的数据结构了，ZooKeeper还配合了监听器才能够做那么多事的。 常见的监听场景有以下两项：
监听Znode节点的数据变化 监听子节点的增减变化 通过监听+Znode节点(持久/短暂[临时])，ZooKeeper就可以玩出这么多花样了。
统一配置管理 我们可以将common.yml这份配置放在ZooKeeper的Znode节点中，系统A、B、C监听着这个Znode节点有无变更，如果变更了，及时响应。 统一命名服务 集群管理。 还是以我们三个系统A、B、C为例，在ZooKeeper中创建临时节点即可： 只要系统A挂了，那/groupMember/A这个节点就会删除，通过监听groupMember下的子节点，系统B和C就能够感知到系统A已经挂了。(新增也是同理)
除了能够感知节点的上下线变化，ZooKeeper还可以实现动态选举Master的功能。(如果集群是主从架构模式下)
原理也很简单，如果想要实现动态选举Master的功能，Znode节点的类型是带顺序号的临时节点(EPHEMERAL_SEQUENTIAL)就好了。
Zookeeper会每次选举最小编号的作为Master，如果Master挂了，自然对应的Znode节点就会删除。然后让新的最小编号作为Master，这样就可以实现动态选举的功能了。 分布式锁 参考分布式锁
ZooKeeper 的一些重要概念 ZooKeeper 本身就是一个分布式程序（只要半数以上节点存活，ZooKeeper 就能正常服务）。 为了保证高可用，最好是以集群形态来部署 ZooKeeper，这样只要集群中大部分机器是可用的（能够容忍一定的机器故障），那么 ZooKeeper 本身仍然是可用的。 ZooKeeper 将数据保存在内存中，这也就保证了 高吞吐量和低延迟（但是内存限制了能够存储的容量不太大，此限制也是保持znode中存储的数据量较小的进一步原因）。 ZooKeeper 是高性能的。 在“读”多于“写”的应用程序中尤其地高性能，因为“写”会导致所有的服务器间同步状态。（“读”多于“写”是协调服务的典型场景。） ZooKeeper有临时节点的概念。 当创建临时节点的客户端会话一直保持活动，瞬时节点就一直存在。而当会话终结时，瞬时节点被删除。持久节点是指一旦这个ZNode被创建了，除非主动进行ZN 移除操作，否则这个ZNode将一直保存在Zookeeper上。 ZooKeeper 底层其实只提供了两个功能： 管理（存储、读取）用户程序提交的数据； 为用户程序提交数据节点监听服务。 可构建集群 为了保证高可用，最好是以集群形态来部署 ZooKeeper，这样只要集群中大部分机器是可用的（能够容忍一定的机器故障），那么zookeeper本身仍然是可用的。 客户端在使用 ZooKeeper 时，需要知道集群机器列表，通过与集群中的某一台机器建立 TCP 连接来使用服务，客户端使用这个TCP链接来发送请求、获取结果、获取监听事件以及发送心跳包。如果这个连接异常断开了，客户端可以连接到另外的机器上。
ZooKeeper 官方提供的架构图： 上图中每一个Server代表一个安装Zookeeper服务的服务器。组成 ZooKeeper 服务的服务器都会在内存中维护当前的服务器状态，并且每台服务器之间都互相保持着通信。集群间通过 Zab 协议（Zookeeper Atomic Broadcast）来保持数据的一致性。
ZooKeeper 集群角色介绍 最典型集群模式： Master/Slave 模式（主备模式）。在这种模式中，通常 Master服务器作为主服务器提供写服务，其他的 Slave 服务器从服务器通过异步复制的方式获取 Master 服务器最新的数据提供读服务。</description>
    </item>
    <item>
      <title>RocketMQ</title>
      <link>https://moge.fun/mq-rocket/</link>
      <pubDate>Sun, 03 Feb 2019 00:00:00 +0000</pubDate>
      <guid>https://moge.fun/mq-rocket/</guid>
      <description>特性 支持顺序消息 支持事务 参考链接 RocketMQ 入门教程 </description>
    </item>
    <item>
      <title>RabbitMQ</title>
      <link>https://moge.fun/mq-rabbitmq/</link>
      <pubDate>Sat, 02 Feb 2019 00:00:00 +0000</pubDate>
      <guid>https://moge.fun/mq-rabbitmq/</guid>
      <description>不作为重点
参考链接 </description>
    </item>
    <item>
      <title>消息队列</title>
      <link>https://moge.fun/mq/</link>
      <pubDate>Fri, 01 Feb 2019 00:00:00 +0000</pubDate>
      <guid>https://moge.fun/mq/</guid>
      <description>概述 消息队列（Message Queue，简称 MQ）是构建分布式互联网应用的基础设施，消息队列已经逐渐成为企业IT系统内部通信的核心手段。它具有低耦合、可靠投递、广播、流量控制、最终一致性等一系列功能，成为异步RPC的主要手段之一。
使用场景 业务解耦 解耦是消息队列要解决的最本质问题。所谓解耦，简单点讲就是一个事务，只关心核心的流程。而需要依赖其他系统但不那么重要的事情，有通知即可，无需等待结果。换句话说，基于消息的模型，关心的是“通知”，而非“处理”。 比如在美团旅游，我们有一个产品中心，产品中心上游对接的是主站、移动后台、旅游供应链等各个数据源；下游对接的是筛选系统、API系统等展示系统。当上游的数据发生变更的时候，如果不使用消息系统，势必要调用我们的接口来更新数据，就特别依赖产品中心接口的稳定性和处理能力。但其实，作为旅游的产品中心，也许只有对于旅游自建供应链，产品中心更新成功才是他们关心的事情。而对于团购等外部系统，产品中心更新成功也好、失败也罢，并不是他们的职责所在。他们只需要保证在信息变更的时候通知到我们就好了。 而我们的下游，可能有更新索引、刷新缓存等一系列需求。对于产品中心来说，这也不是我们的职责所在。说白了，如果他们定时来拉取数据，也能保证数据的更新，只是实时性没有那么强。但使用接口方式去更新他们的数据，显然对于产品中心来说太过于“重量级”了，只需要发布一个产品ID变更的通知，由下游系统来处理，可能更为合理。 再举一个例子，对于我们的订单系统，订单最终支付成功之后可能需要给用户发送短信积分什么的，但其实这已经不是我们系统的核心流程了。如果外部系统速度偏慢（比如短信网关速度不好），那么主流程的时间会加长很多，用户肯定不希望点击支付过好几分钟才看到结果。那么我们只需要通知短信系统“我们支付成功了”，不一定非要等待它处理完成。
异步处理 多应用对消息队列中同一消息进行处理，应用间并发处理消息，相比串行处理，减少处理时间；
限流削峰，错峰流控 试想上下游对于事情的处理能力是不同的。比如，Web前端每秒承受上千万的请求，并不是什么神奇的事情，只需要加多一点机器，再搭建一些LVS负载均衡设备和Nginx等即可。但数据库的处理能力却十分有限，即使使用SSD加分库分表，单机的处理能力仍然在万级。由于成本的考虑，我们不能奢求数据库的机器数量追上前端。 这种问题同样存在于系统和系统之间，如短信系统可能由于短板效应，速度卡在网关上（每秒几百次请求），跟前端的并发量不是一个数量级。但用户晚上个半分钟左右收到短信，一般是不会有太大问题的。如果没有消息队列，两个系统之间通过协商、滑动窗口等复杂的方案也不是说不能实现。但系统复杂性指数级增长，势必在上游或者下游做存储，并且要处理定时、拥塞等一系列问题。而且每当有处理能力有差距的时候，都需要单独开发一套逻辑来维护这套逻辑。所以，利用中间系统转储两个系统的通信内容，并在下游系统有能力处理这些消息的时候，再处理这些消息，是一套相对较通用的方式。
总而言之，消息队列不是万能的。对于需要强事务保证而且延迟敏感的，RPC是优于消息队列的。 对于一些无关痛痒，或者对于别人非常重要但是对于自己不是那么关心的事情，可以利用消息队列去做。 支持最终一致性的消息队列，能够用来处理延迟不那么敏感的“分布式事务”场景，而且相对于笨重的分布式事务，可能是更优的处理方式。 当上下游系统处理能力存在差距的时候，利用消息队列做一个通用的“漏斗”。在下游有能力处理的时候，再进行分发。 如果下游有很多系统关心你的系统发出的通知的时候，果断地使用消息队列吧。 广泛应用于秒杀或抢购活动中，避免流量过大导致应用系统挂掉的情况；
最终一致性 最终一致性不是消息队列的必备特性，但确实可以依靠消息队列来做最终一致性的事情。
投递模式 点对点模式（Point-to-Point， Queue） Point-to-Point，点对点通信模型。PTP是基于队列(Queue)的，一个队列可以有多个生产者，和多个消费者。消息服务器按照收到消息的先后顺序，将消息放到队列中。队列中的每一条消息，只能由一个消费者进行消费，消费之后就会从队列中移除。
发布/订阅模式（publish/subscribe，topic） 每个消息可以有多个订阅者； 发布者和订阅者之间有时间上的依赖性。针对某个主题（Topic）的订阅者，它必须创建一个订阅者之后，才能消费发布者的消息。 为了消费消息，订阅者需要提前订阅该角色主题，并保持在线运行； Partition模型 生产者发送消息到某个Topic中时，最终选择其中一个Partition进行发送。你可以将Parition模型中的分区，理解为PTP模型的队列，不同的是，PTP模型中的队列存储的是所有的消息，而每个Partition只会存储部分数据。 对于消息者，此时多了一个消费者组的概念，Paritition会在同一个消费者组下的消费者中进行分配，每个消费者只消费分配给自己的Paritition。上图演示了不同的消费者可能会分配到不同数量的Paritition。 Paritition模式巧妙的将PTP模型和Pub/Sub模型结合在了一起：
Transfer模型 Paritition模型中的消费者组概念很有用，同一个Topic下的消息可以由多个不同业务方进行消费，只要使用不同的消费者组即可，不同消费者组消费到的位置单独记录，互不影响。 但是，Paritition模型还是限制了消费者数量不能多于分区数。
设计一个简单的消息队列 一般来讲，设计消息队列的整体思路是先build一个整体的数据流,例如producer发送给broker,broker发送给consumer,consumer回复消费确认，broker删除/备份消息等。 利用RPC将数据流串起来。然后考虑RPC的高可用性，尽量做到无状态，方便水平扩展。 之后考虑如何承载消息堆积，然后在合适的时机投递消息，而处理堆积的最佳方式，就是存储，存储的选型需要综合考虑性能/可靠性和开发维护成本等诸多因素。 为了实现广播功能，我们必须要维护消费关系，可以利用zk/config server等保存消费关系。 在完成了上述几个功能后，消息队列基本就实现了。然后我们可以考虑一些高级特性，如可靠投递，事务特性，性能优化等。 下面我们会以设计消息队列时重点考虑的模块为主线，穿插灌输一些消息队列的特性实现方法，来具体分析设计实现一个消息队列时的方方面面。
RPC通信协议 刚才讲到，所谓消息队列，无外乎两次RPC加一次转储，当然需要消费端最终做消费确认的情况是三次RPC。既然是RPC，就必然牵扯出一系列话题，什么负载均衡啊、服务发现啊、通信协议啊、序列化协议啊，等等。在这一块，我的强烈建议是不要重复造轮子。利用公司现有的RPC框架：Thrift也好，Dubbo也好，或者是其他自定义的框架也好。因为消息队列的RPC，和普通的RPC没有本质区别。当然了，自主利用Memchached或者Redis协议重新写一套RPC框架并非不可（如MetaQ使用了自己封装的Gecko NIO框架，卡夫卡也用了类似的协议）。但实现成本和难度无疑倍增。排除对效率的极端要求，都可以使用现成的RPC框架。 简单来讲，服务端提供两个RPC服务，一个用来接收消息，一个用来确认消息收到。并且做到不管哪个server收到消息和确认消息，结果一致即可。当然这中间可能还涉及跨IDC的服务的问题。这里和RPC的原则是一致的，尽量优先选择本机房投递。你可能会问，如果producer和consumer本身就在两个机房了，怎么办？首先，broker必须保证感知的到所有consumer的存在。其次，producer尽量选择就近的机房就好了。
高可用 其实所有的高可用，是依赖于RPC和存储的高可用来做的。先来看RPC的高可用，美团的基于MTThrift的RPC框架，阿里的Dubbo等，其本身就具有服务自动发现，负载均衡等功能。而消息队列的高可用，只要保证broker接受消息和确认消息的接口是幂等的，并且consumer的几台机器处理消息是幂等的，这样就把消息队列的可用性，转交给RPC框架来处理了。 那么怎么保证幂等呢？最简单的方式莫过于共享存储。broker多机器共享一个DB或者一个分布式文件/kv系统，则处理消息自然是幂等的。就算有单点故障，其他节点可以立刻顶上。另外failover可以依赖定时任务的补偿，这是消息队列本身天然就可以支持的功能。存储系统本身的可用性我们不需要操太多心，放心大胆的交给DBA们吧！ 对于不共享存储的队列，如Kafka使用分区加主备模式，就略微麻烦一些。需要保证每一个分区内的高可用性，也就是每一个分区至少要有一个主备且需要做数据的同步，关于这块HA的细节，可以参考下篇pull模型消息系统设计。
服务端承载消息堆积的能力 消息到达服务端如果不经过任何处理就到接收者了，broker就失去了它的意义。为了满足我们错峰/流控/最终可达等一系列需求，把消息存储下来，然后选择时机投递就显得是顺理成章的了。 只是这个存储可以做成很多方式。比如存储在内存里，存储在分布式KV里，存储在磁盘里，存储在数据库里等等。但归结起来，主要有持久化和非持久化两种。 持久化的形式能更大程度地保证消息的可靠性（如断电等不可抗外力），并且理论上能承载更大限度的消息堆积（外存的空间远大于内存）。 但并不是每种消息都需要持久化存储。很多消息对于投递性能的要求大于可靠性的要求，且数量极大（如日志）。这时候，消息不落地直接暂存内存，尝试几次failover，最终投递出去也未尝不可。 市面上的消息队列普遍两种形式都支持。当然具体的场景还要具体结合公司的业务来看。
存储子系统的选择 我们来看看如果需要数据落地的情况下各种存储子系统的选择。理论上，从速度来看，文件系统&amp;gt;分布式KV（持久化）&amp;gt;分布式文件系统&amp;gt;数据库，而可靠性却截然相反。还是要从支持的业务场景出发作出最合理的选择，如果你们的消息队列是用来支持支付/交易等对可靠性要求非常高，但对性能和量的要求没有这么高，而且没有时间精力专门做文件存储系统的研究，DB是最好的选择。 但是DB受制于IOPS，如果要求单broker 5位数以上的QPS性能，基于文件的存储是比较好的解决方案。整体上可以采用数据文件+索引文件的方式处理，具体这块的设计比较复杂，可以参考下篇的存储子系统设计。 分布式KV（如MongoDB，HBase）等，或者持久化的Redis，由于其编程接口较友好，性能也比较可观，如果在可靠性要求不是那么高的场景，也不失为一个不错的选择。
消费关系解析 现在我们的消息队列初步具备了转储消息的能力。下面一个重要的事情就是解析发送接收关系，进行正确的消息投递了。 市面上的消息队列定义了一堆让人晕头转向的名词，如JMS 规范中的Topic/Queue，Kafka里面的Topic/Partition/ConsumerGroup，RabbitMQ里面的Exchange等等。抛开现象看本质，无外乎是单播与广播的区别。所谓单播，就是点到点；而广播，是一点对多点。当然，对于互联网的大部分应用来说，组间广播、组内单播是最常见的情形。 消息需要通知到多个业务集群，而一个业务集群内有很多台机器，只要一台机器消费这个消息就可以了。 当然这不是绝对的，很多时候组内的广播也是有适用场景的，如本地缓存的更新等等。另外，消费关系除了组内组间，可能会有多级树状关系。这种情况太过于复杂，一般不列入考虑范围。所以，一般比较通用的设计是支持组间广播，不同的组注册不同的订阅。组内的不同机器，如果注册一个相同的ID，则单播；如果注册不同的ID(如IP地址+端口)，则广播。 至于广播关系的维护，一般由于消息队列本身都是集群，所以都维护在公共存储上，如config server、zookeeper等。维护广播关系所要做的事情基本是一致的:</description>
    </item>
    <item>
      <title>JVM详解</title>
      <link>https://moge.fun/jvm/</link>
      <pubDate>Tue, 01 May 2018 00:00:00 +0000</pubDate>
      <guid>https://moge.fun/jvm/</guid>
      <description>路线图 ➢ JVM基本常识 → 类加载系统 → 运行时数据区 → 一个对象的一生 → GC收集器 →实战
Class文件的结构属性 Java类加载机制 类的生命周期 类加载器 启动类加载器: Bootstrap ClassLoader，负责加载存放在JDK\jre\lib(JDK代表JDK的安装目录，下同)下，或被-Xbootclasspath参数指定的路径中的，并且能被虚拟机识别的类库(如rt.jar，所有的java.*开头的类均被Bootstrap ClassLoader加载)。启动类加载器是无法被Java程序直接引用的。 扩展类加载器: Extension ClassLoader，该加载器由sun.misc.Launcher$ExtClassLoader实现，它负责加载JDK\jre\lib\ext目录中，或者由java.ext.dirs系统变量指定的路径中的所有类库(如javax.*开头的类)，开发者可以直接使用扩展类加载器。 应用程序类加载器: Application ClassLoader，该类加载器由sun.misc.Launcher$AppClassLoader来实现，它负责加载用户类路径(ClassPath)所指定的类，开发者可以直接使用该类加载器，如果应用程序中没有自定义过自己的类加载器，一般情况下这个就是程序中默认的类加载器。 JVM类加载机制 全盘负责，当一个类加载器负责加载某个Class时，该Class所依赖的和引用的其他Class也将由该类加载器负责载入，除非显示使用另外一个类加载器来载入 父类委托，先让父类加载器试图加载该类，只有在父类加载器无法加载该类时才尝试从自己的类路径中加载该类 缓存机制，缓存机制将会保证所有加载过的Class都会被缓存，当程序中需要使用某个Class时，类加载器先从缓存区寻找该Class，只有缓存区不存在，系统才会读取该类对应的二进制数据，并将其转换成Class对象，存入缓存区。这就是为什么修改了Class后，必须重启JVM，程序的修改才会生效 双亲委派机制, 如果一个类加载器收到了类加载的请求，它首先不会自己去尝试加载这个类，而是把请求委托给父加载器去完成，依次向上，因此，所有的类加载请求最终都应该被传递到顶层的启动类加载器中，只有当父加载器在它的搜索范围中没有找到所需的类时，即无法完成该加载，子加载器才会尝试自己去加载该类。 JVM 内存结构 栈是运行时的单位，而堆是存储的单位。（栈解决程序的运行问题，即程序如何执行，或者说如何处理数据。堆解决的是数据存储的问题，即数据怎么放、放在哪。） Java虚拟机栈用于管理Java方法的调用，而本地方法栈用于管理本地方法的调用。 程序计数器 它是一块很小的内存空间，几乎可以忽略不计。也是运行速度最快的存储区域 在 JVM 规范中，每个线程都有它自己的程序计数器，是线程私有的，生命周期与线程的生命周期一致 任何时间一个线程都只有一个方法在执行，也就是所谓的当前方法。如果当前线程正在执行的是 Java 方法，程序计数器记录的是 JVM 字节码指令地址，如果是执行 native 方法，则是未指定值（undefined） 它是程序控制流的指示器，分支、循环、跳转、异常处理、线程恢复等基础功能都需要依赖这个计数器来完成 字节码解释器工作时就是通过改变这个计数器的值来选取下一条需要执行的字节码指令 它是唯一一个在 JVM 规范中没有规定任何 OutOfMemoryError 情况的区域 虚拟机栈 是线程私有的，生命周期和线程一致。 主管 Java 程序的运行，它保存方法的局部变量、部分结果，并参与方法的调用和返回。 栈是一种快速有效的分配存储方式，访问速度仅次于程序计数器。 JVM 直接对虚拟机栈的操作只有两个：每个方法执行，伴随着入栈（进栈/压栈），方法执行结束出栈。 栈不存在垃圾回收问题。 本地方法栈 Java 虚拟机栈用于管理 Java 方法的调用，而本地方法栈用于管理本地方法的调用 本地方法栈也是线程私有的 允许线程固定或者可动态扩展的内存大小 如果线程请求分配的栈容量超过本地方法栈允许的最大容量，Java 虚拟机将会抛出一个 StackOverflowError 异常 如果本地方法栈可以动态扩展，并且在尝试扩展的时候无法申请到足够的内存，或者在创建新的线程时没有足够的内存去创建对应的本地方法栈，那么 Java虚拟机将会抛出一个OutofMemoryError异常 本地方法是使用 C 语言实现的 它的具体做法是 Native Method Stack 中登记 native 方法，在 Execution Engine 执行时加载本地方法库当某个线程调用一个本地方法时，它就进入了一个全新的并且不再受虚拟机限制的世界。它和虚拟机拥有同样的权限。 本地方法可以通过本地方法接口来访问虚拟机内部的运行时数据区，它甚至可以直接使用本地处理器中的寄存器，直接从本地内存的堆中分配任意数量的内存 并不是所有 JVM 都支持本地方法。因为 Java 虚拟机规范并没有明确要求本地方法栈的使用语言、具体实现方式、数据结构等。 如果 JVM 产品不打算支持 native 方法，也可以无需实现本地方法栈 在 Hotspot JVM 中，直接将本地方法栈和虚拟机栈合二为一 堆内存 为了进行高效的垃圾回收，虚拟机把堆内存逻辑上划分成三块区域（分代的唯一理由就是优化 GC 性能）：</description>
    </item>
    <item>
      <title>ConcurrentHashMap详解</title>
      <link>https://moge.fun/concurrenthashmap/</link>
      <pubDate>Tue, 10 Apr 2018 00:00:00 +0000</pubDate>
      <guid>https://moge.fun/concurrenthashmap/</guid>
      <description>ConcurrentHashMap详解</description>
    </item>
    <item>
      <title>AbstractQueuedSynchronizer详解</title>
      <link>https://moge.fun/abstractqueuedsynchronizer/</link>
      <pubDate>Thu, 05 Apr 2018 00:00:00 +0000</pubDate>
      <guid>https://moge.fun/abstractqueuedsynchronizer/</guid>
      <description>上图中有颜色的为Method，无颜色的为Attribution。 总的来说，AQS框架共分为五层，自上而下由浅入深，从AQS对外暴露的API到底层基础数据。 当有自定义同步器接入时，只需重写第一层所需要的部分方法即可，不需要关注底层具体的实现流程。当自定义同步器进行加锁或者解锁操作时，先经过第一层的API进入AQS内部方法，然后经过第二层进行锁的获取，接着对于获取锁失败的流程，进入第三层和第四层的等待队列处理，而这些处理方式均依赖于第五层的基础数据提供层。 原理概览 AQS核心思想是，如果被请求的共享资源空闲，那么就将当前请求资源的线程设置为有效的工作线程，将共享资源设置为锁定状态；如果共享资源被占用，就需要一定的阻塞等待唤醒机制来保证锁分配。这个机制主要用的是CLH队列的变体实现的，将暂时获取不到锁的线程加入到队列中。
CLH(Craig,Landin,and Hagersten)队列是一个虚拟的双向队列(虚拟的双向队列即不存在队列实例，仅存在结点之间的关联关系)。AQS是将每条请求共享资源的线程封装成一个CLH锁队列的一个结点(Node)来实现锁的分配。
AQS使用一个Volatile的int类型的成员变量来表示同步状态，通过内置的FIFO队列来完成资源获取的排队工作，通过CAS完成对State值的修改。
1 private volatile int state;//共享变量，使用volatile修饰保证线程可见性 AQS数据结构 线程两种资源共享方式 Share(共享)：多个线程可同时执行，如Semaphore/CountDownLatch。Semaphore、CountDownLatCh、 CyclicBarrier、ReadWriteLock。 Exclusive(独占)：只有一个线程能执行，如ReentrantLock。又可分为公平锁和非公平锁： 公平锁：按照线程在队列中的排队顺序，先到者先拿到锁 非公平锁：当线程要获取锁时，无视队列顺序直接去抢锁，谁抢到就是谁的 ReentrantReadWriteLock可以看成是组合式，因为ReentrantReadWriteLock是读写锁允许多个线程同时对某一资源进行读。
不同的自定义同步器争用共享资源的方式也不同。自定义同步器在实现时只需要实现共享资源state的获取与释放方式即可，至于具体线程等待队列的维护(如获取资源失败入队/唤醒出队等)，AQS已经在上层已经帮我们实现好了。
属性值的含义 waitStatus	当前节点在队列中的状态 thread	表示处于该节点的线程 prev	前驱指针 predecessor	返回前驱节点，没有的话抛出npe nextWaiter	指向下一个处于CONDITION状态的节点（由于本篇文章不讲述Condition Queue队列，这个指针不多介绍） next	后继指针 waitStatus（节点状态） 0，表示当前节点在sync queue中，等待着获取锁。 SIGNAL	为-1，表示线程已经准备好了，就等资源释放了,表示当前节点的后继节点包含的线程需要运行，需要进行unpark操作。 CANCELLED	为1，表示线程获取锁的请求已经取消了 CONDITION	为-2，表示当前节点在等待condition，也就是在condition queue中，节点线程等待唤醒 PROPAGATE	为-3，表示当前场景下后续的acquireShared能够得以执行。 AQS重要方法与ReentrantLock的关联 方法 AQS使用了模板方法模式，自定义同步器时需要重写下面几个AQS提供的模板方法
protected boolean isHeldExclusively()	该线程是否正在独占资源。只有用到Condition才需要去实现它。 protected boolean tryAcquire(int arg)	独占方式。arg为获取锁的次数，尝试获取资源，成功则返回True，失败则返回False。 protected boolean tryRelease(int arg)	独占方式。arg为释放锁的次数，尝试释放资源，成功则返回True，失败则返回False。 protected int tryAcquireShared(int arg)	共享方式。arg为获取锁的次数，尝试获取资源。负数表示失败；0表示成功，但没有剩余可用资源；正数表示成功，且有剩余资源。 protected boolean tryReleaseShared(int arg)	共享方式。arg为释放锁的次数，尝试释放资源，如果释放后允许唤醒后续等待结点返回True，否则返回False。 默认情况下，每个方法都抛出 UnsupportedOperationException。 这些方法的实现必须是内部线程安全的，并且通常应该简短而不是阻塞。AQS类中的其他方法都是final ，所以无法被其他类使用，只有这几个方法可以被其他类使用。</description>
    </item>
    <item>
      <title>LockSupport详解</title>
      <link>https://moge.fun/locksupport/</link>
      <pubDate>Wed, 04 Apr 2018 00:00:00 +0000</pubDate>
      <guid>https://moge.fun/locksupport/</guid>
      <description>LockSupport简介 LockSupport用来创建锁和其他同步类的基本线程阻塞原语。简而言之，当调用LockSupport.park时，表示当前线程将会等待，直至获得许可，当调用LockSupport.unpark时，必须把等待获得许可的线程作为参数进行传递，好让此线程继续运行。
核心函数分析 在分析LockSupport函数之前，先引入sun.misc.Unsafe类中的park和unpark函数，因为LockSupport的核心函数都是基于Unsafe类中定义的park和unpark函数，下面给出两个函数的定义:
1 2 public native void park(boolean isAbsolute, long time); public native void unpark(Thread thread); 说明: 对两个函数的说明如下:
park函数，阻塞线程，并且该线程在下列情况发生之前都会被阻塞: ① 调用unpark函数，释放该线程的许可。② 该线程被中断。③ 设置的时间到了。并且，当time为绝对时间时，isAbsolute为true，否则，isAbsolute为false。当time为0时，表示无限等待，直到unpark发生。 unpark函数，释放线程的许可，即激活调用park后阻塞的线程。这个函数不是安全的，调用这个函数时要确保线程依旧存活。 park函数 park函数有两个重载版本，方法摘要如下
1 2 public static void park()； public static void park(Object blocker)； 说明: 两个函数的区别在于park()函数没有没有blocker，即没有设置线程的parkBlocker字段。park(Object)型函数如下。
1 2 3 4 5 6 7 8 9 10 public static void park(Object blocker) { // 获取当前线程 Thread t = Thread.currentThread(); // 设置Blocker setBlocker(t, blocker); // 获取许可 UNSAFE.park(false, 0L); // 重点方法：重新可运行后再此设置Blocker，其他线程执行unpark()后继续 setBlocker(t, null); } 说明: 调用park函数时，首先获取当前线程，然后设置当前线程的parkBlocker字段，即调用setBlocker函数，之后调用Unsafe类的park函数，之后再调用setBlocker函数。</description>
    </item>
    <item>
      <title>synchronized(无锁→偏向锁→轻量级锁→重量级锁)</title>
      <link>https://moge.fun/synchronized/</link>
      <pubDate>Tue, 03 Apr 2018 00:00:00 +0000</pubDate>
      <guid>https://moge.fun/synchronized/</guid>
      <description>synchronized的使用 对象锁 包括方法锁(默认锁对象为this,当前实例对象)和同步代码块锁(自己指定锁对象)
类锁 指synchronize修饰静态的方法或指定锁对象为Class对象
注意点 一把锁只能同时被一个线程获取，没有获得锁的线程只能等待。 每个实例都对应有自己的一把锁(this),不同实例之间互不影响；例外：当锁对象是*.class以及synchronized修饰的是static方法的时候，所有对象共用同一把锁 。 synchronized修饰的方法，无论方法正常执行完毕还是抛出异常，都会释放锁。 synchronized原理分析 加锁和释放锁的原理 Monitorenter和Monitorexit指令，会让对象在执行，使其锁计数器加1或者减1。每一个对象在同一时间只与一个monitor(锁)相关联，而一个monitor在同一时间只能被一个线程获得，一个对象在尝试获得与这个对象相关联的Monitor锁的所有权的时候，monitorenter指令会发生如下3中情况之一：
monitor计数器为0，意味着目前还没有被获得，那这个线程就会立刻获得然后把锁计数器+1，一旦+1，别的线程再想获取，就需要等待 如果这个monitor已经拿到了这个锁的所有权，又重入了这把锁，那锁计数器就会累加，变成2，并且随着重入的次数，会一直累加 这把锁已经被别的线程获取了，等待锁释放 monitorexit指令：释放对于monitor的所有权，释放过程很简单，就是将monitor的计数器减1，如果减完以后，计数器不是0，则代表刚才是重入进来的，当前线程还继续持有这把锁的所有权，如果计数器变成0，则代表当前线程不再拥有该monitor的所有权，即释放锁。
该图可以看出，任意线程对Object的访问，首先要获得Object的监视器，如果获取失败，该线程就进入同步状态，线程状态变为BLOCKED，当Object的监视器占有者释放后，在同步队列中得线程就会有机会重新获取该监视器。
可重入原理：加锁次数计数器 上面的demo中在执行完同步代码块之后紧接着再会去执行一个静态同步方法，而这个方法锁的对象依然就这个类对象，那么这个正在执行的线程还需要获取该锁吗? 答案是不必的，从上图中就可以看出来，执行静态同步方法的时候就只有一条monitorexit指令，并没有monitorenter获取锁的指令。这就是锁的重入性，即在同一锁程中，线程不需要再次获取同一把锁。
synchronized先天具有重入性。每个对象拥有一个计数器，当线程获取该对象锁后，计数器就会加一，释放锁后就会将计数器减一。
保证可见性的原理：内存模型和happens-before规则 Synchronized的happens-before规则，即监视器锁规则：对同一个监视器的解锁，happens-before于对该监视器的加锁。继续来看代码：
1 2 3 4 5 6 7 8 9 10 11 public class MonitorDemo { private int a = 0; public synchronized void writer() { // 1 a++; // 2 } // 3 public synchronized void reader() { // 4 int i = a; // 5 } // 6 } 该代码的happens-before关系如图所示：</description>
    </item>
    <item>
      <title>JUC-并发编程利器</title>
      <link>https://moge.fun/juc/</link>
      <pubDate>Mon, 02 Apr 2018 00:00:00 +0000</pubDate>
      <guid>https://moge.fun/juc/</guid>
      <description>Lock框架和Tools类 接口Condition Condition为接口类型，它将 Object 监视器方法(wait、notify 和 notifyAll)分解成截然不同的对象，以便通过将这些对象与任意Lock实现组合使用，为每个对象提供多个等待set (wait-set)。其中，Lock替代了synchronized方法和语句的使用，Condition替代了Object监视器方法的使用。可以通过await(),signal()来休眠/唤醒线程。
接口Lock Lock为接口类型，Lock实现提供了比使用synchronized方法和语句可获得的更广泛的锁定操作。此实现允许更灵活的结构，可以具有差别很大的属性，可以支持多个相关的Condition对象。
接口ReadWriteLock ReadWriteLock为接口类型， 维护了一对相关的锁，一个用于只读操作，另一个用于写入操作。只要没有 writer，读取锁可以由多个 reader 线程同时保持。写入锁是独占的。
抽象类AbstractOwnableSynchonizer AbstractOwnableSynchonizer为抽象类，可以由线程以独占方式拥有的同步器。此类为创建锁和相关同步器(伴随着所有权的概念)提供了基础。AbstractOwnableSynchronizer 类本身不管理或使用此信息。但是，子类和工具可以使用适当维护的值帮助控制和监视访问以及提供诊断。
抽象类AbstractQueuedLongSynchronizer(long) AbstractQueuedLongSynchronizer为抽象类，以 long 形式维护同步状态的一个 AbstractQueuedSynchronizer 版本。此类具有的结构、属性和方法与 AbstractQueuedSynchronizer 完全相同，但所有与状态相关的参数和结果都定义为 long 而不是 int。当创建需要 64 位状态的多级别锁和屏障等同步器时，此类很有用。
核心抽象类AbstractQueuedSynchronizer(int) AbstractQueuedSynchronizer为抽象类，其为实现依赖于先进先出 (FIFO) 等待队列的阻塞锁和相关同步器(信号量、事件，等等)提供一个框架。此类的设计目标是成为依靠单个原子int值来表示状态的大多数同步器的一个有用基础。
锁常用类LockSupport LockSupport为常用类，主要作用就是挂起线程，唤醒线程。LockSupport的功能和&amp;quot;Thread中的 Thread.suspend()和Thread.resume()有点类似&amp;quot;，LockSupport中的park() 和 unpark() 的作用分别是阻塞线程和解除阻塞线程。但是park()和unpark()不会遇到“Thread.suspend 和 Thread.resume所可能引发的死锁”问题。
该流程在购物APP上非常常见，当你准备支付时放弃，会有一个支付失效，在支付失效期内可以随时回来支付，过期后需要重新选取支付商品。
这里基于LockSupport中park和unpark控制线程状态，实现的等待通知机制。
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 public class LockAPI04 { public static void main(String[] args) throws Exception { OrderPay orderPay = new OrderPay(&amp;#34;UnPaid&amp;#34;) ; Thread orderThread = new Thread(orderPay) ; orderThread.</description>
    </item>
    <item>
      <title>Java并发编程概览</title>
      <link>https://moge.fun/javacurrent/</link>
      <pubDate>Sun, 01 Apr 2018 00:00:00 +0000</pubDate>
      <guid>https://moge.fun/javacurrent/</guid>
      <description>并发三要素 可见性 CPU缓存引起：CPU增加了缓存，以均衡与内存的速度差异导致。 一个线程对共享变量的修改，另外一个线程能够立刻看到。 原子性 分时复用引起：操作系统增加了进程、线程，以分时复用CPU，进而均衡CPU与I/O设备的速度差异导致。 一个操作或者多个操作 要么全部执行并且执行的过程不会被任何因素打断，要么就都不执行。 1 2 3 4 x = 10; //语句1: 直接将数值10赋值给x，也就是说线程执行这个语句的会直接将数值10写入到工作内存中 y = x; //语句2: 包含2个操作，它先要去读取x的值，再将x的值写入工作内存，虽然读取x的值以及 将x的值写入工作内存 这2个操作都是原子性操作，但是合起来就不是原子性操作了。 x++; //语句3： x++包括3个操作：读取x的值，进行加1操作，写入新的值。 x = x + 1; //语句4： 同语句3 有序性 重排序引起：由于编译程序指令重排序优化指令执行次序，使得缓存能够得到更加合理地利用导致。 程序执行的顺序按照代码的先后顺序执行。 可参考多线程环境下初始化一个对象的过程来理解。点击查看 线程安全的实现方法 互斥同步(阻塞同步) synchronized(JVM实现) Lock&amp;amp;ReentrantLock(JDK实现) 互斥同步最主要的问题就是线程阻塞和唤醒所带来的性能问题，因此这种同步也称为阻塞同步。
互斥同步属于一种悲观的并发策略，总是认为只要不去做正确的同步措施，那就肯定会出现问题。无论共享数据是否真的会出现竞争，它都要进行加锁(这里讨论的是概念模型，实际上虚拟机会优化掉很大一部分不必要的加锁)、用户态核心态转换、维护锁计数器和检查是否有被阻塞的线程需要唤醒等操作。
非阻塞同步 CAS 随着硬件指令集的发展，我们可以使用基于冲突检测的乐观并发策略: 先进行操作，如果没有其它线程争用共享数据，那操作就成功了，否则采取补偿措施(不断地重试，直到成功为止)。
这种乐观的并发策略的许多实现都不需要将线程阻塞，因此这种同步操作称为非阻塞同步。
乐观锁需要操作和冲突检测这两个步骤具备原子性，这里就不能再使用互斥同步来保证了，只能靠硬件来完成。
硬件支持的原子性操作最典型的是: 比较并交换(Compare-and-Swap，CAS)。
CAS指令需要有3个操作数，分别是内存地址V旧的预期值A和新值B。当执行操作时，只有当V的值等于A，才将V的值更新为B。
ABA问题 如果一个变量初次读取的时候是 A 值，它的值被改成了 B，后来又被改回为 A，那 CAS 操作就会误认为它从来没有被改变过。
J.U.C 包提供了一个带有标记的原子引用类 AtomicStampedReference 来解决这个问题，它可以通过控制变量值的版本来保证 CAS 的正确性。
大部分情况下 ABA 问题不会影响程序并发的正确性，如果需要解决 ABA 问题，改用传统的互斥同步可能会比原子类更高效。</description>
    </item>
    <item>
      <title>HashMap详解</title>
      <link>https://moge.fun/hashmap/</link>
      <pubDate>Sat, 03 Mar 2018 00:00:00 +0000</pubDate>
      <guid>https://moge.fun/hashmap/</guid>
      <description>实现步骤 HashMap基于哈希散列表，数组+链表/红黑树实现。 通过key的hashCode()方法计算出hashCode。 通过HashMap类中内部hash()方法将第2步中hashCode带入得出hash值。 通过第3步中hash值和HashMap中数组长度做&amp;amp;(位运算)得出在数组中的位置。 当第4步中位置中没有值则直接放入。 当第4步中位置中有值即产生hash冲突问题，此时通过链表(拉链法)来解决hash冲突问题。 如果第6步中第链表大小超过阈值（TREEIFY_THRESHOLD,8），链表转换为红黑树。 在转换为红黑树时，会判断数组长度大于64才转换，否则继续采用扩容策略而不转换。 关键特性 默认初始容量值为16，负载因子为0.75，当size&amp;gt;=threshold（ threshold等于“容量负载因子”）时，会发生扩容：newsize = oldsize2，size一定为2的n次幂 hash冲突默认采用单链表存储，当单链表节点个数大于8时且数组长度大于64，会转化为红黑树存储， 当红黑树中节点少于6时，则转化为单链表存储。 扩容针对整个Map，每次扩容时，原来数组中的元素依次重新计算存放位置，并重新插入 当Map中元素总数超过Entry数组的75%，触发扩容操作，为了减少链表长度，元素分配更均匀 HashMap在1.7和1.8之间的变化： 1.7中是先扩容后插入新值的，1.8中是先插值再扩容 1.7中采用数组+链表，1.8采用的是数组+链表/红黑树，即在1.7中链表长度超过一定长度后就改成红黑树存储。 1.7扩容时需要重新计算哈希值和索引位置，1.8并不重新计算哈希值，巧妙地采用和扩容后容量进行&amp;amp;操作来计算新的索引位置。 1.7是采用表头插入法插入链表，1.8采用的是尾部插入法。 在1.7中采用表头插入法，在扩容时会改变链表中元素原本的顺序，以至于在并发场景下导致链表成环的问题；在1.8中采用尾部插入法，在扩容时会保持链表元素原本的顺序，就不会出现链表成环的问题了。 方法（JDK1.8-数组+链表/红黑树） 确定哈希桶数组索引位置 第1步计算hash
在JDK1.8的实现中，优化了高位运算的算法，通过hashCode()的高16位异或低16位实现的：(h = k.hashCode()) ^ (h &amp;raquo;&amp;gt; 16)，主要是从速度、功效、质量来考虑的。 目的都是在数组很小也能降低hash碰撞。
1 2 3 4 5 6 7 static final int hash(Object key) { int h; // key.hashCode()：返回散列值也就是hashcode // ^ ：按位异或 // &amp;gt;&amp;gt;&amp;gt;:无符号右移，忽略符号位，空位都以0补齐 return (key == null) ? 0 : (h = key.hashCode()) ^ (h &amp;gt;&amp;gt;&amp;gt; 16); } 第2步计算数组位置</description>
    </item>
    <item>
      <title>ArrayList详解</title>
      <link>https://moge.fun/arraylist/</link>
      <pubDate>Fri, 02 Mar 2018 00:00:00 +0000</pubDate>
      <guid>https://moge.fun/arraylist/</guid>
      <description>ArrayList 简介 ArrayList 的底层是数组队列，相当于动态数组。与 Java 中的数组相比，它的容量能动态增长。在添加大量元素前，应用程序可以使用ensureCapacity操作来增加 ArrayList 实例的容量。这可以减少递增式再分配的数量。
ArrayList 核心源码解读 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 package java.</description>
    </item>
    <item>
      <title>Java容器概览</title>
      <link>https://moge.fun/javacontainer/</link>
      <pubDate>Thu, 01 Mar 2018 00:00:00 +0000</pubDate>
      <guid>https://moge.fun/javacontainer/</guid>
      <description>概览 容器主要包括Collection和Map 两种，Collection是存储着对象的集合，而Map存储着键值对（两个对象）的映射表。
Collection List 对付顺序的好帮手： 存储的元素是有序的、可重复的。
ArrayList：基于动态数组实现，支持随机访问，适用于频繁的查找工作。 Vector：和ArrayList类似，但它是线程安全的。 LinkedList：基于双向链表实现，只能顺序访问，但是可以快速地在链表中间插入和删除元素。不仅如此，LinkedList还可以用作栈、队列和双向队列。 Arraylist与 LinkedList 区别? 是否保证线程安全： ArrayList和LinkedList都是不同步的，也就是不保证线程安全； 底层数据结构： Arraylist底层使用的是Object数组；LinkedList底层使用的是双向链表数据结构（JDK1.6 之前为循环链表，JDK1.7 取消了循环。） 插入和删除是否受元素位置的影响： ArrayList 采用数组存储，所以插入和删除元素的时间复杂度受元素位置的影响。 比如：执行add(E e)方法的时候， ArrayList 会默认在将指定的元素追加到此列表的末尾，这种情况时间复杂度就是 O(1)。但是如果要在指定位置 i 插入和删除元素的话（add(int index, E element)）时间复杂度就为 O(n-i)。因为在进行上述操作的时候集合中第 i 和第 i 个元素之后的(n-i)个元素都要执行向后位/向前移一位的操作。 LinkedList 采用链表存储，所以对于add(E e)方法的插入，删除元素时间复杂度不受元素位置的影响，近似 O(1)，如果是要在指定位置 i 插入和删除元素的话（(add(int index, E element)） 时间复杂度近似为 O(n) ，因为需要先移动到指定位置再插入。 是否支持快速随机访问： LinkedList 不支持高效的随机元素访问，而 ArrayList 支持。快速随机访问就是通过元素的序号快速获取元素对象(对应于get(int index)方法)。 内存空间占用： ArrayList的空间浪费主要体现在在list列表的结尾会预留一定的容量空间，而 LinkedList 的空间花费则体现在它的每一个元素都需要消耗比 ArrayList 更多的空间（因为要存放直接后继和直接前驱以及数据）。 Set 注重独一无二的性质: 存储的元素是无序的、不可重复的。
HashSet：基于哈希表实现，支持快速查找，但不支持有序性操作。基于 HashMap 实现的，底层采用 HashMap 来保存元素。 LinkedHashSet：具有 HashSet 的查找效率，并且内部使用双向链表维护元素的插入顺序。LinkedHashSet 是 HashSet 的子类，并且其内部是通过 LinkedHashMap 来实现的。 TreeSet：基于红黑树实现（(自平衡的排序二叉树)），支持有序性操作，例如根据一个范围查找元素的操作。查找效率不如HashSet，HashSet 查找的时间复杂度为 O(1)，TreeSet 则为 O(logN)。 HashSet 如何检查重复 当你把对象加入HashSet时，HashSet 会先计算对象的hashcode值来判断对象加入的位置，同时也会与其他加入的对象的 hashcode 值作比较，如果没有相符的 hashcode，HashSet 会假设对象没有重复出现。但是如果发现有相同 hashcode 值的对象，这时会调用equals()方法来检查 hashcode 相等的对象是否真的相同。如果两者相同，HashSet 就不会让加入操作成功。</description>
    </item>
    <item>
      <title>Java IO知识体系详解 </title>
      <link>https://moge.fun/javaio/</link>
      <pubDate>Mon, 05 Feb 2018 00:00:00 +0000</pubDate>
      <guid>https://moge.fun/javaio/</guid>
      <description>IO装饰者模式 以 InputStream 为例
InputStream 是抽象组件； FileInputStream 是 InputStream 的子类，属于具体组件，提供了字节流的输入操作； FilterInputStream 属于抽象装饰者，装饰者用于装饰组件，为组件提供额外的功能。例如 BufferedInputStream 为 FileInputStream 提供缓存的功能。 实例化一个具有缓存功能的字节流对象时，只需要在 FileInputStream 对象上再套一层 BufferedInputStream 对象即可。
1 2 FileInputStream fileInputStream = new FileInputStream(filePath); BufferedInputStream bufferedInputStream = new BufferedInputStream(fileInputStream); IO常见类的使用 磁盘操作 File 类可以用于表示文件和目录的信息，但是它不表示文件的内容。
1 2 3 4 5 6 7 8 9 10 11 12 13 //递归地列出一个目录下所有文件: public static void listAllFiles(File dir) { if (dir == null || !dir.exists()) { return; } if (dir.isFile()) { System.</description>
    </item>
    <item>
      <title>框架的灵魂-反射</title>
      <link>https://moge.fun/reflection/</link>
      <pubDate>Sat, 03 Feb 2018 00:00:00 +0000</pubDate>
      <guid>https://moge.fun/reflection/</guid>
      <description>什么是反射 简而言之，通过反射，我们可以在运行时获得程序中每一个类型的成员和成员的信息。 程序中一般的对象的类型都是在编译期就确定下来的，而 Java 反射机制可以动态地创建对象并调用其属性，这样的对象的类型在编译期是未知的。 所以我们可以通过反射机制直接创建对象，即使这个对象的类型在编译期是未知的。
反射的核心是 JVM 在运行时才动态加载类或调用方法/访问属性，它不需要事先（写代码的时候或编译期）知道运行对象是谁。
Java 反射主要提供以下功能 在运行时构造任意一个类的对象。 在运行时调用任意一个对象的方法。 在运行时判断任意一个对象所属的类。 在运行时判断任意一个类所具有的成员变量和方法（通过反射甚至可以调用private方法）。 反射的主要用途 反射最重要的用途就是开发各种通用框架。
很多框架（比如 Spring）都是配置化的（比如通过 XML 文件配置 Bean），为了保证框架的通用性，它们可能需要根据配置文件加载不同的对象或类，调用不同的方法，这个时候就必须用到反射，运行时动态加载需要加载的对象。
举一个例子，在运用 Struts 2 框架的开发中我们一般会在 struts.xml 里去配置 Action，比如：
1 2 3 4 &amp;lt;action name=&amp;#34;login&amp;#34; class=&amp;#34;org.ScZyhSoft.test.action.SimpleLoginAction&amp;#34; method=&amp;#34;execute&amp;#34;&amp;gt; &amp;lt;result&amp;gt;/shop/shop-index.jsp&amp;lt;/result&amp;gt; &amp;lt;result name=&amp;#34;error&amp;#34;&amp;gt;login.jsp&amp;lt;/result&amp;gt; &amp;lt;/action&amp;gt; 配置文件与 Action 建立了一种映射关系，当 View 层发出请求时，请求会被 StrutsPrepareAndExecuteFilter 拦截，然后 StrutsPrepareAndExecuteFilter 会去动态地创建 Action 实例。比如我们请求 login.action，那么 StrutsPrepareAndExecuteFilter就会去解析struts.xml文件，检索action中name为login的Action，并根据class属性创建SimpleLoginAction实例，并用invoke方法来调用execute方法，这个过程离不开反射。
对与框架开发人员来说，反射虽小但作用非常大，它是各种容器实现的核心。而对于一般的开发者来说，不深入框架开发则用反射用的就会少一点，不过了解一下框架的底层机制有助于丰富自己的编程思想，也是很有益的。
像Java中的一大利器注解的实现也用到了反射。
为什么你使用 Spring 的时候 ，一个@Component注解就声明了一个类为 Spring Bean 呢？为什么你通过一个 @Value注解就读取到配置文件中的值呢？究竟是怎么起作用的呢？
这些都是因为你可以基于反射分析类，然后获取到类/属性/方法/方法的参数上的注解。你获取到注解之后，就可以做进一步的处理。
反射的基本运用 获得Class对象 使用Class类的forName 静态方法。
1 Class appleClass = Class.</description>
    </item>
    <item>
      <title>Java特性-泛型</title>
      <link>https://moge.fun/generic/</link>
      <pubDate>Fri, 02 Feb 2018 00:00:00 +0000</pubDate>
      <guid>https://moge.fun/generic/</guid>
      <description>泛型，即参数化类型。一提到参数，最熟悉的就是定义方法时有形参，然后调用此方法时传递实参。 那么参数化类型怎么理解呢？顾名思义，就是将类型由原来的具体的类型参数化，类似于方法中的变量参数，此时类型也定义成参数形式（类型形参），然后在使用/调用时传入具体的类型（类型实参）。
Java 语言中引入泛型是一个较大的功能增强。不仅语言、类型系统和编译器有了较大的变化，而且类库也进行了大翻修，所以许多重要的类，比如集合框架，都已经成为泛型化的了。这带来了很多好处：
类型安全。 泛型的主要目标是提高 Java 程序的类型安全。通过知道使用泛型定义的变量的类型限制，编译器可以在一个高得多的程度上验证类型假设。 消除强制类型转换。 泛型的一个附带好处是，消除源代码中的许多强制类型转换。这使得代码更加可读，并且减少了出错机会。 潜在的性能收益。 泛型为较大的优化带来可能。在泛型的初始实现中，编译器将强制类型转换（没有泛型的话，程序员会指定这些强制类型转换）插入生成的字节码中。 注意泛型的类型参数只能是类类型（包括自定义类），不能是简单类型。 常用命名类型参数 K：键，比如映射的键 V：值，比如 List 和 Set 的内容，或者 Map 中的值 E：元素 T：泛型 ?：表示不确定的 java 类型 通配符 Ingeter 是 Number 的一个子类，同时 Generic 与 Generic 实际上是相同的一种基本类型。那么问题来了，在使用 Generic 作为形参的方法中，能否使用Generic 的实例传入呢？在逻辑上类似于 Generic 和 Generic 是否可以看成具有父子关系的泛型类型呢？下面我们通过定义一个方法来验证。
1 2 3 public void show(Generic&amp;lt;Number&amp;gt; obj) { System.out.println(&amp;#34;key value is &amp;#34; + obj.getKey()); } 进行如下的调用：
1 2 3 Generic&amp;lt;Integer&amp;gt; genericInteger = new Generic&amp;lt;Integer&amp;gt;(123); show(genericInteger); //error Generic&amp;lt;java.lang.Integer&amp;gt; cannot be applied to Generic&amp;lt;java.</description>
    </item>
    <item>
      <title>Java世界的入场券-面向对象</title>
      <link>https://moge.fun/objectoriented/</link>
      <pubDate>Thu, 01 Feb 2018 00:00:00 +0000</pubDate>
      <guid>https://moge.fun/objectoriented/</guid>
      <description>面向对象程序设计（英语：Object-oriented programming，缩写：OOP）是种具有对象概念的编程典范，同时也是一种程序开发的抽象方针。它可能包含数据、特性、代码与方法。对象则指的是类（class）的实例。它将对象作为程序的基本单元，将程序和数据封装其中，以提高软件的重用性、灵活性和扩展性，对象里的程序可以访问及经常修改对象相关连的数据。在面向对象程序编程里，计算机程序会被设计成彼此相关的对象。
面向对象就像是一张入场券，掌握了面向对象的思想，就可以在Java世界里尽情遨游，面向对象有三大法宝和七大戒律，并在其指导下萃取出了无数的锦囊妙计和绝世武器，下面我们揭开他们的神秘面纱。
OOP（面向对象编程）的三大法宝 封装 封装，也就是把客观事物封装成抽象的类，并且类可以把自己的属性和方法只让可信的类操作，对不可信的类进行信息隐藏。
继承 继承是指这样一种能力，它可以使用现有的类的所有功能，并在无需重新编写原来类的情况下对这些功能进行扩展。
多态 多态指一个类实例的相同方法在不同情形有不同的表现形式。具体来说就是不同实现类对公共接口有不同的实现方式，但这些操作可以通过相同的方式（公共接口）予以调用。
OOD（面向对象设计）七大戒律 开-闭原则 Open-Close Principle（OCP），即开-闭原则。开，指的是对扩展开放，即要支持方便地扩展；闭，指的是对修改关闭，即要严格限制对已有内容的修改。开-闭原则是最抽象也是最重要的OOD原则。简单工厂模式、工厂方法模式、抽象工厂模式中都提到了如何通过良好的设计遵循开-闭原则。
里氏替换原则 Liskov Substitution Principle（LSP），即里氏替换原则。该原则规定“子类必须能够替换其父类，否则不应当设计为其子类”。换句话说，父类出现的地方，都应该能由其子类代替。所以，子类只能去扩展基类，而不是隐藏或者覆盖基类。
依赖倒置原则 Dependence Inversion Principle（DIP），依赖倒置原则。它讲的是“设计和实现要依赖于抽象而非具体”。一方面抽象化更符合人的思维习惯；另一方面，根据里氏替换原则，可以很容易将原来的抽象替换为扩展后的具体，这样可以很好的支持开-闭原则。
接口隔离原则 Interface Segration Principle（ISP），接口隔离原则，“将大的接口打散成多个小的独立的接口”。由于Java类支持实现多个接口，可以很容易的让类具有多种接口的特征，同时每个类可以选择性地只实现目标接口。
单一职责原则 Single Responsibility Principle（SRP），单一职责原则。它讲的是，不要存在多于一个导致类变更的原因，是高内聚低耦合的一个体现。
迪米特法则/最少知道原则 Law of Demeter or Least Knowledge Principle（LoD or LKP），迪米特法则或最少知道原则。它讲的是“一个对象就尽可能少的去了解其它对象”，从而实现松耦合。如果一个类的职责过多，由于多个职责耦合在了一起，任何一个职责的变更都可能引起其它职责的问题，严重影响了代码的可维护性和可重用性。
合成/聚合复用原则 Composite/Aggregate Reuse Principle（CARP / CRP），合成/聚合复用原则。如果新对象的某些功能在别的已经创建好的对象里面已经实现，那么应当尽量使用别的对象提供的功能，使之成为新对象的一部分，而不要再重新创建。新对象可通过向这些对象的委派达到复用已有功能的效果。简而言之，要尽量使用合成/聚合，而非使用继承。《Java设计模式（九） 桥接模式》中介绍的桥接模式即是对这一原则的典型应用。
行走江湖的锦囊妙计和绝世武器 上面的法宝和戒律是心法，真正行走江湖还需要趁手的兵器和锦囊妙计。 而设计模式就是应用三大法宝和七大戒律下经过反复实践铸造出来锦囊妙计和武器，具体有哪些武器我们暂且不表，毕竟倚天屠龙出世，江湖必将血雨腥风，在这之前我们还需要做好准备工作。</description>
    </item>
    <item>
      <title>Java位运算 </title>
      <link>https://moge.fun/byteopt/</link>
      <pubDate>Wed, 31 Jan 2018 00:00:00 +0000</pubDate>
      <guid>https://moge.fun/byteopt/</guid>
      <description>一切的起源：二进制 位：二进制位，简称“位”。是二进制记数系统中表示小于2的整数的符号，一般用1或 0表示，是具有相等概率的两种状态中的一种。二进制位的位数可表示一个机器字的字长，一个二进制位包含的信息量称为一比特（bit）。
1 2 3 4 5 举个栗子： int占4个字节（byte） 1byte = 8bit 换算下来，一个int类型即占32bit int i = 88; 这里的88为十进制，转换为二进制为：1011000，使用完整的32位表示即为：00000000 00000000 00000000 01011000 上文中的00000000 00000000 00000000 01011000即为十进制88转为二进制的 原码 ，与其相关的定义还有 反码 和 补码
关于原码、反码和补码 在计算机内，有符号数有三种表示法：原码、反码以及补码。
原码：就是二进制定点表示法，即最高位为符号位，“0”正负“1”，其余位表示数值的大小。 反码：正数的反码与其原码相同；负数的反码是对正数逐位取反，符号位保持为1。 补码：正数的补码与其原码相同；负数的补码是在其反码的末位加1。 为什么要使用补码 简单来说，就是计算机计算减法时有各种不方便，于是发明了反码，结果发现反码也有缺陷（有两个零存在：“+0”和“-0”），进而发明了补码解决这个问题。
在计算机系统中，数值一律用补码来表示和存储。原因在于，使用补码，可以将符号位和数值域统一处理；同时，加法和减法也可以统一处理。此外，补码与原码相互转换，其运算过程是相同的，不需要额外的硬件电路。
有关补码的意义及作用在上面的链接里讨论的非常详尽，我这里就不班门弄斧了，理解就好～ 对原码、反码以及补码有一个初步的认知后，我们接下来再看位运算就会清晰很多。
位运算符的基本运算 操作符 描述 例子（A = 8, B = 9） 按位与&amp;amp; 如果相对应位都是1，则结果为1，否则为0 A&amp;amp;B=8，即1000 按位或 | 如果相对应位都是0，则结果为0，否则为1 A B=9，即1001 按位异或^ 如果相对应位值相同，则结果为0，否则为1 A^B=1，即0001 按位取反~ 按位取反运算符翻转操作数的每一位，即0变成1，1变成0 ~A=7，即0111 左移 &amp;laquo; 按位左移运算符。左操作数按位左移右操作数指定的位数 A &amp;laquo; 2 = 32，即1000 00 右移 &amp;raquo; 按位右移运算符。左操作数按位右移右操作数指定的位数 A &amp;raquo; 2 = 2，即0010 </description>
    </item>
    <item>
      <title>数据切分（分库分表）总结</title>
      <link>https://moge.fun/dbsharding/</link>
      <pubDate>Sun, 05 Mar 2017 00:00:00 +0000</pubDate>
      <guid>https://moge.fun/dbsharding/</guid>
      <description>关系型数据库本身比较容易成为系统瓶颈，单机存储容量、连接数、处理能力都有限。当单表的数据量达到1000W或100G以后，由于查询维度较多，即使添加从库、优化索引，做很多操作时性能仍下降严重。此时就要考虑对其进行切分了，切分的目的就在于减少数据库的负担，缩短查询时间。
数据库分布式核心内容无非就是数据切分（Sharding），以及切分后对数据的定位、整合。数据切分就是将数据分散存储到多个数据库中，使得单一数据库中的数据量变小，通过扩充主机的数量缓解单一数据库的性能问题，从而达到提升数据库操作性能的目的。
MySQL分区（可忽略） 一般情况下我们创建的表对应一组存储文件，使用MyISAM存储引擎时是一个.MYI和.MYD文件，使用Innodb存储引擎时是一个.ibd和.frm（表结构）文件。
当数据量较大时（一般千万条记录级别以上），MySQL的性能就会开始下降，这时我们就需要将数据分散到多组存储文件，保证其单个文件的执行效率。
逻辑数据分割 提高单一的写和读应用速度 提高分区范围读查询的速度 分割数据能够有多个不同的物理文件路径 高效的保存历史数据 为什么互联网公司选择自己分库分表来水平扩展 分区表，分区键设计不太灵活，如果不走分区键，很容易出现全表锁 一旦数据并发量上来，如果在分区表实施关联，就是一个灾难 自己分库分表，自己掌控业务场景与访问模式，可控。分区表，研发写了一个sql，都不确定mysql是怎么玩的，不太可控 随着业务的发展，业务越来越复杂，应用的模块越来越多，总的数据量很大，高并发读写操作均超过单个数据库服务器的处理能力怎么办？
这个时候就出现了数据分片，数据分片指按照某个维度将存放在单一数据库中的数据分散地存放至多个数据库或表中。数据分片的有效手段就是对关系型数据库进行分库和分表。
区别于分区的是，分区一般都是放在单机里的，用的比较多的是时间范围分区，方便归档。只不过分库分表需要代码实现，分区则是mysql内部实现。分库分表和分区并不冲突，可以结合使用。
垂直（纵向）切分 垂直切分常见有垂直分库和垂直分表两种。
垂直分库 根据业务耦合性，将关联度低的不同表存储在不同的数据库。做法与大系统拆分为多个小系统类似，按业务分类进行独立划分。与&amp;quot;微服务治理&amp;quot;的做法相似，每个微服务使用单独的一个数据库。如图： 垂直分表 基于数据库中的&amp;quot;列&amp;quot;进行，某个表字段较多，可以新建一张扩展表，将不经常用或字段长度较大的字段拆分出去到扩展表中。在字段很多的情况下（例如一个大表有100多个字段），通过&amp;quot;大表拆小表&amp;quot;，更便于开发与维护，也能避免跨页问题，MySQL底层是通过数据页存储的，一条记录占用空间过大会导致跨页，造成额外的性能开销。另外数据库以行为单位将数据加载到内存中，这样表中字段长度较短且访问频率较高，内存能加载更多的数据，命中率更高，减少了磁盘IO，从而提升了数据库性能。 垂直切分的优点： 解决业务系统层面的耦合，业务清晰 与微服务的治理类似，也能对不同业务的数据进行分级管理、维护、监控、扩展等 高并发场景下，垂直切分能一定程度的提升IO、数据库连接数、单机硬件资源的瓶颈 垂直切分的缺点： 部分表无法join，只能通过接口聚合方式解决，提升了开发的复杂度 分布式事务处理复杂 依然存在单表数据量过大的问题（需要水平切分） 水平（横向）切分 当一个应用难以再细粒度的垂直切分，或切分后数据量行数巨大，存在单库读写、存储性能瓶颈，这时候就需要进行水平切分了。
水平切分分为库内分表和分库分表，是根据表内数据内在的逻辑关系，将同一个表按不同的条件分散到多个数据库或多个表中，每个表中只包含一部分数据，从而使得单个表的数据量变小，达到分布式的效果。如图所示： 库内分表只解决了单一表数据量过大的问题，但没有将表分布到不同机器的库上，因此对于减轻MySQL数据库的压力来说，帮助不是很大，大家还是竞争同一个物理机的CPU、内存、网络IO，最好通过分库分表来解决。
水平切分的优点： 不存在单库数据量过大、高并发的性能瓶颈，提升系统稳定性和负载能力 应用端改造较小，不需要拆分业务模块 水平切分的缺点： 跨分片的事务一致性难以保证 跨库的join关联查询性能较差 数据多次扩展难度和维护量极大 数据分片规则 水平切分后同一张表会出现在多个数据库/表中，每个库/表的内容不同。几种典型的数据分片规则为：
根据数值范围 按照时间区间或ID区间来切分。例如：按日期将不同月甚至是日的数据分散到不同的库中；将userId为1~9999的记录分到第一个库，10000~20000的分到第二个库，以此类推。某种意义上，某些系统中使用的&amp;quot;冷热数据分离&amp;quot;，将一些使用较少的历史数据迁移到其他库中，业务功能上只提供热点数据的查询，也是类似的实践。
优点： 单表大小可控 天然便于水平扩展，后期如果想对整个分片集群扩容时，只需要添加节点即可，无需对其他分片的数据进行迁移 使用分片字段进行范围查找时，连续分片可快速定位分片进行快速查询，有效避免跨分片查询的问题。 缺点： 热点数据成为性能瓶颈。连续分片可能存在数据热点，例如按时间字段分片，有些分片存储最近时间段内的数据，可能会被频繁的读写，而有些分片存储的历史数据，则很少被查询 根据数值取模 一般采用hash取模mod的切分方式，例如：将 Customer 表根据 cusno 字段切分到4个库中，余数为0的放到第一个库，余数为1的放到第二个库，以此类推。这样同一个用户的数据会分散到同一个库中，如果查询条件带有cusno字段，则可明确定位到相应库去查询。
优点： 数据分片相对比较均匀，不容易出现热点和并发访问的瓶颈 缺点： 后期分片集群扩容时，需要迁移旧的数据（使用一致性hash算法能较好的避免这个问题） 容易面临跨分片查询的复杂问题。比如上例中，如果频繁用到的查询条件中不带cusno时，将会导致无法定位数据库，从而需要同时向4个库发起查询，再在内存中合并数据，取最小集返回给应用，分库反而成为拖累。 分库分表带来的问题 事务一致性问题 当更新内容同时分布在不同库中，不可避免会带来跨库事务问题。跨分片事务也是分布式事务，没有简单的方案，一般可使用&amp;quot;XA协议&amp;quot;和&amp;quot;两阶段提交&amp;quot;处理。
分布式事务能最大限度保证了数据库操作的原子性。但在提交事务时需要协调多个节点，推后了提交事务的时间点，延长了事务的执行时间。导致事务在访问共享资源时发生冲突或死锁的概率增高。随着数据库节点的增多，这种趋势会越来越严重，从而成为系统在数据库层面上水平扩展的枷锁。
最终一致性 对于那些性能要求很高，但对一致性要求不高的系统，往往不苛求系统的实时一致性，只要在允许的时间段内达到最终一致性即可，可采用事务补偿的方式。与事务在执行中发生错误后立即回滚的方式不同，事务补偿是一种事后检查补救的措施，一些常见的实现方法有：对数据进行对账检查，基于日志进行对比，定期同标准数据来源进行同步等等。事务补偿还要结合业务系统来考虑。</description>
    </item>
    <item>
      <title>MySQL高可用方案</title>
      <link>https://moge.fun/mysqlhighavailability/</link>
      <pubDate>Sat, 04 Mar 2017 00:00:00 +0000</pubDate>
      <guid>https://moge.fun/mysqlhighavailability/</guid>
      <description>MySQL主从复制架构 基本原理 slave 会从 master 读取 binlog 来进行数据同步
三个步骤 master将改变记录到二进制日志（binary log）。这些记录过程叫做二进制日志事件，binary log events； salve 将 master 的 binary log events 拷贝到它的中继日志（relay log）; slave 重做中继日志中的事件，将改变应用到自己的数据库中。MySQL 复制是异步且是串行化的。 复制的基本原则 每个 slave只有一个 master 每个 salve只能有一个唯一的服务器 ID 每个master可以有多个salve 上图主从复制分了五个步骤进行：
步骤一：主库的更新事件(update、insert、delete)被写到binlog 步骤二：从库发起连接，连接到主库。 步骤三：此时主库创建一个binlog dump thread，把binlog的内容发送到从库。 步骤四：从库启动之后，创建一个I/O线程，读取主库传过来的binlog内容并写入到relay log 步骤五：还会创建一个SQL线程，从relay log里面读取内容，从Exec_Master_Log_Pos位置开始执行读取到的更新事件，将更新内容写入到slave的db 此架构特点 成本低，布署快速、方便 读写分离 还能通过及时增加从库来减少读库压力 主库单点故障 数据一致性问题（同步延迟造成） MySQL+MHA架构 MHA目前在Mysql高可用方案中应该也是比较成熟和常见的方案，它由日本人开发出来，在mysql故障切换过程中，MHA能做到快速自动切换操作，而且还能最大限度保持数据的一致性。
该软件由两部分组成：MHA Manager（管理节点）和MHA Node（数据节点）。MHA Manager可以单独部署在一台独立的机器上管理多个master-slave集群，也可以部署在一台slave节点上。MHA Node运行在每台MySQL服务器上，MHA Manager会定时探测集群中的master节点，当master出现故障时，它可以自动将最新数据的slave提升为新的master，然后将所有其他的slave重新指向新的master。整个故障转移过程对应用程序完全透明。
在MHA自动故障切换过程中，MHA试图从宕机的主服务器上保存二进制日志，最大程度的保证数据的不丢失(配合mysql半同步复制效果更佳)，但这并不总是可行的。例如，如果主服务器硬件故障或无法通过ssh访问，MHA没法保存二进制日志，只进行故障转移而丢失了最新的数据。使用MySQL 5.5的半同步复制，可以大大降低数据丢失的风险。MHA可以与半同步复制结合起来。如果只有一个slave已经收到了最新的二进制日志，MHA可以将最新的二进制日志应用于其他所有的slave服务器上，因此可以保证所有节点的数据一致性。
注意：目前MHA主要支持一主多从的架构，要搭建MHA,要求一个复制集群中必须最少有三台数据库服务器，一主二从，即一台充当master，一台充当备用master，另外一台充当从库，因为至少需要三台服务器，出于机器成本的考虑，淘宝也在该基础上进行了改造，目前淘宝TMHA已经支持一主一从。
常见问题 百万级别或以上的数据如何删除 关于索引：由于索引需要额外的维护成本，因为索引文件是单独存在的文件,所以当我们对数据的增加,修改,删除,都会产生额外的对索引文件的操作,这些操作需要消耗额外的IO,会降低增/改/删的执行效率。所以，在我们删除数据库百万级别数据的时候，查询MySQL官方手册得知删除数据的速度和创建的索引数量是成正比的。
所以我们想要删除百万数据的时候可以先删除索引（此时大概耗时三分多钟） 然后删除其中无用数据（此过程需要不到两分钟） 删除完成后重新创建索引(此时数据较少了)创建索引也非常快，约十分钟左右。 与之前的直接删除绝对是要快速很多，更别说万一删除中断,一切删除会回滚。那更是坑了。 参考文章 浅谈MySQL集群高可用架构 MySQL 同步复制及高可用方案总结 MySQL应用架构演变 Mysql高可用架构之keepalived and MHA </description>
    </item>
    <item>
      <title>MySQL调优</title>
      <link>https://moge.fun/mysqltuning/</link>
      <pubDate>Fri, 03 Mar 2017 00:00:00 +0000</pubDate>
      <guid>https://moge.fun/mysqltuning/</guid>
      <description>影响mysql的性能因素 业务需求对MySQL的影响 存储定位对MySQL的影响 不适合放进MySQL的数据 二进制多媒体数据 流水队列数据 超大文本数据 需要放进缓存的数据 系统各种配置及规则数据 活跃用户的基本信息数据 活跃用户的个性化定制信息数据 准实时的统计信息数据 其他一些访问频繁但变更较少的数据 Schema设计对系统的性能影响 尽量减少对数据库访问的请求 尽量减少无用数据的查询请求 硬件环境对系统性能的影响 性能分析 MySQL常见瓶颈 CPU：CPU在饱和的时候一般发生在数据装入内存或从磁盘上读取数据时候 IO：磁盘I/O瓶颈发生在装入数据远大于内存容量的时候 服务器硬件的性能瓶颈：top，free，iostat 和 vmstat来查看系统的性能状态 性能下降SQL慢 执行时间长 等待时间长 原因分析 查询语句写的烂 索引失效（单值、复合） 关联查询太多join（设计缺陷或不得已的需求） 服务器调优及各个参数设置（缓冲、线程数等） MySQL常见性能分析手段 在优化MySQL时，通常需要对数据库进行分析，常见的分析手段有慢查询日志，EXPLAIN 分析查询，profiling分析以及show命令查询系统状态及系统变量，通过定位分析性能的瓶颈，才能更好的优化数据库系统的性能。
性能瓶颈定位 我们可以通过 show 命令查看 MySQL 状态及变量，找到系统的瓶颈：
1 2 3 4 5 6 Mysql&amp;gt; show status ——显示状态信息（扩展show status like ‘XXX’） Mysql&amp;gt; show variables ——显示系统变量（扩展show variables like ‘XXX’） Mysql&amp;gt; show innodb status ——显示InnoDB存储引擎的状态 Mysql&amp;gt; show processlist ——查看当前SQL执行，包括执行状态、是否锁表等 Shell&amp;gt; mysqladmin variables -u username -p password——显示系统变量 Shell&amp;gt; mysqladmin extended-status -u username -p password——显示状态信息 Explain(执行计划) 使用 Explain 关键字可以模拟优化器执行SQL查询语句，从而知道 MySQL 是如何处理你的 SQL 语句的。分析你的查询语句或是表结构的性能瓶颈</description>
    </item>
    <item>
      <title>MySQL总结</title>
      <link>https://moge.fun/mysql/</link>
      <pubDate>Thu, 02 Mar 2017 00:00:00 +0000</pubDate>
      <guid>https://moge.fun/mysql/</guid>
      <description>简述一条SQL的执行流程 客户端请求 连接器（验证用户身份，给予权限） 查询缓存（存在缓存则直接返回，不存在则执行后续操作） 分析器（对SQL进行词法分析和语法分析操作） 优化器（主要对执行的sql优化选择最优的执行方案方法） 执行器（执行时会先看用户是否有执行权限，有才去使用这个引擎提供的接口） 去引擎层获取数据返回（如果开启查询缓存则会缓存查询结果） 存储引擎 存储引擎是MySQL的组件，用于处理不同表类型的SQL操作。不同的存储引擎提供不同的存储机制、索引技巧、锁定水平等功能，使用不同的存储引擎，还可以获得特定的功能，MySQL服务器使用可插拔的存储引擎体系结构，可以从运行中的 MySQL 服务器加载或卸载存储引擎 。
InnoDB InnoDB 现在是 MySQL 默认的存储引擎，支持事务、行级锁定和外键，只有在需要它不支持的特性时，才考虑使用其它存储引擎。
实现了四个标准的隔离级别，默认级别是可重复读(REPEATABLE READ)。在可重复读隔离级别下，通过多版本并发控制(MVCC)+ 间隙锁(Next-Key Locking)防止幻影读。
主索引是聚簇索引，在索引中保存了数据，从而避免直接读取磁盘，因此对查询性能有很大的提升。
内部做了很多优化，包括从磁盘读取数据时采用的可预测性读、能够加快读操作并且自动创建的自适应哈希索引、能够加速插入操作的插入缓冲区等。
支持真正的在线热备份。其它存储引擎不支持在线热备份，要获取一致性视图需要停止对所有表的写入，而在读写混合场景中，停止写入可能也意味着停止读取。
MyISAM 设计简单，数据以紧密格式存储。对于只读数据，或者表比较小、可以容忍修复操作，则依然可以使用它。
不支持事务。 不支持行级锁，只能对整张表加锁，读取时会对需要读到的所有表加共享锁，写入时则对表加排它锁。但在表有读取操作的同时，也可以往表中插入新的记录，这被称为并发插入(CONCURRENT INSERT)。
比较 对比项 MyISAM InnoDB 主外键 不支持 支持 事务 不支持 支持 行表锁 表锁，即使操作一条记录也会锁住整个表，不适合高并发的操作 行锁,操作时只锁某一行，不对其它行有影响，适合高并发的操作 缓存 只缓存索引，不缓存真实数据 不仅缓存索引还要缓存真实数据，对内存要求较高，而且内存大小对性能有决定性的影响 表空间 小 小 关注点 性能 事务 索引 索引其实是一种数据结构，能够帮助我们快速的检索数据库中的数据，索引是在存储引擎层实现的，而不是在服务器层实现的。可以简单的理解为“排好序的快速查找数据结构”，数据本身之外，数据库还维护者一个满足特定查找算法的数据结构，这些数据结构以某种方式引用（指向）数据，这样就可以在这些数据结构上实现高级查找算法。这种数据结构，就是索引。下图是一种可能的索引方式示例。
索引类型 数据结构角度 B+树索引 Hash索引 Full-Text全文索引 R-Tree索引 从物理存储角度 聚集索引（clustered index） 非聚集索引（non-clustered index），也叫辅助索引（secondary index） 聚集索引和非聚集索引都是B+树结构 从逻辑角度 主键索引：主键索引是一种特殊的唯一索引，不允许有空值 普通索引或者单列索引：每个索引只包含单个列，一个表可以有多个单列索引 多列索引（复合索引、联合索引）：复合索引指多个字段上创建的索引，只有在查询条件中使用了创建索引时的第一个字段，索引才会被使用。使用复合索引时遵循最左前缀集合 唯一索引或者非唯一索引 空间索引：空间索引是对空间数据类型的字段建立的索引，MYSQL中的空间数据类型有4种，分别是GEOMETRY、POINT、LINESTRING、POLYGON。 MYSQL使用SPATIAL关键字进行扩展，使得能够用于创建正规索引类型的语法创建空间索引。创建空间索引的列，必须将其声明为NOT NULL，空间索引只能在存储引擎为MYISAM的表中创建 MySQL主要有两种结构Hash索引和B+Tree索引，我们使用的是InnoDB引擎，默认的是B+树。 B+Tree索引 所有的数据都存放在叶子节点上，且把叶子节点通过指针连接到一起，形成了一条数据链表，以加快相邻数据的检索效率。</description>
    </item>
    <item>
      <title>关系型数据库概览</title>
      <link>https://moge.fun/relationaldatabase/</link>
      <pubDate>Wed, 01 Mar 2017 00:00:00 +0000</pubDate>
      <guid>https://moge.fun/relationaldatabase/</guid>
      <description>数据库组件 核心组件 进程管理器（process manager）：很多数据库具备一个需要妥善管理的进程/线程池。再者，为了实现纳秒级操作，一些现代数据库使用自己的线程而不是操作系统线程。 网络管理器（network manager）：网路I/O是个大问题，尤其是对于分布式数据库。所以一些数据库具备自己的网络管理器。 文件系统管理器（File system manager）：磁盘I/O是数据库的首要瓶颈。具备一个文件系统管理器来完美地处理OS文件系统甚至取代OS文件系统，是非常重要的。 内存管理器（memory manager）：为了避免磁盘I/O带来的性能损失，需要大量的内存。但是如果你要处理大容量内存你需要高效的内存管理器，尤其是你有很多查询同时使用内存的时候。 安全管理器（Security Manager）：用于对用户的验证和授权。 客户端管理器（Client manager）：用于管理客户端连接。 工具 备份管理器（Backup manager）：用于保存和恢复数据。 恢复管理器（Recovery manager）：用于崩溃后重启数据库到一个一致状态。 监控管理器（Monitor manager）：用于记录数据库活动信息和提供监控数据库的工具。 管理员管理器（Administration manager）：用于保存元数据（比如表的名称和结构），提供管理数据库、模式、表空间的工具。 查询管理器 查询解析器（Query parser）：用于检查查询是否合法 查询重写器（Query rewriter）：用于预优化查询 查询优化器（Query optimizer）：用于优化查询 查询执行器（Query executor）：用于编译和执行查询 数据管理器： 事务管理器（Transaction manager）：用于处理事务 缓存管理器（Cache manager）：数据被使用之前置于内存，或者数据写入磁盘之前置于内存 数据访问管理器（Data access manager）：访问磁盘中的数据 数据查询的流程 本章集中探讨数据库如何通过如下进程管理SQL查询的：
客户端管理器 查询管理器 数据管理器（含恢复管理器） 客户端管理器 客户端管理器 客户端管理器是处理客户端通信的。客户端可以是一个（网站）服务器或者一个最终用户或最终应用。客户端管理器通过一系列知名的API（JDBC, ODBC, OLE-DB …）提供不同的方式来访问数据库。客户端管理器也提供专有的数据库访问API。
当你连接到数据库时：
管理器首先检查你的验证信息（用户名和密码），然后检查你是否有访问数据库的授权。这些权限由DBA分配。 然后，管理器检查是否有空闲进程（或线程）来处理你对查询。 管理器还会检查数据库是否负载很重。 管理器可能会等待一会儿来获取需要的资源。如果等待时间达到超时时间，它会关闭连接并给出一个可读的错误信息。 然后管理器会把你的查询送给查询管理器来处理。 因为查询处理进程不是『不全则无』的，一旦它从查询管理器得到数据，它会把部分结果保存到一个缓冲区并且开始给你发送。 如果遇到问题，管理器关闭连接，向你发送可读的解释信息，然后释放资源。 查询管理器 这个多步骤操作过程如下：
查询首先被解析并判断是否合法 然后被重写，去除了无用的操作并且加入预优化部分 接着被优化以便提升性能，并被转换为可执行代码和数据访问计划。 然后计划被编译 最后，被执行 数据管理器 在这一步，查询管理器执行了查询，需要从表和索引获取数据，于是向数据管理器提出请求。 但是有 2 个问题：</description>
    </item>
    <item>
      <title>算法概览</title>
      <link>https://moge.fun/algorithm/</link>
      <pubDate>Sun, 05 Feb 2017 00:00:00 +0000</pubDate>
      <guid>https://moge.fun/algorithm/</guid>
      <description>
数据结构研究的是数据的存储方式，算法研究的是解决问题的思路。数据结构与算法是相辅相成的。
排序算法 冒泡排序(Bubble Sort) 它是一种较简单的排序算法。它会遍历若干次要排序的数列，每次遍历时，它都会从前往后依次的比较相邻两个数的大小；如果前者比后者大，则交换它们的位置。这样，一次遍历之后，最大的元素就在数列的末尾！ 采用相同的方法再次遍历时，第二大的元素就被排列在最大元素之前。重复此操作，直到整个数列都有序为止
快速排序(Quick Sort) 它的基本思想是: 选择一个基准数，通过一趟排序将要排序的数据分割成独立的两部分；其中一部分的所有数据都比另外一部分的所有数据都要小。然后，再按此方法对这两部分数据分别进行快速排序，整个排序过程可以递归进行，以此达到整个数据变成有序序列。
插入排序(Insertion Sort) 直接插入排序(Straight Insertion Sort)的基本思想是: 把n个待排序的元素看成为一个有序表和一个无序表。开始时有序表中只包含1个元素，无序表中包含有n-1个元素，排序过程中每次从无序表中取出第一个元素，将它插入到有序表中的适当位置，使之成为新的有序表，重复n-1次可完成排序过程。
Shell排序(Shell Sort) 希尔排序实质上是一种分组插入方法。它的基本思想是: 对于n个待排序的数列，取一个小于n的整数gap(gap被称为步长)将待排序元素分成若干个组子序列，所有距离为gap的倍数的记录放在同一个组中；然后，对各组内的元素进行直接插入排序。 这一趟排序完成之后，每一个组的元素都是有序的。然后减小gap的值，并重复执行上述的分组和排序。重复这样的操作，当gap=1时，整个数列就是有序的。
选择排序(Selection sort) 它的基本思想是: 首先在未排序的数列中找到最小(or最大)元素，然后将其存放到数列的起始位置；接着，再从剩余未排序的元素中继续寻找最小(or最大)元素，然后放到已排序序列的末尾。以此类推，直到所有元素均排序完毕。
堆排序(Heap Sort) 堆排序是指利用堆这种数据结构所设计的一种排序算法。堆是一个近似完全二叉树的结构，并同时满足堆积的性质：即子结点的键值或索引总是小于（或者大于）它的父节点。
归并排序(Merge Sort) 将两个的有序数列合并成一个有序数列，我们称之为&amp;quot;归并&amp;quot;。归并排序(Merge Sort)就是利用归并思想对数列进行排序。
桶排序(Bucket Sort) 桶排序(Bucket Sort)的原理很简单，将数组分到有限数量的桶子里。每个桶子再个别排序（有可能再使用别的排序算法或是以递归方式继续使用桶排序进行排序）
基数排序(Radix Sort) 它的基本思想是: 将整数按位数切割成不同的数字，然后按每个位数分别比较。具体做法是: 将所有待比较数值统一为同样的数位长度，数位较短的数前面补零。然后，从最低位开始，依次进行一次排序。这样从最低位排序一直到最高位排序完成以后, 数列就变成一个有序序列
算法思想详解 分治算法 分治算法的基本思想是将一个规模为N的问题分解为K个规模较小的子问题，这些子问题相互独立且与原问题性质相同。求出子问题的解，就可得到原问题的解
动态规划算法 动态规划算法通常用于求解具有某种最优性质的问题。在这类问题中，可能会有许多可行解。每一个解都对应于一个值，我们希望找到具有最优值的解。动态规划算法与分治法类似，其基本思想也是将待求解问题分解成若干个子问题，先求解子问题，然后从这些子问题的解得到原问题的解
贪心算法 本文主要介绍算法中贪心算法的思想: 保证每次操作都是局部最优的，并且最后得到的结果是全局最优的
二分法 本文主要介绍算法思想中分治算法重要的二分法，比如二分查找；二分查找也称折半查找（Binary Search），它是一种效率较高的查找方法。但是，折半查找要求线性表必须采用顺序存储结构，而且表中元素按关键字有序排列。
搜索算法 本文主要介绍算法中搜索算法的思想，主要包含BFS，DFS
回溯算法 Backtracking(回溯)属于 DFS, 本文主要介绍算法中Backtracking算法的思想。回溯算法实际上一个类似枚举的搜索尝试过程，主要是在搜索尝试过程中寻找问题的解，当发现已不满足求解条件时，就“回溯”返回，尝试别的路径。回溯法是一种选优搜索法，按选优条件向前搜索，以达到目标。但当探索到某一步时，发现原先选择并不优或达不到目标，就退回一步重新选择，这种走不通就退回再走的技术为回溯法
领域算法 参考文章 算法 </description>
    </item>
    <item>
      <title>树</title>
      <link>https://moge.fun/tree/</link>
      <pubDate>Sat, 04 Feb 2017 00:00:00 +0000</pubDate>
      <guid>https://moge.fun/tree/</guid>
      <description>树是一种数据结构，它是n(n&amp;gt;=0)个节点的有限集。n=0时称为空树。n&amp;gt;0时，有限集的元素构成一个具有层次感的数据结构。
区别于线性表一对一的元素关系，树中的节点是一对多的关系。树具有以下特点:
n&amp;gt;0时，根节点是唯一的，不可能存在多个根节点。 每个节点有零个至多个子节点；除了根节点外，每个节点有且仅有一个父节点。根节点没有父节点。 树的相关概念 子树: 除了根节点外，每个子节点都可以分为多个不相交的子树。 孩子与双亲: 若一个结点有子树，那么该结点称为子树根的&amp;quot;双亲&amp;quot;，子树的根是该结点的&amp;quot;孩子&amp;quot;。 在图一中，B、H是A的孩子，A是B、H的双亲。 兄弟: 具有相同双亲的节点互为兄弟，例如B与H互为兄弟。 节点的度: 一个节点拥有子树的数目。例如A的度为2，B的度为1，C的度为3. 叶子: 没有子树，也即是度为0的节点。 分支节点: 除了叶子节点之外的节点，也即是度不为0的节点。 内部节点: 除了根节点之外的分支节点。 层次: 根节点为第一层，其余节点的层次等于其双亲节点的层次加1. 树的高度: 也称为树的深度，树中节点的最大层次。 有序树: 树中节点各子树之间的次序是重要的，不可以随意交换位置。 无序树: 树种节点各子树之间的次序是不重要的。可以随意交换位置。 森林: 0或多棵互不相交的树的集合。例如图二中的两棵树为森林。 二叉树 二叉树: 最多有两棵子树的树被称为二叉树。
斜树: 所有节点都只有左子树的二叉树叫做左斜树，所有节点都只有右子树的二叉树叫做右斜树。(本质就是链表) 满二叉树: 二叉树中所有非叶子结点的度都是2，且叶子结点都在同一层次上 完全二叉树: 如果一个二叉树与满二叉树前m个节点的结构相同，这样的二叉树被称为完全二叉树 二叉查找树 - BST 二叉查找树(Binary Search Tree)是指一棵空树或者具有下列性质的二叉树:
若任意节点的左子树不空，则左子树上所有节点的值均小于它的根节点的值； 若任意节点的右子树不空，则右子树上所有节点的值均大于它的根节点的值； 任意节点的左、右子树也分别为二叉查找树； 没有键值相等的节点。 二叉查找树相比于其他数据结构的优势在于查找、插入的时间复杂度较低为 O (logn) 。二叉查找树是基础性数据结构，用于构建更为抽象的数据结构，如集合、多重集、关联数组等。 平衡二叉树 - AVL 含有相同节点的二叉查找树可以有不同的形态，而二叉查找树的平均查找长度与树的深度有关，所以需要找出一个查找平均长度最小的一棵，那就是平衡二叉树，具有以下性质:
要么是棵空树，要么其根节点左右子树的深度之差的绝对值不超过1； 其左右子树也都是平衡二叉树； 二叉树节点的平衡因子定义为该节点的左子树的深度减去右子树的深度。则平衡二叉树的所有节点的平衡因子只可能是-1,0,1。 红黑树 红黑树也是一种自平衡的二叉查找树。
每个结点要么是红的要么是黑的。(红或黑) 根结点是黑的。 (根黑) 每个叶结点(叶结点即指树尾端NIL指针或NULL结点)都是黑的。 (叶黑) 如果一个结点是红的，那么它的两个儿子都是黑的。 (红子黑) 对于任意结点而言，其到叶结点树尾端NIL指针的每条路径都包含相同数目的黑结点。(路径下黑相同) 用法最广:</description>
    </item>
    <item>
      <title>哈希表</title>
      <link>https://moge.fun/hashtable/</link>
      <pubDate>Fri, 03 Feb 2017 00:00:00 +0000</pubDate>
      <guid>https://moge.fun/hashtable/</guid>
      <description>定义 散列Hash是和顺序、链接和索引一样，是存储集合或者线性表的一种方法。
散列的基本思想是：以集合或线性表中的每个元素的关键字K为自变量，通过一个散列函数 h(K) 得到的结果，将这个结果解释为一块连续的存储空间（如数组）的地址（如数组下标），将这个元素存储到这个空间中。
h(K) 称为散列函数或者哈希函数，它实现了关键字到存储地址的映射，散列算法，变换成固定长度的输出，该输出就是散列值。h(K)的值 称为散列地址或者哈希地址。存储空间是线性表进行散列存储的空间，所以称之为散列表或者哈希表。
释义 这种转换是一种压缩映射，也就是，散列值的空间通常远小于输入的空间，不同的输入可能会散列成相同的输出，所以不可能从散列值来唯一的确定输入值。简单的说就是一种将任意长度的消息压缩到某一固定长度的消息摘要的函数。
所有散列函数都有如下一个基本特性：根据同一散列函数计算出的散列值如果不同，那么输入值肯定也不同。但是，根据同一散列函数计算出的散列值如果相同，输入值不一定相同。
两个不同的输入值，根据同一散列函数计算出的散列值相同的现象叫做碰撞，衡量一个哈希函数的好坏的重要指标就是发生碰撞的概率以及发生碰撞的解决方案。
常见的Hash函数 直接定址法：直接以关键字k或者k加上某个常数（k+c）作为哈希地址。 数字分析法：提取关键字中取值比较均匀的数字作为哈希地址。 除留余数法：用关键字k除以某个不大于哈希表长度m的数p，将所得余数作为哈希表地址。 分段叠加法：按照哈希表地址位数将关键字分成位数相等的几部分，其中最后一部分可以比较短。然后将这几部分相加，舍弃最高进位后的结果就是该关键字的哈希地址。 平方取中法：如果关键字各个部分分布都不均匀的话，可以先求出它的平方值，然后按照需求取中间的几位作为哈希地址。 伪随机数法：采用一个伪随机数当作哈希函数。 解决碰撞方法 开放定址法：开放定址法就是一旦发生了冲突，就去寻找下一个空的散列地址，只要散列表足够大，空的散列地址总能找到，并将记录存入。 链地址法：将哈希表的每个单元作为链表的头结点，所有哈希地址为i的元素构成一个同义词链表。即发生冲突时就把该关键字链在以该单元为头结点的链表的尾部。 再哈希法：当哈希地址发生冲突用其他的函数计算另一个哈希函数地址，直到冲突不再产生为止。 建立公共溢出区：将哈希表分为基本表和溢出表两部分，发生冲突的元素都放入溢出表中。 散列存储的缺点 计算散列地址需要花费时间，关键字不是整数还先要转换为整数。 占用更多的存储空间，开放定址法的装载因子小于1，链接法则需要空间存储指针。 只能按关键字查找，无法按非关键字查找。 </description>
    </item>
    <item>
      <title>链表</title>
      <link>https://moge.fun/linkedlist/</link>
      <pubDate>Thu, 02 Feb 2017 00:00:00 +0000</pubDate>
      <guid>https://moge.fun/linkedlist/</guid>
      <description>定义 链表是一种物理存储单元上非连续、非顺序的存储结构，数据元素的逻辑顺序是通过链表中的指针链接次序实现的。
详解 链表的存在就是为了解决数组的增删复杂耗时，内存占用较大的问题。它并不需要一块连续的内存空间，它通过指针将一组零散的内存块串联起来。 根据指针的不同，有单链表，双向链表，循环链表之分。 数组和链表是相互补充的一对数据结构。 优点： 操作指针即可删除该元素或者插入新元素，时间复杂度 O(1)。 链表因为元素不连续，而是靠指针指向下一个元素的位置，本身没有大小的限制，不存在数组的扩容问题，所以天然地支持动态扩容。 空间没有限制 插入删除元素很快 缺点： 因为存储空间不连续，你无法根据一个索引算出对应元素的地址，所以不能随机访问。 由于每个元素必须存储指向前后元素位置的指针，会消耗相对更多的储存空间。 同时内存不连续，容易造成内存碎片。 存取速度很慢 对比 数组 数组存储区间是连续的，占用内存严重，故空间复杂的很大。但数组的二分查找时间复杂度小，为O(1)；数组的特点是：寻址容易，插入和删除困难。
链表 链表存储区间离散，占用内存比较宽松，故空间复杂度很小，但时间复杂度很大，达O（N）。链表的特点是：寻址困难，插入和删除容易。
哈希表 那么我们能不能综合两者的特性，做出一种寻址容易，插入删除也容易的数据结构？这就是我们要提起的哈希表。
分类 单向链表 一个节点指向下一个节点。 双向链表 一个节点有两个指针域。 循环链表 能通过任何一个节点找到其他所有的节点，将两种(双向/单向)链表的最后一个结点指向第一个结点从而实现循环。 </description>
    </item>
    <item>
      <title>数组</title>
      <link>https://moge.fun/array/</link>
      <pubDate>Wed, 01 Feb 2017 00:00:00 +0000</pubDate>
      <guid>https://moge.fun/array/</guid>
      <description>定义 有限个相同数据类型的元素按顺序排列的集合为数组。
特性 数组是相同数据类型的元素的集合。 数组中的各元素的存储是有先后顺序的，它们在内存中按照这个先后顺序连续存放在一起。 优点： 由于是紧凑连续存储,可以随机访问，通过索引快速找到对应元素，而且相对节约存储空间，查询修改元素的效率O(1)。 缺点： 正因为连续存储，内存空间必须一次性分配够，所以说数组如果要扩容，需要重新分配一块更大的空间，再把数据全部复制过去，时间复杂度 O(N)。 想在数组中间进行插入和删除，每次必须搬移后面的所有数据以保持连续，时间复杂度 O(N) 二维数组 二维数组也称为矩阵，因为是二维的，所以需要两个下标才能确定一个元素，即行下标和列下标。</description>
    </item>
    <item>
      <title>数据结构概览</title>
      <link>https://moge.fun/datastruct/</link>
      <pubDate>Sun, 15 Jan 2017 00:00:00 +0000</pubDate>
      <guid>https://moge.fun/datastruct/</guid>
      <description>数据结构研究的是数据的存储方式，算法研究的是解决问题的思路。数据结构与算法是相辅相成的。
常用存储结构 线性表，还可细分为顺序表(数组)、链表、栈和队列。 树结构，包括普通树，二叉树，二叉查找树等。 图存储结构。 线性表 线性表并不是一种具体的存储结构，它包含顺序存储结构和链式存储结构，是顺序表和链表的统称。
线性表是一种线性结构，它是由零个或多个数据元素构成的有限序列。 线性表的特征是在一个序列中，除了头尾元素，每个元素都有且只有一个直接前驱，有且只有一个直接后继，而序列头元素没有直接前驱，序列尾元素没有直接后继。 数据结构中常见的线性结构有数组、单链表、双链表、循环链表等。线性表中的元素为某种相同的抽象数据类型。 如图 3a) 所示，将数据依次存储在连续的整块物理空间中，这种存储结构称为顺序存储结构（简称顺序表，数组）； 如图 3b) 所示，数据分散的存储在物理空间中，通过一根线保存着它们之间的逻辑关系，这种存储结构称为链式存储结构（简称链表）。 数组和矩阵(顺序表) 数组是一种连续存储线性结构，元素类型相同，大小相等，数组是多维的，通过使用整型索引值来访问他们的元素，数组尺寸不能改变。
链表 我们知道，使用顺序表（底层实现靠数组）时，需要提前申请一定大小的存储空间，这块存储空间的物理地址是连续的，链表则完全不同，使用链表存储数据时，是随用随申请，因此数据的存储位置是相互分离的，换句话说，数据的存储位置是随机的。
n个节点离散分配，彼此通过指针相连，每个节点只有一个前驱节点，每个节点只有一个后续节点，首节点没有前驱节点，尾节点没有后续节点。确定一个链表我们只需要头指针，通过头指针就可以把整个链表都能推出来。
哈希表(散列) 散列表（Hash table，也叫哈希表），是根据关键码值(Key value)而直接进行访问的数据结构。也就是说，它通过把关键码值映射到表中一个位置来访问记录，以加快查找的速度。这个映射函数叫做散列函数，存放记录的数组叫做散列表。
栈和队列 数组和链表都是线性存储结构的基础，栈和队列都是线性存储结构的应用，栈和队列隶属于线性表，是特殊的线性表，因为它们对线性表中元素的进出做了明确的要求。
栈（LIFO） 使用数组实现的叫静态栈 使用链表实现的叫动态栈 栈（FIFO） 使用数组实现的叫静态队列 使用链表实现的叫动态队列 树存储结构 树存储结构适合存储具有“一对多”关系的数据。
图存储结构 图存储结构适合存储具有“多对多”关系的数据。
和线性表，树的差异: 线性表中我们把数据元素叫元素，树中将数据元素叫结点，在图中数据元素，我们则称之为顶点(Vertex)。 线性表可以没有元素，称为空表；树中可以没有节点，称为空树；但是，在图中不允许没有顶点(有穷非空性)。 线性表中的各元素是线性关系，树中的各元素是层次关系，而图中各顶点的关系是用边来表示(边集可以为空)。 总结 我们知道，实际应用当中，我们经常使用的是查找和排序操作，这在我们的各种管理系统、数据库系统、操作系统等当中，十分常用。
数组 的下标寻址十分迅速，但计算机的内存是有限的，故数组的长度也是有限的，实际应用当中的数据往往十分庞大；而且无序数组的查找最坏情况需要遍历整个数组；后来人们提出了二分查找，二分查找要求数组的构造一定有序，二分法查找解决了普通数组查找复杂度过高的问题。任和一种数组无法解决的问题就是插入、删除操作比较复杂，因此，在一个增删查改比较频繁的数据结构中，数组不会被优先考虑 普通链表 由于它的结构特点被证明根本不适合进行查找 哈希表 是数组和链表的折中，同时它的设计依赖散列函数的设计，数组不能无限长、链表也不适合查找，所以也不适合大规模的查找 二叉查找树 因为可能退化成链表，同样不适合进行查找 AVL树 是为了解决可能退化成链表问题，但是AVL树的旋转过程非常麻烦，因此插入和删除很慢，也就是构建AVL树比较麻烦 红黑树 是平衡二叉树和AVL树的折中，因此是比较合适的。集合类中的Map、关联数组具有较高的查询效率，它们的底层实现就是红黑树。 多路查找树 是大规模数据存储中，实现索引查询这样一个实际背景下，树节点存储的元素数量是有限的(如果元素数量非常多的话，查找就退化成节点内部的线性查找了)，这样导致二叉查找树结构由于树的深度过大而造成磁盘I/O读写过于频繁，进而导致查询效率低下。 B树 与自平衡二叉查找树不同，B树适用于读写相对大的数据块的存储系统，例如磁盘。它的应用是文件系统及部分非关系型数据库索引。 B+树 在B树基础上，为叶子结点增加链表指针(B树+叶子有序链表)，所有关键字都在叶子结点 中出现，非叶子结点作为叶子结点的索引；B+树总是到叶子结点才命中。通常用于关系型数据库(如Mysql)和操作系统的文件系统中。 B*树 是B+树的变体，在B+树的非根和非叶子结点再增加指向兄弟的指针, 在B+树基础上，为非叶子结点也增加链表指针，将结点的最低利用率从1/2提高到2/3。 R树是用来做空间数据存储的树状数据结构。例如给地理位置，矩形和多边形这类多维数据建立索引。 Trie树 是自然语言处理中最常用的数据结构，很多字符串处理任务都会用到。Trie树本身是一种有限状态自动机，还有很多变体。什么模式匹配、正则表达式，都与这有关。 针对大量数据，如果在内存中作业优先考虑红黑树(map,set之类多为RB-tree实现)，如果在硬盘中作业优先考虑B系列树(B+, B, B)*</description>
    </item>
    <item>
      <title>计算机网络</title>
      <link>https://moge.fun/network/</link>
      <pubDate>Thu, 05 Jan 2017 00:00:00 +0000</pubDate>
      <guid>https://moge.fun/network/</guid>
      <description> 一般网线传输的模拟信号需要通过猫(调制解调器)转换成数字信号，再经由路由器把信号发给PC端，如果PC端数量超过了路由器的连接上限就需要加装交换器。因此，家里有宽带就必须有猫，有多台电脑上网就必须要路由器，假如电脑很多，超过路由器的接口数就需要交换机扩展接口。
参考文章 7层协议 HTTP协议 DNS协议 知识点串联：输入URL到页面加载过程详解 </description>
    </item>
    <item>
      <title>估值</title>
      <link>https://moge.fun/appraisement/</link>
      <pubDate>Sat, 02 Jan 2016 00:00:00 +0000</pubDate>
      <guid>https://moge.fun/appraisement/</guid>
      <description>第一大块 蓝筹股 是以金融、地产、公用事业，还有建筑为主的蓝筹股，比较典型的特征是，估值很低，盈利质量好，盈利增速比较低。但是他不太愿意去参与蓝筹股投资，因为虽然低估值，但是并不满足盈利出现非线性变化的特征。换句话说就是，盈利无法突变。 这些行业可能十年前，甚至十年后的商业模式和盈利增速都是相对稳定，这种相对比较低的增速，它无法平抑估值上的波动。 巴菲特所说的捡烟蒂，指的就是这类股票，这类票机构看不上，但是对散户来说，拿着搏个稳定增长，还是很舒服的。 第二大块 低估值成长 我们挑的基金，挑的都是低估值成长风格的基金。他认为，中国制造业太大了，很多细分行业是没人注意的到的，只有靠基金经理自己去挖，去走访调研，寻找小领域里别人没注意到，但是业绩即将爆发的票，先买入这种票，等市场开始关注到的时候，就会出现一个估值和业绩的双抬升，戴维斯双击。
第三大块 顺周期行业 顺周期行业投资者参与热情并不高，因为在大家看来，顺周期是一个短久期的资产，没有量的逻辑，只有价格的逻辑，而价格的波动又过于频繁，所以个人投资者很难去判断行业盈利中枢到底在哪，容易造成永久性亏损（套几年）。讲白了就是，你摸不准这个行业在高景气度的时候，到底能赚多少钱，因为它可能十年才来一个牛市，十年前那个价格早就不具有参考性了，就像现在的煤炭、钢铁、有色、化工，你能准确说出它的历史高位在哪吗？没有一个人能够打包票。这就是顺周期的难点，他认为当前顺周期的分歧很大。</description>
    </item>
    <item>
      <title>投资纲领</title>
      <link>https://moge.fun/investment/</link>
      <pubDate>Fri, 01 Jan 2016 00:00:00 +0000</pubDate>
      <guid>https://moge.fun/investment/</guid>
      <description>总体策略 低估加倍 高估不买 高估卖出 好资产 + 好价格 + 长期持有 资产配置 购买标的 宽基指数（沪深300和中证500） 我们可以把沪深300和中证500这样的宽基指数作为「核心」资产，比如占整体仓位的 60% 以上，保证我们能够跟上中国经济的增长，投资到未来头部的公司。 40% 基于估值和增强型指数基金进一步提高仓位。 「卫星」资产 我们可以根据自己的判断或者市场的估值，加入一部分「卫星」资产。 主动基金（优秀基金精力管理的基金）中概互联基金 科创板（还需观看） 。 30% 分散投资给几个优秀的主动型基金经理。 债券 30% 的债券仓位，用债券基金以及有知有行未来推荐的其它「固收+」产品来进一步提高收益。 计算得出年化收益率：40% * 13% + 30% * 11% + 30% * 4% + 1% = 10.7%。
具体操作 每年一次大额买入 参考有知有行的「股市温度计」来确定自己一次性买入的仓位。 假如当年大额资金5万，当时股市温度为40处于中估状态，则先投入50%，计算得出当年大额买入资金为2.5万。 每年一次的再平衡 根据自定的家庭资产比例和当年股债实时状态，进行股债再平衡调整。 每月定投 参考有知有行的「股市温度计」，在中估时投入，低估时加倍，高估时停止买入 高估状态卖出部分锁定收益 A股的波动大，牛市之后往往出现暴跌，而浮亏越大，回本难度越大，甚至难度是呈指数级增长的。 </description>
    </item>
    <item>
      <title>学与思</title>
      <link>https://moge.fun/studyandthink/</link>
      <pubDate>Fri, 02 Jan 2015 00:00:00 +0000</pubDate>
      <guid>https://moge.fun/studyandthink/</guid>
      <description>学而不思则罔，思而不学则殆 一味学习而不思考，就会因为不能深刻理解而不能合理有效利用学习的知识，甚至会陷入迷茫。 一味空想而不去进行实实在在地学习和钻研，则终究是沙上建塔，一无所得。 因此我们只有把学习和思考结合起来，才能学到切实有用的知识，否则就会收效甚微。 </description>
    </item>
    <item>
      <title>Markdown语法</title>
      <link>https://moge.fun/mdgrammar/</link>
      <pubDate>Thu, 01 Jan 2015 00:00:00 +0000</pubDate>
      <guid>https://moge.fun/mdgrammar/</guid>
      <description>标题 #### 这是 H5 ####这是 H5 段落 这是一个段落。这是另一个段落。这是一个段落。
这是另一个段落。
斜体 *这是斜体*这是斜体
粗体 **这是粗体**这是粗体
粗体+斜体 ***这是粗体+斜体*** 这是粗体+斜体
删除线 ~~没有价值就会被抛弃~~没有价值就会被抛弃
引用 &amp;gt; Markdown是一种可以使用普通文本编辑器编写的标记语言，通过简单的标记语法，它可以使普通文本内容具有一定的格式。Markdown是一种可以使用普通文本编辑器编写的标记语言，通过简单的标记语法，它可以使普通文本内容具有一定的格式。
列表 * 学习* 思考* 创造学习 思考 创造 有序列表 1. 昨夜西风凋碧树。独上高楼，望尽天涯路。2. 衣带渐宽终不悔，为伊消得人憔悴。3. 众里寻他千百度。蓦然回首，那人却在，灯火阑珊处。昨夜西风凋碧树。独上高楼，望尽天涯路。 衣带渐宽终不悔，为伊消得人憔悴。 众里寻他千百度。蓦然回首，那人却在，灯火阑珊处。 分隔线 ---------------------------------------链接 [百度](http://www.baidu.com/ &amp;quot;百度一下&amp;quot;)百度
表格 | 账户 | 余额 | 类别 || :--- | :--- | :--- || 人民币 | 5百万 | 活期 || 比特币 | 5个 | 数字资产 || 股票基金 | 5亿 | 理财 |账户 余额 类别 人民币 5百万 活期 比特币 5个 数字资产 股票基金 5亿 理财 代码区域（四个空格） 1 2 3 4 /** 这是一个Java代码区块 */ public static void main(String[] args) { System.</description>
    </item>
    <item>
      <title>减缓焦虑，积聚生活正能量</title>
      <link>https://moge.fun/energy/</link>
      <pubDate>Thu, 01 Jan 2015 00:00:00 +0000</pubDate>
      <guid>https://moge.fun/energy/</guid>
      <description>面对不断袭来的压力和信息，我们要做的，就是找到自己的节奏，建立一套稳定的模式，用来应对和处理种种事务。尽可能让一切「平稳」下来。 这也许需要一些取舍，一些选择、牺牲和放弃 —— 但一旦这套模式能够建立起来，一切都是值得的。 思虑过载 变被动为主动，自己去决定「我要做什么」，重新找回「自主性」。
前一天晚上做好安排 整理一遍任务清单，从收集/待办的池子中， 挑出5-6个最重要、最关键的任务，安排到第二天 留出一定的宽裕度 做出取舍。该舍弃的，就果断舍弃。 与其把所有事情做到60分，不如把最重要的事情做到100分。 聚焦在长期价值上 不妨这样问问自己：我可以做些什么，来摆脱目前这种忙碌的状态？
无论是设计一套流程，还是把部分工作委托出去，又或者是把细碎的任务合并起来，还是优化、压缩任务步骤和时间……这些，长期来看都是更具价值的，也是你应该着重去聚焦的。 把它们作为你每天「最重要的事项」，想办法让自己能够抽身出来。
被压榨感 什么是被压榨感？它是指：自己一直在劳动和付出，但却始终得不到反馈、认可和肯定，仿佛自己的付出都是无价值的。
去发现生活中微小的幸福感。 决策疲劳 不要在晚上作出重要的决定。 通过给自己设立规则，让规则帮助自己作出决策。规则覆盖不到的地方，则用随机来解决。 外在打扰 建立你的「第二大脑」，把思维外部化。
信息过载 我们不断去追逐新信息，不断获取新鲜感的刺激，这本身是一个高耗能的行为 —— 但我们的大脑，会受到新鲜感的蛊惑，从而忽略和掩盖住这种耗能。
意识地克制自己，去做好信息的「反刍」，而非追逐新的信息。 试着把你记录的不同笔记放到一起，看看它们之间能产生什么联系，能否创造出新的火花。 在闲暇的碎片时间里，去反刍、回想自己记下的旧内容，尽量控制对新信息的摄入。 tips 一定要睡好。 睡眠过程中的深度睡眠，能够有效促进腺苷到ATP的水合反应，为我们的机体储存能量、清除代谢垃圾。 请保证每天6小时以上不受干扰的睡眠，这极其重要。
多散步。 散步是最轻松有效的锻炼。不但能够促进血清素的合成，也能有效扩充大脑容量。波士顿大学的一项研究表明，每天步行1小时（约5000步），相当于大脑延缓衰老1年。
适当的运动。 每周 150 分钟一定强度的运动，能够有效提高心肺功能，从而提高每一天精力的上限。
这才是精力管理的关键 —— 上限太低，再怎么「管理」，也是无效的。</description>
    </item>
    <item>
      <title>关于我</title>
      <link>https://moge.fun/about/</link>
      <pubDate>Thu, 01 Jan 2015 00:00:00 +0000</pubDate>
      <guid>https://moge.fun/about/</guid>
      <description>用写作触发思考。</description>
    </item>
    <item>
      <title>归档</title>
      <link>https://moge.fun/archives/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://moge.fun/archives/</guid>
      <description></description>
    </item>
    <item>
      <title>搜索</title>
      <link>https://moge.fun/search/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://moge.fun/search/</guid>
      <description></description>
    </item>
  </channel>
</rss>
