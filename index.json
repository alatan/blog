[{"categories":["微服务"],"content":"微服务最佳实践方案","date":"2020-03-15","objectID":"/springcloudalibaba/","tags":["SpringCloud"],"title":"微服务方案SpringCloudAlibaba","uri":"/springcloudalibaba/"},{"categories":["微服务"],"content":"Spring Cloud Alibaba 致力于提供微服务开发的一站式解决方案 ","date":"2020-03-15","objectID":"/springcloudalibaba/:0:0","tags":["SpringCloud"],"title":"微服务方案SpringCloudAlibaba","uri":"/springcloudalibaba/"},{"categories":["微服务"],"content":"组件 Nacos：一个更易于构建云原生应用的动态服务发现、配置管理和服务管理平台。 Sentinel：把流量作为切入点，从流量控制、熔断降级、系统负载保护等多个维度保护服务的稳定性。 Seata：阿里巴巴开源产品，一个易于使用的高性能微服务分布式事务解决方案。 ","date":"2020-03-15","objectID":"/springcloudalibaba/:0:1","tags":["SpringCloud"],"title":"微服务方案SpringCloudAlibaba","uri":"/springcloudalibaba/"},{"categories":["微服务"],"content":"微服务最佳实践 Spring Cloud - Gateway API网关 Spring Cloud - Ribbon 实现负载均衡 Spring Cloud - Feign 实现远程调用 Spring Cloud - Sleuth 实现调用链监控 Spring Cloud Alibaba - Nacos 实现注册中心 Spring Cloud Alibaba - Nacos 实现配置中心 Spring Cloud Alibaba - Sentinel 实现服务容错 Spring Cloud Alibaba - Seata 实现分布式事务 ","date":"2020-03-15","objectID":"/springcloudalibaba/:0:2","tags":["SpringCloud"],"title":"微服务方案SpringCloudAlibaba","uri":"/springcloudalibaba/"},{"categories":["分布式"],"content":"分布式基础介绍","date":"2020-03-10","objectID":"/distributed/","tags":["分布式"],"title":"分布式介绍","uri":"/distributed/"},{"categories":["分布式"],"content":"分布式理论基础 CAP 理论是分布式中基础理论，有三个重要指标：一致性、可用性、分区容错性。 一致性（Consistency） 可用性（Availability） 分区容错性（Partition Tolerance） ","date":"2020-03-10","objectID":"/distributed/:0:1","tags":["分布式"],"title":"分布式介绍","uri":"/distributed/"},{"categories":["知识体系"],"content":"Java架构演变历史","date":"2020-03-01","objectID":"/javaarchhistory/","tags":["大纲"],"title":"Java架构演变历史","uri":"/javaarchhistory/"},{"categories":["知识体系"],"content":"Java网站架构演变过程，大致分为5个阶段，分别为单体架构、集群架构、分布式架构、SOA架构和微服务架构。 ","date":"2020-03-01","objectID":"/javaarchhistory/:0:0","tags":["大纲"],"title":"Java架构演变历史","uri":"/javaarchhistory/"},{"categories":["知识体系"],"content":"单体架构 应用、数据库、文件都部署在一台机器上。简单来讲其实就是我们熟知的SSM架构(Spring+SpringMVC+MyBatis)，把所有的业务模块都放在一个应用中开发，这里面又衍生出三层架构，即表示层、业务逻辑层和数据库访问层，虽然在软件设计中划分了经典的三层模型，但是对业务场景没有划分，一个典型的单体应用就是将所有的业务场景的表示层、业务逻辑层和数据访问层放在一个工程项目中，最终经过编译、打包，部署在一台服务器上。 单体架构优点 部署简单: 由于是完整的结构体，可以直接部署在一个服务器上即可。 技术单一: 项目不需要复杂的技术栈，往往一套熟悉的技术栈就可以完成开发。 用人成本低: 单个程序员可以完成业务接口到数据库的整个流程。 单体架构缺点 系统启动慢： 一个进程包含了所有的业务逻辑，涉及到的启动模块过多，导致系统的启动、重启时间周期过长; 系统错误隔离性差、可用性差：任何一个模块的错误均可能造成整个系统的宕机; 可伸缩性差：系统的扩容只能只对这个应用进行扩容，不能做到对某个功能点进行扩容; 线上问题修复周期长：任何一个线上问题修复需要对整个应用系统进行全面升级。 ","date":"2020-03-01","objectID":"/javaarchhistory/:0:1","tags":["大纲"],"title":"Java架构演变历史","uri":"/javaarchhistory/"},{"categories":["知识体系"],"content":"集群架构 不同服务器部署同一套应用程序对外提供服务，实现服务的负载均衡或者互备(热备，主从)。同一种组件的多个实例，形成逻辑上的整体。单个节点可以提供完整服务，集群是物理形态。 集群架构相关技术点 应用和数据分离(大量用户高并发的访问导致系统性能越来越差，数据存储空间开始出现不足) 缓存的使用(QPS持续提高，为了降低接口访问时间、提高服务性能和并发，根据二八定律可以将80%的数据缓存) 负载均衡器的代理服务器 数据库读写分离 反向代理和CDN加速 ","date":"2020-03-01","objectID":"/javaarchhistory/:0:2","tags":["大纲"],"title":"Java架构演变历史","uri":"/javaarchhistory/"},{"categories":["知识体系"],"content":"分布式架构 服务的不同模块部署在不同的机器上，单个节点不能提供完整服务，需要多节点协调提供服务(相同组件部署在不同节点，节点间通过交互信息协作提供服务)，分布式强调的是工作方式。 分布式相关技术点 业务分库分表 NoSQL和搜索引擎对可伸缩的分布式特性具有更好的支持，应用服务器通过一个统一的数据访问模块访问各种数据，减轻应用程序管理诸多数据源的麻烦。 业务模块拆分成子项目 ","date":"2020-03-01","objectID":"/javaarchhistory/:0:3","tags":["大纲"],"title":"Java架构演变历史","uri":"/javaarchhistory/"},{"categories":["知识体系"],"content":"SOA架构 面向服务的设计架构，其中包含多个服务，服务之间通过相互依赖最终提供一系列的功能。一个服务通常以独立的形式存在于操作系统进程中。各个服务之间通过网络调用。 中心化实现：ESB(企业服务总线)，各服务通过ESB进行交互，解决异构系统之间的连通性，通过协议转换，消息解析，消息路由把服务提供者的数据传送到服务消费者。 去中心化实现：微服务 ","date":"2020-03-01","objectID":"/javaarchhistory/:0:4","tags":["大纲"],"title":"Java架构演变历史","uri":"/javaarchhistory/"},{"categories":["知识体系"],"content":"微服务架构 在SOA上做的升华，微服务架构强调业务需要彻底组件化和服务化，原有的单个业务系统会拆分为多个可独立开发，设计，运行的小应用。这些小应用通过服务完成交互和集成。 ","date":"2020-03-01","objectID":"/javaarchhistory/:0:5","tags":["大纲"],"title":"Java架构演变历史","uri":"/javaarchhistory/"},{"categories":["知识体系"],"content":"Java知识大纲","date":"2020-01-01","objectID":"/javaoutline/","tags":["大纲"],"title":"Java知识大纲","uri":"/javaoutline/"},{"categories":["知识体系"],"content":"基础 ","date":"2020-01-01","objectID":"/javaoutline/:1:0","tags":["大纲"],"title":"Java知识大纲","uri":"/javaoutline/"},{"categories":["知识体系"],"content":"数据结构与算法 ","date":"2020-01-01","objectID":"/javaoutline/:1:1","tags":["大纲"],"title":"Java知识大纲","uri":"/javaoutline/"},{"categories":["知识体系"],"content":"操作系统 ","date":"2020-01-01","objectID":"/javaoutline/:1:2","tags":["大纲"],"title":"Java知识大纲","uri":"/javaoutline/"},{"categories":["知识体系"],"content":"网络基础 ","date":"2020-01-01","objectID":"/javaoutline/:1:3","tags":["大纲"],"title":"Java知识大纲","uri":"/javaoutline/"},{"categories":["知识体系"],"content":"数据库基础 ","date":"2020-01-01","objectID":"/javaoutline/:1:4","tags":["大纲"],"title":"Java知识大纲","uri":"/javaoutline/"},{"categories":["知识体系"],"content":"编译原理 ","date":"2020-01-01","objectID":"/javaoutline/:1:5","tags":["大纲"],"title":"Java知识大纲","uri":"/javaoutline/"},{"categories":["知识体系"],"content":"Java ","date":"2020-01-01","objectID":"/javaoutline/:2:0","tags":["大纲"],"title":"Java知识大纲","uri":"/javaoutline/"},{"categories":["知识体系"],"content":"Java基础 ","date":"2020-01-01","objectID":"/javaoutline/:2:1","tags":["大纲"],"title":"Java知识大纲","uri":"/javaoutline/"},{"categories":["知识体系"],"content":"并发编程 ","date":"2020-01-01","objectID":"/javaoutline/:2:2","tags":["大纲"],"title":"Java知识大纲","uri":"/javaoutline/"},{"categories":["知识体系"],"content":"JVM ","date":"2020-01-01","objectID":"/javaoutline/:2:3","tags":["大纲"],"title":"Java知识大纲","uri":"/javaoutline/"},{"categories":["知识体系"],"content":"性能优化 性能指标体系 JVM调优 Tomcat调优 MySQL调优 ","date":"2020-01-01","objectID":"/javaoutline/:2:4","tags":["大纲"],"title":"Java知识大纲","uri":"/javaoutline/"},{"categories":["知识体系"],"content":"故障排除 ","date":"2020-01-01","objectID":"/javaoutline/:2:5","tags":["大纲"],"title":"Java知识大纲","uri":"/javaoutline/"},{"categories":["知识体系"],"content":"最佳实践 ","date":"2020-01-01","objectID":"/javaoutline/:3:0","tags":["大纲"],"title":"Java知识大纲","uri":"/javaoutline/"},{"categories":["知识体系"],"content":"重构 ","date":"2020-01-01","objectID":"/javaoutline/:3:1","tags":["大纲"],"title":"Java知识大纲","uri":"/javaoutline/"},{"categories":["知识体系"],"content":"设计模式 ","date":"2020-01-01","objectID":"/javaoutline/:3:2","tags":["大纲"],"title":"Java知识大纲","uri":"/javaoutline/"},{"categories":["知识体系"],"content":"开发框架 Spring体系 MyBatis ","date":"2020-01-01","objectID":"/javaoutline/:3:3","tags":["大纲"],"title":"Java知识大纲","uri":"/javaoutline/"},{"categories":["知识体系"],"content":"常见业务 支付幂等性 减库存 秒杀 分布式锁 redis实现的分布式锁。 应该保证互斥性（在任何时候只有一个客户端持有锁。使用setnx）。 不能死锁（设置过期时间）。 保证上锁和解锁是同一个客户端（设置不同的value值）。 业务时间太长。导致锁过期（设置看门狗。自动续锁）。 锁的重入性（使用redis的hset）。 分布式事务 分布式缓存 ","date":"2020-01-01","objectID":"/javaoutline/:3:4","tags":["大纲"],"title":"Java知识大纲","uri":"/javaoutline/"},{"categories":["知识体系"],"content":"中间价 ","date":"2020-01-01","objectID":"/javaoutline/:4:0","tags":["大纲"],"title":"Java知识大纲","uri":"/javaoutline/"},{"categories":["知识体系"],"content":"消息队列 ","date":"2020-01-01","objectID":"/javaoutline/:4:1","tags":["大纲"],"title":"Java知识大纲","uri":"/javaoutline/"},{"categories":["知识体系"],"content":"缓存 本地缓存 分布式缓存 ","date":"2020-01-01","objectID":"/javaoutline/:4:2","tags":["大纲"],"title":"Java知识大纲","uri":"/javaoutline/"},{"categories":["知识体系"],"content":"ELK ","date":"2020-01-01","objectID":"/javaoutline/:4:3","tags":["大纲"],"title":"Java知识大纲","uri":"/javaoutline/"},{"categories":["知识体系"],"content":"数据库 分库分表 数据同步 数据库连接池 ","date":"2020-01-01","objectID":"/javaoutline/:4:4","tags":["大纲"],"title":"Java知识大纲","uri":"/javaoutline/"},{"categories":["知识体系"],"content":"分布式 分布式架构原理 分布式架构策略 分布式中间件 分布式架构实战 ","date":"2020-01-01","objectID":"/javaoutline/:5:0","tags":["大纲"],"title":"Java知识大纲","uri":"/javaoutline/"},{"categories":["知识体系"],"content":"四大理论 拜占庭将军问题 CAP 理论 ACID 理论 BASE 理论 ","date":"2020-01-01","objectID":"/javaoutline/:5:1","tags":["大纲"],"title":"Java知识大纲","uri":"/javaoutline/"},{"categories":["知识体系"],"content":"八大协议/算法 Paxos 算法 Raft 算法 一致性 Hash 算法 Gossip 协议算法 Quorum NWR 算法 FBFT 算法 POW 算法 ZAB 协议 ","date":"2020-01-01","objectID":"/javaoutline/:5:2","tags":["大纲"],"title":"Java知识大纲","uri":"/javaoutline/"},{"categories":["知识体系"],"content":"微服务 ","date":"2020-01-01","objectID":"/javaoutline/:6:0","tags":["大纲"],"title":"Java知识大纲","uri":"/javaoutline/"},{"categories":["知识体系"],"content":"工具 版本管理 Git 项目管理 Maven/Gradle 代码质量管理 Sonar 持续集成部署 Jenkins\u0026GitLab CI/CD 监控系统 测试 Postman Jmeter VisualVM ","date":"2020-01-01","objectID":"/javaoutline/:7:0","tags":["大纲"],"title":"Java知识大纲","uri":"/javaoutline/"},{"categories":["Spring"],"content":"Spring总结","date":"2019-03-01","objectID":"/spring/","tags":["Spring","大纲"],"title":"Spring总结","uri":"/spring/"},{"categories":["Spring"],"content":" Spring 是一种轻量级开发框架，旨在提高开发人员的开发效率以及系统的可维护性。 我们一般说 Spring 框架指的都是 Spring Framework，它是很多模块的集合，使用这些模块可以很方便地协助我们进行开发。这些模块是：核心容器、数据访问/集成、Web、AOP（面向切面编程）、工具、消息和测试模块。比如：Core Container 中的 Core 组件是Spring 所有组件的核心，Beans 组件和 Context 组件是实现IOC和依赖注入的基础，AOP组件用来实现面向切面编程。 Spring 官网列出的 Spring 的 6 个特征: 核心技术 ：依赖注入(DI)，AOP，事件(events)，资源，i18n，验证，数据绑定，类型转换，SpEL。 测试 ：模拟对象，TestContext框架，Spring MVC 测试，WebTestClient。 数据访问 ：事务，DAO支持，JDBC，ORM，编组XML。 Web支持 : Spring MVC和Spring WebFlux Web框架。 集成 ：远程处理，JMS，JCA，JMX，电子邮件，任务，调度，缓存。 语言 ：Kotlin，Groovy，动态语言。 Spring模块\" Spring模块 ","date":"2019-03-01","objectID":"/spring/:0:0","tags":["Spring","大纲"],"title":"Spring总结","uri":"/spring/"},{"categories":["Spring"],"content":"IOC ","date":"2019-03-01","objectID":"/spring/:1:0","tags":["Spring","大纲"],"title":"Spring总结","uri":"/spring/"},{"categories":["Spring"],"content":"IOC容器初始化过程 BeanFactory和ApplicationContext是Spring中两种很重要的容器，前者提供了最基本的依赖注入的支持，后者在继承前者的基础上进行了功能的拓展，增加了事件传播，资源访问，国际化的支持等功能。同时两者的生命周期也稍微有些不同。 Spring IOC容器初始化过程分为Resource定位，载入解析，注册。IOC容器初始化过程中不包含Bean的依赖注入。Bean的依赖注入一般会发生在第一次通过getBean向容器索取Bean的时候。 IOC容器初始化过程\" IOC容器初始化过程 关键步骤 IOC容器初始化入口是在构造方法中调用refresh开始的。 通过ResourceLoader来完成资源文件位置的定位，DefaultResourceLoader是默认的实现，同时上下文本身就给除了ResourceLoader的实现。 创建的IOC容器是DefaultListableBeanFactory。 IOC对Bean的管理和依赖注入功能的实现是通过对其持有的BeanDefinition进行相关操作来完成的。 通过BeanDefinitionReader来完成定义信息的解析和Bean信息的注册。 XmlBeanDefinitionReader是BeanDefinitionReader的实现了，通过它来解析xml配置中的bean定义。 实际的处理过程是委托给BeanDefinitionParserDelegate来完成的。得到Bean的定义信息，这些信息在Spring中使用BeanDefinition对象来表示。 BeanDefinition的注册是由BeanDefinitionRegistry实现的registerBeanDefiition方法进行的。内部使用ConcurrentHashMap来保存BeanDefiition。 Spring解决循环依赖的过程总结 Spring在初始化Bean的时候，会先初始化当前Bean所依赖的Bean，如果两个Bean互相依赖，就产生了循环依赖，Spring针对循环依赖的办法是：提前曝光加上三个缓存singletonObjects、earlySingletonObjects、singletonFactories。 假设当前Bean是A，A依赖的Bean是B，B又依赖A。 提前曝光的意思就是，当前Bean A实例化完，还没有初始化完就先把当前Bean曝光出去，在B初始化需要依赖A的时候，就先拿到提前曝光的A，这样就可以继续将B初始化完成，然后返回A继续进行初始化。 循环依赖解决只针对单例Bean。 总结 Spring启动。 加载配置文件，xml、JavaConfig、注解、其他形式等等，将描述我们自己定义的和Spring内置的定义的Bean加载进来。 加载完配置文件后将配置文件转化成统一的Resource来处理。 使用Resource解析将我们定义的一些配置都转化成Spring内部的标识形式：BeanDefinition。 在低级的容器BeanFactory中，到这里就可以宣告Spring容器初始化完成了，Bean的初始化是在我们使用Bean的时候触发的；在高级的容器ApplicationContext中，会自动触发那些1. lazy-init=false的单例Bean，让Bean以及依赖的Bean进行初始化的流程，初始化完成Bean之后高级容器也初始化完成了。 在我们的应用中使用Bean。 Spring容器关闭，销毁各个Bean。 ","date":"2019-03-01","objectID":"/spring/:1:1","tags":["Spring","大纲"],"title":"Spring总结","uri":"/spring/"},{"categories":["Spring"],"content":"SpringBean生命周期 SpringBean生命周期\" SpringBean生命周期 手动或者自动的触发获取一个Bean，使用BeanFactory的时候需要我们代码自己获取Bean，ApplicationContext则是在IOC启动的时候自动初始化一个Bean。 IOC会根据BeanDefinition来实例化这个Bean，如果这个Bean还有依赖其他的Bean则会先初始化依赖的Bean，这里又涉及到了循环依赖的解决。实例化Bean的时候根据工厂方法、构造方法或者简单初始化等选择具体的实例来进行实例化，最终都是使用反射进行实例化。 Bean实例化完成，也就是一个对象实例化完成后，会继续填充这个Bean的各个属性，也是使用反射机制将属性设置到Bean中去。 填充完属性后，会调用各种Aware方法，将需要的组件设置到当前Bean中。BeanFactory这种低级容器需要我们手动注册Aware接口，而ApplicationContext这种高级容器在IOC启动的时候就自动给我们注册了Aware等接口。 接下来如果Bean实现了PostProcessor一系列的接口，会先调用其中的postProcessBeforeInitialization方法。BeanFactory这种低级容器需要我们手动注册PostProcessor接口，而ApplicationContext这种高级容器在IOC启动的时候就自动给我们注册了PostProcessor等接口。 如果Bean实现了InitializingBean接口，则会调用对应的afterPropertiesSet方法。 如果Bean设置了init-method属性，则会调用init-method指定的方法。 接下来如果Bean实现了PostProcessor一系列的接口，会先调用其中的postProcessAfterInitialization方法。BeanFactory这种低级容器需要我们手动注册PostProcessor接口，而 ApplicationContext这种高级容器在IOC启动的时候就自动给我们注册了PostProcessor等接口。 到这里Bean就可以使用了。 容器关闭的时候需要销毁Bean。 如果Bean实现了DisposableBean，则调用destroy方法。 如果Bean配置了destroy-method属性，则调用指定的destroy-method方法。 ","date":"2019-03-01","objectID":"/spring/:1:2","tags":["Spring","大纲"],"title":"Spring总结","uri":"/spring/"},{"categories":["Spring"],"content":"AOP Spring AOP流程大致上可以分为三个阶段：标签解析和AutoProxyCreator的注册、AOP代理的创建、代理的使用。 ","date":"2019-03-01","objectID":"/spring/:2:0","tags":["Spring","大纲"],"title":"Spring总结","uri":"/spring/"},{"categories":["Spring"],"content":"标签解析和AutoProxyCreator的注册 在Spring的扩展点中，最早期的扩展点是NamespaceHandler，这个阶段是在解析成BeanDefinition的阶段。Spring在这里完成自定义标签的解析工作，比如aop、tx等等。AOP功能在这里注册了自己的NamespaceHandler以及BeanDefinitionParser，用来将AOP标签转换成BeanDefinition交给IOC容器管理。 ","date":"2019-03-01","objectID":"/spring/:2:1","tags":["Spring","大纲"],"title":"Spring总结","uri":"/spring/"},{"categories":["Spring"],"content":"关于AutoProxyCreator的理解 同时在这里也会注册一个AutoProxyCreator，这个组件是用来在后面Bean的初始化过程中生成代理的。这个AutoProxtCreator实现了一个接口是：SmartInstantiationAwareBeanPostProcessor，看起来很眼熟，SmartInstantiationAwareBeanPostProcessor这个接口的父接口是：InstantiationAwareBeanPostProcessor，而InstantiationAwareBeanPostProcessor的父接口是BeanPostProcessor，到这里我们可能就大概明白了。 我们知道实现了BeanPostProcessor接口的类会在Bean初始化过程中的填充属性之后这一步被调用，调用的方法是postProcessBeforeInitialization和postProcessAfterInitialization。但是Spring干嘛还要衍生出那么多子接口呢？通过接口的名字我们可以看到不同，那些接口名字都含有一个关键词：Instantiation实例化，并不是初始化Initialization，也就是说这些接口中的方法调用是要在Bean实例化的时候进行处理。在Bean的生命周期中，我们知道Bean的实例化是Bean初始化步骤中最早的一步，所以对于Instantiation等方法的处理会比Initialization要早。 试想一下，我们自己写这些逻辑的时候，会在什么时候去创建AOP代理？第一个时间点：在Bean实例化之前，我就通过创建代理的逻辑直接返回一个代理好的实例，就不用继续走Bean初始化的后面的步骤了；第二个时间点：在Bean初始化之后，也就是走完了所有的Bean初始化过程后生成了一个完整的Bean，我再进行代理的创建。Spring就是这么处理的，要么我就不用Spring创建Bean，我直接返回一个代理，要么我就等Spring创建完成一个Bean再返回一个代理。Spring还有会另外一个触发点创建代理：getEarlyBeanReference，用来在解决循环依赖时提前曝光的Bean的代理生成，暂时不做说明。 ","date":"2019-03-01","objectID":"/spring/:2:2","tags":["Spring","大纲"],"title":"Spring总结","uri":"/spring/"},{"categories":["Spring"],"content":"AOP代理创建 明确了代理创建的时间点，就可以继续看AOP代理的创建过程了。 筛选出所有适合当前Bean的通知器，也就是所有的Advisor、Advise、Interceptor。 选择使用JDK还是CGLIB来进行创建代理。 使用具体的代理实现来创建代理。 ","date":"2019-03-01","objectID":"/spring/:2:3","tags":["Spring","大纲"],"title":"Spring总结","uri":"/spring/"},{"categories":["Spring"],"content":"代理的使用 获取当前调用方法的拦截器链，包含了所有将要执行的advice。 如果没有任何拦截器，直接执行目标方法。 如果有拦截器存在，则将拦截器和目标方法封装成一个MethodInvocation，递归调用proceed方法进行调用。 上面的处理中还有对目标对象的自我方法调用实施增强的处理，比如平时遇到的问题：在同一个类中一个方法调用另外一个带事务注解的方法，事务不会生效；在同一个类中一个方法调用另外一个带缓存注解的方法，缓存不会生效。 以上就是大概的流程，总结一下就是：AOP实现使用的是动态代理和拦截器链。 ","date":"2019-03-01","objectID":"/spring/:2:4","tags":["Spring","大纲"],"title":"Spring总结","uri":"/spring/"},{"categories":["Spring"],"content":"SpringMVC执行流程 用户请求发送到前端控制器DispatcherServlet。 前端控制器DispatcherServlet接收到请求后，DispatcherServlet会使用HandlerMapping来处理，HandlerMapping会查找到具体进行处理请求的Handler对象。 HandlerMapping找到对应的Handler之后，并不是返回一个Handler原始对象，而是一个Handler执行链，在这个执行链中包括了拦截器和处理请求的Handler。HandlerMapping返回一个执行链给DispatcherServlet。 DispatcherServlet接收到执行链之后，会调用Handler适配器去执行Handler。 Handler适配器执行完成Handler（也就是我们写的Controller）之后会得到一个ModelAndView，并返回给DispatcherServlet。 DispatcherServlet接收到Handler适配器返回的ModelAndView之后，会根据其中的视图名调用视图解析器。 视图解析器根据逻辑视图名解析成一个真正的View视图，并返回给DispatcherServlet。 DispatcherServlet接收到视图之后，会根据上面的ModelAndView中的model来进行视图中数据的填充，也就是所谓的视图渲染。 渲染完成之后，DispatcherServlet就可以将结果返回给用户了。 ","date":"2019-03-01","objectID":"/spring/:3:0","tags":["Spring","大纲"],"title":"Spring总结","uri":"/spring/"},{"categories":["Spring"],"content":"SpringBoot自动配置的原理 需要先了解一下Spring的@Import注解和@Enable注解的实现原理，以及SpringFactoriesLoader的实现，再来看SpringBoot的自动配置原理就基本上会明白了。 SpringBoot应用一般都会在主类上注解@SpringBootApplication，这个注解上有@EnableAutoConfiguration注解，一般@Enable注解上都会有@Import注解，这里也不例外，有个@Import(EnableAutoConfigurationImportSelector.class)。 EnableAutoConfigurationImportSelector是一个ImportSelector，Spring在初始化的时候会调用invokeBeanFactoryPostProcessor，这里会调用实现了接口BeanDefinitionRegistryPostProcessor的postProcessBeanDefinitionRegistry方法，ConfigurationClassPostProcessor也实现了此接口，在该方法postProcessBeanDefinitionRegistry中会处理@Configuration相关注解，这里就进行了@Import注解的处理。对于ImportSelector，会调用它的selectImports方法进行处理。 EnableAutoConfigurationImportSelector的selectImports方法中会先使用SpringFactoriesLoader在classpath下的spring.factories文件中来加载@EnableAutoConfiguration类型的各种实现类，也包括各种starter中和我们自定义的starter中的对应实现类。SpringBoot中预先配置的EnableAutoConfiguration可以在spring-boot-project/spring-boot-autoconfigure/src/main/resources/META-INF/spring.factories中查询，配置了很多很多个自动配置类。 加载完这些配置类的名字后，经过一系列的校验等操作，就会把所有的EnableAutoConfiguration实现类的名字都返回给Spring，Spring会继续的处理这些配置类，也就是处理这些配置类中的@Configuration、@Import这些注解，继续递归处理这些注解，最后把相关的Bean都注册到容器中。 ","date":"2019-03-01","objectID":"/spring/:4:0","tags":["Spring","大纲"],"title":"Spring总结","uri":"/spring/"},{"categories":["Spring"],"content":"总结 @SpringBootApplication等同于下面三个注解： @SpringBootConfiguration @EnableAutoConfiguration @ComponentScan 其中@EnableAutoConfiguration是关键(启用自动配置)，内部实际上就去加载META-INF/spring.factories文件的信息，然后筛选出以EnableAutoConfiguration为key的数据，加载到IOC容器中，实现自动配置功能！ ","date":"2019-03-01","objectID":"/spring/:4:1","tags":["Spring","大纲"],"title":"Spring总结","uri":"/spring/"},{"categories":["数据库"],"content":"MyBatis总结","date":"2019-01-02","objectID":"/mybatis/","tags":["ORM","大纲"],"title":" MyBatis总结","uri":"/mybatis/"},{"categories":["数据库"],"content":"MyBatis框架整体设计\" MyBatis框架整体设计 ","date":"2019-01-02","objectID":"/mybatis/:0:0","tags":["ORM","大纲"],"title":" MyBatis总结","uri":"/mybatis/"},{"categories":["数据库"],"content":"接口层-和数据库交互的方式 MyBatis和数据库的交互有两种方式： 使用传统的MyBatis提供的API； 使用Mapper接口； ","date":"2019-01-02","objectID":"/mybatis/:1:0","tags":["ORM","大纲"],"title":" MyBatis总结","uri":"/mybatis/"},{"categories":["缓存"],"content":"Redis概览","date":"2019-01-01","objectID":"/redis/","tags":["缓存","大纲"],"title":"Redis概览","uri":"/redis/"},{"categories":["缓存"],"content":"Redis总览\" Redis总览 Redis是一款内存高速缓存数据库。Redis全称为：Remote Dictionary Server（远程数据服务. ，Redis是一种支持key-value等多种数据结构的存储系统。可用于缓存，事件发布或订阅，高速队列等场景。支持网络，提供字符串，哈希，列表，队列，集合结构直接存取，基于内存，可持久化。 ","date":"2019-01-01","objectID":"/redis/:0:0","tags":["缓存","大纲"],"title":"Redis概览","uri":"/redis/"},{"categories":["缓存"],"content":"基础数据类型 Redis所有的key（键. 都是字符串。我们在谈基础数据结构时，讨论的是存储值的数据类型，主要包括常见的5种数据类型，分别是：String、List、Set、Zset、Hash 结构类型 结构存储的值 结构的读写能力 String字符串 可以是字符串、整数或浮点数 对整个字符串或字符串的一部分进行操作；对整数或浮点数进行自增或自减操作； List列表 一个链表，链表上的每个节点都包含一个字符串 对链表的两端进行push和pop操作，读取单个或多个元素；根据值查找或删除元素； Set集合 包含字符串的无序集合 字符串的集合，包含基础的方法有看是否存在添加、获取、删除；还包含计算交集、并集、差集等 Hash散列 包含键值对的无序散列表 包含方法有添加、获取、删除单个元素 Zset有序集合 和散列一样，用于存储键值对 字符串成员与浮点数分数之间的有序映射；元素的排列顺序由分数的大小决定；包含方法有添加、获取、删除单个元素以及根据分值范围或成员来获取元素 ","date":"2019-01-01","objectID":"/redis/:1:0","tags":["缓存","大纲"],"title":"Redis概览","uri":"/redis/"},{"categories":["缓存"],"content":"持久化 为了防止数据丢失以及服务重启时能够恢复数据，Redis支持数据的持久化，主要分为两种方式，分别是RDB和AOF; 当然实际场景下还会使用这两种的混合模式 ","date":"2019-01-01","objectID":"/redis/:2:0","tags":["缓存","大纲"],"title":"Redis概览","uri":"/redis/"},{"categories":["缓存"],"content":"RDB 持久化 RDB 就是 Redis DataBase 的缩写，中文名为快照/内存快照，RDB持久化是把当前进程数据生成快照保存到磁盘上的过程，由于是某一时刻的快照，那么快照中的值要早于或者等于内存中的值。 触发方式 手动触发 save命令：阻塞当前Redis服务器，直到RDB过程完成为止，对于内存 比较大的实例会造成长时间阻塞，线上环境不建议使用 bgsave命令：Redis进程执行fork操作创建子进程，RDB持久化过程由子 进程负责，完成后自动结束。阻塞只发生在fork阶段，一般时间很短 bgsave命令具体流程如下： redis客户端执行bgsave命令或者自动触发bgsave命令； 主进程判断当前是否已经存在正在执行的子进程，如果存在，那么主进程直接返回； 如果不存在正在执行的子进程，那么就fork一个新的子进程进行持久化数据，fork过程是阻塞的，fork操作完成后主进程即可执行其他操作； 子进程先将数据写入到临时的rdb文件中，待快照数据写入完成后再原子替换旧的rdb文件； 同时发送信号给主进程，通知主进程rdb持久化完成，主进程更新相关的统计信息（info Persitence下的rdb_*相关选项. 。 自动触发 在以下4种情况时会自动触发 redis.conf中配置save m n，即在m秒内有n次修改时，自动触发bgsave生成rdb文件； 主从复制时，从节点要从主节点进行全量复制时也会触发bgsave操作，生成当时的快照发送到从节点； 执行debug reload命令重新加载redis时也会触发bgsave操作； 默认情况下执行shutdown命令时，如果没有开启aof持久化，那么也会触发bgsave操作； RDB优缺点 优点 RDB文件是某个时间节点的快照，默认使用LZF算法进行压缩，压缩后的文件体积远远小于内存大小，适用于备份、全量复制等场景； Redis加载RDB文件恢复数据要远远快于AOF方式； 缺点 RDB方式实时性不够，无法做到秒级的持久化； 每次调用bgsave都需要fork子进程，fork子进程属于重量级操作，频繁执行成本较高； RDB文件是二进制的，没有可读性，AOF文件在了解其结构的情况下可以手动修改或者补全； 版本兼容RDB文件问题； ","date":"2019-01-01","objectID":"/redis/:2:1","tags":["缓存","大纲"],"title":"Redis概览","uri":"/redis/"},{"categories":["缓存"],"content":"AOF 持久化 Redis是“写后”日志，Redis先执行命令，把数据写入内存，然后才记录日志。日志里记录的是Redis收到的每一条命令，这些命令是以文本形式保存。PS: 大多数的数据库采用的是写前日志（WAL. ，例如MySQL，通过写前日志和两阶段提交，实现数据和逻辑的一致性。 ","date":"2019-01-01","objectID":"/redis/:2:2","tags":["缓存","大纲"],"title":"Redis概览","uri":"/redis/"},{"categories":["缓存"],"content":"RDB和AOF混合方式（4.0版本) Redis 4.0 中提出了一个混合使用 AOF 日志和内存快照的方法。简单来说，内存快照以一定的频率执行，在两次快照之间，使用 AOF 日志记录这期间的所有命令操作。 ","date":"2019-01-01","objectID":"/redis/:2:3","tags":["缓存","大纲"],"title":"Redis概览","uri":"/redis/"},{"categories":["缓存"],"content":"从持久化中恢复数据 流程如下： redis重启时判断是否开启aof，如果开启了aof，那么就优先加载aof文件； 如果aof存在，那么就去加载aof文件，加载成功的话redis重启成功，如果aof文件加载失败，那么会打印日志表示启动失败，此时可以去修复aof文件后重新启动； 若aof文件不存在，那么redis就会转而去加载rdb文件，如果rdb文件不存在，redis直接启动成功； 如果rdb文件存在就会去加载rdb文件恢复数据，如加载失败则打印日志提示启动失败，如加载成功，那么redis重启成功，且使用rdb文件恢复数据； 那么为什么会优先加载AOF呢？因为AOF保存的数据更完整，通过上面的分析我们知道AOF基本上最多损失1s的数据。 ","date":"2019-01-01","objectID":"/redis/:2:4","tags":["缓存","大纲"],"title":"Redis概览","uri":"/redis/"},{"categories":["缓存"],"content":"Redis事务 Redis 事务的本质是一组命令的集合。事务支持一次执行多个命令，一个事务中所有命令都会被序列化。在事务执行过程，会按照顺序串行化执行队列中的命令，其他客户端提交的命令请求不会插入到事务执行命令序列中。 总结说：redis事务就是一次性、顺序性、排他性的执行一个队列中的一系列命令。 ","date":"2019-01-01","objectID":"/redis/:3:0","tags":["缓存","大纲"],"title":"Redis概览","uri":"/redis/"},{"categories":["缓存"],"content":"高可用：主从复制 我们知道要避免单点故障，即保证高可用，便需要冗余（副本. 方式提供集群服务。而Redis 提供了主从库模式，以保证数据副本的一致，主从库之间采用的是读写分离的方式。 主从复制，是指将一台Redis服务器的数据，复制到其他的Redis服务器。前者称为主节点(master)，后者称为从节点(slave)；数据的复制是单向的，只能由主节点到从节点。 读操作：主库、从库都可以接收； 写操作：首先到主库执行，然后，主库将写操作同步给从库。 主从复制的作用主要包括： 数据冗余：主从复制实现了数据的热备份，是持久化之外的一种数据冗余方式。 故障恢复：当主节点出现问题时，可以由从节点提供服务，实现快速的故障恢复；实际上是一种服务的冗余。 负载均衡：在主从复制的基础上，配合读写分离，可以由主节点提供写服务，由从节点提供读服务（即写Redis数据时应用连接主节点，读Redis数据时应用连接从节点. ，分担服务器负载；尤其是在写少读多的场景下，通过多个从节点分担读负载，可以大大提高Redis服务器的并发量。 高可用基石：除了上述作用以外，主从复制还是哨兵和集群能够实施的基础，因此说主从复制是Redis高可用的基础。 ","date":"2019-01-01","objectID":"/redis/:4:0","tags":["缓存","大纲"],"title":"Redis概览","uri":"/redis/"},{"categories":["缓存"],"content":"主从复制原理 全量复制 当我们启动多个 Redis 实例的时候，它们相互之间就可以通过 replicaof（Redis 5.0 之前使用 slaveof. 命令形成主库和从库的关系，之后会按照三个阶段完成数据的第一次同步。 全量复制\" 全量复制 增量复制 增量复制\" 增量复制 ","date":"2019-01-01","objectID":"/redis/:4:1","tags":["缓存","大纲"],"title":"Redis概览","uri":"/redis/"},{"categories":["缓存"],"content":"高可用：哨兵机制（Redis Sentinel. 如果主节点出现故障该怎么办呢？ 在 Redis 主从集群中，哨兵机制是实现主从库自动切换的关键机制，它有效地解决了主从复制模式下故障转移的问题。 主要功能： 监控（Monitoring. ：哨兵会不断地检查主节点和从节点是否运作正常。 自动故障转移（Automatic failover. ：当主节点不能正常工作时，哨兵会开始自动故障转移操作，它会将失效主节点的其中一个从节点升级为新的主节点，并让其他从节点改为复制新的主节点。 配置提供者（Configuration provider. ：客户端在初始化时，通过连接哨兵来获得当前Redis服务的主节点地址。 通知（Notification. ：哨兵可以将故障转移的结果发送给客户端。 ","date":"2019-01-01","objectID":"/redis/:5:0","tags":["缓存","大纲"],"title":"Redis概览","uri":"/redis/"},{"categories":["缓存"],"content":"高可拓展：分片技术（Redis Cluster) 主从复制和哨兵机制保障了高可用，就读写分离而言虽然slave节点扩展了主从的读并发能力，但是写能力和存储能力是无法进行扩展，就只能是master节点能够承载的上限。如果面对海量数据那么必然需要构建master（主节点分片)之间的集群，同时必然需要吸收高可用（主从复制和哨兵机制. 能力，即每个master分片节点还需要有slave节点，这是分布式系统中典型的纵向扩展（集群的分片技术. 的体现；所以在Redis 3.0版本中对应的设计就是Redis Cluster。 ","date":"2019-01-01","objectID":"/redis/:6:0","tags":["缓存","大纲"],"title":"Redis概览","uri":"/redis/"},{"categories":["缓存"],"content":"缓存问题 Redis最常用的一个场景就是作为缓存，在实践中可能会有哪些问题？比如一致性, 穿击, 穿透, 雪崩, 污染等。 ","date":"2019-01-01","objectID":"/redis/:7:0","tags":["缓存","大纲"],"title":"Redis概览","uri":"/redis/"},{"categories":["缓存"],"content":"缓存穿透 缓存穿透是指缓存和数据库中都没有的数据，而用户不断发起请求。由于缓存是不命中时被动写的，并且出于容错考虑，如果从存储层查不到数据则不写入缓存，这将导致这个不存在的数据每次请求都要到存储层去查询，失去了缓存的意义。 在流量大时，可能DB就挂掉了，要是有人利用不存在的key频繁攻击我们的应用，这就是漏洞。如发起为id为“-1”的数据或id为特别大不存在的数据。这时的用户很可能是攻击者，攻击会导致数据库压力过大。 解决方案： 接口层增加校验，如用户鉴权校验，id做基础校验，id\u003c=0的直接拦截； 从缓存取不到的数据，在数据库中也没有取到，这时也可以将key-value对写为key-null，缓存有效时间可以设置短点，如30秒（设置太长会导致正常情况也没法使用. 。这样可以防止攻击用户反复用同一个id暴力攻击 布隆过滤器。bloomfilter就类似于一个hash set，用于快速判某个元素是否存在于集合中，其典型的应用场景就是快速判断一个key是否存在于某容器，不存在就直接返回。布隆过滤器的关键就在于hash算法和容器大小。 ","date":"2019-01-01","objectID":"/redis/:7:1","tags":["缓存","大纲"],"title":"Redis概览","uri":"/redis/"},{"categories":["缓存"],"content":"缓存击穿 缓存击穿是指缓存中没有但数据库中有的数据（一般是缓存时间到期)，这时由于并发用户特别多，同时读缓存没读到数据，又同时去数据库去取数据，引起数据库压力瞬间增大，造成过大压力。 解决方案 设置热点数据永远不过期。 接口限流与熔断，降级。重要的接口一定要做好限流策略，防止用户恶意刷接口，同时要降级准备，当接口中的某些服务不可用时候，进行熔断，失败快速返回机制。 加互斥锁. ","date":"2019-01-01","objectID":"/redis/:7:2","tags":["缓存","大纲"],"title":"Redis概览","uri":"/redis/"},{"categories":["缓存"],"content":"缓存雪崩 缓存雪崩是指缓存中数据大批量到过期时间，而查询数据量巨大，引起数据库压力过大甚至down机。和缓存击穿不同的是，缓存击穿指并发查同一条数据，缓存雪崩是不同数据都过期了，很多数据都查不到从而查数据库。 解决方案： 缓存数据的过期时间设置随机，防止同一时间大量数据过期现象发生。 如果缓存数据库是分布式部署，将热点数据均匀分布在不同的缓存数据库中。 设置热点数据永远不过期。 ","date":"2019-01-01","objectID":"/redis/:7:3","tags":["缓存","大纲"],"title":"Redis概览","uri":"/redis/"},{"categories":["缓存"],"content":"缓存污染（或满了) 缓存污染问题说的是缓存中一些只会被访问一次或者几次的的数据，被访问完后，再也不会被访问到，但这部分数据依然留存在缓存中，消耗缓存空间。 缓存污染会随着数据的持续增加而逐渐显露，随着服务的不断运行，缓存中会存在大量的永远不会再次被访问的数据。缓存空间是有限的，如果缓存空间满了，再往缓存里写数据时就会有额外开销，影响Redis性能。这部分额外开销主要是指写的时候判断淘汰策略，根据淘汰策略去选择要淘汰的数据，然后进行删除操作。 缓存淘汰策略 不淘汰 noevictionv4.0后默认的。 对设置了过期时间的数据中进行淘汰 随机：volatile-random ttl：volatile-ttl 越早过期的数据越优先被选择。 lru：volatile-lru LRU算法：LRU 算法的全称是 Least Recently Used，按照最近最少使用的原则来筛选数据。这种模式下会使用 LRU 算法筛选设置了过期时间的键值对。 lfu：volatile-lfu LFU 算法：LFU 缓存策略是在 LRU 策略基础上，为每个数据增加了一个计数器，来统计这个数据的访问次数。当使用 LFU 策略筛选淘汰数据时，首先会根据数据的访问次数进行筛选，把访问次数最低的数据淘汰出缓存。如果两个数据的访问次数相同，LFU 策略再比较这两个数据的访问时效性，把距离上一次访问时间更久的数据淘汰出缓存。 全部数据进行淘汰 随机：allkeys-random lru：allkeys-lru lfu：allkeys-lfu ","date":"2019-01-01","objectID":"/redis/:7:4","tags":["缓存","大纲"],"title":"Redis概览","uri":"/redis/"},{"categories":["缓存"],"content":"数据库和缓存一致性 方案：队列 + 重试机制 流程如下所示 更新数据库数据； 缓存因为种种问题删除失败 将需要删除的key发送至消息队列 自己消费消息，获得需要删除的key 继续重试删除操作，直到成功 然而，该方案有一个缺点，对业务线代码造成大量的侵入。于是有了方案二，在方案二中，启动一个订阅程序去订阅数据库的binlog，获得需要操作的数据。在应用程序中，另起一段程序，获得这个订阅程序传来的信息，进行删除缓存操作。 方案：异步更新缓存(基于订阅binlog的同步机制) MySQL binlog增量订阅消费+消息队列+增量数据更新到redis 读Redis：热数据基本都在Redis 写MySQL: 增删改都是操作MySQL 更新Redis数据：MySQL的数据操作binlog，来更新到Redis 读取binlog后分析 ，利用消息队列,推送更新各台的redis缓存数据。 这样一旦MySQL中产生了新的写入、更新、删除等操作，就可以把binlog相关的消息推送至Redis，Redis再根据binlog中的记录，对Redis进行更新。 其实这种机制，很类似MySQL的主从备份机制，因为MySQL的主备也是通过binlog来实现的数据一致性。 这里可以结合使用canal(阿里的一款开源框架)，通过该框架可以对MySQL的binlog进行订阅，而canal正是模仿了mysql的slave数据库的备份请求，使得Redis的数据更新达到了相同的效果。 当然，这里的消息推送工具你也可以采用别的第三方：kafka、rabbitMQ等来实现推送更新Redis。 ","date":"2019-01-01","objectID":"/redis/:7:5","tags":["缓存","大纲"],"title":"Redis概览","uri":"/redis/"},{"categories":["缓存"],"content":"参考文章 持久化 高可用：主从复制 缓存问题 3种常用的缓存读写策略 ","date":"2019-01-01","objectID":"/redis/:8:0","tags":["缓存","大纲"],"title":"Redis概览","uri":"/redis/"},{"categories":["Java基础"],"content":"JVM详解","date":"2018-04-20","objectID":"/jvm/","tags":["JVM","大纲"],"title":"JVM详解","uri":"/jvm/"},{"categories":["Java基础"],"content":"JVM概览\" JVM概览 ","date":"2018-04-20","objectID":"/jvm/:0:0","tags":["JVM","大纲"],"title":"JVM详解","uri":"/jvm/"},{"categories":["Java基础"],"content":"Class文件的结构属性 类的结构\" 类的结构 ","date":"2018-04-20","objectID":"/jvm/:1:0","tags":["JVM","大纲"],"title":"JVM详解","uri":"/jvm/"},{"categories":["Java基础"],"content":"Java类加载机制 ","date":"2018-04-20","objectID":"/jvm/:2:0","tags":["JVM","大纲"],"title":"JVM详解","uri":"/jvm/"},{"categories":["Java基础"],"content":"类的生命周期 类的生命周期\" 类的生命周期 ","date":"2018-04-20","objectID":"/jvm/:2:1","tags":["JVM","大纲"],"title":"JVM详解","uri":"/jvm/"},{"categories":["Java基础"],"content":"类加载器 启动类加载器: Bootstrap ClassLoader，负责加载存放在JDK\\jre\\lib(JDK代表JDK的安装目录，下同)下，或被-Xbootclasspath参数指定的路径中的，并且能被虚拟机识别的类库(如rt.jar，所有的java.*开头的类均被Bootstrap ClassLoader加载)。启动类加载器是无法被Java程序直接引用的。 扩展类加载器: Extension ClassLoader，该加载器由sun.misc.Launcher$ExtClassLoader实现，它负责加载JDK\\jre\\lib\\ext目录中，或者由java.ext.dirs系统变量指定的路径中的所有类库(如javax.*开头的类)，开发者可以直接使用扩展类加载器。 应用程序类加载器: Application ClassLoader，该类加载器由sun.misc.Launcher$AppClassLoader来实现，它负责加载用户类路径(ClassPath)所指定的类，开发者可以直接使用该类加载器，如果应用程序中没有自定义过自己的类加载器，一般情况下这个就是程序中默认的类加载器。 ","date":"2018-04-20","objectID":"/jvm/:2:2","tags":["JVM","大纲"],"title":"JVM详解","uri":"/jvm/"},{"categories":["Java基础"],"content":"JVM类加载机制 全盘负责，当一个类加载器负责加载某个Class时，该Class所依赖的和引用的其他Class也将由该类加载器负责载入，除非显示使用另外一个类加载器来载入 父类委托，先让父类加载器试图加载该类，只有在父类加载器无法加载该类时才尝试从自己的类路径中加载该类 缓存机制，缓存机制将会保证所有加载过的Class都会被缓存，当程序中需要使用某个Class时，类加载器先从缓存区寻找该Class，只有缓存区不存在，系统才会读取该类对应的二进制数据，并将其转换成Class对象，存入缓存区。这就是为什么修改了Class后，必须重启JVM，程序的修改才会生效 双亲委派机制, 如果一个类加载器收到了类加载的请求，它首先不会自己去尝试加载这个类，而是把请求委托给父加载器去完成，依次向上，因此，所有的类加载请求最终都应该被传递到顶层的启动类加载器中，只有当父加载器在它的搜索范围中没有找到所需的类时，即无法完成该加载，子加载器才会尝试自己去加载该类。 ","date":"2018-04-20","objectID":"/jvm/:2:3","tags":["JVM","大纲"],"title":"JVM详解","uri":"/jvm/"},{"categories":["Java基础"],"content":"JVM 内存结构 JVM内存结构\" JVM内存结构 栈是运行时的单位，而堆是存储的单位。（栈解决程序的运行问题，即程序如何执行，或者说如何处理数据。堆解决的是数据存储的问题，即数据怎么放、放在哪。） Java虚拟机栈用于管理Java方法的调用，而本地方法栈用于管理本地方法的调用。 ","date":"2018-04-20","objectID":"/jvm/:3:0","tags":["JVM","大纲"],"title":"JVM详解","uri":"/jvm/"},{"categories":["Java基础"],"content":"程序计数器 它是一块很小的内存空间，几乎可以忽略不计。也是运行速度最快的存储区域 在 JVM 规范中，每个线程都有它自己的程序计数器，是线程私有的，生命周期与线程的生命周期一致 任何时间一个线程都只有一个方法在执行，也就是所谓的当前方法。如果当前线程正在执行的是 Java 方法，程序计数器记录的是 JVM 字节码指令地址，如果是执行 native 方法，则是未指定值（undefined） 它是程序控制流的指示器，分支、循环、跳转、异常处理、线程恢复等基础功能都需要依赖这个计数器来完成 字节码解释器工作时就是通过改变这个计数器的值来选取下一条需要执行的字节码指令 它是唯一一个在 JVM 规范中没有规定任何 OutOfMemoryError 情况的区域 ","date":"2018-04-20","objectID":"/jvm/:3:1","tags":["JVM","大纲"],"title":"JVM详解","uri":"/jvm/"},{"categories":["Java基础"],"content":"虚拟机栈 是线程私有的，生命周期和线程一致。 主管 Java 程序的运行，它保存方法的局部变量、部分结果，并参与方法的调用和返回。 栈是一种快速有效的分配存储方式，访问速度仅次于程序计数器。 JVM 直接对虚拟机栈的操作只有两个：每个方法执行，伴随着入栈（进栈/压栈），方法执行结束出栈。 栈不存在垃圾回收问题。 ","date":"2018-04-20","objectID":"/jvm/:3:2","tags":["JVM","大纲"],"title":"JVM详解","uri":"/jvm/"},{"categories":["Java基础"],"content":"本地方法栈 Java 虚拟机栈用于管理 Java 方法的调用，而本地方法栈用于管理本地方法的调用 本地方法栈也是线程私有的 允许线程固定或者可动态扩展的内存大小 如果线程请求分配的栈容量超过本地方法栈允许的最大容量，Java 虚拟机将会抛出一个 StackOverflowError 异常 如果本地方法栈可以动态扩展，并且在尝试扩展的时候无法申请到足够的内存，或者在创建新的线程时没有足够的内存去创建对应的本地方法栈，那么 Java虚拟机将会抛出一个OutofMemoryError异常 本地方法是使用 C 语言实现的 它的具体做法是 Native Method Stack 中登记 native 方法，在 Execution Engine 执行时加载本地方法库当某个线程调用一个本地方法时，它就进入了一个全新的并且不再受虚拟机限制的世界。它和虚拟机拥有同样的权限。 本地方法可以通过本地方法接口来访问虚拟机内部的运行时数据区，它甚至可以直接使用本地处理器中的寄存器，直接从本地内存的堆中分配任意数量的内存 并不是所有 JVM 都支持本地方法。因为 Java 虚拟机规范并没有明确要求本地方法栈的使用语言、具体实现方式、数据结构等。 如果 JVM 产品不打算支持 native 方法，也可以无需实现本地方法栈 在 Hotspot JVM 中，直接将本地方法栈和虚拟机栈合二为一 ","date":"2018-04-20","objectID":"/jvm/:3:3","tags":["JVM","大纲"],"title":"JVM详解","uri":"/jvm/"},{"categories":["Java基础"],"content":"堆内存 为了进行高效的垃圾回收，虚拟机把堆内存逻辑上划分成三块区域（分代的唯一理由就是优化 GC 性能）： 新生带（年轻代）：新对象和没达到一定年龄的对象都在新生代 老年代（养老区）：被长时间使用的对象，老年代的内存空间应该要比年轻代更大 元空间（JDK1.8 之前叫永久代）：像一些方法中的操作临时对象等，JDK1.8 之前是占用 JVM 内存，JDK1.8 之后直接使用物理内存 年轻代 年轻代是所有新对象创建的地方。当填充年轻代时，执行垃圾收集。这种垃圾收集称为 Minor GC。年轻一代被分为三个部分——伊甸园（Eden Memory）和两个幸存区（Survivor Memory，被称为from/to或s0/s1），默认比例是8:1:1 大多数新创建的对象都位于 Eden 内存空间中 当 Eden 空间被对象填充时，执行Minor GC，并将所有幸存者对象移动到一个幸存者空间中 Minor GC 检查幸存者对象，并将它们移动到另一个幸存者空间。所以每次，一个幸存者空间总是空的 经过多次 GC 循环后存活下来的对象被移动到老年代。通常，这是通过设置年轻一代对象的年龄阈值来实现的，然后他们才有资格提升到老一代 老年代 旧的一代内存包含那些经过许多轮小型 GC 后仍然存活的对象。通常，垃圾收集是在老年代内存满时执行的。老年代垃圾收集称为 主GC（Major GC），通常需要更长的时间。 大对象直接进入老年代（大对象是指需要大量连续内存空间的对象）。这样做的目的是避免在 Eden 区和两个Survivor 区之间发生大量的内存拷贝 堆内存空间\" 堆内存空间 ","date":"2018-04-20","objectID":"/jvm/:3:4","tags":["JVM","大纲"],"title":"JVM详解","uri":"/jvm/"},{"categories":["Java基础"],"content":"元空间\u0026方法区 方法区（method area）只是 JVM 规范中定义的一个概念，用于存储类信息、常量池、静态变量、JIT编译后的代码等数据，并没有规定如何去实现它，不同的厂商有不同的实现。而永久代（PermGen）是 Hotspot 虚拟机特有的概念， Java8 的时候又被元空间取代了，永久代和元空间都可以理解为方法区的落地实现。 永久代物理是堆的一部分，和新生代，老年代地址是连续的（受垃圾回收器管理），而元空间存在于本地内存（我们常说的堆外内存，不受垃圾回收器管理），这样就不受 JVM 限制了，也比较难发生OOM（都会有溢出异常） Java7 中我们通过-XX:PermSize 和 -xx:MaxPermSize 来设置永久代参数，Java8 之后，随着永久代的取消，这些参数也就随之失效了，改为通过-XX:MetaspaceSize 和 -XX:MaxMetaspaceSize 用来设置元空间参数 存储内容不同，元空间存储类的元信息，静态变量和常量池等并入堆中。相当于永久代的数据被分到了堆和元空间中 如果方法区域中的内存不能用于满足分配请求，则 Java 虚拟机抛出 OutOfMemoryError JVM 规范说方法区在逻辑上是堆的一部分，但目前实际上是与 Java 堆分开的（Non-Heap） 所以对于方法区，Java8 之后的变化： 移除了永久代（PermGen），替换为元空间（Metaspace）； 永久代中的 class metadata 转移到了 native memory（本地内存，而不是虚拟机）； 永久代中的 interned Strings 和 class static variables 转移到了 Java heap； 永久代参数 （PermSize MaxPermSize） -\u003e 元空间参数（MetaspaceSize MaxMetaspaceSize 对象在堆中的生命周期 在 JVM 内存模型的堆中，堆被划分为新生代和老年代 新生代又被进一步划分为 Eden区 和 Survivor区，Survivor 区由 From Survivor 和 To Survivor 组成 当创建一个对象时，对象会被优先分配到新生代的 Eden 区 此时 JVM 会给对象定义一个对象年轻计数器（-XX:MaxTenuringThreshold） 当 Eden 空间不足时，JVM 将执行新生代的垃圾回收（Minor GC） JVM 会把存活的对象转移到 Survivor 中，并且对象年龄 +1 对象在 Survivor 中同样也会经历 Minor GC，每经历一次 Minor GC，对象年龄都会+1 如果分配的对象超过了-XX:PetenureSizeThreshold，对象会直接被分配到老年代 对象的分配过程 为对象分配内存是一件非常严谨和复杂的任务，JVM 的设计者们不仅需要考虑内存如何分配、在哪里分配等问题，并且由于内存分配算法和内存回收算法密切相关，所以还需要考虑 GC 执行完内存回收后是否会在内存空间中产生内存碎片。 new 的对象先放在伊甸园区，此区有大小限制 当伊甸园的空间填满时，程序又需要创建对象，JVM 的垃圾回收器将对伊甸园区进行垃圾回收（Minor GC），将伊甸园区中的不再被其他对象所引用的对象进行销毁。再加载新的对象放到伊甸园区 然后将伊甸园中的剩余对象移动到幸存者 0 区 如果再次触发垃圾回收，此时上次幸存下来的放到幸存者 0 区，如果没有回收，就会放到幸存者 1 区 如果再次经历垃圾回收，此时会重新放回幸存者 0 区，接着再去幸存者 1 区 什么时候才会去养老区呢？ 默认是 15 次回收标记 在养老区，相对悠闲。当养老区内存不足时，再次触发 Major GC，进行养老区的内存清理 若养老区执行了 Major GC 之后发现依然无法进行对象的保存，就会产生 OOM 异常 ","date":"2018-04-20","objectID":"/jvm/:3:5","tags":["JVM","大纲"],"title":"JVM详解","uri":"/jvm/"},{"categories":["Java基础"],"content":"JVM内存模型(JMM) Java内存模型，其实是保证了Java程序在各种平台下对内存的访问都能够得到一致效果的机制及规范。目的是解决由于多线程通过共享内存进行通信时，存在的原子性、可见性（缓存一致性）以及有序性问题。 ","date":"2018-04-20","objectID":"/jvm/:4:0","tags":["JVM","大纲"],"title":"JVM详解","uri":"/jvm/"},{"categories":["Java基础"],"content":"并发编程模型的分类 在并发编程中，我们需要处理两个关键问题：线程之间如何通信及线程之间如何同步（这里的线程是指并发执行的活动实体）。通信是指线程之间以何种机制来交换信息。在命令式编程中，线程之间的通信机制有两种：共享内存和消息传递。 在共享内存的并发模型里，线程之间共享程序的公共状态，线程之间通过写 - 读内存中的公共状态来隐式进行通信。在消息传递的并发模型里，线程之间没有公共状态，线程之间必须通过明确的发送消息来显式进行通信。 同步是指程序用于控制不同线程之间操作发生相对顺序的机制。在共享内存并发模型里，同步是显式进行的。程序员必须显式指定某个方法或某段代码需要在线程之间互斥执行。在消息传递的并发模型里，由于消息的发送必须在消息的接收之前，因此同步是隐式进行的。 Java 的并发采用的是共享内存模型，Java 线程之间的通信总是隐式进行，整个通信过程对程序员完全透明。如果编写多线程程序的 Java 程序员不理解隐式进行的线程之间通信的工作机制，很可能会遇到各种奇怪的内存可见性问题。 ","date":"2018-04-20","objectID":"/jvm/:4:1","tags":["JVM","大纲"],"title":"JVM详解","uri":"/jvm/"},{"categories":["Java基础"],"content":"Java 内存模型的抽象 JMM 通过控制主内存与每个线程的本地内存之间的交互，来为 java 程序员提供内存可见性保证。 Java 线程之间的通信由 Java 内存模型（本文简称为 JMM）控制，JMM 决定一个线程对共享变量的写入何时对另一个线程可见。从抽象的角度来看，JMM 定义了线程和主内存之间的抽象关系：线程之间的共享变量存储在主内存（main memory）中，每个线程都有一个私有的本地内存（local memory），本地内存中存储了该线程以读 / 写共享变量的副本。本地内存是 JMM 的一个抽象概念，并不真实存在。它涵盖了缓存，写缓冲区，寄存器以及其他的硬件和编译器优化。Java内存模型的抽象示意图如下： Java内存模型的抽象示意图\" Java内存模型的抽象示意图 ","date":"2018-04-20","objectID":"/jvm/:4:2","tags":["JVM","大纲"],"title":"JVM详解","uri":"/jvm/"},{"categories":["Java基础"],"content":"重排序 在执行程序时为了提高性能，编译器和处理器常常会对指令做重排序。重排序分三种类型： 编译器优化的重排序。编译器在不改变单线程程序语义的前提下，可以重新安排语句的执行顺序。 指令级并行的重排序。现代处理器采用了指令级并行技术（Instruction-Level Parallelism， ILP）来将多条指令重叠执行。如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序。 内存系统的重排序。由于处理器使用缓存和读 / 写缓冲区，这使得加载和存储操作看上去可能是在乱序执行。 从 java 源代码到最终实际执行的指令序列，会分别经历下面三种重排序： JMM指令重排序\" JMM指令重排序 上述的 1 属于编译器重排序，2 和 3 属于处理器重排序。这些重排序都可能会导致多线程程序出现内存可见性问题。对于编译器，JMM 的编译器重排序规则会禁止特定类型的编译器重排序（不是所有的编译器重排序都要禁止）。对于处理器重排序，JMM 的处理器重排序规则会要求 java 编译器在生成指令序列时，插入特定类型的内存屏障（memory barriers，intel 称之为 memory fence）指令，通过内存屏障指令来禁止特定类型的处理器重排序（不是所有的处理器重排序都要禁止）。 JMM属于语言级的内存模型，它确保在不同的编译器和不同的处理器平台之上，通过禁止特定类型的编译器重排序和处理器重排序，为程序员提供一致的内存可见性保证。 ","date":"2018-04-20","objectID":"/jvm/:4:3","tags":["JVM","大纲"],"title":"JVM详解","uri":"/jvm/"},{"categories":["Java基础"],"content":"处理器重排序与内存屏障指令 为了保证内存可见性，java编译器在生成指令序列的适当位置会插入内存屏障指令来禁止特定类型的处理器重排序。 StoreLoad Barriers 是一个“全能型”的屏障，它同时具有其他三个屏障的效果。现代的多处理器大都支持该屏障（其他类型的屏障不一定被所有处理器支持）。执行该屏障开销会很昂贵，因为当前处理器通常要把写缓冲区中的数据全部刷新到内存中（buffer fully flush）。 ","date":"2018-04-20","objectID":"/jvm/:4:4","tags":["JVM","大纲"],"title":"JVM详解","uri":"/jvm/"},{"categories":["Java基础"],"content":"happens-before 从 JDK5 开始，java 使用新的 JSR -133 内存模型（本文除非特别说明，针对的都是 JSR- 133 内存模型）。JSR-133 提出了 happens-before 的概念，通过这个概念来阐述操作之间的内存可见性。如果一个操作执行的结果需要对另一个操作可见，那么这两个操作之间必须存在 happens-before 关系。这里提到的两个操作既可以是在一个线程之内，也可以是在不同线程之间。 与程序员密切相关的 happens-before 规则如下： 程序顺序规则：一个线程中的每个操作，happens- before 于该线程中的任意后续操作。 监视器锁规则：对一个监视器锁的解锁，happens- before 于随后对这个监视器锁的加锁。 volatile 变量规则：对一个 volatile 域的写，happens- before 于任意后续对这个 volatile 域的读。 传递性：如果 A happens- before B，且 B happens- before C，那么 A happens- before C。 ","date":"2018-04-20","objectID":"/jvm/:4:5","tags":["JVM","大纲"],"title":"JVM详解","uri":"/jvm/"},{"categories":["Java基础"],"content":"Java垃圾回收 ","date":"2018-04-20","objectID":"/jvm/:5:0","tags":["JVM","大纲"],"title":"JVM详解","uri":"/jvm/"},{"categories":["Java基础"],"content":"判断一个对象是否可被回收 引用计数算法 给对象添加一个引用计数器，当对象增加一个引用时计数器加 1，引用失效时计数器减 1。引用计数为 0 的对象可被回收。 两个对象出现循环引用的情况下，此时引用计数器永远不为 0，导致无法对它们进行回收。 正因为循环引用的存在，因此 Java 虚拟机不使用引用计数算法。 可达性分析算法 通过 GC Roots 作为起始点进行搜索，能够到达到的对象都是存活的，不可达的对象可被回收，Java 虚拟机使用该算法来判断对象是否可被回收，在 Java 中 GC Roots 一般包含以下内容: 虚拟机栈中引用的对象 本地方法栈中引用的对象 方法区中类静态属性引用的对象 方法区中的常量引用的对象 方法区的回收 因为方法区主要存放永久代对象，而永久代对象的回收率比新生代低很多，因此在方法区上进行回收性价比不高。 主要是对常量池的回收和对类的卸载，在大量使用反射、动态代理、CGLib 等 ByteCode 框架、动态生成 JSP 以及 OSGi 这类频繁自定义 ClassLoader 的场景都需要虚拟机具备类卸载功能，以保证不会出现内存溢出。 类的卸载条件很多，需要满足以下三个条件，并且满足了也不一定会被卸载: 该类所有的实例都已经被回收，也就是堆中不存在该类的任何实例。 加载该类的 ClassLoader 已经被回收。 该类对应的 Class 对象没有在任何地方被引用，也就无法在任何地方通过反射访问该类方法。 finalize() finalize() 类似 C++ 的析构函数，用来做关闭外部资源等工作。但是 try-finally 等方式可以做的更好，并且该方法运行代价高昂，不确定性大，无法保证各个对象的调用顺序，因此最好不要使用。 当一个对象可被回收时，如果需要执行该对象的 finalize() 方法，那么就有可能通过在该方法中让对象重新被引用，从而实现自救。自救只能进行一次，如果回收的对象之前调用了 finalize() 方法自救，后面回收时不会调用 finalize() 方法。 ","date":"2018-04-20","objectID":"/jvm/:5:1","tags":["JVM","大纲"],"title":"JVM详解","uri":"/jvm/"},{"categories":["Java基础"],"content":"垃圾回收算法 标记 - 清除 将存活的对象进行标记，然后清理掉未被标记的对象。 不足: 标记和清除过程效率都不高； 会产生大量不连续的内存碎片，导致无法给大对象分配内存。 标记 - 整理 让所有存活的对象都向一端移动，然后直接清理掉端边界以外的内存。 复制 将内存划分为大小相等的两块，每次只使用其中一块，当这一块内存用完了就将还存活的对象复制到另一块上面，然后再把使用过的内存空间进行一次清理。 主要不足是只使用了内存的一半。 现在的商业虚拟机都采用这种收集算法来回收新生代，但是并不是将新生代划分为大小相等的两块，而是分为一块较大的 Eden 空间和两块较小的 Survivor 空间，每次使用 Eden 空间和其中一块 Survivor。在回收时，将 Eden 和 Survivor 中还存活着的对象一次性复制到另一块 Survivor 空间上，最后清理 Eden 和使用过的那一块 Survivor。 HotSpot 虚拟机的 Eden 和 Survivor 的大小比例默认为 8:1，保证了内存的利用率达到 90%。如果每次回收有多于 10% 的对象存活，那么一块 Survivor 空间就不够用了，此时需要依赖于老年代进行分配担保，也就是借用老年代的空间存储放不下的对象。 分代收集 现在的商业虚拟机采用分代收集算法，它根据对象存活周期将内存划分为几块，不同块采用适当的收集算法。 一般将堆分为新生代和老年代。 新生代使用: 复制算法 老年代使用: 标记 - 清除 或者 标记 - 整理 算法 ","date":"2018-04-20","objectID":"/jvm/:5:2","tags":["JVM","大纲"],"title":"JVM详解","uri":"/jvm/"},{"categories":["Java基础"],"content":"垃圾收集器 垃圾收集器\" 垃圾收集器 垃圾收集器对比\" 垃圾收集器对比 ","date":"2018-04-20","objectID":"/jvm/:5:3","tags":["JVM","大纲"],"title":"JVM详解","uri":"/jvm/"},{"categories":["Java基础"],"content":"内存分配与回收策略 Minor GC 和 Full GC Minor GC: 发生在新生代上，因为新生代对象存活时间很短，因此 Minor GC 会频繁执行，执行的速度一般也会比较快。 Full GC: 发生在老年代上，老年代对象其存活时间长，因此 Full GC 很少执行，执行速度会比 Minor GC 慢很多。 针对 HotSpot VM 的实现，它里面的 GC 按照回收区域又分为两大类：部分收集（Partial GC），整堆收集（Full GC） 部分收集：不是完整收集整个 Java 堆的垃圾收集。其中又分为： 新生代收集（Minor GC/Young GC）：只是新生代的垃圾收集 老年代收集（Major GC/Old GC）：只是老年代的垃圾收集 目前，只有 CMS GC 会有单独收集老年代的行为 很多时候 Major GC 会和 Full GC 混合使用，需要具体分辨是老年代回收还是整堆回收 混合收集（Mixed GC）：收集整个新生代以及部分老年代的垃圾收集 目前只有 G1 GC 会有这种行为 整堆收集（Full GC）：收集整个 Java 堆和方法区的垃圾 内存分配策略 对象优先在 Eden 分配 大对象直接进入老年代 长期存活的对象进入老年代 动态对象年龄判定 空间分配担保 ","date":"2018-04-20","objectID":"/jvm/:5:4","tags":["JVM","大纲"],"title":"JVM详解","uri":"/jvm/"},{"categories":["Java基础"],"content":"JVM 调优参数 ","date":"2018-04-20","objectID":"/jvm/:6:0","tags":["JVM","大纲"],"title":"JVM详解","uri":"/jvm/"},{"categories":["Java基础"],"content":"JVM参数 -Xms 堆最小值 -Xmx 堆最大堆值。-Xms与-Xmx 的单位默认字节都是以k、m做单位的。 通常这两个配置参数相等，避免每次空间不足，动态扩容带来的影响。 -Xmn 新生代大小 -Xss 每个线程池的堆栈大小。 在jdk5以上的版本，每个线程堆栈大小为1m，jdk5以前的版本是每个线程池大小为256k。一般在相同物理内存下，如果减少－xss值会产生更大的线程数，但不同的操作系统对进程内线程数是有限制的，是不能无限生成。 -XX:NewRatio 设置新生代与老年代比值，-XX:NewRatio=4 表示新生代与老年代所占比例为1:4 ，新生代占比整个堆的五分之一。如果设置了-Xmn的情况下，该参数是不需要在设置的。 -XX:PermSize 设置持久代初始值，默认是物理内存的六十四分之一 -XX:MaxPermSize 设置持久代最大值，默认是物理内存的四分之一 -XX:MaxTenuringThreshold 新生代中对象存活次数，默认15。(若对象在eden区，经历一次MinorGC后还活着，则被移动到Survior区，年龄加1。以后，对象每次经历MinorGC，年龄都加1。达到阀值，则移入老年代) -XX:SurvivorRatio Eden区与Subrvivor区大小的比值，如果设置为8，两个Subrvivor区与一个Eden区的比值为2:8，一个Survivor区占整个新生代的十分之一 -XX:+UseFastAccessorMethods 原始类型快速优化 -XX:+AggressiveOpts 编译速度加快 -XX:PretenureSizeThreshold 对象超过多大值时直接在老年代中分配 ","date":"2018-04-20","objectID":"/jvm/:6:1","tags":["JVM","大纲"],"title":"JVM详解","uri":"/jvm/"},{"categories":["Java基础"],"content":"最佳实践 Xmn用于设置新生代的大小。过小会增加Minor GC频率，过大会减小老年代的大小。一般设为整个堆空间的1/4或1/3. XX:SurvivorRatio用于设置新生代中survivor空间(from/to)和eden空间的大小比例；XX:TargetSurvivorRatio表示，当经历Minor GC后，survivor空间占有量(百分比)超过它的时候，就会压缩进入老年代(当然，如果survivor空间不够，则直接进入老年代)。默认值为50%。 为了性能考虑，一开始尽量将新生代对象留在新生代，避免新生的大对象直接进入老年代。因为新生对象大部分都是短期的，这就造成了老年代的内存浪费，并且回收代价也高(Full GC发生在老年代和方法区Perm) 当Xms=Xmx，可以使得堆相对稳定，避免不停震荡 一般来说，MaxPermSize设为64MB可以满足绝大多数的应用了。若依然出现方法区溢出，则可以设为128MB。若128MB还不能满足需求，那么就应该考虑程序优化了，减少动态类的产生。 ","date":"2018-04-20","objectID":"/jvm/:6:2","tags":["JVM","大纲"],"title":"JVM详解","uri":"/jvm/"},{"categories":["Java基础"],"content":"JVM分析和问题排查 ","date":"2018-04-20","objectID":"/jvm/:7:0","tags":["JVM","大纲"],"title":"JVM详解","uri":"/jvm/"},{"categories":["Java基础"],"content":"参考文章 https://www.pdai.tech/md/java/jvm/java-jvm-jmm.html https://www.pdai.tech/md/java/jvm/java-jvm-struct.html https://www.pdai.tech/md/java/jvm/java-jvm-x-introduce.html ","date":"2018-04-20","objectID":"/jvm/:8:0","tags":["JVM","大纲"],"title":"JVM详解","uri":"/jvm/"},{"categories":["Java基础"],"content":"ConcurrentHashMap详解","date":"2018-04-10","objectID":"/concurrenthashmap/","tags":["数据结构"],"title":"ConcurrentHashMap详解","uri":"/concurrenthashmap/"},{"categories":["Java基础"],"content":"ConcurrentHashMap详解 ","date":"2018-04-10","objectID":"/concurrenthashmap/:0:0","tags":["数据结构"],"title":"ConcurrentHashMap详解","uri":"/concurrenthashmap/"},{"categories":["Java基础"],"content":"AbstractQueuedSynchronizer详解","date":"2018-04-05","objectID":"/abstractqueuedsynchronizer/","tags":["并发编程"],"title":"AbstractQueuedSynchronizer详解","uri":"/abstractqueuedsynchronizer/"},{"categories":["Java基础"],"content":"AQS\" AQS 上图中有颜色的为Method，无颜色的为Attribution。 总的来说，AQS框架共分为五层，自上而下由浅入深，从AQS对外暴露的API到底层基础数据。 当有自定义同步器接入时，只需重写第一层所需要的部分方法即可，不需要关注底层具体的实现流程。当自定义同步器进行加锁或者解锁操作时，先经过第一层的API进入AQS内部方法，然后经过第二层进行锁的获取，接着对于获取锁失败的流程，进入第三层和第四层的等待队列处理，而这些处理方式均依赖于第五层的基础数据提供层。 ","date":"2018-04-05","objectID":"/abstractqueuedsynchronizer/:0:0","tags":["并发编程"],"title":"AbstractQueuedSynchronizer详解","uri":"/abstractqueuedsynchronizer/"},{"categories":["Java基础"],"content":"原理概览 AQS核心思想是，如果被请求的共享资源空闲，那么就将当前请求资源的线程设置为有效的工作线程，将共享资源设置为锁定状态；如果共享资源被占用，就需要一定的阻塞等待唤醒机制来保证锁分配。这个机制主要用的是CLH队列的变体实现的，将暂时获取不到锁的线程加入到队列中。 CLH(Craig,Landin,and Hagersten)队列是一个虚拟的双向队列(虚拟的双向队列即不存在队列实例，仅存在结点之间的关联关系)。AQS是将每条请求共享资源的线程封装成一个CLH锁队列的一个结点(Node)来实现锁的分配。 AQS使用一个Volatile的int类型的成员变量来表示同步状态，通过内置的FIFO队列来完成资源获取的排队工作，通过CAS完成对State值的修改。 private volatile int state;//共享变量，使用volatile修饰保证线程可见性 ","date":"2018-04-05","objectID":"/abstractqueuedsynchronizer/:1:0","tags":["并发编程"],"title":"AbstractQueuedSynchronizer详解","uri":"/abstractqueuedsynchronizer/"},{"categories":["Java基础"],"content":"AQS数据结构 AQS数据结构\" AQS数据结构 ","date":"2018-04-05","objectID":"/abstractqueuedsynchronizer/:2:0","tags":["并发编程"],"title":"AbstractQueuedSynchronizer详解","uri":"/abstractqueuedsynchronizer/"},{"categories":["Java基础"],"content":"线程两种资源共享方式 Share(共享)：多个线程可同时执行，如Semaphore/CountDownLatch。Semaphore、CountDownLatCh、 CyclicBarrier、ReadWriteLock。 Exclusive(独占)：只有一个线程能执行，如ReentrantLock。又可分为公平锁和非公平锁： 公平锁：按照线程在队列中的排队顺序，先到者先拿到锁 非公平锁：当线程要获取锁时，无视队列顺序直接去抢锁，谁抢到就是谁的 ReentrantReadWriteLock可以看成是组合式，因为ReentrantReadWriteLock是读写锁允许多个线程同时对某一资源进行读。 不同的自定义同步器争用共享资源的方式也不同。自定义同步器在实现时只需要实现共享资源state的获取与释放方式即可，至于具体线程等待队列的维护(如获取资源失败入队/唤醒出队等)，AQS已经在上层已经帮我们实现好了。 ","date":"2018-04-05","objectID":"/abstractqueuedsynchronizer/:2:1","tags":["并发编程"],"title":"AbstractQueuedSynchronizer详解","uri":"/abstractqueuedsynchronizer/"},{"categories":["Java基础"],"content":"属性值的含义 waitStatus 当前节点在队列中的状态 thread 表示处于该节点的线程 prev 前驱指针 predecessor 返回前驱节点，没有的话抛出npe nextWaiter 指向下一个处于CONDITION状态的节点（由于本篇文章不讲述Condition Queue队列，这个指针不多介绍） next 后继指针 ","date":"2018-04-05","objectID":"/abstractqueuedsynchronizer/:2:2","tags":["并发编程"],"title":"AbstractQueuedSynchronizer详解","uri":"/abstractqueuedsynchronizer/"},{"categories":["Java基础"],"content":"waitStatus（节点状态） 0，表示当前节点在sync queue中，等待着获取锁。 SIGNAL 为-1，表示线程已经准备好了，就等资源释放了,表示当前节点的后继节点包含的线程需要运行，需要进行unpark操作。 CANCELLED 为1，表示线程获取锁的请求已经取消了 CONDITION 为-2，表示当前节点在等待condition，也就是在condition queue中，节点线程等待唤醒 PROPAGATE 为-3，表示当前场景下后续的acquireShared能够得以执行。 AQS独占模式加锁\" AQS独占模式加锁 AQS共享模式加锁\" AQS共享模式加锁 ","date":"2018-04-05","objectID":"/abstractqueuedsynchronizer/:2:3","tags":["并发编程"],"title":"AbstractQueuedSynchronizer详解","uri":"/abstractqueuedsynchronizer/"},{"categories":["Java基础"],"content":"AQS重要方法与ReentrantLock的关联 ","date":"2018-04-05","objectID":"/abstractqueuedsynchronizer/:3:0","tags":["并发编程"],"title":"AbstractQueuedSynchronizer详解","uri":"/abstractqueuedsynchronizer/"},{"categories":["Java基础"],"content":"方法 AQS使用了模板方法模式，自定义同步器时需要重写下面几个AQS提供的模板方法 protected boolean isHeldExclusively() 该线程是否正在独占资源。只有用到Condition才需要去实现它。 protected boolean tryAcquire(int arg) 独占方式。arg为获取锁的次数，尝试获取资源，成功则返回True，失败则返回False。 protected boolean tryRelease(int arg) 独占方式。arg为释放锁的次数，尝试释放资源，成功则返回True，失败则返回False。 protected int tryAcquireShared(int arg) 共享方式。arg为获取锁的次数，尝试获取资源。负数表示失败；0表示成功，但没有剩余可用资源；正数表示成功，且有剩余资源。 protected boolean tryReleaseShared(int arg) 共享方式。arg为释放锁的次数，尝试释放资源，如果释放后允许唤醒后续等待结点返回True，否则返回False。 默认情况下，每个方法都抛出 UnsupportedOperationException。 这些方法的实现必须是内部线程安全的，并且通常应该简短而不是阻塞。AQS类中的其他方法都是final ，所以无法被其他类使用，只有这几个方法可以被其他类使用。 以ReentrantLock为例，state初始化为0，表示未锁定状态。A线程lock()时，会调用tryAcquire()独占该锁并将state+1。此后，其他线程再tryAcquire()时就会失败，直到A线程unlock()到state=0(即释放锁)为止，其它线程才有机会获取该锁。当然，释放锁之前，A线程自己是可以重复获取此锁的(state会累加)，这就是可重入的概念。但要注意，获取多少次就要释放多么次，这样才能保证state是能回到零态的。 一般来说，自定义同步器要么是独占方式，要么是共享方式，它们也只需实现tryAcquire-tryRelease、tryAcquireShared-tryReleaseShared中的一种即可。AQS也支持自定义同步器同时实现独占和共享两种方式，如ReentrantReadWriteLock。ReentrantLock是独占锁，所以实现了tryAcquire-tryRelease。 以非公平锁为例，这里主要阐述一下非公平锁与AQS之间方法的关联之处，具体每一处核心方法的作用会在文章后面详细进行阐述。 ReentrantLock加锁流程\" ReentrantLock加锁流程 为了帮助大家理解ReentrantLock和AQS之间方法的交互过程，以非公平锁为例，我们将加锁和解锁的交互流程单独拎出来强调一下，以便于对后续内容的理解。 ReentrantLock流程梳理\" ReentrantLock流程梳理 ","date":"2018-04-05","objectID":"/abstractqueuedsynchronizer/:3:1","tags":["并发编程"],"title":"AbstractQueuedSynchronizer详解","uri":"/abstractqueuedsynchronizer/"},{"categories":["Java基础"],"content":"加锁： 通过ReentrantLock的加锁方法Lock进行加锁操作。 会调用到内部类Sync的Lock方法，由于Sync#lock是抽象方法，根据ReentrantLock初始化选择的公平锁和非公平锁，执行相关内部类的Lock方法，本质上都会执行AQS的Acquire方法。 AQS的Acquire方法会执行tryAcquire方法，但是由于tryAcquire需要自定义同步器实现，因此执行了ReentrantLock中的tryAcquire方法，由于ReentrantLock是通过公平锁和非公平锁内部类实现的tryAcquire方法，因此会根据锁类型不同，执行不同的tryAcquire。 tryAcquire是获取锁逻辑，获取失败后，会执行框架AQS的后续逻辑，跟ReentrantLock自定义同步器无关。 ","date":"2018-04-05","objectID":"/abstractqueuedsynchronizer/:3:2","tags":["并发编程"],"title":"AbstractQueuedSynchronizer详解","uri":"/abstractqueuedsynchronizer/"},{"categories":["Java基础"],"content":"解锁： 通过ReentrantLock的解锁方法Unlock进行解锁。 Unlock会调用内部类Sync的Release方法，该方法继承于AQS。 Release中会调用tryRelease方法，tryRelease需要自定义同步器实现，tryRelease只在ReentrantLock中的Sync实现，因此可以看出，释放锁的过程，并不区分是否为公平锁。 释放成功后，所有处理由AQS框架完成，与自定义同步器无关。 通过上面的描述，大概可以总结出ReentrantLock加锁解锁时API层核心方法的映射关系。 ReentrantLock映射关系\" ReentrantLock映射关系 ","date":"2018-04-05","objectID":"/abstractqueuedsynchronizer/:3:3","tags":["并发编程"],"title":"AbstractQueuedSynchronizer详解","uri":"/abstractqueuedsynchronizer/"},{"categories":["Java基础"],"content":"通过ReentrantLock理解AQS ReentrantLock中公平锁和非公平锁在底层是相同的，这里以非公平锁为例进行分析。 // java.util.concurrent.locks.ReentrantLock static final class NonfairSync extends Sync { ... final void lock() { if (compareAndSetState(0, 1)) setExclusiveOwnerThread(Thread.currentThread()); else acquire(1); } ... } // java.util.concurrent.locks.AbstractQueuedSynchronizer public final void acquire(int arg) { if (!tryAcquire(arg) \u0026\u0026 acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt(); } // java.util.concurrent.locks.AbstractQueuedSynchronizer protected boolean tryAcquire(int arg) { throw new UnsupportedOperationException(); } 可以看出，这里只是AQS的简单实现，具体获取锁的实现方法是由各自的公平锁和非公平锁单独实现的（以ReentrantLock为例）。如果该方法返回了True，则说明当前线程获取锁成功，就不用往后执行了；如果获取失败，就需要加入到等待队列中。下面会详细解释线程是何时以及怎样被加入进等待队列中的。 ","date":"2018-04-05","objectID":"/abstractqueuedsynchronizer/:4:0","tags":["并发编程"],"title":"AbstractQueuedSynchronizer详解","uri":"/abstractqueuedsynchronizer/"},{"categories":["Java基础"],"content":"线程加入等待队列 加入队列的时机 当执行Acquire(1)时，会通过tryAcquire获取锁。在这种情况下，如果获取锁失败，就会调用addWaiter加入到等待队列中去。 如何加入队列 获取锁失败后，会执行addWaiter(Node.EXCLUSIVE)加入等待队列，具体实现方法如下： // java.util.concurrent.locks.AbstractQueuedSynchronizer private Node addWaiter(Node mode) { Node node = new Node(Thread.currentThread(), mode); // Try the fast path of enq; backup to full enq on failure Node pred = tail; if (pred != null) { node.prev = pred; if (compareAndSetTail(pred, node)) { pred.next = node; return node; } } enq(node); return node; } private final boolean compareAndSetTail(Node expect, Node update) { return unsafe.compareAndSwapObject(this, tailOffset, expect, update); } 主要的流程如下： 通过当前的线程和锁模式新建一个节点。 Pred指针指向尾节点Tail。 将New中Node的Prev指针指向Pred。 通过compareAndSetTail方法，完成尾节点的设置。这个方法主要是对tailOffset和Expect进行比较，如果tailOffset的Node和Expect的Node地址是相同的，那么设置Tail的值为Update的值。 如果Pred指针是Null（说明等待队列中没有元素），或者当前Pred指针和Tail指向的位置不同（说明被别的线程已经修改），就需要看一下Enq的方法。 // java.util.concurrent.locks.AbstractQueuedSynchronizer private Node enq(final Node node) { for (;;) { Node t = tail; if (t == null) { // Must initialize if (compareAndSetHead(new Node())) tail = head; } else { node.prev = t; if (compareAndSetTail(t, node)) { t.next = node; return t; } } } } 如果没有被初始化，需要进行初始化一个头结点出来。但请注意，初始化的头结点并不是当前线程节点，而是调用了无参构造函数的节点。如果经历了初始化或者并发导致队列中有元素，则与之前的方法相同。其实，addWaiter就是一个在双端链表添加尾节点的操作，需要注意的是，双端链表的头结点是一个无参构造函数的头结点。 总结一下，线程获取锁的时候，过程大体如下： 当没有线程获取到锁时，线程1获取锁成功。 线程2申请锁，但是锁被线程1占有。 如果再有线程要获取锁，依次在队列中往后排队即可。 等待队列中线程出队列时机 回到最初的源码： // java.util.concurrent.locks.AbstractQueuedSynchronizer public final void acquire(int arg) { if (!tryAcquire(arg) \u0026\u0026 acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt(); } 上文解释了addWaiter方法，这个方法其实就是把对应的线程以Node的数据结构形式加入到双端队列里，返回的是一个包含该线程的Node。 而这个Node会作为参数，进入到acquireQueued方法中。acquireQueued方法可以对排队中的线程进行“获锁”操作。 总的来说，一个线程获取锁失败了，被放入等待队列，acquireQueued会把放入队列中的线程不断去获取锁，直到获取成功或者不再需要获取（中断）。 下面我们从“何时出队列？”和“如何出队列？”两个方向来分析一下acquireQueued源码： // java.util.concurrent.locks.AbstractQueuedSynchronizer final boolean acquireQueued(final Node node, int arg) { // 标记是否成功拿到资源 boolean failed = true; try { // 标记等待过程中是否中断过 boolean interrupted = false; // 开始自旋，要么获取锁，要么中断 for (;;) { // 获取当前节点的前驱节点 final Node p = node.predecessor(); // 如果p是头结点，说明当前节点在真实数据队列的首部，就尝试获取锁（别忘了头结点是虚节点） if (p == head \u0026\u0026 tryAcquire(arg)) { // 获取锁成功，头指针移动到当前node setHead(node); p.next = null; // help GC failed = false; return interrupted; } // 说明p为头节点且当前没有获取到锁（可能是非公平锁被抢占了）或者是p不为头结点，这个时候就要判断当前node是否要被阻塞（被阻塞条件：前驱节点的waitStatus为-1），防止无限循环浪费资源。具体两个方法下面细细分析 if (shouldParkAfterFailedAcquire(p, node) \u0026\u0026 parkAndCheckInterrupt()) interrupted = true; } } finally { if (failed) cancelAcquire(node); } } 注：setHead方法是把当前节点置为虚节点，但并没有修改waitStatus，因为它是一直需要用的数据。 // java.util.concurrent.locks.AbstractQueuedSynchronizer private void setHead(Node node) { head = node; node.thread = null; node.prev = null; } // java.util.concurrent.locks.AbstractQueuedSynchronizer // 靠前驱节点判断当前线程是否应该被阻塞 private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) { // 获取头结点的节点状态 int ws = pred.waitStatus; // 说明头结点处于唤醒状态 if (ws == Node.SIGNAL) return true; // 通过枚举值我们知道waitStatus\u003e0是取消状态 if (ws \u003e 0) { do { // 循环向前查找取消节点，把取消节点从队列中剔除 node.prev = pred = pred.prev; } while (pred.waitStatus \u003e 0); pred.next = node; } else { // 设置前任节点等待状态为SIGNAL compareAndSetWaitStatus(pred, ws, Node.SIGNAL); } return false; } parkAndCheckInterrupt主要用于挂起当前线程，阻塞调用栈，返回当前线程的中断状态。 // java.util.concurrent.locks.AbstractQueuedSynchronizer private final boolean parkAndCheckInterrupt() { LockSupport.park(this); return Thread.interrupted(); } 上述方法的流程图如下： AQS加锁流程1\" AQS加锁流程1 从上图可以看出，跳出当前循环的条件是当“前置节点是头结点，且当前线程获取锁成功”。为了防止因死循环导致CPU资源被浪费，我们会判断前置节点的状态来决定是否要将当前线程挂起，具体挂起流程用流程图表示如下（shouldParkAfterFailedAcquire流程）： AQS加锁流程2\" AQS加锁流程2 从队列中释放节点的疑虑打消了，那么又有新问题了： shouldParkAfterFailedAcquire中取消节点是怎么生成的呢？什么时候会把一个节点的waitStatus设置为-1？ 是在什么时间释放节点通知到被挂起的线程呢 CANCELLED状态节点生成 acquireQueued方法中的Finally代码： // java.util.concurrent.locks.AbstractQueuedSynchronizer final boolean acquireQueued(final Node node, int arg) { boolean failed","date":"2018-04-05","objectID":"/abstractqueuedsynchronizer/:4:1","tags":["并发编程"],"title":"AbstractQueuedSynchronizer详解","uri":"/abstractqueuedsynchronizer/"},{"categories":["Java基础"],"content":"如何解锁 我们已经剖析了加锁过程中的基本流程，接下来再对解锁的基本流程进行分析。由于ReentrantLock在解锁的时候，并不区分公平锁和非公平锁，所以我们直接看解锁的源码： // java.util.concurrent.locks.ReentrantLock public void unlock() { sync.release(1); } // java.util.concurrent.locks.AbstractQueuedSynchronizer // 可以看到，本质释放锁的地方，是通过框架来完成的。 public final boolean release(int arg) { if (tryRelease(arg)) { Node h = head; if (h != null \u0026\u0026 h.waitStatus != 0) unparkSuccessor(h); return true; } return false; } //在ReentrantLock里面的公平锁和非公平锁的父类Sync定义了可重入锁的释放锁机制。 // java.util.concurrent.locks.ReentrantLock.Sync // 方法返回当前锁是不是没有被线程持有 protected final boolean tryRelease(int releases) { // 减少可重入次数 int c = getState() - releases; // 当前线程不是持有锁的线程，抛出异常 if (Thread.currentThread() != getExclusiveOwnerThread()) throw new IllegalMonitorStateException(); boolean free = false; // 如果持有线程全部释放，将当前独占锁所有线程设置为null，并更新state if (c == 0) { free = true; setExclusiveOwnerThread(null); } setState(c); return free; } // java.util.concurrent.locks.AbstractQueuedSynchronizer public final boolean release(int arg) { // 上边自定义的tryRelease如果返回true，说明该锁没有被任何线程持有 if (tryRelease(arg)) { // 获取头结点 Node h = head; // 头结点不为空并且头结点的waitStatus不是初始化节点情况，解除线程挂起状态 if (h != null \u0026\u0026 h.waitStatus != 0) unparkSuccessor(h); return true; } return false; } //再看一下unparkSuccessor方法 // java.util.concurrent.locks.AbstractQueuedSynchronizer private void unparkSuccessor(Node node) { // 获取头结点waitStatus int ws = node.waitStatus; if (ws \u003c 0) compareAndSetWaitStatus(node, ws, 0); // 获取当前节点的下一个节点 Node s = node.next; // 如果下个节点是null或者下个节点被cancelled，就找到队列最开始的非cancelled的节点 if (s == null || s.waitStatus \u003e 0) { s = null; // 就从尾部节点开始找，到队首，找到队列第一个waitStatus\u003c0的节点。 for (Node t = tail; t != null \u0026\u0026 t != node; t = t.prev) if (t.waitStatus \u003c= 0) s = t; } // 如果当前节点的下个节点不为空，而且状态\u003c=0，就把当前节点unpark if (s != null) LockSupport.unpark(s.thread); } // 为什么要从后往前找第一个非Cancelled的节点呢？原因如下。 // 之前的addWaiter方法： // java.util.concurrent.locks.AbstractQueuedSynchronizer private Node addWaiter(Node mode) { Node node = new Node(Thread.currentThread(), mode); // Try the fast path of enq; backup to full enq on failure Node pred = tail; if (pred != null) { node.prev = pred; if (compareAndSetTail(pred, node)) { pred.next = node; return node; } } enq(node); return node; } 我们从这里可以看到，节点入队并不是原子操作，也就是说，node.prev = pred; compareAndSetTail(pred, node) 这两个地方可以看作Tail入队的原子操作，但是此时pred.next = node;还没执行，如果这个时候执行了unparkSuccessor方法，就没办法从前往后找了，所以需要从后往前找。还有一点原因，在产生CANCELLED状态节点的时候，先断开的是Next指针，Prev指针并未断开，因此也是必须要从后往前遍历才能够遍历完全部的Node。 综上所述，如果是从前往后找，由于极端情况下入队的非原子操作和CANCELLED节点产生过程中断开Next指针的操作，可能会导致无法遍历所有的节点。所以，唤醒对应的线程后，对应的线程就会继续往下执行。继续执行acquireQueued方法以后，中断如何处理？ ","date":"2018-04-05","objectID":"/abstractqueuedsynchronizer/:4:2","tags":["并发编程"],"title":"AbstractQueuedSynchronizer详解","uri":"/abstractqueuedsynchronizer/"},{"categories":["Java基础"],"content":"中断恢复后的执行流程 唤醒后，会执行return Thread.interrupted();，这个函数返回的是当前执行线程的中断状态，并清除。 // java.util.concurrent.locks.AbstractQueuedSynchronizer private final boolean parkAndCheckInterrupt() { LockSupport.park(this); return Thread.interrupted(); } 再回到acquireQueued代码，当parkAndCheckInterrupt返回True或者False的时候，interrupted的值不同，但都会执行下次循环。如果这个时候获取锁成功，就会把当前interrupted返回。 // java.util.concurrent.locks.AbstractQueuedSynchronizer final boolean acquireQueued(final Node node, int arg) { boolean failed = true; try { boolean interrupted = false; for (;;) { final Node p = node.predecessor(); if (p == head \u0026\u0026 tryAcquire(arg)) { setHead(node); p.next = null; // help GC failed = false; return interrupted; } if (shouldParkAfterFailedAcquire(p, node) \u0026\u0026 parkAndCheckInterrupt()) interrupted = true; } } finally { if (failed) cancelAcquire(node); } } 如果acquireQueued为True，就会执行selfInterrupt方法。 // java.util.concurrent.locks.AbstractQueuedSynchronizer static void selfInterrupt() { Thread.currentThread().interrupt(); } 该方法其实是为了中断线程。但为什么获取了锁以后还要中断线程呢？这部分属于Java提供的协作式中断知识内容，感兴趣同学可以查阅一下。这里简单介绍一下： 当中断线程被唤醒时，并不知道被唤醒的原因，可能是当前线程在等待中被中断，也可能是释放了锁以后被唤醒。因此我们通过Thread.interrupted()方法检查中断标记（该方法返回了当前线程的中断状态，并将当前线程的中断标识设置为False），并记录下来，如果发现该线程被中断过，就再中断一次。 线程在等待资源的过程中被唤醒，唤醒后还是会不断地去尝试获取锁，直到抢到锁为止。也就是说，在整个流程中，并不响应中断，只是记录中断记录。最后抢到锁返回了，那么如果被中断过的话，就需要补充一次中断。 ","date":"2018-04-05","objectID":"/abstractqueuedsynchronizer/:4:3","tags":["并发编程"],"title":"AbstractQueuedSynchronizer详解","uri":"/abstractqueuedsynchronizer/"},{"categories":["Java基础"],"content":"AbstractQueuedSynchronizer总结 对于AbstractQueuedSynchronizer的分析，最核心的就是sync queue的分析。 每一个结点都是由前一个结点唤醒 当结点发现前驱结点是head并且尝试获取成功，则会轮到该线程运行。 condition queue中的结点向sync queue中转移是通过条件的signal()操作完成的。 当结点的状态为SIGNAL时，表示后面的结点需要运行。 ","date":"2018-04-05","objectID":"/abstractqueuedsynchronizer/:5:0","tags":["并发编程"],"title":"AbstractQueuedSynchronizer详解","uri":"/abstractqueuedsynchronizer/"},{"categories":["Java基础"],"content":"参考文章 从ReentrantLock的实现看AQS的原理及应用 锁核心类AQS详解 ","date":"2018-04-05","objectID":"/abstractqueuedsynchronizer/:6:0","tags":["并发编程"],"title":"AbstractQueuedSynchronizer详解","uri":"/abstractqueuedsynchronizer/"},{"categories":["Java基础"],"content":"LockSupport详解","date":"2018-04-04","objectID":"/locksupport/","tags":["并发编程"],"title":"LockSupport详解","uri":"/locksupport/"},{"categories":["Java基础"],"content":"LockSupport简介 LockSupport用来创建锁和其他同步类的基本线程阻塞原语。简而言之，当调用LockSupport.park时，表示当前线程将会等待，直至获得许可，当调用LockSupport.unpark时，必须把等待获得许可的线程作为参数进行传递，好让此线程继续运行。 ","date":"2018-04-04","objectID":"/locksupport/:1:0","tags":["并发编程"],"title":"LockSupport详解","uri":"/locksupport/"},{"categories":["Java基础"],"content":"核心函数分析 在分析LockSupport函数之前，先引入sun.misc.Unsafe类中的park和unpark函数，因为LockSupport的核心函数都是基于Unsafe类中定义的park和unpark函数，下面给出两个函数的定义: public native void park(boolean isAbsolute, long time); public native void unpark(Thread thread); 说明: 对两个函数的说明如下: park函数，阻塞线程，并且该线程在下列情况发生之前都会被阻塞: ① 调用unpark函数，释放该线程的许可。② 该线程被中断。③ 设置的时间到了。并且，当time为绝对时间时，isAbsolute为true，否则，isAbsolute为false。当time为0时，表示无限等待，直到unpark发生。 unpark函数，释放线程的许可，即激活调用park后阻塞的线程。这个函数不是安全的，调用这个函数时要确保线程依旧存活。 ","date":"2018-04-04","objectID":"/locksupport/:2:0","tags":["并发编程"],"title":"LockSupport详解","uri":"/locksupport/"},{"categories":["Java基础"],"content":"park函数 park函数有两个重载版本，方法摘要如下 public static void park()； public static void park(Object blocker)； 说明: 两个函数的区别在于park()函数没有没有blocker，即没有设置线程的parkBlocker字段。park(Object)型函数如下。 public static void park(Object blocker) { // 获取当前线程 Thread t = Thread.currentThread(); // 设置Blocker setBlocker(t, blocker); // 获取许可 UNSAFE.park(false, 0L); // 重点方法：重新可运行后再此设置Blocker，其他线程执行unpark()后继续 setBlocker(t, null); } 说明: 调用park函数时，首先获取当前线程，然后设置当前线程的parkBlocker字段，即调用setBlocker函数，之后调用Unsafe类的park函数，之后再调用setBlocker函数。 那么问题来了，为什么要在此park函数中要调用两次setBlocker函数呢? 原因其实很简单，调用park函数时，当前线程首先设置好parkBlocker字段，然后再调用Unsafe的park函数，此后，当前线程就已经阻塞了，等待该线程的unpark函数被调用，所以后面的一个setBlocker函数无法运行，unpark函数被调用，该线程获得许可后，就可以继续运行了，也就运行第二个setBlocker，把该线程的parkBlocker字段设置为null，这样就完成了整个park函数的逻辑。如果没有第二个setBlocker，那么之后没有调用park(Object blocker)，而直接调用getBlocker函数，得到的还是前一个park(Object blocker)设置的blocker，显然是不符合逻辑的。 总之，必须要保证在park(Object blocker)整个函数执行完后，该线程的parkBlocker字段又恢复为null。所以，park(Object)型函数里必须要调用setBlocker函数两次。 setBlocker方法如下: private static void setBlocker(Thread t, Object arg) { // 设置线程t的parkBlocker字段的值为arg UNSAFE.putObject(t, parkBlockerOffset, arg); } ","date":"2018-04-04","objectID":"/locksupport/:2:1","tags":["并发编程"],"title":"LockSupport详解","uri":"/locksupport/"},{"categories":["Java基础"],"content":"unpark函数 此函数表示如果给定线程的许可尚不可用，则使其可用。如果线程在 park 上受阻塞，则它将解除其阻塞状态。否则，保证下一次调用 park 不会受阻塞。如果给定线程尚未启动，则无法保证此操作有任何效果。具体函数如下: public static void unpark(Thread thread) { if (thread != null) // 线程为不空 UNSAFE.unpark(thread); // 释放该线程许可 } ","date":"2018-04-04","objectID":"/locksupport/:2:2","tags":["并发编程"],"title":"LockSupport详解","uri":"/locksupport/"},{"categories":["Java基础"],"content":"更深入的理解 ","date":"2018-04-04","objectID":"/locksupport/:3:0","tags":["并发编程"],"title":"LockSupport详解","uri":"/locksupport/"},{"categories":["Java基础"],"content":"Thread.sleep()和Object.wait()的区别 Thread.sleep()不会释放占有的锁，Object.wait()会释放占有的锁； Thread.sleep()必须传入时间，Object.wait()可传可不传，不传表示一直阻塞下去； Thread.sleep()到时间了会自动唤醒，然后继续执行； Object.wait()不带时间的，需要另一个线程使用Object.notify()唤醒； Object.wait()带时间的，假如没有被notify，到时间了会自动唤醒，这时又分好两种情况，一是立即获取到了锁，线程自然会继续执行；二是没有立即获取锁，线程进入同步队列等待获取锁； 其实，他们俩最大的区别就是Thread.sleep()不会释放锁资源，Object.wait()会释放锁资源。 ","date":"2018-04-04","objectID":"/locksupport/:3:1","tags":["并发编程"],"title":"LockSupport详解","uri":"/locksupport/"},{"categories":["Java基础"],"content":"Thread.sleep()和Condition.await()的区别 Condition.await()和Object.wait()的原理是基本一致的，不同的是Condition.await()底层是调用LockSupport.park()来实现阻塞当前线程的。 实际上，它在阻塞当前线程之前还干了两件事，一是把当前线程添加到条件队列中，二是“完全”释放锁，也就是让state状态变量变为0，然后才是调用LockSupport.park()阻塞当前线程。 ","date":"2018-04-04","objectID":"/locksupport/:3:2","tags":["并发编程"],"title":"LockSupport详解","uri":"/locksupport/"},{"categories":["Java基础"],"content":"Thread.sleep()和LockSupport.park()的区别 LockSupport.park()还有几个兄弟方法——parkNanos()、parkUtil()等，我们这里说的park()方法统称这一类方法。 从功能上来说，Thread.sleep()和LockSupport.park()方法类似，都是阻塞当前线程的执行，且都不会释放当前线程占有的锁资源。 Thread.sleep()没法从外部唤醒，只能自己醒过来； LockSupport.park()方法可以被另一个线程调用LockSupport.unpark()方法唤醒； Thread.sleep()方法声明上抛出了InterruptedException中断异常，所以调用者需要捕获这个异常或者再抛出； LockSupport.park()方法不需要捕获中断异常； Thread.sleep()本身就是一个native方法； LockSupport.park()底层是调用的Unsafe的native方法 ","date":"2018-04-04","objectID":"/locksupport/:3:3","tags":["并发编程"],"title":"LockSupport详解","uri":"/locksupport/"},{"categories":["Java基础"],"content":"Object.wait()和LockSupport.park()的区别 二者都会阻塞当前线程的运行，他们有什么区别呢? 经过上面的分析相信你一定很清楚了，真的吗? 往下看！ Object.wait()方法需要在synchronized块中执行； LockSupport.park()可以在任意地方执行； Object.wait()方法声明抛出了中断异常，调用者需要捕获或者再抛出； LockSupport.park()不需要捕获中断异常； Object.wait()不带超时的，需要另一个线程执行notify()来唤醒，但不一定继续执行后续内容； LockSupport.park()不带超时的，需要另一个线程执行unpark()来唤醒，一定会继续执行后续内容； 如果在wait()之前执行了notify()会怎样? 抛出IllegalMonitorStateException异常； 如果在park()之前执行了unpark()会怎样? 线程不会被阻塞，直接跳过park()，继续执行后续内容； park()/unpark()底层的原理是“二元信号量”，你可以把它相像成只有一个许可证的Semaphore，只不过这个信号量在重复执行unpark()的时候也不会再增加许可证，最多只有一个许可证。 ","date":"2018-04-04","objectID":"/locksupport/:3:4","tags":["并发编程"],"title":"LockSupport详解","uri":"/locksupport/"},{"categories":["Java基础"],"content":"LockSupport.park()不会释放锁资源 LockSupport.park()不会释放锁资源，它只负责阻塞当前线程，释放锁资源实际上是在Condition的await()方法中实现的。 ","date":"2018-04-04","objectID":"/locksupport/:3:5","tags":["并发编程"],"title":"LockSupport详解","uri":"/locksupport/"},{"categories":["Java基础"],"content":"synchronized详解","date":"2018-04-03","objectID":"/synchronized/","tags":["并发编程"],"title":"synchronized(无锁→偏向锁→轻量级锁→重量级锁)","uri":"/synchronized/"},{"categories":["Java基础"],"content":"synchronized的使用 ","date":"2018-04-03","objectID":"/synchronized/:1:0","tags":["并发编程"],"title":"synchronized(无锁→偏向锁→轻量级锁→重量级锁)","uri":"/synchronized/"},{"categories":["Java基础"],"content":"对象锁 包括方法锁(默认锁对象为this,当前实例对象)和同步代码块锁(自己指定锁对象) ","date":"2018-04-03","objectID":"/synchronized/:1:1","tags":["并发编程"],"title":"synchronized(无锁→偏向锁→轻量级锁→重量级锁)","uri":"/synchronized/"},{"categories":["Java基础"],"content":"类锁 指synchronize修饰静态的方法或指定锁对象为Class对象 ","date":"2018-04-03","objectID":"/synchronized/:1:2","tags":["并发编程"],"title":"synchronized(无锁→偏向锁→轻量级锁→重量级锁)","uri":"/synchronized/"},{"categories":["Java基础"],"content":"注意点 一把锁只能同时被一个线程获取，没有获得锁的线程只能等待。 每个实例都对应有自己的一把锁(this),不同实例之间互不影响；例外：锁对象是*.class以及synchronized修饰的是static方法的时候，所有对象共用同一把锁 。 synchronized修饰的方法，无论方法正常执行完毕还是抛出异常，都会释放锁。 ","date":"2018-04-03","objectID":"/synchronized/:1:3","tags":["并发编程"],"title":"synchronized(无锁→偏向锁→轻量级锁→重量级锁)","uri":"/synchronized/"},{"categories":["Java基础"],"content":"synchronized原理分析 ","date":"2018-04-03","objectID":"/synchronized/:2:0","tags":["并发编程"],"title":"synchronized(无锁→偏向锁→轻量级锁→重量级锁)","uri":"/synchronized/"},{"categories":["Java基础"],"content":"加锁和释放锁的原理 Monitorenter和Monitorexit指令，会让对象在执行，使其锁计数器加1或者减1。每一个对象在同一时间只与一个monitor(锁)相关联，而一个monitor在同一时间只能被一个线程获得，一个对象在尝试获得与这个对象相关联的Monitor锁的所有权的时候，monitorenter指令会发生如下3中情况之一： monitor计数器为0，意味着目前还没有被获得，那这个线程就会立刻获得然后把锁计数器+1，一旦+1，别的线程再想获取，就需要等待 如果这个monitor已经拿到了这个锁的所有权，又重入了这把锁，那锁计数器就会累加，变成2，并且随着重入的次数，会一直累加 这把锁已经被别的线程获取了，等待锁释放 monitorexit指令：释放对于monitor的所有权，释放过程很简单，就是讲monitor的计数器减1，如果减完以后，计数器不是0，则代表刚才是重入进来的，当前线程还继续持有这把锁的所有权，如果计数器变成0，则代表当前线程不再拥有该monitor的所有权，即释放锁。 schronized-moniter\" schronized-moniter 该图可以看出，任意线程对Object的访问，首先要获得Object的监视器，如果获取失败，该线程就进入同步状态，线程状态变为BLOCKED，当Object的监视器占有者释放后，在同步队列中得线程就会有机会重新获取该监视器。 ","date":"2018-04-03","objectID":"/synchronized/:2:1","tags":["并发编程"],"title":"synchronized(无锁→偏向锁→轻量级锁→重量级锁)","uri":"/synchronized/"},{"categories":["Java基础"],"content":"可重入原理：加锁次数计数器 上面的demo中在执行完同步代码块之后紧接着再会去执行一个静态同步方法，而这个方法锁的对象依然就这个类对象，那么这个正在执行的线程还需要获取该锁吗? 答案是不必的，从上图中就可以看出来，执行静态同步方法的时候就只有一条monitorexit指令，并没有monitorenter获取锁的指令。这就是锁的重入性，即在同一锁程中，线程不需要再次获取同一把锁。 synchronized先天具有重入性。每个对象拥有一个计数器，当线程获取该对象锁后，计数器就会加一，释放锁后就会将计数器减一。 ","date":"2018-04-03","objectID":"/synchronized/:2:2","tags":["并发编程"],"title":"synchronized(无锁→偏向锁→轻量级锁→重量级锁)","uri":"/synchronized/"},{"categories":["Java基础"],"content":"保证可见性的原理：内存模型和happens-before规则 Synchronized的happens-before规则，即监视器锁规则：对同一个监视器的解锁，happens-before于对该监视器的加锁。继续来看代码： public class MonitorDemo { private int a = 0; public synchronized void writer() { // 1 a++; // 2 } // 3 public synchronized void reader() { // 4 int i = a; // 5 } // 6 } 该代码的happens-before关系如图所示： happens-before\" happens-before 在图中每一个箭头连接的两个节点就代表之间的happens-before关系，黑色的是通过程序顺序规则推导出来，红色的为监视器锁规则推导而出：线程A释放锁happens-before线程B加锁，蓝色的则是通过程序顺序规则和监视器锁规则推测出来happens-befor关系，通过传递性规则进一步推导的happens-before关系。现在我们来重点关注2 happens-before 5，通过这个关系我们可以得出什么? 根据happens-before的定义中的一条:如果A happens-before B，则A的执行结果对B可见，并且A的执行顺序先于B。线程A先对共享变量A进行加一，由2 happens-before 5关系可知线程A的执行结果对线程B可见即线程B所读取到的a的值为1。 ","date":"2018-04-03","objectID":"/synchronized/:2:3","tags":["并发编程"],"title":"synchronized(无锁→偏向锁→轻量级锁→重量级锁)","uri":"/synchronized/"},{"categories":["Java基础"],"content":"JVM中锁的优化 简单来说在JVM中monitorenter和monitorexit字节码依赖于底层的操作系统的Mutex Lock来实现的。 但是由于使用Mutex Lock需要将当前线程挂起并从用户态切换到内核态来执行，这种切换的代价是非常昂贵的；然而在现实中的大部分情况下，同步方法是运行在单线程环境(无锁竞争环境)如果每次都调用Mutex Lock那么将严重的影响程序的性能。 不过在jdk1.6中对锁的实现引入了大量的优化，如锁粗化(Lock Coarsening)、锁消除(Lock Elimination)、轻量级锁(Lightweight Locking)、偏向锁(Biased Locking)、适应性自旋(Adaptive Spinning)等技术来减少锁操作的开销。 ","date":"2018-04-03","objectID":"/synchronized/:3:0","tags":["并发编程"],"title":"synchronized(无锁→偏向锁→轻量级锁→重量级锁)","uri":"/synchronized/"},{"categories":["Java基础"],"content":"锁优化 锁粗化(Lock Coarsening)：也就是减少不必要的紧连在一起的unlock，lock操作，将多个连续的锁扩展成一个范围更大的锁。 锁消除(Lock Elimination)：通过运行时JIT编译器的逃逸分析来消除一些没有在当前同步块以外被其他线程共享的数据的锁保护，通过逃逸分析也可以在线程本地Stack上进行对象空间的分配(同时还可以减少Heap上的垃圾收集开销)。 偏向锁(Biased Locking)：是为了在无锁竞争的情况下避免在锁获取过程中执行不必要的CAS原子指令，因为CAS原子指令虽然相对于重量级锁来说开销比较小但还是存在非常可观的本地延迟。 轻量级锁(Lightweight Locking)：这种锁实现的背后基于这样一种假设，即在真实的情况下我们程序中的大部分同步代码一般都处于无锁竞争状态(即单线程执行环境)，在无锁竞争的情况下完全可以避免调用操作系统层面的重量级互斥锁，取而代之的是在monitorenter和monitorexit中只需要依靠一条CAS原子指令就可以完成锁的获取及释放。当存在锁竞争的情况下，执行CAS指令失败的线程将调用操作系统互斥锁进入到阻塞状态，当锁被释放的时候被唤醒(具体处理步骤下面详细讨论)。 自适应自旋锁(Adaptive Spinning)：当线程在获取轻量级锁的过程中执行CAS操作失败时，在进入与monitor相关联的操作系统重量级锁(mutex semaphore)前会进入忙等待(Spinning)然后再次尝试，当尝试一定的次数后如果仍然没有成功则调用与该monitor关联的semaphore(即互斥锁)进入到阻塞状态。 ","date":"2018-04-03","objectID":"/synchronized/:3:1","tags":["并发编程"],"title":"synchronized(无锁→偏向锁→轻量级锁→重量级锁)","uri":"/synchronized/"},{"categories":["Java基础"],"content":"锁的类型 在Java SE 1.6里Synchronied同步锁，一共有四种状态：无锁、偏向锁、轻量级所、重量级锁，它会随着竞争情况逐渐升级。 锁可以升级但是不可以降级，目的是为了提供获取锁和释放锁的效率。 锁膨胀方向(不可逆)： 无锁 → 偏向锁 → 轻量级锁 → 重量级锁 流程：偏向锁通过对比Mark Word解决加锁问题，避免执行CAS操作。而轻量级锁是通过用CAS操作和自旋来解决加锁问题，避免线程阻塞和唤醒而影响性能。重量级锁是将除了拥有锁的线程以外的线程都阻塞。 下面是各个过程的详细介绍： ","date":"2018-04-03","objectID":"/synchronized/:3:2","tags":["并发编程"],"title":"synchronized(无锁→偏向锁→轻量级锁→重量级锁)","uri":"/synchronized/"},{"categories":["Java基础"],"content":"自旋锁与自适应自旋锁 自旋锁对比非自旋锁\" 自旋锁对比非自旋锁 自旋锁 引入背景：大家都知道，在没有加入锁优化时，Synchronized是一个非常“胖大”的家伙。在多线程竞争锁时，当一个线程获取锁时，它会阻塞所有正在竞争的线程，这样对性能带来了极大的影响。在挂起线程和恢复线程的操作都需要转入内核态中完成，这些操作对系统的并发性能带来了很大的压力。同时HotSpot团队注意到在很多情况下，共享数据的锁定状态只会持续很短的一段时间，为了这段时间去挂起和回复阻塞线程并不值得。在如今多处理器环境下，完全可以让另一个没有获取到锁的线程在门外等待一会(自旋)，但不放弃CPU的执行时间。等待持有锁的线程是否很快就会释放锁。为了让线程等待，我们只需要让线程执行一个忙循环(自旋)，这便是自旋锁由来的原因。 自旋锁早在JDK1.4 中就引入了，只是当时默认时关闭的。在JDK 1.6后默认为开启状态。 自旋锁本质上与阻塞并不相同，先不考虑其对多处理器的要求，如果锁占用的时间非常的短，那么自旋锁的性能会非常的好，相反，其会带来更多的性能开销(因为在线程自旋时，始终会占用CPU的时间片，如果锁占用的时间太长，那么自旋的线程会白白消耗掉CPU资源)。 因此自旋等待的时间必须要有一定的限度，如果自选超过了限定的次数仍然没有成功获取到锁，就应该使用传统的方式去挂起线程了，在JDK定义中，自旋锁默认的自旋次数为10次，用户可以使用参数-XX:PreBlockSpin来更改。 可是现在又出现了一个问题：如果线程锁在线程自旋刚结束就释放掉了锁，那么是不是有点得不偿失。所以这时候我们需要更加聪明的锁来实现更加灵活的自旋。来提高并发的性能。(这里则需要自适应自旋锁) 自适应自旋锁 在JDK 1.6中引入了自适应自旋锁。这就意味着自旋的时间不再固定了，而是由前一次在同一个锁上的自旋时间及锁的拥有者的状态来决定的。 如果在同一个锁对象上，自旋等待刚刚成功获取过锁，并且持有锁的线程正在运行中，那么JVM会认为该锁自旋获取到锁的可能性很大，会自动增加等待时间。 比如增加到100此循环。相反，如果对于某个锁，自旋很少成功获取锁。那再以后要获取这个锁时将可能省略掉自旋过程，以避免浪费处理器资源。 有了自适应自旋，JVM对程序的锁的状态预测会越来越准备，JVM也会越来越聪明。 ","date":"2018-04-03","objectID":"/synchronized/:3:3","tags":["并发编程"],"title":"synchronized(无锁→偏向锁→轻量级锁→重量级锁)","uri":"/synchronized/"},{"categories":["Java基础"],"content":"锁消除 锁消除时指虚拟机即时编译器再运行时，对一些代码上要求同步，但是被检测到不可能存在共享数据竞争的锁进行消除。 锁消除的主要判定依据来源于逃逸分析的数据支持。意思就是：JVM会判断再一段程序中的同步明显不会逃逸出去从而被其他线程访问到，那JVM就把它们当作栈上数据对待，认为这些数据时线程独有的，不需要加同步。此时就会进行锁消除。 ​ 当然在实际开发中，我们很清楚的知道那些地方时线程独有的，不需要加同步锁，但是在Java API中有很多方法都是加了同步的，那么此时JVM会判断这段代码是否需要加锁。如果数据并不会逃逸，则会进行锁消除。比如如下操作：在操作String类型数据时，由于String是一个不可变类，对字符串的连接操作总是通过生成的新的String对象来进行的。因此Javac编译器会对String连接做自动优化。在JDK 1.5之前会使用StringBuffer对象的连续append()操作，在JDK 1.5及以后的版本中，会转化为StringBuidler对象的连续append()操作。 public static String test03(String s1, String s2, String s3) { String s = s1 + s2 + s3; return s; } 上述代码使用javap 编译结果 锁消除\" 锁消除 众所周知，StringBuilder不是安全同步的，但是在上述代码中，JVM判断该段代码并不会逃逸，则将该代码带默认为线程独有的资源，并不需要同步，所以执行了锁消除操作。(还有Vector中的各种操作也可实现锁消除。在没有逃逸出数据安全防卫内) ","date":"2018-04-03","objectID":"/synchronized/:3:4","tags":["并发编程"],"title":"synchronized(无锁→偏向锁→轻量级锁→重量级锁)","uri":"/synchronized/"},{"categories":["Java基础"],"content":"锁粗化 ​原则上，我们都知道在加同步锁时，尽可能的将同步块的作用范围限制到尽量小的范围(只在共享数据的实际作用域中才进行同步，这样是为了使得需要同步的操作数量尽可能变小。在存在锁同步竞争中，也可以使得等待锁的线程尽早的拿到锁)。 ​大部分上述情况是完美正确的，但是如果存在连串的一系列操作都对同一个对象反复加锁和解锁，甚至加锁操作时出现在循环体中的，那即使没有线程竞争，频繁地进行互斥同步操作也会导致不必要地性能操作。 ","date":"2018-04-03","objectID":"/synchronized/:3:5","tags":["并发编程"],"title":"synchronized(无锁→偏向锁→轻量级锁→重量级锁)","uri":"/synchronized/"},{"categories":["Java基础"],"content":"偏向锁 引入背景：在大多实际环境下，锁不仅不存在多线程竞争，而且总是由同一个线程多次获取，那么在同一个线程反复获取所释放锁中，其中并还没有锁的竞争，那么这样看上去，多次的获取锁和释放锁带来了很多不必要的性能开销和上下文切换。 ​ 为了解决这一问题，HotSpot的作者在Java SE1.6中对Synchronized进行了优化，引入了偏向锁。 当一个线程访问同步快并获取锁时，会在对象头和栈帧中的锁记录里存储锁偏向的线程ID，以后该线程在进入和退出同步块时不需要进行CAS操作来加锁和解锁。只需要简单地测试一下对象头的Mark Word里是否存储着指向当前线程的偏向锁。如果成功，表示线程已经获取到了锁。 偏向锁1\" 偏向锁1 偏向锁的撤销 偏向锁使用了一种等待竞争出现才会释放锁的机制，所以当其他线程尝试获取偏向锁时，持有偏向锁的线程才会释放锁。 但是偏向锁的撤销需要等到全局安全点(就是当前线程没有正在执行的字节码)。 它会首先暂停拥有偏向锁的线程，让你后检查持有偏向锁的线程是否活着。 如果线程不处于活动状态，直接将对象头设置为无锁状态。 如果线程活着，JVM会遍历栈帧中的锁记录，栈帧中的锁记录和对象头要么偏向于其他线程，要么恢复到无锁状态或者标记对象不适合作为偏向锁。 偏向锁2\" 偏向锁2 ","date":"2018-04-03","objectID":"/synchronized/:3:6","tags":["并发编程"],"title":"synchronized(无锁→偏向锁→轻量级锁→重量级锁)","uri":"/synchronized/"},{"categories":["Java基础"],"content":"轻量级锁 引入背景：这种锁实现的背后基于这样一种假设，即在真实的情况下我们程序中的大部分同步代码一般都处于无锁竞争状态(即单线程执行环境)，在无锁竞争的情况下完全可以避免调用操作系统层面的重量级互斥锁，取而代之的是在monitorenter和monitorexit中只需要依靠一条CAS原子指令就可以完成锁的获取及释放。当存在锁竞争的情况下，执行CAS指令失败的线程将调用操作系统互斥锁进入到阻塞状态，当锁被释放的时候被唤醒。 ​在JDK 1.6之后引入的轻量级锁，需要注意的是轻量级锁并不是替代重量级锁的，而是对在大多数情况下同步块并不会有竞争出现提出的一种优化。 它可以减少重量级锁对线程的阻塞带来地线程开销，从而提高并发性能。 ​如果要理解轻量级锁，那么必须先要了解HotSpot虚拟机中对象头地内存布局。 在对象头中(Object Header)存在两部分： 第一部分用于存储对象自身的运行时数据，HashCode、GCAge、锁标记位、是否为偏向锁等。一般为32位或者64位(视操作系统位数定)。官方称之为Mark Word，它是实现轻量级锁和偏向锁的关键。 另外一部分存储的是指向方法区对象类型数据的指针(Klass Point)，如果对象是数组的话，还会有一个额外的部分用于存储数据的长度。 轻量级锁加锁 在线程执行同步块之前，JVM会先在当前线程的栈帧中创建一个名为锁记录(Lock Record)的空间，用于存储锁对象目前的Mark Word的拷贝(JVM会将对象头中的Mark Word拷贝到锁记录中，官方称为Displaced Mark Ward)这个时候线程堆栈与对象头的状态如图： 轻量级锁加锁1\" 轻量级锁加锁1 如上图所示：如果当前对象没有被锁定，那么锁标志位位01状态，JVM在执行当前线程时，首先会在当前线程栈帧中创建锁记录Lock Record的空间用于存储锁对象目前的Mark Word的拷贝。 ​ 然后，虚拟机使用CAS操作将标记字段Mark Word拷贝到锁记录中，并且将Mark Word更新为指向Lock Record的指针。如果更新成功了，那么这个线程就有用了该对象的锁，并且对象Mark Word的锁标志位更新为(Mark Word中最后的2bit)00，即表示此对象处于轻量级锁定状态，如图： 轻量级锁加锁2\" 轻量级锁加锁2 如果这个更新操作失败，JVM会检查当前的Mark Word中是否存在指向当前线程的栈帧的指针，如果有，说明该锁已经被获取，可以直接调用。如果没有，则说明该锁被其他线程抢占了，如果**有两条以上的线程竞争同一个锁，那轻量级锁就不再有效，直接膨胀位重量级锁，没有获得锁的线程会被阻塞。**此时，锁的标志位为10，Mark Word中存储的时指向重量级锁的指针。 ​ 轻量级解锁时，会使用原子的CAS操作将Displaced Mark Word替换回到对象头中，如果成功，则表示没有发生竞争关系。如果失败，表示当前锁存在竞争关系。锁就会膨胀成重量级锁。两个线程同时争夺锁，导致锁膨胀的流程图如下： 轻量级锁加锁3\" 轻量级锁加锁3 ","date":"2018-04-03","objectID":"/synchronized/:3:7","tags":["并发编程"],"title":"synchronized(无锁→偏向锁→轻量级锁→重量级锁)","uri":"/synchronized/"},{"categories":["Java基础"],"content":"锁的优缺点对比 锁 优点 缺点 使用场景 偏向锁 加锁和解锁不需要CAS操作，没有额外的性能消耗，和执行非同步方法相比仅存在纳秒级的差距 如果线程间存在锁竞争，会带来额外的锁撤销的消耗 适用于只有一个线程访问同步快的场景 轻量级锁 竞争的线程不会阻塞，提高了响应速度 如线程成始终得不到锁竞争的线程，使用自旋会消耗CPU性能 追求响应时间，同步快执行速度非常快 重量级锁 线程竞争不适用自旋，不会消耗CPU 线程阻塞，响应时间缓慢，在多线程下，频繁的获取释放锁，会带来巨大的性能消耗 追求吞吐量，同步快执行速度较长 锁对比\" 锁对比 ","date":"2018-04-03","objectID":"/synchronized/:3:8","tags":["并发编程"],"title":"synchronized(无锁→偏向锁→轻量级锁→重量级锁)","uri":"/synchronized/"},{"categories":["Java基础"],"content":"synchronized与Lock ","date":"2018-04-03","objectID":"/synchronized/:4:0","tags":["并发编程"],"title":"synchronized(无锁→偏向锁→轻量级锁→重量级锁)","uri":"/synchronized/"},{"categories":["Java基础"],"content":"synchronized的缺陷 效率低：锁的释放情况少，只有代码执行完毕或者异常结束才会释放锁；试图获取锁的时候不能设定超时，不能中断一个正在使用锁的线程，相对而言，Lock可以中断和设置超时 不够灵活：加锁和释放的时机单一，每个锁仅有一个单一的条件(某个对象)，相对而言，读写锁更加灵活 无法知道是否成功获得锁，相对而言，Lock可以拿到状态。 ","date":"2018-04-03","objectID":"/synchronized/:4:1","tags":["并发编程"],"title":"synchronized(无锁→偏向锁→轻量级锁→重量级锁)","uri":"/synchronized/"},{"categories":["Java基础"],"content":"Lock解决相应问题 Lock类这里不做过多解释，主要看里面的4个方法: lock(): 加锁 unlock(): 解锁 tryLock(): 尝试获取锁，返回一个boolean值 tryLock(long,TimeUtil): 尝试获取锁，可以设置超时 Synchronized只有锁只与一个条件(是否获取锁)相关联，不灵活，后来Condition与Lock的结合解决了这个问题。 多线程竞争一个锁时，其余未得到锁的线程只能不停的尝试获得锁，而不能中断。高并发的情况下会导致性能下降。ReentrantLock的lockInterruptibly()方法可以优先考虑响应中断。 一个线程等待时间过长，它可以中断自己，然后ReentrantLock响应这个中断，不再让这个线程继续等待。有了这个机制，使用ReentrantLock时就不会像synchronized那样产生死锁了。 ","date":"2018-04-03","objectID":"/synchronized/:4:2","tags":["并发编程"],"title":"synchronized(无锁→偏向锁→轻量级锁→重量级锁)","uri":"/synchronized/"},{"categories":["Java基础"],"content":"再深入理解 synchronized是通过软件(JVM)实现的，简单易用，即使在JDK5之后有了Lock，仍然被广泛地使用。 ","date":"2018-04-03","objectID":"/synchronized/:5:0","tags":["并发编程"],"title":"synchronized(无锁→偏向锁→轻量级锁→重量级锁)","uri":"/synchronized/"},{"categories":["Java基础"],"content":"使用synchronized注意点 避免死锁 锁对象不能为空，因为锁的信息都保存在对象头里 作用域不宜过大，影响程序执行的速度，控制范围过大，编写代码也容易出错 在能选择的情况下，既不要用Lock也不要用synchronized关键字，用java.util.concurrent包中的各种各样的类，如果不用该包下的类，在满足业务的情况下，可以使用synchronized关键，因为代码量少，避免出错 ","date":"2018-04-03","objectID":"/synchronized/:5:1","tags":["并发编程"],"title":"synchronized(无锁→偏向锁→轻量级锁→重量级锁)","uri":"/synchronized/"},{"categories":["Java基础"],"content":"synchronized是公平锁吗？ synchronized实际上是非公平的，新来的线程有可能立即获得监视器，而在等待区中等候已久的线程可能再次等待，不过这种抢占的方式可以预防饥饿。 ","date":"2018-04-03","objectID":"/synchronized/:5:2","tags":["并发编程"],"title":"synchronized(无锁→偏向锁→轻量级锁→重量级锁)","uri":"/synchronized/"},{"categories":["Java基础"],"content":"参考文章 synchronized详解 不可不说的Java“锁”事 ","date":"2018-04-03","objectID":"/synchronized/:6:0","tags":["并发编程"],"title":"synchronized(无锁→偏向锁→轻量级锁→重量级锁)","uri":"/synchronized/"},{"categories":["Java基础"],"content":"JUC并发编程利器","date":"2018-04-02","objectID":"/juc/","tags":["并发编程","大纲"],"title":"JUC-并发编程利器","uri":"/juc/"},{"categories":["Java基础"],"content":"JUC概览\" JUC概览 ","date":"2018-04-02","objectID":"/juc/:0:0","tags":["并发编程","大纲"],"title":"JUC-并发编程利器","uri":"/juc/"},{"categories":["Java基础"],"content":"Lock框架和Tools类 Lock框架和Tools类\" Lock框架和Tools类 ","date":"2018-04-02","objectID":"/juc/:1:0","tags":["并发编程","大纲"],"title":"JUC-并发编程利器","uri":"/juc/"},{"categories":["Java基础"],"content":"接口Condition Condition为接口类型，它将 Object 监视器方法(wait、notify 和 notifyAll)分解成截然不同的对象，以便通过将这些对象与任意Lock实现组合使用，为每个对象提供多个等待set (wait-set)。其中，Lock替代了synchronized方法和语句的使用，Condition替代了Object监视器方法的使用。可以通过await(),signal()来休眠/唤醒线程。 ","date":"2018-04-02","objectID":"/juc/:1:1","tags":["并发编程","大纲"],"title":"JUC-并发编程利器","uri":"/juc/"},{"categories":["Java基础"],"content":"接口Lock Lock为接口类型，Lock实现提供了比使用synchronized方法和语句可获得的更广泛的锁定操作。此实现允许更灵活的结构，可以具有差别很大的属性，可以支持多个相关的Condition对象。 ","date":"2018-04-02","objectID":"/juc/:1:2","tags":["并发编程","大纲"],"title":"JUC-并发编程利器","uri":"/juc/"},{"categories":["Java基础"],"content":"接口ReadWriteLock ReadWriteLock为接口类型， 维护了一对相关的锁，一个用于只读操作，另一个用于写入操作。只要没有 writer，读取锁可以由多个 reader 线程同时保持。写入锁是独占的。 ","date":"2018-04-02","objectID":"/juc/:1:3","tags":["并发编程","大纲"],"title":"JUC-并发编程利器","uri":"/juc/"},{"categories":["Java基础"],"content":"抽象类AbstractOwnableSynchonizer AbstractOwnableSynchonizer为抽象类，可以由线程以独占方式拥有的同步器。此类为创建锁和相关同步器(伴随着所有权的概念)提供了基础。AbstractOwnableSynchronizer 类本身不管理或使用此信息。但是，子类和工具可以使用适当维护的值帮助控制和监视访问以及提供诊断。 ","date":"2018-04-02","objectID":"/juc/:1:4","tags":["并发编程","大纲"],"title":"JUC-并发编程利器","uri":"/juc/"},{"categories":["Java基础"],"content":"抽象类AbstractQueuedLongSynchronizer(long) AbstractQueuedLongSynchronizer为抽象类，以 long 形式维护同步状态的一个 AbstractQueuedSynchronizer 版本。此类具有的结构、属性和方法与 AbstractQueuedSynchronizer 完全相同，但所有与状态相关的参数和结果都定义为 long 而不是 int。当创建需要 64 位状态的多级别锁和屏障等同步器时，此类很有用。 ","date":"2018-04-02","objectID":"/juc/:1:5","tags":["并发编程","大纲"],"title":"JUC-并发编程利器","uri":"/juc/"},{"categories":["Java基础"],"content":"核心抽象类AbstractQueuedSynchronizer(int) AbstractQueuedSynchronizer为抽象类，其为实现依赖于先进先出 (FIFO) 等待队列的阻塞锁和相关同步器(信号量、事件，等等)提供一个框架。此类的设计目标是成为依靠单个原子int值来表示状态的大多数同步器的一个有用基础。 ","date":"2018-04-02","objectID":"/juc/:1:6","tags":["并发编程","大纲"],"title":"JUC-并发编程利器","uri":"/juc/"},{"categories":["Java基础"],"content":"锁常用类LockSupport LockSupport为常用类，主要作用就是挂起线程，唤醒线程。LockSupport的功能和\"Thread中的 Thread.suspend()和Thread.resume()有点类似”，LockSupport中的park() 和 unpark() 的作用分别是阻塞线程和解除阻塞线程。但是park()和unpark()不会遇到“Thread.suspend 和 Thread.resume所可能引发的死锁”问题。 该流程在购物APP上非常常见，当你准备支付时放弃，会有一个支付失效，在支付失效期内可以随时回来支付，过期后需要重新选取支付商品。 这里基于LockSupport中park和unpark控制线程状态，实现的等待通知机制。 public class LockAPI04 { public static void main(String[] args) throws Exception { OrderPay orderPay = new OrderPay(\"UnPaid\") ; Thread orderThread = new Thread(orderPay) ; orderThread.start(); Thread.sleep(3000); orderPay.changeState(\"Pay\"); LockSupport.unpark(orderThread); } } class OrderPay implements Runnable { // 支付状态 private String orderState ; public OrderPay (String orderState){ this.orderState = orderState ; } public synchronized void changeState (String orderState){ this.orderState = orderState ; } @Override public void run() { if (orderState.equals(\"UnPaid\")){ System.out.println(\"订单待支付...\"+orderState); LockSupport.park(orderState); } System.out.println(\"orderState=\"+orderState); System.out.println(\"订单准备发货...\"); } } ","date":"2018-04-02","objectID":"/juc/:1:7","tags":["并发编程","大纲"],"title":"JUC-并发编程利器","uri":"/juc/"},{"categories":["Java基础"],"content":"锁常用类ReentrantLock ReentrantLock为常用类，它是一个可重入的互斥锁 Lock，它具有与使用 synchronized 方法和语句所访问的隐式监视器锁相同的一些基本行为和语义，但功能更强大。 ","date":"2018-04-02","objectID":"/juc/:1:8","tags":["并发编程","大纲"],"title":"JUC-并发编程利器","uri":"/juc/"},{"categories":["Java基础"],"content":"锁常用类ReentrantReadWriteLock ReentrantReadWriteLock是读写锁接口ReadWriteLock的实现类，它包括Lock子类ReadLock和WriteLock。ReadLock是共享锁，WriteLock是独占锁。 基于读锁时，其他线程可以进行读操作，基于写锁时，其他线程读、写操作都禁止。 public class LockAPI03 { public static void main(String[] args) throws Exception { DataMap dataMap = new DataMap() ; Thread read = new Thread(new GetRun(dataMap)) ; Thread write = new Thread(new PutRun(dataMap)) ; write.start(); Thread.sleep(2000); read.start(); } } class GetRun implements Runnable { private DataMap dataMap ; public GetRun (DataMap dataMap){ this.dataMap = dataMap ; } @Override public void run() { System.out.println(\"GetRun：\"+dataMap.get(\"myKey\")); } } class PutRun implements Runnable { private DataMap dataMap ; public PutRun (DataMap dataMap){ this.dataMap = dataMap ; } @Override public void run() { dataMap.put(\"myKey\",\"myValue\"); } } class DataMap { Map\u003cString,String\u003e dataMap = new HashMap\u003c\u003e() ; ReadWriteLock rwLock = new ReentrantReadWriteLock() ; Lock readLock = rwLock.readLock() ; Lock writeLock = rwLock.writeLock() ; // 读取数据 public String get (String key){ readLock.lock(); try{ return dataMap.get(key) ; } finally { readLock.unlock(); } } // 写入数据 public void put (String key,String value){ writeLock.lock(); try{ dataMap.put(key,value) ; System.out.println(\"执行写入结束...\"); Thread.sleep(10000); } catch (Exception e) { System.out.println(\"Exception...\"); } finally { writeLock.unlock(); } } } ","date":"2018-04-02","objectID":"/juc/:1:9","tags":["并发编程","大纲"],"title":"JUC-并发编程利器","uri":"/juc/"},{"categories":["Java基础"],"content":"锁常用类StampedLock 它是java8在java.util.concurrent.locks新增的一个API。StampedLock控制锁有三种模式(写，读，乐观读)，一个StampedLock状态是由版本和模式两个部分组成，锁获取方法返回一个数字作为票据stamp，它用相应的锁状态表示并控制访问，数字0表示没有写锁被授权访问。在读锁上分为悲观锁和乐观锁。 ","date":"2018-04-02","objectID":"/juc/:1:10","tags":["并发编程","大纲"],"title":"JUC-并发编程利器","uri":"/juc/"},{"categories":["Java基础"],"content":"工具常用类CountDownLatch CountDownLatch为常用类，它是一个同步辅助类，在完成一组正在其他线程中执行的操作之前，它允许一个或多个线程一直等待。 ","date":"2018-04-02","objectID":"/juc/:1:11","tags":["并发编程","大纲"],"title":"JUC-并发编程利器","uri":"/juc/"},{"categories":["Java基础"],"content":"工具常用类CyclicBarrier CyclicBarrier为常用类，其是一个同步辅助类，它允许一组线程互相等待，直到到达某个公共屏障点 (common barrier point)。在涉及一组固定大小的线程的程序中，这些线程必须不时地互相等待，此时 CyclicBarrier 很有用。因为该 barrier 在释放等待线程后可以重用，所以称它为循环 的 barrier。 ","date":"2018-04-02","objectID":"/juc/:1:12","tags":["并发编程","大纲"],"title":"JUC-并发编程利器","uri":"/juc/"},{"categories":["Java基础"],"content":"工具常用类Phaser Phaser是JDK 7新增的一个同步辅助类，它可以实现CyclicBarrier和CountDownLatch类似的功能，而且它支持对任务的动态调整，并支持分层结构来达到更高的吞吐量。 ","date":"2018-04-02","objectID":"/juc/:1:13","tags":["并发编程","大纲"],"title":"JUC-并发编程利器","uri":"/juc/"},{"categories":["Java基础"],"content":"工具常用类Semaphore Semaphore为常用类，其是一个计数信号量，从概念上讲，信号量维护了一个许可集。如有必要，在许可可用前会阻塞每一个 acquire()，然后再获取该许可。每个 release() 添加一个许可，从而可能释放一个正在阻塞的获取者。但是，不使用实际的许可对象，Semaphore 只对可用许可的号码进行计数，并采取相应的行动。通常用于限制可以访问某些资源(物理或逻辑的)的线程数目。 ","date":"2018-04-02","objectID":"/juc/:1:14","tags":["并发编程","大纲"],"title":"JUC-并发编程利器","uri":"/juc/"},{"categories":["Java基础"],"content":"工具常用类Exchanger Exchanger是用于线程协作的工具类, 主要用于两个线程之间的数据交换。它提供一个同步点，在这个同步点，两个线程可以交换彼此的数据。这两个线程通过exchange()方法交换数据，当一个线程先执行exchange()方法后，它会一直等待第二个线程也执行exchange()方法，当这两个线程到达同步点时，这两个线程就可以交换数据了。 ","date":"2018-04-02","objectID":"/juc/:1:15","tags":["并发编程","大纲"],"title":"JUC-并发编程利器","uri":"/juc/"},{"categories":["Java基础"],"content":"对比 同步工具 同步工具与AQS的关联 ReentrantLock 使用AQS保存锁重复持有的次数。当一个线程获取锁时，ReentrantLock记录当前获得锁的线程标识，用于检测是否重复获取，以及错误线程试图解锁操作时异常情况的处理。 Semaphore 使用AQS同步状态来保存信号量的当前计数。tryRelease会增加计数，acquireShared会减少计数。 CountDownLatch 使用AQS同步状态来表示计数。计数为0时，所有的Acquire操作（CountDownLatch的await方法）才可以通过。 ReentrantReadWriteLock 使用AQS同步状态中的16位保存写锁持有的次数，剩下的16位用于保存读锁的持有次数。 ThreadPoolExecutor Worker利用AQS同步状态实现对独占线程变量的设置（tryAcquire和tryRelease）。 ","date":"2018-04-02","objectID":"/juc/:1:16","tags":["并发编程","大纲"],"title":"JUC-并发编程利器","uri":"/juc/"},{"categories":["Java基础"],"content":"Collections: 并发集合 并发集合\" 并发集合 ","date":"2018-04-02","objectID":"/juc/:2:0","tags":["并发编程","大纲"],"title":"JUC-并发编程利器","uri":"/juc/"},{"categories":["Java基础"],"content":"CAS,Unsafe和原子类 JUC中多数类是通过volatile和CAS来实现的，CAS本质上提供的是一种无锁方案，而Synchronized和Lock是互斥锁方案; Java原子类本质上使用的是CAS，而CAS底层是通过Unsafe类实现的。 ","date":"2018-04-02","objectID":"/juc/:3:0","tags":["并发编程","大纲"],"title":"JUC-并发编程利器","uri":"/juc/"},{"categories":["Java基础"],"content":"Atomic原子类 其基本的特性就是在多线程环境下，当有多个线程同时执行这些类的实例包含的方法时，具有排他性，即当某个线程进入方法，执行其中的指令时，不会被其他线程打断，而别的线程就像自旋锁一样，一直等到该方法执行完成，才由JVM从等待队列中选择一个另一个线程进入，这只是一种逻辑上的理解。实际上是借助硬件的相关指令来实现的，不会阻塞线程(或者说只是在硬件级别上阻塞了)。 ","date":"2018-04-02","objectID":"/juc/:3:1","tags":["并发编程","大纲"],"title":"JUC-并发编程利器","uri":"/juc/"},{"categories":["Java基础"],"content":"Executors线程池 线程池\" 线程池 ","date":"2018-04-02","objectID":"/juc/:4:0","tags":["并发编程","大纲"],"title":"JUC-并发编程利器","uri":"/juc/"},{"categories":["Java基础"],"content":"Executor Executor接口提供一种将任务提交与每个任务将如何运行的机制(包括线程使用的细节、调度等)分离开来的方法。通常使用 Executor 而不是显式地创建线程。 ","date":"2018-04-02","objectID":"/juc/:4:1","tags":["并发编程","大纲"],"title":"JUC-并发编程利器","uri":"/juc/"},{"categories":["Java基础"],"content":"ExecutorService ExecutorService继承自Executor接口，ExecutorService提供了管理终止的方法，以及可为跟踪一个或多个异步任务执行状况而生成 Future 的方法。 可以关闭 ExecutorService，这将导致其停止接受新任务。关闭后，执行程序将最后终止，这时没有任务在执行，也没有任务在等待执行，并且无法提交新任务。 ","date":"2018-04-02","objectID":"/juc/:4:2","tags":["并发编程","大纲"],"title":"JUC-并发编程利器","uri":"/juc/"},{"categories":["Java基础"],"content":"ScheduledExecutorService ScheduledExecutorService继承自ExecutorService接口，可安排在给定的延迟后运行或定期执行的命令。 ","date":"2018-04-02","objectID":"/juc/:4:3","tags":["并发编程","大纲"],"title":"JUC-并发编程利器","uri":"/juc/"},{"categories":["Java基础"],"content":"AbstractExecutorService AbstractExecutorService继承自ExecutorService接口，其提供 ExecutorService 执行方法的默认实现。此类使用 newTaskFor 返回的 RunnableFuture 实现 submit、invokeAny 和 invokeAll 方法，默认情况下，RunnableFuture 是此包中提供的 FutureTask 类。 ","date":"2018-04-02","objectID":"/juc/:4:4","tags":["并发编程","大纲"],"title":"JUC-并发编程利器","uri":"/juc/"},{"categories":["Java基础"],"content":"FutureTask FutureTask 为 Future 提供了基础实现，如获取任务执行结果(get)和取消任务(cancel)等。如果任务尚未完成，获取任务执行结果时将会阻塞。一旦执行结束，任务就不能被重启或取消(除非使用runAndReset执行计算)。FutureTask 常用来封装 Callable 和 Runnable，也可以作为一个任务提交到线程池中执行。除了作为一个独立的类之外，此类也提供了一些功能性函数供我们创建自定义 task 类使用。FutureTask 的线程安全由CAS来保证。 ","date":"2018-04-02","objectID":"/juc/:4:5","tags":["并发编程","大纲"],"title":"JUC-并发编程利器","uri":"/juc/"},{"categories":["Java基础"],"content":"核心: ThreadPoolExecutor ThreadPoolExecutor实现了AbstractExecutorService接口，也是一个 ExecutorService，它使用可能的几个池线程之一执行每个提交的任务，通常使用 Executors 工厂方法配置。 线程池可以解决两个不同问题: 由于减少了每个任务调用的开销，它们通常可以在执行大量异步任务时提供增强的性能，并且还可以提供绑定和管理资源(包括执行任务集时使用的线程)的方法。每个 ThreadPoolExecutor 还维护着一些基本的统计数据，如完成的任务数。 ","date":"2018-04-02","objectID":"/juc/:4:6","tags":["并发编程","大纲"],"title":"JUC-并发编程利器","uri":"/juc/"},{"categories":["Java基础"],"content":"核心: ScheduledThreadExecutor ScheduledThreadPoolExecutor实现ScheduledExecutorService接口，可安排在给定的延迟后运行命令，或者定期执行命令。需要多个辅助线程时，或者要求 ThreadPoolExecutor 具有额外的灵活性或功能时，此类要优于 Timer。 ","date":"2018-04-02","objectID":"/juc/:4:7","tags":["并发编程","大纲"],"title":"JUC-并发编程利器","uri":"/juc/"},{"categories":["Java基础"],"content":"核心: Fork/Join框架 ForkJoinPool 是JDK 7加入的一个线程池类。Fork/Join 技术是分治算法(Divide-and-Conquer)的并行实现，它是一项可以获得良好的并行性能的简单且高效的设计技术。目的是为了帮助我们更好地利用多处理器带来的好处，使用所有可用的运算能力来提升应用的性能。 ","date":"2018-04-02","objectID":"/juc/:4:8","tags":["并发编程","大纲"],"title":"JUC-并发编程利器","uri":"/juc/"},{"categories":["Java基础"],"content":"工具类: Executors Executors是一个工具类，用其可以创建ExecutorService、ScheduledExecutorService、ThreadFactory、Callable等对象。它的使用融入到了ThreadPoolExecutor, ScheduledThreadExecutor和ForkJoinPool中。 ","date":"2018-04-02","objectID":"/juc/:4:9","tags":["并发编程","大纲"],"title":"JUC-并发编程利器","uri":"/juc/"},{"categories":["Java基础"],"content":"Java并发编程","date":"2018-04-01","objectID":"/javacurrent/","tags":["并发编程","大纲"],"title":"Java并发编程概览","uri":"/javacurrent/"},{"categories":["Java基础"],"content":"Java并发编程概览Java并发编程概览 \" Java并发编程概览 ","date":"2018-04-01","objectID":"/javacurrent/:0:0","tags":["并发编程","大纲"],"title":"Java并发编程概览","uri":"/javacurrent/"},{"categories":["Java基础"],"content":"并发三要素 ","date":"2018-04-01","objectID":"/javacurrent/:1:0","tags":["并发编程","大纲"],"title":"Java并发编程概览","uri":"/javacurrent/"},{"categories":["Java基础"],"content":"可见性 一个线程对共享变量的修改，另外一个线程能够立刻看到。 CPU缓存引起：CPU增加了缓存，以均衡与内存的速度差异导致。 ","date":"2018-04-01","objectID":"/javacurrent/:1:1","tags":["并发编程","大纲"],"title":"Java并发编程概览","uri":"/javacurrent/"},{"categories":["Java基础"],"content":"原子性 一个操作或者多个操作 要么全部执行并且执行的过程不会被任何因素打断，要么就都不执行。 分时复用引起：操作系统增加了进程、线程，以分时复用CPU，进而均衡CPU与I/O设备的速度差异导致。 x = 10; //语句1: 直接将数值10赋值给x，也就是说线程执行这个语句的会直接将数值10写入到工作内存中 y = x; //语句2: 包含2个操作，它先要去读取x的值，再将x的值写入工作内存，虽然读取x的值以及 将x的值写入工作内存 这2个操作都是原子性操作，但是合起来就不是原子性操作了。 x++; //语句3： x++包括3个操作：读取x的值，进行加1操作，写入新的值。 x = x + 1; //语句4： 同语句3 ","date":"2018-04-01","objectID":"/javacurrent/:1:2","tags":["并发编程","大纲"],"title":"Java并发编程概览","uri":"/javacurrent/"},{"categories":["Java基础"],"content":"有序性 程序执行的顺序按照代码的先后顺序执行。 重排序引起：由于编译程序指令重排序优化指令执行次序，使得缓存能够得到更加合理地利用导致。 ","date":"2018-04-01","objectID":"/javacurrent/:1:3","tags":["并发编程","大纲"],"title":"Java并发编程概览","uri":"/javacurrent/"},{"categories":["Java基础"],"content":"线程安全的实现方法 ","date":"2018-04-01","objectID":"/javacurrent/:2:0","tags":["并发编程","大纲"],"title":"Java并发编程概览","uri":"/javacurrent/"},{"categories":["Java基础"],"content":"互斥同步(阻塞同步) synchronized(JVM实现) Lock\u0026ReentrantLock(JDK实现) 互斥同步最主要的问题就是线程阻塞和唤醒所带来的性能问题，因此这种同步也称为阻塞同步。 互斥同步属于一种悲观的并发策略，总是认为只要不去做正确的同步措施，那就肯定会出现问题。无论共享数据是否真的会出现竞争，它都要进行加锁(这里讨论的是概念模型，实际上虚拟机会优化掉很大一部分不必要的加锁)、用户态核心态转换、维护锁计数器和检查是否有被阻塞的线程需要唤醒等操作。 ","date":"2018-04-01","objectID":"/javacurrent/:2:1","tags":["并发编程","大纲"],"title":"Java并发编程概览","uri":"/javacurrent/"},{"categories":["Java基础"],"content":"非阻塞同步 CAS 随着硬件指令集的发展，我们可以使用基于冲突检测的乐观并发策略: 先进行操作，如果没有其它线程争用共享数据，那操作就成功了，否则采取补偿措施(不断地重试，直到成功为止)。 这种乐观的并发策略的许多实现都不需要将线程阻塞，因此这种同步操作称为非阻塞同步。 乐观锁需要操作和冲突检测这两个步骤具备原子性，这里就不能再使用互斥同步来保证了，只能靠硬件来完成。 硬件支持的原子性操作最典型的是: 比较并交换(Compare-and-Swap，CAS)。 CAS指令需要有3个操作数，分别是内存地址V旧的预期值A和新值B。当执行操作时，只有当V的值等于A，才将V的值更新为B。 AtomicInteger J.U.C 包里面的整数原子类 AtomicInteger，其中的 compareAndSet() 和 getAndIncrement() 等方法都使用了 Unsafe 类的 CAS 操作。 public final int incrementAndGet() { return unsafe.getAndAddInt(this, valueOffset, 1) + 1; } public final int getAndAddInt(Object var1, long var2, int var4) { int var5; do { var5 = this.getIntVolatile(var1, var2); } while(!this.compareAndSwapInt(var1, var2, var5, var5 + var4)); return var5; } ABA 如果一个变量初次读取的时候是 A 值，它的值被改成了 B，后来又被改回为 A，那 CAS 操作就会误认为它从来没有被改变过。 J.U.C 包提供了一个带有标记的原子引用类 AtomicStampedReference 来解决这个问题，它可以通过控制变量值的版本来保证 CAS 的正确性。 大部分情况下 ABA 问题不会影响程序并发的正确性，如果需要解决 ABA 问题，改用传统的互斥同步可能会比原子类更高效。 ","date":"2018-04-01","objectID":"/javacurrent/:2:2","tags":["并发编程","大纲"],"title":"Java并发编程概览","uri":"/javacurrent/"},{"categories":["Java基础"],"content":"无需同步方案 栈封闭 多个线程访问同一个方法的局部变量时，不会出现线程安全问题，因为局部变量存储在虚拟机栈中，属于线程私有的。 线程本地存储(ThreadLocal) 如果一段代码中所需要的数据必须与其他代码共享，那就看看这些共享数据的代码是否能保证在同一个线程中执行。如果能保证，我们就可以把共享数据的可见范围限制在同一个线程之内，这样，无须同步也能保证线程之间不出现数据争用的问题。 符合这种特点的应用并不少见，大部分使用消费队列的架构模式(如“生产者-消费者”模式)都会将产品的消费过程尽量在一个线程中消费完。 其中最重要的一个应用实例就是经典 Web 交互模型中的“一个请求对应一个服务器线程”(Thread-per-Request)的处理方式，这种处理方式的广泛应用使得很多 Web 服务端应用都可以使用线程本地存储来解决线程安全问题。 可重入代码 这种代码也叫做纯代码(Pure Code)，可以在代码执行的任何时刻中断它，转而去执行另外一段代码(包括递归调用它本身)，而在控制权返回后，原来的程序不会出现任何错误。 可重入代码有一些共同的特征，例如不依赖存储在堆上的数据和公用的系统资源、用到的状态量都由参数中传入、不调用非可重入的方法等。 ","date":"2018-04-01","objectID":"/javacurrent/:2:3","tags":["并发编程","大纲"],"title":"Java并发编程概览","uri":"/javacurrent/"},{"categories":["Java基础"],"content":"解决并发 ","date":"2018-04-01","objectID":"/javacurrent/:3:0","tags":["并发编程","大纲"],"title":"Java并发编程概览","uri":"/javacurrent/"},{"categories":["Java基础"],"content":"3个关键字 synchronized：原子性，可见性，有序性 volatile：有序性，可见性 防重排序 public class Singleton { public static volatile Singleton singleton; /** * 构造函数私有，禁止外部实例化 */ private Singleton() {}; public static Singleton getInstance() { if (singleton == null) { synchronized (singleton.class) { if (singleton == null) { singleton = new Singleton(); } } } return singleton; } } 现在我们分析一下为什么要在变量singleton之间加上volatile关键字。要理解这个问题，先要了解对象的构造过程，实例化一个对象其实可以分为三个步骤： 分配内存空间。 初始化对象。 将内存空间的地址赋值给对应的引用。 但是由于操作系统可以对指令进行重排序，所以上面的过程也可能会变成如下过程： 分配内存空间。 将内存空间的地址赋值给对应的引用。 初始化对象 如果是这个流程，多线程环境下就可能将一个未初始化的对象引用暴露出来，从而导致不可预料的结果。因此，为了防止这个过程的重排序，我们需要将变量设置为volatile类型的变量。 实现可见性 volatile 变量的内存可见性是基于内存屏障(Memory Barrier)实现: 内存屏障，又称内存栅栏，是一个 CPU 指令。 在程序运行时，为了提高执行性能，编译器和处理器会对指令进行重排序，JMM 为了保证在不同的编译器和 CPU 上有相同的结果，通过插入特定类型的内存屏障来禁止+ 特定类型的编译器重排序和处理器重排序，插入一条内存屏障会告诉编译器和 CPU：不管什么指令都不能和这条 Memory Barrier 指令重排序。 详细见：volatile理论基础 使用 volatile 必须具备的条件 对变量的写操作不依赖于当前值。 该变量没有包含在具有其他变量的不变式中。 只有在状态真正独立于程序内其他内容时才能使用volatile。 final：有序性 写final域的重排序规则可以确保：在对象引用为任意线程可见之前，对象的final域已经被正确初始化过了，而普通域就不具有这个保障。 读final域的重排序规则可以确保：在读一个对象的final域之前，一定会先读这个包含这个final域的对象的引用。 ","date":"2018-04-01","objectID":"/javacurrent/:3:1","tags":["并发编程","大纲"],"title":"Java并发编程概览","uri":"/javacurrent/"},{"categories":["Java基础"],"content":"Happens-Before 规则 上面提到了可以用volatile和synchronized来保证有序性。除此之外，JVM 还规定了先行发生原则，让一个操作无需控制就能先于另一个操作完成。 单一线程原则（在一个线程内，在程序前面的操作先行发生于后面的操作。） 管程锁定规则（一个 unlock 操作先行发生于后面对同一个锁的 lock 操作。） volatile 变量规则（对一个 volatile 变量的写操作先行发生于后面对这个变量的读操作。） 线程启动规则（Thread 对象的 start() 方法调用先行发生于此线程的每一个动作。） 线程加入规则（Thread 对象的结束先行发生于 join() 方法返回。） 线程中断规则（对线程 interrupt()方法的调用先行发生于被中断线程的代码检测到中断事件的发生，可以通过interrupted()方法检测到是否有中断发生。） 对象终结规则 一个对象的初始化完成(构造函数执行结束)先行发生于它的 finalize() 方法的开始。 传递性（如果操作 A 先行发生于操作 B，操作 B 先行发生于操作 C，那么操作 A 先行发生于操作 C。） ","date":"2018-04-01","objectID":"/javacurrent/:3:2","tags":["并发编程","大纲"],"title":"Java并发编程概览","uri":"/javacurrent/"},{"categories":["Java基础"],"content":"锁优化及JMM 新的JDK优化锁的实现保证并发，内存模型也会保证可见性。 ","date":"2018-04-01","objectID":"/javacurrent/:3:3","tags":["并发编程","大纲"],"title":"Java并发编程概览","uri":"/javacurrent/"},{"categories":["Java基础"],"content":"J.U.C框架 ","date":"2018-04-01","objectID":"/javacurrent/:4:0","tags":["并发编程","大纲"],"title":"Java并发编程概览","uri":"/javacurrent/"},{"categories":["Java基础"],"content":"Unsafe(CAS)和原子类 ","date":"2018-04-01","objectID":"/javacurrent/:4:1","tags":["并发编程","大纲"],"title":"Java并发编程概览","uri":"/javacurrent/"},{"categories":["Java基础"],"content":"AQS框架 AQS框架借助于两个类：Unsafe(提供CAS操作)和LockSupport(提供park/unpark操作)。 ","date":"2018-04-01","objectID":"/javacurrent/:4:2","tags":["并发编程","大纲"],"title":"Java并发编程概览","uri":"/javacurrent/"},{"categories":["Java基础"],"content":"锁 LockSupport ReentrantLock ReentrantReadWriteLock ","date":"2018-04-01","objectID":"/javacurrent/:4:3","tags":["并发编程","大纲"],"title":"Java并发编程概览","uri":"/javacurrent/"},{"categories":["Java基础"],"content":"并发集合 ConcurrentHashMap CopyOnWriteArrayList ConcurrentLinkedQueue BlockingQueue ","date":"2018-04-01","objectID":"/javacurrent/:4:4","tags":["并发编程","大纲"],"title":"Java并发编程概览","uri":"/javacurrent/"},{"categories":["Java基础"],"content":"线程池 FutureTask ThreadPoolExecutor ScheduledThreadPoolExecutor Fork/Join ","date":"2018-04-01","objectID":"/javacurrent/:4:5","tags":["并发编程","大纲"],"title":"Java并发编程概览","uri":"/javacurrent/"},{"categories":["Java基础"],"content":"工具类 CountDownLatch CyclicBarrier Semaphore Phaser Exchanger ThreadLocal ","date":"2018-04-01","objectID":"/javacurrent/:4:6","tags":["并发编程","大纲"],"title":"Java并发编程概览","uri":"/javacurrent/"},{"categories":["Java基础"],"content":"参考文章 Java 并发 - 理论基础 ","date":"2018-04-01","objectID":"/javacurrent/:5:0","tags":["并发编程","大纲"],"title":"Java并发编程概览","uri":"/javacurrent/"},{"categories":["Java基础"],"content":"HashMap详解","date":"2018-03-03","objectID":"/hashmap/","tags":["数据结构"],"title":"HashMap详解","uri":"/hashmap/"},{"categories":["Java基础"],"content":"实现步骤 HashMap基于哈希散列表，数组+链表/红黑树实现。 通过key的hashCode()方法计算出hashCode。 通过HashMap类中内部hash()方法将第2步中hashCode带入得出hash值。 通过第3步中hash值和HashMap中数组长度做\u0026(位运算)得出在数组中的位置。 当第4步中位置中没有值则直接放入。 当第4步中位置中有值即产生hash冲突问题，此时通过链表(拉链法)来解决hash冲突问题。 如果第6步中第链表大小超过阈值（TREEIFY_THRESHOLD,8），链表转换为红黑树。 在转换为红黑树时，会判断数组长度大于64才转换，否则继续采用扩容策略而不转换。 ","date":"2018-03-03","objectID":"/hashmap/:1:0","tags":["数据结构"],"title":"HashMap详解","uri":"/hashmap/"},{"categories":["Java基础"],"content":"关键特性 默认初始容量值为16，负载因子为0.75，当size\u003e=threshold（ threshold等于“容量负载因子”）时，会发生扩容：newsize = oldsize2，size一定为2的n次幂 hash冲突默认采用单链表存储，当单链表节点个数大于8时且数组长度大于64，会转化为红黑树存储， 当红黑树中节点少于6时，则转化为单链表存储。 扩容针对整个Map，每次扩容时，原来数组中的元素依次重新计算存放位置，并重新插入 当Map中元素总数超过Entry数组的75%，触发扩容操作，为了减少链表长度，元素分配更均匀 ","date":"2018-03-03","objectID":"/hashmap/:2:0","tags":["数据结构"],"title":"HashMap详解","uri":"/hashmap/"},{"categories":["Java基础"],"content":"HashMap在1.7和1.8之间的变化： 1.7中是先扩容后插入新值的，1.8中是先插值再扩容 1.7中采用数组+链表，1.8采用的是数组+链表/红黑树，即在1.7中链表长度超过一定长度后就改成红黑树存储。 1.7扩容时需要重新计算哈希值和索引位置，1.8并不重新计算哈希值，巧妙地采用和扩容后容量进行\u0026操作来计算新的索引位置。 1.7是采用表头插入法插入链表，1.8采用的是尾部插入法。 在1.7中采用表头插入法，在扩容时会改变链表中元素原本的顺序，以至于在并发场景下导致链表成环的问题；在1.8中采用尾部插入法，在扩容时会保持链表元素原本的顺序，就不会出现链表成环的问题了。 ","date":"2018-03-03","objectID":"/hashmap/:3:0","tags":["数据结构"],"title":"HashMap详解","uri":"/hashmap/"},{"categories":["Java基础"],"content":"方法（JDK1.8-数组+链表/红黑树） 确定哈希桶数组索引位置 第1步计算hash 在JDK1.8的实现中，优化了高位运算的算法，通过hashCode()的高16位异或低16位实现的：(h = k.hashCode()) ^ (h »\u003e 16)，主要是从速度、功效、质量来考虑的。 目的都是在数组很小也能降低hash碰撞。 static final int hash(Object key) { int h; // key.hashCode()：返回散列值也就是hashcode // ^ ：按位异或 // \u003e\u003e\u003e:无符号右移，忽略符号位，空位都以0补齐 return (key == null) ? 0 : (h = key.hashCode()) ^ (h \u003e\u003e\u003e 16); } 第2步计算数组位置 通过(n - 1) \u0026 hash来得到该对象的保存位，而HashMap底层数组的长度总是2的n次方。 当length总是2的n次方时，h\u0026 (length-1)运算等价于对length取模，也就是h%length，但是\u0026(位运算)比%(取模运算)具有更高的效率。 (n - 1) \u0026 hash HashMap的put方法 public V put(K key, V value) { // 对key的hashCode()做hash return putVal(hash(key), key, value, false, true); } final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) { Node\u003cK,V\u003e[] tab; Node\u003cK,V\u003e p; int n, i; // 步骤①：tab为空则创建 if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; // 步骤②：计算index，并对null做处理 if ((p = tab[i = (n - 1) \u0026 hash]) == null) tab[i] = newNode(hash, key, value, null); else { Node\u003cK,V\u003e e; K k; // 步骤③：节点key存在，直接覆盖value if (p.hash == hash \u0026\u0026 ((k = p.key) == key || (key != null \u0026\u0026 key.equals(k)))) e = p; // 步骤④：判断该链为红黑树 else if (p instanceof TreeNode) e = ((TreeNode\u003cK,V\u003e)p).putTreeVal(this, tab, hash, key, value); // 步骤⑤：该链为链表 else { for (int binCount = 0; ; ++binCount) { if ((e = p.next) == null) { p.next = newNode(hash, key,value,null); //链表长度大于8转换为红黑树进行处理 if (binCount \u003e= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; } // key已经存在直接覆盖value if (e.hash == hash \u0026\u0026 ((k = e.key) == key || (key != null \u0026\u0026 key.equals(k)))) break; p = e; } } if (e != null) { // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; } } ++modCount; // 步骤⑥：超过最大容量 就扩容 if (++size \u003e threshold) resize(); afterNodeInsertion(evict); return null; } final void treeifyBin(Node\u003cK,V\u003e[] tab, int hash) { int n, index; Node\u003cK,V\u003e e; //树形化还有一个要求就是数组长度必须大于等于64，否则继续采用扩容策略 if (tab == null || (n = tab.length) \u003c MIN_TREEIFY_CAPACITY) resize(); else if ((e = tab[index = (n - 1) \u0026 hash]) != null) { TreeNode\u003cK,V\u003e hd = null, tl = null;//hd指向首节点，tl指向尾节点 do { TreeNode\u003cK,V\u003e p = replacementTreeNode(e, null);//将链表节点转化为红黑树节点 if (tl == null) // 如果尾节点为空，说明还没有首节点 hd = p; // 当前节点作为首节点 else { // 尾节点不为空，构造一个双向链表结构，将当前节点追加到双向链表的末尾 p.prev = tl; // 当前树节点的前一个节点指向尾节点 tl.next = p; // 尾节点的后一个节点指向当前节点 } tl = p; // 把当前节点设为尾节点 } while ((e = e.next) != null); // 继续遍历单链表 //将原本的单链表转化为一个节点类型为TreeNode的双向链表 if ((tab[index] = hd) != null) // 把转换后的双向链表，替换数组原来位置上的单向链表 hd.treeify(tab); // 将当前双向链表树形化 } } //将双向链表转化为红黑树的实现 final void treeify(Node\u003cK,V\u003e[] tab) { TreeNode\u003cK,V\u003e root = null; // 定义红黑树的根节点 for (TreeNode\u003cK,V\u003e x = this, next; x != null; x = next) { // 从TreeNode双向链表的头节点开始逐个遍历 next = (TreeNode\u003cK,V\u003e)x.next; // 头节点的后继节点 x.left = x.right = null; if (root == null) { x.parent = null; x.red = false; root = x; // 头节点作为红黑树的根，设置为黑色 } else { // 红黑树存在根节点 K k = x.key; int h = x.hash; Class\u003c?\u003e kc = null; for (TreeNode\u003cK,V\u003e p = root;;) { // 从根开始遍历整个红黑树 int dir, ph; K pk = p.key; if ((ph = p.hash) \u003e h) // 当前红黑树节点p的hash值大于双向链表节点x的哈希值 dir = -1; else if (ph \u003c h) // 当前红黑树节点的hash值小于双向链表节点x的哈希值 dir = 1; else if ((kc == null \u0026\u0026 (kc = comparableClassFor(k)) == null) || (dir = compareComparables(kc, k, pk)) == 0) // 当前红黑树节点的hash值等于双向链表节点x的哈希值，则如果key值采用比较器一致则比较key值 dir = tieBreakOrder(k, pk); //如果key值也一致则比较className和identityHashCode TreeNode\u003cK,V\u003e xp = p; if ((p = (dir \u003c= 0) ? p.left : p.right) == null) { // 如果当前红黑树节点p是叶子节点，那么双向链表节点x就找到了插入的位置 x.parent = xp; if (dir \u003c= 0) //根据dir的值，插入到p的左孩子或者右孩子 xp.left = x; else xp.right = x; root = balanceInsertion(root, x); //红黑树中插入元素，需要进行平衡调整(过程和TreeMap调整逻辑一模一样) break; } } } } //将TreeNode双向链表转化为红黑树结构之后，由于红黑树是基于根节点进行查找，所以必须将红黑树的根节点作为数组当前位置的元素 moveRootToFront(tab, root); } //然后将红黑树的根节点移动端数组的索引所在位置上 static \u003cK,V\u003e void moveRootToFront(Node\u003cK,V\u003e[] tab, TreeNode\u003cK,V\u003e root) { int n; if (root != null \u0026\u0026 tab != null \u0026\u0026 (n = tab.length) \u003e 0) { int index = (n - 1) \u0026 root.hash; //找到红黑树根节点在数组中的位置 TreeNode\u003cK,V\u003e first = (TreeNode\u003cK,V\u003e)tab[inde","date":"2018-03-03","objectID":"/hashmap/:4:0","tags":["数据结构"],"title":"HashMap详解","uri":"/hashmap/"},{"categories":["Java基础"],"content":"参考文章 https://www.hollischuang.com/archives/2091 https://yuanrengu.com/2020/ba184259.html https://zhuanlan.zhihu.com/p/21673805 https://mp.weixin.qq.com/s?__biz=MzIwNTI2ODY5OA==\u0026mid=2649938471\u0026idx=1\u0026sn=2964df2adc4feaf87c11b4915b9a018e ","date":"2018-03-03","objectID":"/hashmap/:5:0","tags":["数据结构"],"title":"HashMap详解","uri":"/hashmap/"},{"categories":["Java基础"],"content":"ArrayList详解","date":"2018-03-02","objectID":"/arraylist/","tags":["数据结构"],"title":"ArrayList详解","uri":"/arraylist/"},{"categories":["Java基础"],"content":"ArrayList 简介 ArrayList 的底层是数组队列，相当于动态数组。与 Java 中的数组相比，它的容量能动态增长。在添加大量元素前，应用程序可以使用ensureCapacity操作来增加 ArrayList 实例的容量。这可以减少递增式再分配的数量。 ","date":"2018-03-02","objectID":"/arraylist/:1:0","tags":["数据结构"],"title":"ArrayList详解","uri":"/arraylist/"},{"categories":["Java基础"],"content":"ArrayList 核心源码解读 package java.util; import java.util.function.Consumer; import java.util.function.Predicate; import java.util.function.UnaryOperator; public class ArrayList\u003cE\u003e extends AbstractList\u003cE\u003e implements List\u003cE\u003e, RandomAccess, Cloneable, java.io.Serializable { private static final long serialVersionUID = 8683452581122892189L; /** * 默认初始容量大小 */ private static final int DEFAULT_CAPACITY = 10; /** * 空数组（用于空实例）。 */ private static final Object[] EMPTY_ELEMENTDATA = {}; //用于默认大小空实例的共享空数组实例。 //我们把它从EMPTY_ELEMENTDATA数组中区分出来，以知道在添加第一个元素时容量需要增加多少。 private static final Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = {}; /** * 保存ArrayList数据的数组 */ transient Object[] elementData; // non-private to simplify nested class access /** * ArrayList 所包含的元素个数 */ private int size; /** * 带初始容量参数的构造函数（用户可以在创建ArrayList对象时自己指定集合的初始大小） */ public ArrayList(int initialCapacity) { if (initialCapacity \u003e 0) { //如果传入的参数大于0，创建initialCapacity大小的数组 this.elementData = new Object[initialCapacity]; } else if (initialCapacity == 0) { //如果传入的参数等于0，创建空数组 this.elementData = EMPTY_ELEMENTDATA; } else { //其他情况，抛出异常 throw new IllegalArgumentException(\"Illegal Capacity: \"+ initialCapacity); } } /** *默认无参构造函数 *DEFAULTCAPACITY_EMPTY_ELEMENTDATA 为0.初始化为10，也就是说初始其实是空数组 当添加第一个元素的时候数组容量才变成10 */ public ArrayList() { this.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA; } /** * 构造一个包含指定集合的元素的列表，按照它们由集合的迭代器返回的顺序。 */ public ArrayList(Collection\u003c? extends E\u003e c) { //将指定集合转换为数组 elementData = c.toArray(); //如果elementData数组的长度不为0 if ((size = elementData.length) != 0) { // 如果elementData不是Object类型数据（c.toArray可能返回的不是Object类型的数组所以加上下面的语句用于判断） if (elementData.getClass() != Object[].class) //将原来不是Object类型的elementData数组的内容，赋值给新的Object类型的elementData数组 elementData = Arrays.copyOf(elementData, size, Object[].class); } else { // 其他情况，用空数组代替 this.elementData = EMPTY_ELEMENTDATA; } } /** * 修改这个ArrayList实例的容量是列表的当前大小。 应用程序可以使用此操作来最小化ArrayList实例的存储。 */ public void trimToSize() { modCount++; if (size \u003c elementData.length) { elementData = (size == 0) ? EMPTY_ELEMENTDATA : Arrays.copyOf(elementData, size); } } //下面是ArrayList的扩容机制 //ArrayList的扩容机制提高了性能，如果每次只扩充一个， //那么频繁的插入会导致频繁的拷贝，降低性能，而ArrayList的扩容机制避免了这种情况。 /** * 如有必要，增加此ArrayList实例的容量，以确保它至少能容纳元素的数量 * @param minCapacity 所需的最小容量 */ public void ensureCapacity(int minCapacity) { //如果是true，minExpand的值为0，如果是false,minExpand的值为10 int minExpand = (elementData != DEFAULTCAPACITY_EMPTY_ELEMENTDATA) // any size if not default element table ? 0 // larger than default for default empty table. It's already // supposed to be at default size. : DEFAULT_CAPACITY; //如果最小容量大于已有的最大容量 if (minCapacity \u003e minExpand) { ensureExplicitCapacity(minCapacity); } } //得到最小扩容量 private void ensureCapacityInternal(int minCapacity) { if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) { // 获取“默认的容量”和“传入参数”两者之间的最大值 minCapacity = Math.max(DEFAULT_CAPACITY, minCapacity); } ensureExplicitCapacity(minCapacity); } //判断是否需要扩容 private void ensureExplicitCapacity(int minCapacity) { modCount++; // overflow-conscious code if (minCapacity - elementData.length \u003e 0) //调用grow方法进行扩容，调用此方法代表已经开始扩容了 grow(minCapacity); } /** * 要分配的最大数组大小 */ private static final int MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8; /** * ArrayList扩容的核心方法。 */ private void grow(int minCapacity) { // oldCapacity为旧容量，newCapacity为新容量 int oldCapacity = elementData.length; //将oldCapacity 右移一位，其效果相当于oldCapacity /2， //我们知道位运算的速度远远快于整除运算，整句运算式的结果就是将新容量更新为旧容量的1.5倍， int newCapacity = oldCapacity + (oldCapacity \u003e\u003e 1); //然后检查新容量是否大于最小需要容量，若还是小于最小需要容量，那么就把最小需要容量当作数组的新容量， if (newCapacity - minCapacity \u003c 0) newCapacity = minCapacity; //再检查新容量是否超出了ArrayList所定义的最大容量， //若超出了，则调用hugeCapacity()来比较minCapacity和 MAX_ARRAY_SIZE， //如果minCapacity大于MAX_ARRAY_SIZE，则新容量则为Interger.MAX_VALUE，否则，新容量大小则为 MAX_ARRAY_SIZE。 if (newCapacity - MAX_ARRAY_SIZE \u003e 0) newCapacity = hugeCapacity(minCapacity); // minCapacity is usually close to size, so this is a win: elementData = Arrays.copyOf(elementData, newCapacity); } //比较minCapacity和 MAX_ARRAY_SIZE private static int hug","date":"2018-03-02","objectID":"/arraylist/:2:0","tags":["数据结构"],"title":"ArrayList详解","uri":"/arraylist/"},{"categories":["Java基础"],"content":"Java容器","date":"2018-03-01","objectID":"/javacontainer/","tags":["数据结构","大纲"],"title":"Java容器概览","uri":"/javacontainer/"},{"categories":["Java基础"],"content":"概览 容器主要包括Collection和Map 两种，Collection存储着对象的集合，而Map存储着键值对（两个对象）的映射表。 ","date":"2018-03-01","objectID":"/javacontainer/:1:0","tags":["数据结构","大纲"],"title":"Java容器概览","uri":"/javacontainer/"},{"categories":["Java基础"],"content":"Collection ","date":"2018-03-01","objectID":"/javacontainer/:2:0","tags":["数据结构","大纲"],"title":"Java容器概览","uri":"/javacontainer/"},{"categories":["Java基础"],"content":"List 对付顺序的好帮手： 存储的元素是有序的、可重复的。 ArrayList：基于动态数组实现，支持随机访问，适用于频繁的查找工作。 Vector：和ArrayList类似，但它是线程安全的。 LinkedList：基于双向链表实现，只能顺序访问，但是可以快速地在链表中间插入和删除元素。不仅如此，LinkedList还可以用作栈、队列和双向队列。 Arraylist与 LinkedList 区别? 是否保证线程安全： ArrayList和LinkedList都是不同步的，也就是不保证线程安全； 底层数据结构： Arraylist底层使用的是Object数组；LinkedList底层使用的是双向链表数据结构（JDK1.6 之前为循环链表，JDK1.7 取消了循环。） 插入和删除是否受元素位置的影响： ArrayList 采用数组存储，所以插入和删除元素的时间复杂度受元素位置的影响。 比如：执行add(E e)方法的时候， ArrayList 会默认在将指定的元素追加到此列表的末尾，这种情况时间复杂度就是 O(1)。但是如果要在指定位置 i 插入和删除元素的话（add(int index, E element)）时间复杂度就为 O(n-i)。因为在进行上述操作的时候集合中第 i 和第 i 个元素之后的(n-i)个元素都要执行向后位/向前移一位的操作。 LinkedList 采用链表存储，所以对于add(E e)方法的插入，删除元素时间复杂度不受元素位置的影响，近似 O(1)，如果是要在指定位置 i 插入和删除元素的话（(add(int index, E element)） 时间复杂度近似为 O(n) ，因为需要先移动到指定位置再插入。 是否支持快速随机访问： LinkedList 不支持高效的随机元素访问，而 ArrayList 支持。快速随机访问就是通过元素的序号快速获取元素对象(对应于get(int index)方法)。 内存空间占用： ArrayList的空间浪费主要体现在在list列表的结尾会预留一定的容量空间，而 LinkedList 的空间花费则体现在它的每一个元素都需要消耗比 ArrayList 更多的空间（因为要存放直接后继和直接前驱以及数据）。 ","date":"2018-03-01","objectID":"/javacontainer/:2:1","tags":["数据结构","大纲"],"title":"Java容器概览","uri":"/javacontainer/"},{"categories":["Java基础"],"content":"Set 注重独一无二的性质: 存储的元素是无序的、不可重复的。 HashSet：基于哈希表实现，支持快速查找，但不支持有序性操作。基于 HashMap 实现的，底层采用 HashMap 来保存元素。 LinkedHashSet：具有 HashSet 的查找效率，并且内部使用双向链表维护元素的插入顺序。LinkedHashSet 是 HashSet 的子类，并且其内部是通过 LinkedHashMap 来实现的。 TreeSet：基于红黑树实现（(自平衡的排序二叉树)），支持有序性操作，例如根据一个范围查找元素的操作。查找效率不如HashSet，HashSet 查找的时间复杂度为 O(1)，TreeSet 则为 O(logN)。 HashSet 如何检查重复 当你把对象加入HashSet时，HashSet 会先计算对象的hashcode值来判断对象加入的位置，同时也会与其他加入的对象的 hashcode 值作比较，如果没有相符的 hashcode，HashSet 会假设对象没有重复出现。但是如果发现有相同 hashcode 值的对象，这时会调用equals()方法来检查 hashcode 相等的对象是否真的相同。如果两者相同，HashSet 就不会让加入操作成功。 hashCode()与 equals() 的相关规定： 如果两个对象相等，则 hashcode 一定也是相同的 两个对象相等,对两个 equals() 方法返回 true 两个对象有相同的 hashcode 值，它们也不一定是相等的 综上，equals() 方法被覆盖过，则 hashCode() 方法也必须被覆盖 hashCode()的默认行为是对堆上的对象产生独特值。如果没有重写 hashCode()，则该 class 的两个对象无论如何都不会相等（即使这两个对象指向相同的数据）。 ","date":"2018-03-01","objectID":"/javacontainer/:2:2","tags":["数据结构","大纲"],"title":"Java容器概览","uri":"/javacontainer/"},{"categories":["Java基础"],"content":"Queue LinkedList：可以用它来实现双向队列。 PriorityQueue：基于堆结构实现，可以用它来实现优先队列。 ","date":"2018-03-01","objectID":"/javacontainer/:2:3","tags":["数据结构","大纲"],"title":"Java容器概览","uri":"/javacontainer/"},{"categories":["Java基础"],"content":"Map 用 Key 来搜索的专家: 使用键值对（key-value）存储，Key 是无序的、不可重复的，value 是无序的、可重复的，每个键最多映射到一个值。 TreeMap： 红黑树（自平衡的排序二叉树） HashMap： JDK1.8之前HashMap由数组+链表组成的，数组是HashMap的主体，链表则是主要为了解决哈希冲突而存在的（“拉链法”解决冲突）。JDK1.8 以后在解决哈希冲突时有了较大的变化，当链表长度大于阈值（默认为 8）（将链表转换成红黑树前会判断，如果当前数组的长度小于 64，那么会选择先进行数组扩容，而不是转换为红黑树）时，将链表转化为红黑树，以减少搜索时间 HashTable：和 HashMap 类似，但它是线程安全的，这意味着同一时刻多个线程同时写入 HashTable 不会导致数据不一致。它是遗留类，不应该去使用它，而是使用 ConcurrentHashMap 来支持线程安全，ConcurrentHashMap 的效率会更高。 LinkedHashMap：LinkedHashMap 继承自 HashMap，LinkedHashMap 在上面结构的基础上，增加了一条双向链表，使得上面的结构可以保持键值对的插入顺序，顺序为插入顺序或者最近最少使用（LRU）顺序。 ","date":"2018-03-01","objectID":"/javacontainer/:3:0","tags":["数据结构","大纲"],"title":"Java容器概览","uri":"/javacontainer/"},{"categories":["Java基础"],"content":"如何选择 主要根据集合的特点来选用，比如我们需要根据键值获取到元素值时就选用 Map 接口下的集合，需要排序时选择 TreeMap,不需要排序时就选择 HashMap,需要保证线程安全就选用 ConcurrentHashMap。 当我们只需要存放元素值时，就选择实现Collection 接口的集合，需要保证元素唯一时选择实现 Set 接口的集合比如 TreeSet 或 HashSet，不需要就选择实现 List 接口的比如 ArrayList 或 LinkedList，然后再根据实现这些接口的集合的特点来选用。 ","date":"2018-03-01","objectID":"/javacontainer/:4:0","tags":["数据结构","大纲"],"title":"Java容器概览","uri":"/javacontainer/"},{"categories":["Java基础"],"content":"为什么要使用 当我们需要保存一组类型相同的数据的时候，我们应该是用一个容器来保存，这个容器就是数组，但是，使用数组存储对象具有一定的弊端，因为我们在实际开发中，存储的数据的类型是多种多样的，于是，就出现了“集合”，集合同样也是用来存储多个数据的。 数组的缺点是一旦声明之后，长度就不可变了；同时，声明数组时的数据类型也决定了该数组存储的数据的类型；而且，数组存储的数据是有序的、可重复的，特点单一。 但是集合提高了数据存储的灵活性，Java 集合不仅可以用来存储不同类型不同数量的对象，还可以保存具有映射关系的数据。 ","date":"2018-03-01","objectID":"/javacontainer/:5:0","tags":["数据结构","大纲"],"title":"Java容器概览","uri":"/javacontainer/"},{"categories":["Java基础"],"content":"Java IO知识体系详解","date":"2018-02-05","objectID":"/javaio/","tags":["Java基础","大纲"],"title":"Java IO知识体系详解 ","uri":"/javaio/"},{"categories":["Java基础"],"content":"IO大纲\" IO大纲 ","date":"2018-02-05","objectID":"/javaio/:0:0","tags":["Java基础","大纲"],"title":"Java IO知识体系详解 ","uri":"/javaio/"},{"categories":["Java基础"],"content":"IO装饰者模式 以 InputStream 为例 InputStream 是抽象组件； FileInputStream 是 InputStream 的子类，属于具体组件，提供了字节流的输入操作； FilterInputStream 属于抽象装饰者，装饰者用于装饰组件，为组件提供额外的功能。例如 BufferedInputStream 为 FileInputStream 提供缓存的功能。 实例化一个具有缓存功能的字节流对象时，只需要在 FileInputStream 对象上再套一层 BufferedInputStream 对象即可。 FileInputStream fileInputStream = new FileInputStream(filePath); BufferedInputStream bufferedInputStream = new BufferedInputStream(fileInputStream); ","date":"2018-02-05","objectID":"/javaio/:1:0","tags":["Java基础","大纲"],"title":"Java IO知识体系详解 ","uri":"/javaio/"},{"categories":["Java基础"],"content":"IO常见类的使用 ","date":"2018-02-05","objectID":"/javaio/:2:0","tags":["Java基础","大纲"],"title":"Java IO知识体系详解 ","uri":"/javaio/"},{"categories":["Java基础"],"content":"磁盘操作 File 类可以用于表示文件和目录的信息，但是它不表示文件的内容。 //递归地列出一个目录下所有文件: public static void listAllFiles(File dir) { if (dir == null || !dir.exists()) { return; } if (dir.isFile()) { System.out.println(dir.getName()); return; } for (File file : dir.listFiles()) { listAllFiles(file); } } ","date":"2018-02-05","objectID":"/javaio/:2:1","tags":["Java基础","大纲"],"title":"Java IO知识体系详解 ","uri":"/javaio/"},{"categories":["Java基础"],"content":"字节操作（InputStream 和 OutputStream ） public static void copyFile(String src, String dist) throws IOException { FileInputStream in = new FileInputStream(src); FileOutputStream out = new FileOutputStream(dist); byte[] buffer = new byte[20 * 1024]; // read() 最多读取 buffer.length 个字节 // 返回的是实际读取的个数 // 返回 -1 的时候表示读到 eof，即文件尾 while (in.read(buffer, 0, buffer.length) != -1) { out.write(buffer); } in.close(); out.close(); } ","date":"2018-02-05","objectID":"/javaio/:2:2","tags":["Java基础","大纲"],"title":"Java IO知识体系详解 ","uri":"/javaio/"},{"categories":["Java基础"],"content":"字符操作（Reader 和 Writer ） //实现逐行输出文本文件的内容 public static void readFileContent(String filePath) throws IOException { FileReader fileReader = new FileReader(filePath); BufferedReader bufferedReader = new BufferedReader(fileReader); String line; while ((line = bufferedReader.readLine()) != null) { System.out.println(line); } // 装饰者模式使得 BufferedReader 组合了一个 Reader 对象 // 在调用 BufferedReader 的 close() 方法时会去调用 Reader 的 close() 方法 // 因此只要一个 close() 调用即可 bufferedReader.close(); } ","date":"2018-02-05","objectID":"/javaio/:2:3","tags":["Java基础","大纲"],"title":"Java IO知识体系详解 ","uri":"/javaio/"},{"categories":["Java基础"],"content":"对象操作(序列化Serializable \u0026 transient) 序列化就是将一个对象转换成字节序列，方便存储和传输。 序列化: ObjectOutputStream.writeObject() 反序列化: ObjectInputStream.readObject() 序列化的类需要实现Serializable接口，它只是一个标准，没有任何方法需要实现，但是如果不去实现它的话而进行序列化，会抛出异常。 transient 关键字可以使一些属性不会被序列化。 不会对静态变量进行序列化，因为序列化只是保存对象的状态，静态变量属于类的状态。 public static void main(String[] args) throws IOException, ClassNotFoundException { A a1 = new A(123, \"abc\"); String objectFile = \"file/a1\"; ObjectOutputStream objectOutputStream = new ObjectOutputStream(new FileOutputStream(objectFile)); objectOutputStream.writeObject(a1); objectOutputStream.close(); ObjectInputStream objectInputStream = new ObjectInputStream(new FileInputStream(objectFile)); A a2 = (A) objectInputStream.readObject(); objectInputStream.close(); System.out.println(a2); } private static class A implements Serializable { private int x; private String y; A(int x, String y) { this.x = x; this.y = y; } @Override public String toString() { return \"x = \" + x + \" \" + \"y = \" + y; } } ","date":"2018-02-05","objectID":"/javaio/:2:4","tags":["Java基础","大纲"],"title":"Java IO知识体系详解 ","uri":"/javaio/"},{"categories":["Java基础"],"content":"网络操作 InetAddress: 用于表示网络上的硬件资源，即 IP 地址； URL: 统一资源定位符； Sockets: 使用 TCP 协议实现网络通信； Datagram: 使用 UDP 协议实现网络通信。 /** * InetAddress * 没有公有的构造函数，只能通过静态方法来创建实例。 */ InetAddress.getByName(String host); InetAddress.getByAddress(byte[] address); /** * URL * 可以直接从 URL 中读取字节流数据。 */ public static void main(String[] args) throws IOException { URL url = new URL(\"http://www.baidu.com\"); /* 字节流 */ InputStream is = url.openStream(); /* 字符流 */ InputStreamReader isr = new InputStreamReader(is, \"utf-8\"); /* 提供缓存功能 */ BufferedReader br = new BufferedReader(isr); String line; while ((line = br.readLine()) != null) { System.out.println(line); } br.close(); } Sockets ServerSocket: 服务器端类 Socket: 客户端类 服务器和客户端通过 InputStream 和 OutputStream 进行输入输出。 Datagram DatagramSocket: 通信类 DatagramPacket: 数据包类 ","date":"2018-02-05","objectID":"/javaio/:2:5","tags":["Java基础","大纲"],"title":"Java IO知识体系详解 ","uri":"/javaio/"},{"categories":["Java基础"],"content":"Unix IO 模型简介 ","date":"2018-02-05","objectID":"/javaio/:3:0","tags":["Java基础","大纲"],"title":"Java IO知识体系详解 ","uri":"/javaio/"},{"categories":["Java基础"],"content":"阻塞式 I/O 应用进程被阻塞，直到数据复制到应用进程缓冲区中才返回。 应该注意到，在阻塞的过程中，其它程序还可以执行，因此阻塞不意味着整个操作系统都被阻塞。因为其他程序还可以执行，因此不消耗 CPU 时间，这种模型的执行效率会比较高。 阻塞式IO\" 阻塞式IO ","date":"2018-02-05","objectID":"/javaio/:3:1","tags":["Java基础","大纲"],"title":"Java IO知识体系详解 ","uri":"/javaio/"},{"categories":["Java基础"],"content":"非阻塞式 I/O 应用进程执行系统调用之后，内核返回一个错误码。应用进程可以继续执行，但是需要不断的执行系统调用来获知 I/O 是否完成，这种方式称为轮询(polling)。 由于 CPU 要处理更多的系统调用，因此这种模型是比较低效的。 非阻塞式IO\" 非阻塞式IO ","date":"2018-02-05","objectID":"/javaio/:3:2","tags":["Java基础","大纲"],"title":"Java IO知识体系详解 ","uri":"/javaio/"},{"categories":["Java基础"],"content":"信号驱动式 I/O(SIGIO) 应用进程使用 sigaction 系统调用，内核立即返回，应用进程可以继续执行，也就是说等待数据阶段应用进程是非阻塞的。内核在数据到达时向应用进程发送 SIGIO 信号，应用进程收到之后在信号处理程序中调用 recvfrom 将数据从内核复制到应用进程中。 相比于非阻塞式 I/O 的轮询方式，信号驱动 I/O 的 CPU 利用率更高。 信号驱动式IO\" 信号驱动式IO ","date":"2018-02-05","objectID":"/javaio/:3:3","tags":["Java基础","大纲"],"title":"Java IO知识体系详解 ","uri":"/javaio/"},{"categories":["Java基础"],"content":"异步 I/O(AIO) 进行 aio_read 系统调用会立即返回，应用进程继续执行，不会被阻塞，内核会在所有操作完成之后向应用进程发送信号。 异步 I/O 与信号驱动 I/O 的区别在于，异步 I/O 的信号是通知应用进程 I/O 完成，而信号驱动 I/O 的信号是通知应用进程可以开始 I/O。 异步IO\" 异步IO ","date":"2018-02-05","objectID":"/javaio/:3:4","tags":["Java基础","大纲"],"title":"Java IO知识体系详解 ","uri":"/javaio/"},{"categories":["Java基础"],"content":"I/O 复用(select 和 poll) 使用 select 或者 poll 等待数据，并且可以等待多个套接字中的任何一个变为可读，这一过程会被阻塞，当某一个套接字可读时返回。之后再使用 recvfrom 把数据从内核复制到进程中。 它可以让单个进程具有处理多个 I/O 事件的能力。又被称为 Event Driven I/O，即事件驱动 I/O。 如果一个 Web 服务器没有 I/O 复用，那么每一个 Socket 连接都需要创建一个线程去处理。如果同时有几万个连接，那么就需要创建相同数量的线程。并且相比于多进程和多线程技术，I/O 复用不需要进程线程创建和切换的开销，系统开销更小。 复用IO\" 复用IO IO多路复用工作模式 1. LT 模式 当 epoll_wait() 检测到描述符事件到达时，将此事件通知进程，进程可以不立即处理该事件，下次调用 epoll_wait() 会再次通知进程。是默认的一种模式，并且同时支持 Blocking 和 No-Blocking。 2. ET 模式 和 LT 模式不同的是，通知之后进程必须立即处理事件，下次再调用 epoll_wait() 时不会再得到事件到达的通知。 很大程度上减少了 epoll 事件被重复触发的次数，因此效率要比 LT 模式高。只支持 No-Blocking，以避免由于一个文件句柄的阻塞读/阻塞写操作把处理多个文件描述符的任务饿死。 ","date":"2018-02-05","objectID":"/javaio/:3:5","tags":["Java基础","大纲"],"title":"Java IO知识体系详解 ","uri":"/javaio/"},{"categories":["Java基础"],"content":"I/O模型比较 同步I/O与异步I/O 同步 I/O: 应用进程在调用 recvfrom 操作时会阻塞。 异步 I/O: 不会阻塞。 阻塞式 I/O、非阻塞式 I/O、I/O 复用和信号驱动 I/O 都是同步 I/O，虽然非阻塞式 I/O 和信号驱动 I/O 在等待数据阶段不会阻塞，但是在之后的将数据从内核复制到应用进程这个操作会阻塞。 前四种 I/O 模型的主要区别在于第一个阶段，而第二个阶段是一样的: 将数据从内核复制到应用进程过程中，应用进程会被阻塞。 IO对比\" IO对比 阻塞IO 和 非阻塞IO 这两个概念是程序级别的。主要描述的是程序请求操作系统IO操作后，如果IO资源没有准备好，那么程序该如何处理的问题: 前者等待；后者继续执行(并且使用线程一直轮询，直到有IO资源准备好了) 同步IO 和 非同步IO 这两个概念是操作系统级别的。主要描述的是操作系统在收到程序请求IO操作后，如果IO资源没有准备好，该如何响应程序的问题: 前者不响应，直到IO资源准备好以后；后者返回一个标记(好让程序和自己知道以后的数据往哪里通知)，当IO资源准备好以后，再用事件机制返回给程序。 ","date":"2018-02-05","objectID":"/javaio/:3:6","tags":["Java基础","大纲"],"title":"Java IO知识体系详解 ","uri":"/javaio/"},{"categories":["Java基础"],"content":"NIO Standard IO是对字节流的读写，在进行IO之前，首先创建一个流对象，流对象进行读写操作都是按字节，一个字节一个字节的来读或写。而NIO把IO抽象成块，类似磁盘的读写，每次IO操作的单位都是一个块，块被读入内存之后就是一个byte[]，NIO一次可以读或写多个字节。 ","date":"2018-02-05","objectID":"/javaio/:4:0","tags":["Java基础","大纲"],"title":"Java IO知识体系详解 ","uri":"/javaio/"},{"categories":["Java基础"],"content":"流与块 I/O 与 NIO 最重要的区别是数据打包和传输的方式，I/O 以流的方式处理数据，而 NIO 以块的方式处理数据。 面向流的 I/O 一次处理一个字节数据: 一个输入流产生一个字节数据，一个输出流消费一个字节数据。为流式数据创建过滤器非常容易，链接几个过滤器，以便每个过滤器只负责复杂处理机制的一部分。不利的一面是，面向流的 I/O 通常相当慢。 面向块的 I/O 一次处理一个数据块，按块处理数据比按流处理数据要快得多。但是面向块的 I/O 缺少一些面向流的 I/O 所具有的优雅性和简单性。 I/O 包和 NIO 已经很好地集成了，java.io.* 已经以 NIO 为基础重新实现了，所以现在它可以利用 NIO 的一些特性。例如，java.io.* 包中的一些类包含以块的形式读写数据的方法，这使得即使在面向流的系统中，处理速度也会更快。 ","date":"2018-02-05","objectID":"/javaio/:4:1","tags":["Java基础","大纲"],"title":"Java IO知识体系详解 ","uri":"/javaio/"},{"categories":["Java基础"],"content":"通道与缓冲区 通道 通道Channel 是对原 I/O 包中的流的模拟，可以通过它读取和写入数据。 通道与流的不同之处在于，流只能在一个方向上移动(一个流必须是 InputStream 或者 OutputStream 的子类)，而通道是双向的，可以用于读、写或者同时用于读写。 通道包括以下类型: FileChannel: 从文件中读写数据； DatagramChannel: 通过 UDP 读写网络中数据； SocketChannel: 通过 TCP 读写网络中数据； ServerSocketChannel: 可以监听新进来的 TCP 连接，对每一个新进来的连接都会创建一个 SocketChannel。 缓冲区 发送给一个通道的所有数据都必须首先放到缓冲区中，同样地，从通道中读取的任何数据都要先读到缓冲区中。也就是说，不会直接对通道进行读写数据，而是要先经过缓冲区。 缓冲区实质上是一个数组，但它不仅仅是一个数组。缓冲区提供了对数据的结构化访问，而且还可以跟踪系统的读/写进程。 缓冲区包括以下类型: ByteBuffer CharBuffer ShortBuffer IntBuffer LongBuffer FloatBuffer DoubleBuffer 使用 NIO 快速复制文件的实例 public static void fastCopy(String src, String dist) throws IOException { /* 获得源文件的输入字节流 */ FileInputStream fin = new FileInputStream(src); /* 获取输入字节流的文件通道 */ FileChannel fcin = fin.getChannel(); /* 获取目标文件的输出字节流 */ FileOutputStream fout = new FileOutputStream(dist); /* 获取输出字节流的通道 */ FileChannel fcout = fout.getChannel(); /* 为缓冲区分配 1024 个字节 */ ByteBuffer buffer = ByteBuffer.allocateDirect(1024); while (true) { /* 从输入通道中读取数据到缓冲区中 */ int r = fcin.read(buffer); /* read() 返回 -1 表示 EOF */ if (r == -1) { break; } /* 切换读写 */ buffer.flip(); /* 把缓冲区的内容写入输出文件中 */ fcout.write(buffer); /* 清空缓冲区 */ buffer.clear(); } } ","date":"2018-02-05","objectID":"/javaio/:4:2","tags":["Java基础","大纲"],"title":"Java IO知识体系详解 ","uri":"/javaio/"},{"categories":["Java基础"],"content":"选择器 Selector的英文含义是“选择器”，不过根据我们详细介绍的Selector的岗位职责，您可以把它称之为“轮询代理器”、“事件订阅器”、“channel容器管理机”都行。 NIO 常常被叫做非阻塞 IO，主要是因为 NIO 在网络通信中的非阻塞特性被广泛使用。 NIO 实现了 IO 多路复用中的 Reactor 模型，一个线程 Thread 使用一个选择器 Selector 通过轮询的方式去监听多个通道 Channel 上的事件，从而让一个线程就可以处理多个事件。 通过配置监听的通道 Channel 为非阻塞，那么当 Channel 上的 IO 事件还未到达时，就不会进入阻塞状态一直等待，而是继续轮询其它 Channel，找到 IO 事件已经到达的 Channel 执行。 因为创建和切换线程的开销很大，因此使用一个线程来处理多个事件而不是一个线程处理一个事件具有更好的性能。 应该注意的是，只有套接字 Channel 才能配置为非阻塞，而 FileChannel 不能，为 FileChannel 配置非阻塞也没有意义。 套接字 NIO 实例 public class NIOServer { public static void main(String[] args) throws IOException { Selector selector = Selector.open(); ServerSocketChannel ssChannel = ServerSocketChannel.open(); ssChannel.configureBlocking(false); ssChannel.register(selector, SelectionKey.OP_ACCEPT); ServerSocket serverSocket = ssChannel.socket(); InetSocketAddress address = new InetSocketAddress(\"127.0.0.1\", 8888); serverSocket.bind(address); while (true) { selector.select(); Set\u003cSelectionKey\u003e keys = selector.selectedKeys(); Iterator\u003cSelectionKey\u003e keyIterator = keys.iterator(); while (keyIterator.hasNext()) { SelectionKey key = keyIterator.next(); if (key.isAcceptable()) { ServerSocketChannel ssChannel1 = (ServerSocketChannel) key.channel(); // 服务器会为每个新连接创建一个 SocketChannel SocketChannel sChannel = ssChannel1.accept(); sChannel.configureBlocking(false); // 这个新连接主要用于从客户端读取数据 sChannel.register(selector, SelectionKey.OP_READ); } else if (key.isReadable()) { SocketChannel sChannel = (SocketChannel) key.channel(); System.out.println(readDataFromSocketChannel(sChannel)); sChannel.close(); } keyIterator.remove(); } } } private static String readDataFromSocketChannel(SocketChannel sChannel) throws IOException { ByteBuffer buffer = ByteBuffer.allocate(1024); StringBuilder data = new StringBuilder(); while (true) { buffer.clear(); int n = sChannel.read(buffer); if (n == -1) { break; } buffer.flip(); int limit = buffer.limit(); char[] dst = new char[limit]; for (int i = 0; i \u003c limit; i++) { dst[i] = (char) buffer.get(i); } data.append(dst); buffer.clear(); } return data.toString(); } } public class NIOClient { public static void main(String[] args) throws IOException { Socket socket = new Socket(\"127.0.0.1\", 8888); OutputStream out = socket.getOutputStream(); String s = \"hello world\"; out.write(s.getBytes()); out.close(); } } ","date":"2018-02-05","objectID":"/javaio/:4:3","tags":["Java基础","大纲"],"title":"Java IO知识体系详解 ","uri":"/javaio/"},{"categories":["Java基础"],"content":"内存映射文件 内存映射文件 I/O 是一种读和写文件数据的方法，它可以比常规的基于流或者基于通道的 I/O 快得多。 向内存映射文件写入可能是危险的，只是改变数组的单个元素这样的简单操作，就可能会直接修改磁盘上的文件。修改数据与将数据保存到磁盘是没有分开的。 NIO 与普通I/O 的区别主要有以下两点 NIO 是非阻塞的 NIO 面向块，I/O 面向流 ","date":"2018-02-05","objectID":"/javaio/:4:4","tags":["Java基础","大纲"],"title":"Java IO知识体系详解 ","uri":"/javaio/"},{"categories":["Java基础"],"content":"IO多路复用详解 https://www.pdai.tech/md/java/io/java-io-nio-select-epoll html ","date":"2018-02-05","objectID":"/javaio/:5:0","tags":["Java基础","大纲"],"title":"Java IO知识体系详解 ","uri":"/javaio/"},{"categories":["Java基础"],"content":"异步IO 阻塞式同步IO、非阻塞式同步IO、多路复用IO 这三种IO模型，以及JAVA对于这三种IO模型的支持。重点说明了IO模型是由操作系统提供支持，且这三种IO模型都是同步IO，都是采用的“应用程序不询问我，我绝不会主动通知”的方式。 异步IO则是采用“订阅-通知”模式: 即应用程序向操作系统注册IO监听，然后继续做自己的事情。当操作系统发生IO事件，并且准备好数据后，在主动通知应用程序，触发相应的函数。 ","date":"2018-02-05","objectID":"/javaio/:6:0","tags":["Java基础","大纲"],"title":"Java IO知识体系详解 ","uri":"/javaio/"},{"categories":["Java基础"],"content":"为什么还有Netty 那么有的读者可能就会问，既然JAVA NIO / JAVA AIO已经实现了各主流操作系统的底层支持，那么为什么现在主流的JAVA NIO技术会是Netty和MINA呢? 答案很简单: 因为更好用，这里举几个方面的例子: 虽然JAVA NIO 和 JAVA AIO框架提供了 多路复用IO/异步IO的支持，但是并没有提供上层“信息格式”的良好封装。例如前两者并没有提供针对 Protocol Buffer、JSON这些信息格式的封装，但是Netty框架提供了这些数据格式封装(基于责任链模式的编码和解码功能) 要编写一个可靠的、易维护的、高性能的(注意它们的排序)NIO/AIO 服务器应用。除了框架本身要兼容实现各类操作系统的实现外。更重要的是它应该还要处理很多上层特有服务，例如: 客户端的权限、还有上面提到的信息格式封装、简单的数据读取。这些Netty框架都提供了响应的支持。 JAVA NIO框架存在一个poll/epoll bug: Selector doesn’t block on Selector.select(timeout)，不能block意味着CPU的使用率会变成100%(这是底层JNI的问题，上层要处理这个异常实际上也好办)。当然这个bug只有在Linux内核上才能重现。 这个问题在JDK 1.7版本中还没有被完全解决: http://bugs.java.com/bugdatabase/view_bug.do?bug_id=2147719。虽然Netty 4.0中也是基于JAVA NIO框架进行封装的(上文中已经给出了Netty中NioServerSocketChannel类的介绍)，但是Netty已经将这个bug进行了处理。 ","date":"2018-02-05","objectID":"/javaio/:7:0","tags":["Java基础","大纲"],"title":"Java IO知识体系详解 ","uri":"/javaio/"},{"categories":["Java基础"],"content":"参考文章 https://www.pdai.tech/md/java/io/java-io-bio.html https://www.pdai.tech/md/java/io/java-io-nio.html https://www.pdai.tech/md/java/io/java-io-nio-select-epoll.html https://www.pdai.tech/md/java/io/java-io-aio.html ","date":"2018-02-05","objectID":"/javaio/:8:0","tags":["Java基础","大纲"],"title":"Java IO知识体系详解 ","uri":"/javaio/"},{"categories":["Java基础"],"content":"反射让一切有了可能","date":"2018-02-03","objectID":"/reflection/","tags":["Java基础"],"title":"框架的灵魂-反射","uri":"/reflection/"},{"categories":["Java基础"],"content":"什么是反射 简而言之，通过反射，我们可以在运行时获得程序中每一个类型的成员和成员的信息。 程序中一般的对象的类型都是在编译期就确定下来的，而 Java 反射机制可以动态地创建对象并调用其属性，这样的对象的类型在编译期是未知的。 所以我们可以通过反射机制直接创建对象，即使这个对象的类型在编译期是未知的。 反射的核心是 JVM 在运行时才动态加载类或调用方法/访问属性，它不需要事先（写代码的时候或编译期）知道运行对象是谁。 ","date":"2018-02-03","objectID":"/reflection/:1:0","tags":["Java基础"],"title":"框架的灵魂-反射","uri":"/reflection/"},{"categories":["Java基础"],"content":"Java 反射主要提供以下功能 在运行时构造任意一个类的对象。 在运行时调用任意一个对象的方法。 在运行时判断任意一个对象所属的类。 在运行时判断任意一个类所具有的成员变量和方法（通过反射甚至可以调用private方法）。 ","date":"2018-02-03","objectID":"/reflection/:1:1","tags":["Java基础"],"title":"框架的灵魂-反射","uri":"/reflection/"},{"categories":["Java基础"],"content":"反射的主要用途 反射最重要的用途就是开发各种通用框架。 很多框架（比如 Spring）都是配置化的（比如通过 XML 文件配置 Bean），为了保证框架的通用性，它们可能需要根据配置文件加载不同的对象或类，调用不同的方法，这个时候就必须用到反射，运行时动态加载需要加载的对象。 举一个例子，在运用 Struts 2 框架的开发中我们一般会在 struts.xml 里去配置 Action，比如： \u003caction name=\"login\" class=\"org.ScZyhSoft.test.action.SimpleLoginAction\" method=\"execute\"\u003e \u003cresult\u003e/shop/shop-index.jsp\u003c/result\u003e \u003cresult name=\"error\"\u003elogin.jsp\u003c/result\u003e \u003c/action\u003e 配置文件与 Action 建立了一种映射关系，当 View 层发出请求时，请求会被 StrutsPrepareAndExecuteFilter 拦截，然后 StrutsPrepareAndExecuteFilter 会去动态地创建 Action 实例。比如我们请求 login.action，那么 StrutsPrepareAndExecuteFilter就会去解析struts.xml文件，检索action中name为login的Action，并根据class属性创建SimpleLoginAction实例，并用invoke方法来调用execute方法，这个过程离不开反射。 对与框架开发人员来说，反射虽小但作用非常大，它是各种容器实现的核心。而对于一般的开发者来说，不深入框架开发则用反射用的就会少一点，不过了解一下框架的底层机制有助于丰富自己的编程思想，也是很有益的。 像Java中的一大利器注解的实现也用到了反射。 为什么你使用 Spring 的时候 ，一个@Component注解就声明了一个类为 Spring Bean 呢？为什么你通过一个 @Value注解就读取到配置文件中的值呢？究竟是怎么起作用的呢？ 这些都是因为你可以基于反射分析类，然后获取到类/属性/方法/方法的参数上的注解。你获取到注解之后，就可以做进一步的处理。 ","date":"2018-02-03","objectID":"/reflection/:2:0","tags":["Java基础"],"title":"框架的灵魂-反射","uri":"/reflection/"},{"categories":["Java基础"],"content":"反射的基本运用 ","date":"2018-02-03","objectID":"/reflection/:3:0","tags":["Java基础"],"title":"框架的灵魂-反射","uri":"/reflection/"},{"categories":["Java基础"],"content":"获得Class对象 使用Class类的forName 静态方法。 Class appleClass = Class.forName(\"base.reflection.Apple\"); 直接获取 Class appleClass = Apple.class; 获取某一个对象的class Apple apple = new Apple(); Class appleClass = apple.getClass(); 通过类加载器ClassLoader.loadClass()传入类路径获取 Class appleClass = ClassLoader.getSystemClassLoader().loadClass(\"base.reflection.Apple\"); ","date":"2018-02-03","objectID":"/reflection/:3:1","tags":["Java基础"],"title":"框架的灵魂-反射","uri":"/reflection/"},{"categories":["Java基础"],"content":"构造方法 Constructor[] declaredConstructors = appleClass.getDeclaredConstructors(); Constructor[] constructors = appleClass.getConstructors(); //通过无参构造来获取该类对象 newInstance() Apple apple= (Apple)appleClass.newInstance(); //通过有参构造来获取该类对象 newInstance Constructor constructor = appleClass.getConstructor(String.class,int.class,int.class); Apple apple=(Apple)constructor.newInstance(\"红色\",10,5); ","date":"2018-02-03","objectID":"/reflection/:3:2","tags":["Java基础"],"title":"框架的灵魂-反射","uri":"/reflection/"},{"categories":["Java基础"],"content":"属性 //getDeclaredFields所有已声明的成员变量，但不能得到其父类的成员变量 Field[] declaredFields = appleClass.getDeclaredFields(); //getFields访问公有的成员变量 Field[] fields = appleClass.getFields(); ","date":"2018-02-03","objectID":"/reflection/:3:3","tags":["Java基础"],"title":"框架的灵魂-反射","uri":"/reflection/"},{"categories":["Java基础"],"content":"方法 //getDeclaredMethods 方法返回类或接口声明的所有方法，包括公共、保护、默认（包）访问和私有方法，但不包括继承的方法。 Method[] declaredMethods = appleClass.getDeclaredMethods(); //getMethods方法返回某个类的所有公用（public）方法，包括其继承类的公用方法。 Method[] methods = appleClass.getMethods(); ","date":"2018-02-03","objectID":"/reflection/:3:4","tags":["Java基础"],"title":"框架的灵魂-反射","uri":"/reflection/"},{"categories":["Java基础"],"content":"调用方法 Constructor constructor = appleClass.getConstructor(String.class,int.class,int.class); Apple apple = (Apple)constructor.newInstance(\"红色\",10,5); //获取toString方法并调用 Method method = appleClass.getDeclaredMethod(\"toString\"); String str = (String)method.invoke(apple); System.out.println(str); ","date":"2018-02-03","objectID":"/reflection/:3:5","tags":["Java基础"],"title":"框架的灵魂-反射","uri":"/reflection/"},{"categories":["Java基础"],"content":"利用反射创建数组 Class\u003c?\u003e cls = Class.forName(\"java.lang.String\"); Object array = Array.newInstance(cls,5); //往数组里添加内容 Array.set(array,0,\"hello\"); Array.set(array,1,\"Java\"); Array.set(array,2,\"fuck\"); Array.set(array,3,\"Scala\"); Array.set(array,4,\"Clojure\"); //获取某一项的内容 System.out.println(Array.get(array,3)); ","date":"2018-02-03","objectID":"/reflection/:3:6","tags":["Java基础"],"title":"框架的灵魂-反射","uri":"/reflection/"},{"categories":["Java基础"],"content":"参数化类型","date":"2018-02-02","objectID":"/generic/","tags":["Java基础"],"title":"Java特性-泛型","uri":"/generic/"},{"categories":["Java基础"],"content":"泛型，即参数化类型。一提到参数，最熟悉的就是定义方法时有形参，然后调用此方法时传递实参。 那么参数化类型怎么理解呢？顾名思义，就是将类型由原来的具体的类型参数化，类似于方法中的变量参数，此时类型也定义成参数形式（类型形参），然后在使用/调用时传入具体的类型（类型实参）。 Java 语言中引入泛型是一个较大的功能增强。不仅语言、类型系统和编译器有了较大的变化，而且类库也进行了大翻修，所以许多重要的类，比如集合框架，都已经成为泛型化的了。这带来了很多好处： 类型安全。 泛型的主要目标是提高 Java 程序的类型安全。通过知道使用泛型定义的变量的类型限制，编译器可以在一个高得多的程度上验证类型假设。 消除强制类型转换。 泛型的一个附带好处是，消除源代码中的许多强制类型转换。这使得代码更加可读，并且减少了出错机会。 潜在的性能收益。 泛型为较大的优化带来可能。在泛型的初始实现中，编译器将强制类型转换（没有泛型的话，程序员会指定这些强制类型转换）插入生成的字节码中。 注意泛型的类型参数只能是类类型（包括自定义类），不能是简单类型。 ","date":"2018-02-02","objectID":"/generic/:0:0","tags":["Java基础"],"title":"Java特性-泛型","uri":"/generic/"},{"categories":["Java基础"],"content":"常用命名类型参数 K：键，比如映射的键 V：值，比如 List 和 Set 的内容，或者 Map 中的值 E：元素 T：泛型 ?：表示不确定的 java 类型 ","date":"2018-02-02","objectID":"/generic/:0:1","tags":["Java基础"],"title":"Java特性-泛型","uri":"/generic/"},{"categories":["Java基础"],"content":"通配符 Ingeter 是 Number 的一个子类，同时 Generic 与 Generic 实际上是相同的一种基本类型。那么问题来了，在使用 Generic 作为形参的方法中，能否使用Generic 的实例传入呢？在逻辑上类似于 Generic 和 Generic 是否可以看成具有父子关系的泛型类型呢？下面我们通过定义一个方法来验证。 public void show(Generic\u003cNumber\u003e obj) { System.out.println(\"key value is \" + obj.getKey()); } 进行如下的调用： Generic\u003cInteger\u003e genericInteger = new Generic\u003cInteger\u003e(123); show(genericInteger); //error Generic\u003cjava.lang.Integer\u003e cannot be applied to Generic\u003cjava.lang.Number\u003e 通过提示信息我们可以看到 Generic 不能被看作为 Generic 的子类。由此可以看出：同一种泛型可以对应多个版本（因为参数类型是不确定的），不同版本的泛型类实例是不兼容的。 我们不能因此定义一个 show(Generic obj)来处理，因此我们需要一个在逻辑上可以表示同时是Generic和Generic父类的引用类型。由此类型通配符应运而生。 T、K、V、E 等泛型字母为有类型，类型参数赋予具体的值。除了有类型，还可以用通配符来表述类型，？ 未知类型，类型参数赋予不确定值，任意类型只能用在声明类型、方法参数上，不能用在定义泛型类上。将方法改写成如下： public void show(Generic\u003c?\u003e obj) { System.out.println(\"key value is \" + obj.getKey()); } 此处 ? 是类型实参，而不是类型形参。即和 Number、String、Integer 一样都是实际的类型，可以把 ？ 看成所有类型的父类，是一种真实的类型。可以解决当具体类型不确定的时候，这个通配符就是 ?；当操作类型时，不需要使用类型的具体功能时，只使用 Object 类中的功能。那么可以用 ? 通配符来表未知类型。 ","date":"2018-02-02","objectID":"/generic/:0:2","tags":["Java基础"],"title":"Java特性-泛型","uri":"/generic/"},{"categories":["Java基础"],"content":"泛型上下边界 通配符上限为：Generic\u003c? extends Number\u003e 通配符下限为：Generic\u003c? super Number\u003e 在使用泛型的时候，我们还可以为传入的泛型类型实参进行上下边界的限制，如：类型实参只准传入某种类型的父类或某种类型的子类。为泛型添加上边界，即传入的类型实参必须是指定类型的子类型。 public void show(Generic\u003c? extends Number\u003e obj) { System.out.println(\"key value is \" + obj.getKey()); } 我们在泛型方法的入参限定参数类型为 Number 的子类。 Generic\u003cString\u003e genericString = new Generic\u003cString\u003e(\"11111\"); Generic\u003cInteger\u003e genericInteger = new Generic\u003cInteger\u003e(2222); showKeyValue1(genericString); // error showKeyValue1(genericInteger); 当我们的入参为 String 类型时，编译报错，因为 String 类型并不是 Number 类型的子类。 类型通配符上限通过形如 Generic\u003c? extends Number\u003e 形式定义；相对应的，类型通配符下限为Generic\u003c? super Number\u003e形式，其含义与类型通配符上限正好相反，在此不作过多阐述。 ","date":"2018-02-02","objectID":"/generic/:0:3","tags":["Java基础"],"title":"Java特性-泛型","uri":"/generic/"},{"categories":["Java基础"],"content":"一个泛型的增删改查Service @Transactional(readOnly = true) public abstract class CrudService\u003cD extends CrudDao\u003cT\u003e, T extends DataEntity\u003cT\u003e\u003e extends BaseService { /** * 持久层对象 */ @Autowired protected D dao; /** * 获取单条数据 * @param entity * @return */ public T get(T entity) { return dao.get(entity); } /** * 查询列表数据 * @param entity * @return */ public List\u003cT\u003e findList(T entity) { return dao.findList(entity); } /** * 查询分页数据 * @param page 分页对象 * @param entity * @return */ public Page\u003cT\u003e findPage(Page\u003cT\u003e page, T entity) { entity.setPage(page); page.setList(dao.findList(entity)); return page; } /** * 保存数据（插入或更新） * @param entity */ @Transactional(readOnly = false) public int save(T entity) { if (entity.getIsNewRecord()){ entity.preInsert(); return dao.insert(entity); }else{ entity.preUpdate(); return dao.update(entity); } } /** * 删除数据 * @param entity */ @Transactional(readOnly = false) public int delete(T entity) { return dao.delete(entity); } } ","date":"2018-02-02","objectID":"/generic/:0:4","tags":["Java基础"],"title":"Java特性-泛型","uri":"/generic/"},{"categories":["Java基础"],"content":"面向对象的三大法宝和七大戒律","date":"2018-02-01","objectID":"/objectoriented/","tags":["Java基础"],"title":"Java世界的入场券-面向对象","uri":"/objectoriented/"},{"categories":["Java基础"],"content":" 面向对象程序设计（英语：Object-oriented programming，缩写：OOP）是种具有对象概念的编程典范，同时也是一种程序开发的抽象方针。它可能包含数据、特性、代码与方法。对象则指的是类（class）的实例。它将对象作为程序的基本单元，将程序和数据封装其中，以提高软件的重用性、灵活性和扩展性，对象里的程序可以访问及经常修改对象相关连的数据。在面向对象程序编程里，计算机程序会被设计成彼此相关的对象。 面向对象就像是一张入场券，掌握了面向对象的思想，就可以在Java世界里尽情遨游，面向对象有三大法宝和七大戒律，并在其指导下萃取出了无数的锦囊妙计和绝世武器，下面我们揭开他们的神秘面纱。 ","date":"2018-02-01","objectID":"/objectoriented/:0:0","tags":["Java基础"],"title":"Java世界的入场券-面向对象","uri":"/objectoriented/"},{"categories":["Java基础"],"content":"OOP（面向对象编程）的三大法宝 封装 封装，也就是把客观事物封装成抽象的类，并且类可以把自己的属性和方法只让可信的类操作，对不可信的类进行信息隐藏。 继承 继承是指这样一种能力，它可以使用现有的类的所有功能，并在无需重新编写原来类的情况下对这些功能进行扩展。 多态 多态指一个类实例的相同方法在不同情形有不同的表现形式。具体来说就是不同实现类对公共接口有不同的实现方式，但这些操作可以通过相同的方式（公共接口）予以调用。 ","date":"2018-02-01","objectID":"/objectoriented/:0:1","tags":["Java基础"],"title":"Java世界的入场券-面向对象","uri":"/objectoriented/"},{"categories":["Java基础"],"content":"OOD（面向对象设计）七大戒律 开-闭原则 Open-Close Principle（OCP），即开-闭原则。开，指的是对扩展开放，即要支持方便地扩展；闭，指的是对修改关闭，即要严格限制对已有内容的修改。开-闭原则是最抽象也是最重要的OOD原则。简单工厂模式、工厂方法模式、抽象工厂模式中都提到了如何通过良好的设计遵循开-闭原则。 里氏替换原则 Liskov Substitution Principle（LSP），即里氏替换原则。该原则规定“子类必须能够替换其父类，否则不应当设计为其子类”。换句话说，父类出现的地方，都应该能由其子类代替。所以，子类只能去扩展基类，而不是隐藏或者覆盖基类。 依赖倒置原则 Dependence Inversion Principle（DIP），依赖倒置原则。它讲的是“设计和实现要依赖于抽象而非具体”。一方面抽象化更符合人的思维习惯；另一方面，根据里氏替换原则，可以很容易将原来的抽象替换为扩展后的具体，这样可以很好的支持开-闭原则。 接口隔离原则 Interface Segration Principle（ISP），接口隔离原则，“将大的接口打散成多个小的独立的接口”。由于Java类支持实现多个接口，可以很容易的让类具有多种接口的特征，同时每个类可以选择性地只实现目标接口。 单一职责原则 Single Responsibility Principle（SRP），单一职责原则。它讲的是，不要存在多于一个导致类变更的原因，是高内聚低耦合的一个体现。 迪米特法则/最少知道原则 Law of Demeter or Least Knowledge Principle（LoD or LKP），迪米特法则或最少知道原则。它讲的是“一个对象就尽可能少的去了解其它对象”，从而实现松耦合。如果一个类的职责过多，由于多个职责耦合在了一起，任何一个职责的变更都可能引起其它职责的问题，严重影响了代码的可维护性和可重用性。 合成/聚合复用原则 Composite/Aggregate Reuse Principle（CARP / CRP），合成/聚合复用原则。如果新对象的某些功能在别的已经创建好的对象里面已经实现，那么应当尽量使用别的对象提供的功能，使之成为新对象的一部分，而不要再重新创建。新对象可通过向这些对象的委派达到复用已有功能的效果。简而言之，要尽量使用合成/聚合，而非使用继承。《Java设计模式（九） 桥接模式》中介绍的桥接模式即是对这一原则的典型应用。 ","date":"2018-02-01","objectID":"/objectoriented/:0:2","tags":["Java基础"],"title":"Java世界的入场券-面向对象","uri":"/objectoriented/"},{"categories":["Java基础"],"content":"行走江湖的锦囊妙计和绝世武器 上面的法宝和戒律是心法，真正行走江湖还需要趁手的兵器和锦囊妙计。 而设计模式就是应用三大法宝和七大戒律下经过反复实践铸造出来锦囊妙计和武器，具体有哪些武器我们暂且不表，毕竟倚天屠龙出世，江湖必将血雨腥风，在这之前我们还需要做好准备工作。 ","date":"2018-02-01","objectID":"/objectoriented/:0:3","tags":["Java基础"],"title":"Java世界的入场券-面向对象","uri":"/objectoriented/"},{"categories":["Java基础"],"content":"Java位运算","date":"2018-02-01","objectID":"/byteopt/","tags":["Java基础"],"title":"Java位运算 ","uri":"/byteopt/"},{"categories":["Java基础"],"content":"一切的起源：二进制 位：二进制位，简称“位”。是二进制记数系统中表示小于2的整数的符号，一般用1或 0表示，是具有相等概率的两种状态中的一种。二进制位的位数可表示一个机器字的字长，一个二进制位包含的信息量称为一比特（bit）。 举个栗子： int占4个字节（byte） 1byte = 8bit 换算下来，一个int类型即占32bit int i = 88; 这里的88为十进制，转换为二进制为：1011000，使用完整的32位表示即为：00000000 00000000 00000000 01011000 上文中的00000000 00000000 00000000 01011000即为十进制88转为二进制的 原码 ，与其相关的定义还有 反码 和 补码 ","date":"2018-02-01","objectID":"/byteopt/:1:0","tags":["Java基础"],"title":"Java位运算 ","uri":"/byteopt/"},{"categories":["Java基础"],"content":"关于原码、反码和补码 在计算机内，有符号数有三种表示法：原码、反码以及补码。 原码：就是二进制定点表示法，即最高位为符号位，“0”正负“1”，其余位表示数值的大小。 反码：正数的反码与其原码相同；负数的反码是对正数逐位取反，符号位保持为1。 补码：正数的补码与其原码相同；负数的补码是在其反码的末位加1。 ","date":"2018-02-01","objectID":"/byteopt/:2:0","tags":["Java基础"],"title":"Java位运算 ","uri":"/byteopt/"},{"categories":["Java基础"],"content":"为什么要使用补码 简单来说，就是计算机计算减法时有各种不方便，于是发明了反码，结果发现反码也有缺陷（有两个零存在：“+0”和“-0”），进而发明了补码解决这个问题。 在计算机系统中，数值一律用补码来表示和存储。原因在于，使用补码，可以将符号位和数值域统一处理；同时，加法和减法也可以统一处理。此外，补码与原码相互转换，其运算过程是相同的，不需要额外的硬件电路。 有关补码的意义及作用在上面的链接里讨论的非常详尽，我这里就不班门弄斧了，理解就好～ 对原码、反码以及补码有一个初步的认知后，我们接下来再看位运算就会清晰很多。 ","date":"2018-02-01","objectID":"/byteopt/:2:1","tags":["Java基础"],"title":"Java位运算 ","uri":"/byteopt/"},{"categories":["Java基础"],"content":"位运算符的基本运算 操作符 描述 例子（A = 8, B = 9） 按位与\u0026 如果相对应位都是1，则结果为1，否则为0 A\u0026B=8，即1000 按位或 | 如果相对应位都是0，则结果为0，否则为1 A B=9，即1001 按位异或^ 如果相对应位值相同，则结果为0，否则为1 A^B=1，即0001 按位取反~ 按位取反运算符翻转操作数的每一位，即0变成1，1变成0 ~A=7，即0111 左移 « 按位左移运算符。左操作数按位左移右操作数指定的位数 A « 2 = 32，即1000 00 右移 » 按位右移运算符。左操作数按位右移右操作数指定的位数 A » 2 = 2，即0010 ","date":"2018-02-01","objectID":"/byteopt/:3:0","tags":["Java基础"],"title":"Java位运算 ","uri":"/byteopt/"},{"categories":["数据库"],"content":"MySQL总结","date":"2017-03-02","objectID":"/mysql/","tags":["数据库","大纲"],"title":"MySQL总结","uri":"/mysql/"},{"categories":["数据库"],"content":"存储引擎 ","date":"2017-03-02","objectID":"/mysql/:1:0","tags":["数据库","大纲"],"title":"MySQL总结","uri":"/mysql/"},{"categories":["数据库"],"content":"InnoDB 是 MySQL 默认的事务型存储引擎，只有在需要它不支持的特性时，才考虑使用其它存储引擎。 实现了四个标准的隔离级别，默认级别是可重复读(REPEATABLE READ)。在可重复读隔离级别下，通过多版本并发控制(MVCC)+ 间隙锁(Next-Key Locking)防止幻影读。 主索引是聚簇索引，在索引中保存了数据，从而避免直接读取磁盘，因此对查询性能有很大的提升。 内部做了很多优化，包括从磁盘读取数据时采用的可预测性读、能够加快读操作并且自动创建的自适应哈希索引、能够加速插入操作的插入缓冲区等。 支持真正的在线热备份。其它存储引擎不支持在线热备份，要获取一致性视图需要停止对所有表的写入，而在读写混合场景中，停止写入可能也意味着停止读取。 ","date":"2017-03-02","objectID":"/mysql/:1:1","tags":["数据库","大纲"],"title":"MySQL总结","uri":"/mysql/"},{"categories":["数据库"],"content":"MyISAM 设计简单，数据以紧密格式存储。对于只读数据，或者表比较小、可以容忍修复操作，则依然可以使用它。 提供了大量的特性，包括压缩表、空间数据索引等。 不支持事务。 不支持行级锁，只能对整张表加锁，读取时会对需要读到的所有表加共享锁，写入时则对表加排它锁。但在表有读取操作的同时，也可以往表中插入新的记录，这被称为并发插入(CONCURRENT INSERT)。 可以手工或者自动执行检查和修复操作，但是和事务恢复以及崩溃恢复不同，可能导致一些数据丢失，而且修复操作是非常慢的。 如果指定了 DELAY_KEY_WRITE 选项，在每次修改执行完成时，不会立即将修改的索引数据写入磁盘，而是会写到内存中的键缓冲区，只有在清理键缓冲区或者关闭表的时候才会将对应的索引块写入磁盘。这种方式可以极大的提升写入性能，但是在数据库或者主机崩溃时会造成索引损坏，需要执行修复操作。 ","date":"2017-03-02","objectID":"/mysql/:1:2","tags":["数据库","大纲"],"title":"MySQL总结","uri":"/mysql/"},{"categories":["数据库"],"content":"比较 事务: InnoDB 是事务型的，可以使用 Commit 和 Rollback 语句。 并发: MyISAM 只支持表级锁，而 InnoDB 还支持行级锁。 外键: InnoDB 支持外键。 备份: InnoDB 支持在线热备份。 崩溃恢复: MyISAM 崩溃后发生损坏的概率比 InnoDB 高很多，而且恢复的速度也更慢。 其它特性: MyISAM 支持压缩表和空间数据索引。 ","date":"2017-03-02","objectID":"/mysql/:1:3","tags":["数据库","大纲"],"title":"MySQL总结","uri":"/mysql/"},{"categories":["数据库"],"content":"索引 索引其实是一种数据结构，能够帮助我们快速的检索数据库中的数据，索引是在存储引擎层实现的，而不是在服务器层实现的。 ","date":"2017-03-02","objectID":"/mysql/:2:0","tags":["数据库","大纲"],"title":"MySQL总结","uri":"/mysql/"},{"categories":["数据库"],"content":"索引类型 MySQL主要有两种结构Hash索引和B+Tree索引，我们使用的是InnoDB引擎，默认的是B+树。 B Tree 指的是 Balance Tree，也就是平衡树。平衡树是一颗查找树，并且所有叶子节点位于同一层。 B+ Tree 是基于 B Tree 和叶子节点顺序访问指针进行实现，它具有 B Tree 的平衡性，并且通过顺序访问指针来提高区间查询的性能。 在 B+ Tree 中，一个节点中的 key 从左到右非递减排列，如果某个指针的左右相邻 key 分别是 keyi 和 keyi+1，且不为 null，则该指针指向节点的所有 key 大于等于 keyi 且小于等于 keyi+1。 B+ Tree是一种多路平衡查询树，所以他的节点是天然有序的（左子节点小于父节点、父节点小于右子节点），所以对于范围查询的时候不需要做全表扫描。 B+Tree 索引 因为不再需要进行全表扫描，只需要对树进行搜索即可，因此查找速度快很多。 除了用于查找，还可以用于排序和分组。 可以指定多个列作为索引列，多个索引列共同组成键。 适用于全键值、键值范围和键前缀查找，其中键前缀查找只适用于最左前缀查找。如果不是按照索引列的顺序进行查找，则无法使用索引。 InnoDB 的 B+Tree 索引分为主索引和辅助索引。 Mysql选用B+树这种数据结构作为索引，可以提高查询索引时的磁盘IO效率，并且可以提高范围查询的效率，并且B+树里的元素也是有序的。 ","date":"2017-03-02","objectID":"/mysql/:2:1","tags":["数据库","大纲"],"title":"MySQL总结","uri":"/mysql/"},{"categories":["数据库"],"content":"哈希索引 哈希索引能以 O(1) 时间进行查找，但是失去了有序性，它具有以下限制: 无法用于排序与分组； 只支持等值精确查找，无法用于部分查找和范围查找。 哈希索引没办法利用索引完成排序 哈希索引不支持多列联合索引的最左匹配规则 如果有大量重复键值得情况下，哈希索引的效率会很低，因为存在哈希碰撞问题 InnoDB 存储引擎有一个特殊的功能叫“自适应哈希索引”，当某个索引值被使用的非常频繁时，会在 B+Tree 索引之上再创建一个哈希索引，这样就让 B+Tree 索引具有哈希索引的一些优点，比如快速的哈希查找。 ","date":"2017-03-02","objectID":"/mysql/:2:2","tags":["数据库","大纲"],"title":"MySQL总结","uri":"/mysql/"},{"categories":["数据库"],"content":"B+Tree的叶子节点存储内容不同分为聚簇索引和非聚簇索引 主键索引的叶子节点 data 域记录着完整的数据记录，这种索引方式被称为聚簇索引。因为无法把数据行存放在两个不同的地方，所以一个表只能有一个聚簇索引。 聚簇索引\" 聚簇索引 辅助索引的叶子节点的 data 域记录着主键的值，因此在使用辅助索引进行查找时，需要先查找到主键值，然后再到主索引中进行回表查询，覆盖索引则无需再回表查询 非聚簇索引\" 非聚簇索引 ","date":"2017-03-02","objectID":"/mysql/:2:3","tags":["数据库","大纲"],"title":"MySQL总结","uri":"/mysql/"},{"categories":["数据库"],"content":"覆盖索引（covering index） 指一个查询语句的执行只用从索引中就能够取得，不必从数据表中读取。也可以称之为实现了索引覆盖。 当一条查询语句符合覆盖索引条件时，MySQL只需要通过索引就可以返回查询所需要的数据，这样避免了查到索引后再返回表操作，减少I/O提高效率。 如，表covering_index_sample中有一个普通索引 idx_key1_key2(key1,key2)。当我们通过SQL语句：select key2 from covering_index_sample where key1 = ‘keytest’;的时候，就可以通过覆盖索引查询，无需回表。 ","date":"2017-03-02","objectID":"/mysql/:2:4","tags":["数据库","大纲"],"title":"MySQL总结","uri":"/mysql/"},{"categories":["数据库"],"content":"联合索引、最左前缀匹配 创建多列索引时，我们根据业务需求，where子句中使用最频繁的一列放在最左边，因为MySQL索引查询会遵循最左前缀匹配的原则，即最左优先，在检索数据时从联合索引的最左边开始匹配。 所以当我们创建一个联合索引的时候，如(key1,key2,key3)，相当于创建了（key1）、(key1,key2)和(key1,key2,key3)三个索引，这就是最左匹配原则。 ","date":"2017-03-02","objectID":"/mysql/:2:5","tags":["数据库","大纲"],"title":"MySQL总结","uri":"/mysql/"},{"categories":["数据库"],"content":"索引下推 MySQL 5.6引入了索引下推优化，默认开启，使用SET optimizer_switch = ‘index_condition_pushdown=off’;可以将其关闭。 索引下推优化，可以在有like条件查询的情况下，减少回表次数。 ","date":"2017-03-02","objectID":"/mysql/:2:6","tags":["数据库","大纲"],"title":"MySQL总结","uri":"/mysql/"},{"categories":["数据库"],"content":"主从复制 主数据库有个bin-log二进制文件，纪录了所有增删改Sql语句。（binlog线程） 从数据库把主数据库的bin-log文件的sql语句复制过来。（io线程） 从数据库的relay-log重做日志文件中再执行一次这些sql语句。（Sql执行线程） 主从复制\" 主从复制 上图主从复制分了五个步骤进行： 步骤一：主库的更新事件(update、insert、delete)被写到binlog 步骤二：从库发起连接，连接到主库。 步骤三：此时主库创建一个binlog dump thread，把binlog的内容发送到从库。 步骤四：从库启动之后，创建一个I/O线程，读取主库传过来的binlog内容并写入到relay log 步骤五：还会创建一个SQL线程，从relay log里面读取内容，从Exec_Master_Log_Pos位置开始执行读取到的更新事件，将更新内容写入到slave的db ","date":"2017-03-02","objectID":"/mysql/:3:0","tags":["数据库","大纲"],"title":"MySQL总结","uri":"/mysql/"},{"categories":["数据库"],"content":"参考文章 MySQL索引数据结构详解 ","date":"2017-03-02","objectID":"/mysql/:4:0","tags":["数据库","大纲"],"title":"MySQL总结","uri":"/mysql/"},{"categories":["数据库"],"content":"关系型数据库概览","date":"2017-03-01","objectID":"/relationaldatabase/","tags":["数据库","大纲"],"title":"关系型数据库概览","uri":"/relationaldatabase/"},{"categories":["数据库"],"content":"数据库总览\" 数据库总览 SQL数据库原理\" SQL数据库原理 ","date":"2017-03-01","objectID":"/relationaldatabase/:0:0","tags":["数据库","大纲"],"title":"关系型数据库概览","uri":"/relationaldatabase/"},{"categories":["数据库"],"content":"数据库组件 SQL数据库概览\" SQL数据库概览 ","date":"2017-03-01","objectID":"/relationaldatabase/:1:0","tags":["数据库","大纲"],"title":"关系型数据库概览","uri":"/relationaldatabase/"},{"categories":["数据库"],"content":"核心组件 进程管理器（process manager）：很多数据库具备一个需要妥善管理的进程/线程池。再者，为了实现纳秒级操作，一些现代数据库使用自己的线程而不是操作系统线程。 网络管理器（network manager）：网路I/O是个大问题，尤其是对于分布式数据库。所以一些数据库具备自己的网络管理器。 文件系统管理器（File system manager）：磁盘I/O是数据库的首要瓶颈。具备一个文件系统管理器来完美地处理OS文件系统甚至取代OS文件系统，是非常重要的。 内存管理器（memory manager）：为了避免磁盘I/O带来的性能损失，需要大量的内存。但是如果你要处理大容量内存你需要高效的内存管理器，尤其是你有很多查询同时使用内存的时候。 安全管理器（Security Manager）：用于对用户的验证和授权。 客户端管理器（Client manager）：用于管理客户端连接。 ","date":"2017-03-01","objectID":"/relationaldatabase/:1:1","tags":["数据库","大纲"],"title":"关系型数据库概览","uri":"/relationaldatabase/"},{"categories":["数据库"],"content":"工具 备份管理器（Backup manager）：用于保存和恢复数据。 恢复管理器（Recovery manager）：用于崩溃后重启数据库到一个一致状态。 监控管理器（Monitor manager）：用于记录数据库活动信息和提供监控数据库的工具。 管理员管理器（Administration manager）：用于保存元数据（比如表的名称和结构），提供管理数据库、模式、表空间的工具。 ","date":"2017-03-01","objectID":"/relationaldatabase/:1:2","tags":["数据库","大纲"],"title":"关系型数据库概览","uri":"/relationaldatabase/"},{"categories":["数据库"],"content":"查询管理器 查询解析器（Query parser）：用于检查查询是否合法 查询重写器（Query rewriter）：用于预优化查询 查询优化器（Query optimizer）：用于优化查询 查询执行器（Query executor）：用于编译和执行查询 ","date":"2017-03-01","objectID":"/relationaldatabase/:1:3","tags":["数据库","大纲"],"title":"关系型数据库概览","uri":"/relationaldatabase/"},{"categories":["数据库"],"content":"数据管理器： 事务管理器（Transaction manager）：用于处理事务 缓存管理器（Cache manager）：数据被使用之前置于内存，或者数据写入磁盘之前置于内存 数据访问管理器（Data access manager）：访问磁盘中的数据 ","date":"2017-03-01","objectID":"/relationaldatabase/:1:4","tags":["数据库","大纲"],"title":"关系型数据库概览","uri":"/relationaldatabase/"},{"categories":["数据库"],"content":"数据查询的流程 本章集中探讨数据库如何通过如下进程管理SQL查询的： 客户端管理器 查询管理器 数据管理器（含恢复管理器） 客户端管理器 ","date":"2017-03-01","objectID":"/relationaldatabase/:2:0","tags":["数据库","大纲"],"title":"关系型数据库概览","uri":"/relationaldatabase/"},{"categories":["数据库"],"content":"客户端管理器 客户端管理器是处理客户端通信的。客户端可以是一个（网站）服务器或者一个最终用户或最终应用。客户端管理器通过一系列知名的API（JDBC, ODBC, OLE-DB …）提供不同的方式来访问数据库。客户端管理器也提供专有的数据库访问API。 客户端管理器\" 客户端管理器 当你连接到数据库时： 管理器首先检查你的验证信息（用户名和密码），然后检查你是否有访问数据库的授权。这些权限由DBA分配。 然后，管理器检查是否有空闲进程（或线程）来处理你对查询。 管理器还会检查数据库是否负载很重。 管理器可能会等待一会儿来获取需要的资源。如果等待时间达到超时时间，它会关闭连接并给出一个可读的错误信息。 然后管理器会把你的查询送给查询管理器来处理。 因为查询处理进程不是『不全则无』的，一旦它从查询管理器得到数据，它会把部分结果保存到一个缓冲区并且开始给你发送。 如果遇到问题，管理器关闭连接，向你发送可读的解释信息，然后释放资源。 ","date":"2017-03-01","objectID":"/relationaldatabase/:2:1","tags":["数据库","大纲"],"title":"关系型数据库概览","uri":"/relationaldatabase/"},{"categories":["数据库"],"content":"查询管理器 查询管理器\" 查询管理器 这个多步骤操作过程如下： 查询首先被解析并判断是否合法 然后被重写，去除了无用的操作并且加入预优化部分 接着被优化以便提升性能，并被转换为可执行代码和数据访问计划。 然后计划被编译 最后，被执行 ","date":"2017-03-01","objectID":"/relationaldatabase/:2:2","tags":["数据库","大纲"],"title":"关系型数据库概览","uri":"/relationaldatabase/"},{"categories":["数据库"],"content":"数据管理器 查询管理器\" 查询管理器 在这一步，查询管理器执行了查询，需要从表和索引获取数据，于是向数据管理器提出请求。 但是有 2 个问题： 关系型数据库使用事务模型，所以，当其他人在同一时刻使用或修改数据时，你无法得到这部分数据。 数据提取是数据库中速度最慢的操作，所以数据管理器需要足够聪明地获得数据并保存在内存缓冲区内。 缓冲区 缓冲池(buffer pool)是一种常见的降低磁盘访问的机制； 缓冲池通常以页(page)为单位缓存数据； 缓冲池的常见管理算法是LRU，memcache，OS，InnoDB都使用了这种算法； InnoDB对普通LRU进行了优化：将缓冲池分为老生代和新生代，入缓冲池的页，优先进入老生代，页被访问，才进入新生代，以解决预读失效的问题页被访问，且在老生代停留时间超过配置阈值的，才进入新生代，以解决批量数据访问，大量热数据淘汰的问题 ","date":"2017-03-01","objectID":"/relationaldatabase/:2:3","tags":["数据库","大纲"],"title":"关系型数据库概览","uri":"/relationaldatabase/"},{"categories":["数据库"],"content":"核心知识点 ","date":"2017-03-01","objectID":"/relationaldatabase/:3:0","tags":["数据库","大纲"],"title":"关系型数据库概览","uri":"/relationaldatabase/"},{"categories":["数据库"],"content":"事务 事务指的是满足 ACID 特性的一组操作，可以通过 Commit 提交一个事务，也可以使用 Rollback 进行回滚。 ACID特性 原子性(Atomicity) 事务被视为不可分割的最小单元，事务的所有操作要么全部提交成功，要么全部失败回滚。 回滚可以用日志来实现，日志记录着事务所执行的修改操作，在回滚时反向执行这些修改操作即可。 一致性(Consistency) 数据库在事务执行前后都保持一致性状态。在一致性状态下，所有事务对一个数据的读取结果都是相同的。 隔离性(Isolation) 一个事务所做的修改在最终提交以前，对其它事务是不可见的。 持久性(Durability) 一旦事务提交，则其所做的修改将会永远保存到数据库中。即使系统发生崩溃，事务执行的结果也不能丢失。 可以通过数据库备份和恢复来实现，在系统发生崩溃时，使用备份的数据库进行数据恢复。 ACID特性的相互关系 事务的 ACID 特性概念简单，但不是很好理解，主要是因为这几个特性不是一种平级关系: 只有满足一致性，事务的执行结果才是正确的。 在无并发的情况下，事务串行执行，隔离性一定能够满足。此时只要能满足原子性，就一定能满足一致性。 在并发的情况下，多个事务并行执行，事务不仅要满足原子性，还需要满足隔离性，才能满足一致性。 事务满足持久化是为了能应对数据库崩溃的情况。 ACID\" ACID ","date":"2017-03-01","objectID":"/relationaldatabase/:3:1","tags":["数据库","大纲"],"title":"关系型数据库概览","uri":"/relationaldatabase/"},{"categories":["数据库"],"content":"并发一致性问题 在并发环境下，事务的隔离性很难保证，因此会出现很多并发一致性问题。 丢失修改 T1和T2两个事务都对一个数据进行修改，T1先修改，T2随后修改，T2的修改覆盖了T1的修改。 读脏数据 T1修改一个数据，T2随后读取这个数据。如果T1撤销了这次修改，那么T2读取的数据是脏数据。 不可重复读 T2读取一个数据，T1对该数据做了修改。如果T2再次读取这个数据，此时读取的结果和第一次读取的结果不同。 幻影读 T1读取某个范围的数据，T2在这个范围内插入新的数据，T1再次读取这个范围的数据，此时读取的结果和和第一次读取的结果不同。 ","date":"2017-03-01","objectID":"/relationaldatabase/:3:2","tags":["数据库","大纲"],"title":"关系型数据库概览","uri":"/relationaldatabase/"},{"categories":["数据库"],"content":"并发一致性的解决方案 产生并发不一致性问题主要原因是破坏了事务的隔离性，解决方法是通过并发控制来保证隔离性。并发控制可以通过封锁来实现，但是封锁操作需要用户自己控制，相当复杂。 数据库管理系统提供了事务的隔离级别，让用户以一种更轻松的方式处理并发一致性问题。 ","date":"2017-03-01","objectID":"/relationaldatabase/:3:3","tags":["数据库","大纲"],"title":"关系型数据库概览","uri":"/relationaldatabase/"},{"categories":["数据库"],"content":"隔离级别 使用select @@tx_isolation;查询数据库的隔离级别。Mysql默认的级别是可重复读，优先考虑把数据库系统的隔离级别设为读已提交。 未提交读(READ UNCOMMITTED) 读未提交，一个事务可以读到另一个事务未提交的数据！ 提交读(READ COMMITTED) 读已提交，一个事务可以读到另一个事务已提交的数据! 一个事务只能读取已经提交的事务所做的修改。换句话说，一个事务所做的修改在提交之前对其它事务是不可见的。 可重复读(REPEATABLE READ) 可重复读，加入间隙锁保证在同一个事务中多次读取同样数据的结果是一样的。 可串行化(SERIALIZABLE) 串行化，该级别下读写串行化，且所有的select语句后都自动加上lock in share mode，即使用了共享锁。因此在该隔离级别下，使用的是当前读，而不是快照读。 多版本并发控制是MySQL的InnoDB存储引擎实现隔离级别的一种具体方式，用于实现提交读和可重复读这两种隔离级别。 而未提交读隔离级别总是读取最新的数据行，无需使用 MVCC。可串行化隔离级别需要对所有读取的行都加锁，单纯使用 MVCC 无法实现。 MySQL的InnoDB存储引擎采用两段锁协议，会根据隔离级别在需要的时候自动加锁，并且所有的锁都是在同一时刻被释放，这被称为隐式锁定。 隔离级别\" 隔离级别 ","date":"2017-03-01","objectID":"/relationaldatabase/:3:4","tags":["数据库","大纲"],"title":"关系型数据库概览","uri":"/relationaldatabase/"},{"categories":["数据库"],"content":"封锁 封锁粒度 MySQL 中提供了两种封锁粒度: 行级锁以及表级锁。 封锁粒度\" 封锁粒度 封锁类型 读写锁 排它锁(Exclusive)，简写为 X 锁，又称写锁。 共享锁(Shared)，简写为 S 锁，又称读锁。 有以下两个规定: 一个事务对数据对象 A 加了 X 锁，就可以对 A 进行读取和更新。加锁期间其它事务不能对 A 加任何锁。 一个事务对数据对象 A 加了 S 锁，可以对 A 进行读取操作，但是不能进行更新操作。加锁期间其它事务能对 A 加 S 锁，但是不能加 X 锁。 意向锁 使用意向锁(Intention Locks)可以更容易地支持多粒度封锁。 在存在行级锁和表级锁的情况下，事务T想要对表A加X锁，就需要先检测是否有其它事务对表A或者表A中的任意一行加了锁，那么就需要对表A的每一行都检测一次，这是非常耗时的。 意向锁在原来的 X/S 锁之上引入了 IX/IS，IX/IS 都是表锁，用来表示一个事务想要在表中的某个数据行上加 X 锁或 S 锁。 一个事务在获得某个数据行对象的 S 锁之前，必须先获得表的 IS 锁或者更强的锁； 一个事务在获得某个数据行对象的 X 锁之前，必须先获得表的 IX 锁。 任意 IS/IX 锁之间都是兼容的，因为它们只是表示想要对表加锁，而不是真正加锁； S 锁只与 S 锁和 IS 锁兼容，也就是说事务 T 想要对数据行加 S 锁，其它事务可以已经获得对表或者表中的行的 S 锁。 通过引入意向锁，事务 T 想要对表 A 加 X 锁，只需要先检测是否有其它事务对表A加了 X/IX/S/IS 锁，如果加了就表示有其它事务正在使用这个表或者表中某一行的锁，因此事务T加X锁失败。 封锁协议 三级封锁协议 一级封锁协议 事务 T 要修改数据 A 时必须加 X 锁，直到 T 结束才释放锁。 可以解决丢失修改问题，因为不能同时有两个事务对同一个数据进行修改，那么事务的修改就不会被覆盖。 二级封锁协议 在一级的基础上，要求读取数据 A 时必须加 S 锁，读取完马上释放 S 锁。 可以解决读脏数据问题，因为如果一个事务在对数据 A 进行修改，根据 1 级封锁协议，会加 X 锁，那么就不能再加 S 锁了，也就是不会读入数据。 三级封锁协议 在二级的基础上，要求读取数据 A 时必须加 S 锁，直到事务结束了才能释放 S 锁。 可以解决不可重复读的问题，因为读 A 时，其它事务不能对 A 加 X 锁，从而避免了在读的期间数据发生改变。 两段锁协议 加锁和解锁分为两个阶段进行。 可串行化调度是指，通过并发控制，使得并发执行的事务结果与某个串行执行的事务结果相同。 事务遵循两段锁协议是保证可串行化调度的充分条件。例如以下操作满足两段锁协议，它是可串行化调度。 MySQL 的 InnoDB 存储引擎采用两段锁协议，会根据隔离级别在需要的时候自动加锁，并且所有的锁都是在同一时刻被释放，这被称为隐式锁定。 ","date":"2017-03-01","objectID":"/relationaldatabase/:3:5","tags":["数据库","大纲"],"title":"关系型数据库概览","uri":"/relationaldatabase/"},{"categories":["数据库"],"content":"多版本并发控制 多版本并发控制(Multi-Version Concurrency Control, MVCC)是 MySQL 的 InnoDB 存储引擎实现隔离级别的一种具体方式，用于实现提交读和可重复读这两种隔离级别。而未提交读隔离级别总是读取最新的数据行，无需使用 MVCC。可串行化隔离级别需要对所有读取的行都加锁，单纯使用 MVCC 无法实现。 版本号 系统版本号: 是一个递增的数字，每开始一个新的事务，系统版本号就会自动递增。 事务版本号: 事务开始时的系统版本号。 隐藏的列 MVCC 在每行记录后面都保存着两个隐藏的列，用来存储两个版本号: 创建版本号: 指示创建一个数据行的快照时的系统版本号； 删除版本号: 如果该快照的删除版本号大于当前事务版本号表示该快照有效，否则表示该快照已经被删除了。 Undo 日志 MVCC 使用到的快照存储在 Undo 日志中，该日志通过回滚指针把一个数据行(Record)的所有快照连接起来。 实现过程 以下实现过程针对可重复读隔离级别。 当开始新一个事务时，该事务的版本号肯定会大于当前所有数据行快照的创建版本号，理解这一点很关键。 SELECT 多个事务必须读取到同一个数据行的快照，并且这个快照是距离现在最近的一个有效快照。但是也有例外，如果有一个事务正在修改该数据行，那么它可以读取事务本身所做的修改，而不用和其它事务的读取结果一致。 把没有对一个数据行做修改的事务称为 T，T 所要读取的数据行快照的创建版本号必须小于 T 的版本号，因为如果大于或者等于 T 的版本号，那么表示该数据行快照是其它事务的最新修改，因此不能去读取它。除此之外，T 所要读取的数据行快照的删除版本号必须大于 T 的版本号，因为如果小于等于 T 的版本号，那么表示该数据行快照是已经被删除的，不应该去读取它。 INSERT 将当前系统版本号作为数据行快照的创建版本号。 DELETE 将当前系统版本号作为数据行快照的删除版本号。 UPDATE 将当前系统版本号作为更新前的数据行快照的删除版本号，并将当前系统版本号作为更新后的数据行快照的创建版本号。可以理解为先执行 DELETE 后执行 INSERT。 快照读与当前读 快照读 使用 MVCC 读取的是快照中的数据，这样可以减少加锁所带来的开销。 select * from table ...; 当前读 读取的是最新的数据，需要加锁。以下第一个语句需要加 S 锁，其它都需要加 X 锁。 select * from table where ? lock in share mode; //S锁 (共享锁) select * from table where ? for update; //加X锁 (排他锁) insert; update; delete; ","date":"2017-03-01","objectID":"/relationaldatabase/:3:6","tags":["数据库","大纲"],"title":"关系型数据库概览","uri":"/relationaldatabase/"},{"categories":["数据库"],"content":"Next-Key Locks Next-Key Locks 是 MySQL 的 InnoDB 存储引擎的一种锁实现。 MVCC不能解决幻读的问题，Next-Key Locks 就是为了解决这个问题而存在的。在可重复读(REPEATABLE READ)隔离级别下，使用 MVCC + Next-Key Locks 可以解决幻读问题。 Record Locks（行锁） 锁定一个记录上的索引，而不是记录本身。 该锁是对索引记录进行加锁！锁是在加索引上而不是行上的。注意了，innodb一定存在聚簇索引，因此行锁最终都会落到聚簇索引上！ 如果表没有设置索引，InnoDB 会自动在主键上创建隐藏的聚簇索引，因此 Record Locks 依然可以使用。 Gap Locks（间隙锁） 锁定索引之间的间隙，但是不包含索引本身。其目的只有一个，防止其他事物插入数据。 隔离级别比Read Committed低的情况下，不会使用间隙锁，如隔离级别为Read Uncommited时，也不存在间隙锁。当隔离级别为Repeatable Read和Serializable时，就会存在间隙锁。 例如当一个事务执行以下语句，其它事务就不能在 t.c 中插入 15。 SELECT c FROM t WHERE c BETWEEN 10 and 20 FOR UPDATE; Next-Key Locks 它是 Record Locks 和 Gap Locks 的结合，不仅锁定一个记录上的索引，也锁定索引之间的间隙。 例如一个索引包含以下值: 10, 11, 13, and 20，那么就需要锁定以下区间: (negative infinity, 10] (10, 11] (11, 13] (13, 20] (20, positive infinity) ","date":"2017-03-01","objectID":"/relationaldatabase/:3:7","tags":["数据库","大纲"],"title":"关系型数据库概览","uri":"/relationaldatabase/"},{"categories":["数据库"],"content":"锁行锁表 InnoDB行锁是通过给索引上的索引项加锁来实现，只有通过索引条件检索数据，InnoDB才使用行级锁，否则表锁（注意下面的解释）。 这里的表锁并不是用表锁来实现锁表的操作，而是利用了Next-Key Locks，也可以理解为是用了行锁+间隙锁来实现锁表的操作! 之所以能够锁表，是通过行锁+间隙锁来实现的。那么，RU和RC都不存在间隙锁，这种说法在RU和RC中还能成立么？ 因此，该说法只在RR和Serializable中是成立的。 如果隔离级别为RU和RC，无论条件列上是否有索引，都不会锁表，只锁行！ ","date":"2017-03-01","objectID":"/relationaldatabase/:3:8","tags":["数据库","大纲"],"title":"关系型数据库概览","uri":"/relationaldatabase/"},{"categories":["数据库"],"content":"参考文章 关系型数据库是如何工作的 数据库系统核心知识点 select加锁分析 MySQL InnoDB的MVCC实现机制 一条SQL的执行过程详解 ","date":"2017-03-01","objectID":"/relationaldatabase/:4:0","tags":["数据库","大纲"],"title":"关系型数据库概览","uri":"/relationaldatabase/"},{"categories":["算法"],"content":"算法概览","date":"2017-02-05","objectID":"/algorithm/","tags":["算法","大纲"],"title":"算法概览","uri":"/algorithm/"},{"categories":["算法"],"content":"概览\" 概览 数据结构研究的是数据的存储方式，算法研究的是解决问题的思路。数据结构与算法是相辅相成的。 ","date":"2017-02-05","objectID":"/algorithm/:0:0","tags":["算法","大纲"],"title":"算法概览","uri":"/algorithm/"},{"categories":["算法"],"content":"排序算法 排序算法概览\" 排序算法概览 ","date":"2017-02-05","objectID":"/algorithm/:1:0","tags":["算法","大纲"],"title":"算法概览","uri":"/algorithm/"},{"categories":["算法"],"content":"冒泡排序(Bubble Sort) 它是一种较简单的排序算法。它会遍历若干次要排序的数列，每次遍历时，它都会从前往后依次的比较相邻两个数的大小；如果前者比后者大，则交换它们的位置。这样，一次遍历之后，最大的元素就在数列的末尾！ 采用相同的方法再次遍历时，第二大的元素就被排列在最大元素之前。重复此操作，直到整个数列都有序为止 ","date":"2017-02-05","objectID":"/algorithm/:1:1","tags":["算法","大纲"],"title":"算法概览","uri":"/algorithm/"},{"categories":["算法"],"content":"快速排序(Quick Sort) 它的基本思想是: 选择一个基准数，通过一趟排序将要排序的数据分割成独立的两部分；其中一部分的所有数据都比另外一部分的所有数据都要小。然后，再按此方法对这两部分数据分别进行快速排序，整个排序过程可以递归进行，以此达到整个数据变成有序序列。 ","date":"2017-02-05","objectID":"/algorithm/:1:2","tags":["算法","大纲"],"title":"算法概览","uri":"/algorithm/"},{"categories":["算法"],"content":"插入排序(Insertion Sort) 直接插入排序(Straight Insertion Sort)的基本思想是: 把n个待排序的元素看成为一个有序表和一个无序表。开始时有序表中只包含1个元素，无序表中包含有n-1个元素，排序过程中每次从无序表中取出第一个元素，将它插入到有序表中的适当位置，使之成为新的有序表，重复n-1次可完成排序过程。 ","date":"2017-02-05","objectID":"/algorithm/:1:3","tags":["算法","大纲"],"title":"算法概览","uri":"/algorithm/"},{"categories":["算法"],"content":"Shell排序(Shell Sort) 希尔排序实质上是一种分组插入方法。它的基本思想是: 对于n个待排序的数列，取一个小于n的整数gap(gap被称为步长)将待排序元素分成若干个组子序列，所有距离为gap的倍数的记录放在同一个组中；然后，对各组内的元素进行直接插入排序。 这一趟排序完成之后，每一个组的元素都是有序的。然后减小gap的值，并重复执行上述的分组和排序。重复这样的操作，当gap=1时，整个数列就是有序的。 ","date":"2017-02-05","objectID":"/algorithm/:1:4","tags":["算法","大纲"],"title":"算法概览","uri":"/algorithm/"},{"categories":["算法"],"content":"选择排序(Selection sort) 它的基本思想是: 首先在未排序的数列中找到最小(or最大)元素，然后将其存放到数列的起始位置；接着，再从剩余未排序的元素中继续寻找最小(or最大)元素，然后放到已排序序列的末尾。以此类推，直到所有元素均排序完毕。 ","date":"2017-02-05","objectID":"/algorithm/:1:5","tags":["算法","大纲"],"title":"算法概览","uri":"/algorithm/"},{"categories":["算法"],"content":"堆排序(Heap Sort) 堆排序是指利用堆这种数据结构所设计的一种排序算法。堆是一个近似完全二叉树的结构，并同时满足堆积的性质：即子结点的键值或索引总是小于（或者大于）它的父节点。 ","date":"2017-02-05","objectID":"/algorithm/:1:6","tags":["算法","大纲"],"title":"算法概览","uri":"/algorithm/"},{"categories":["算法"],"content":"归并排序(Merge Sort) 将两个的有序数列合并成一个有序数列，我们称之为\"归并”。归并排序(Merge Sort)就是利用归并思想对数列进行排序。 ","date":"2017-02-05","objectID":"/algorithm/:1:7","tags":["算法","大纲"],"title":"算法概览","uri":"/algorithm/"},{"categories":["算法"],"content":"桶排序(Bucket Sort) 桶排序(Bucket Sort)的原理很简单，将数组分到有限数量的桶子里。每个桶子再个别排序（有可能再使用别的排序算法或是以递归方式继续使用桶排序进行排序） ","date":"2017-02-05","objectID":"/algorithm/:1:8","tags":["算法","大纲"],"title":"算法概览","uri":"/algorithm/"},{"categories":["算法"],"content":"基数排序(Radix Sort) 它的基本思想是: 将整数按位数切割成不同的数字，然后按每个位数分别比较。具体做法是: 将所有待比较数值统一为同样的数位长度，数位较短的数前面补零。然后，从最低位开始，依次进行一次排序。这样从最低位排序一直到最高位排序完成以后, 数列就变成一个有序序列 ","date":"2017-02-05","objectID":"/algorithm/:1:9","tags":["算法","大纲"],"title":"算法概览","uri":"/algorithm/"},{"categories":["算法"],"content":"算法思想详解 ","date":"2017-02-05","objectID":"/algorithm/:2:0","tags":["算法","大纲"],"title":"算法概览","uri":"/algorithm/"},{"categories":["算法"],"content":"分治算法 分治算法的基本思想是将一个规模为N的问题分解为K个规模较小的子问题，这些子问题相互独立且与原问题性质相同。求出子问题的解，就可得到原问题的解 ","date":"2017-02-05","objectID":"/algorithm/:2:1","tags":["算法","大纲"],"title":"算法概览","uri":"/algorithm/"},{"categories":["算法"],"content":"动态规划算法 动态规划算法通常用于求解具有某种最优性质的问题。在这类问题中，可能会有许多可行解。每一个解都对应于一个值，我们希望找到具有最优值的解。动态规划算法与分治法类似，其基本思想也是将待求解问题分解成若干个子问题，先求解子问题，然后从这些子问题的解得到原问题的解 ","date":"2017-02-05","objectID":"/algorithm/:2:2","tags":["算法","大纲"],"title":"算法概览","uri":"/algorithm/"},{"categories":["算法"],"content":"贪心算法 本文主要介绍算法中贪心算法的思想: 保证每次操作都是局部最优的，并且最后得到的结果是全局最优的 ","date":"2017-02-05","objectID":"/algorithm/:2:3","tags":["算法","大纲"],"title":"算法概览","uri":"/algorithm/"},{"categories":["算法"],"content":"二分法 本文主要介绍算法思想中分治算法重要的二分法，比如二分查找；二分查找也称折半查找（Binary Search），它是一种效率较高的查找方法。但是，折半查找要求线性表必须采用顺序存储结构，而且表中元素按关键字有序排列。 ","date":"2017-02-05","objectID":"/algorithm/:2:4","tags":["算法","大纲"],"title":"算法概览","uri":"/algorithm/"},{"categories":["算法"],"content":"搜索算法 本文主要介绍算法中搜索算法的思想，主要包含BFS，DFS ","date":"2017-02-05","objectID":"/algorithm/:2:5","tags":["算法","大纲"],"title":"算法概览","uri":"/algorithm/"},{"categories":["算法"],"content":"回溯算法 Backtracking(回溯)属于 DFS, 本文主要介绍算法中Backtracking算法的思想。回溯算法实际上一个类似枚举的搜索尝试过程，主要是在搜索尝试过程中寻找问题的解，当发现已不满足求解条件时，就“回溯”返回，尝试别的路径。回溯法是一种选优搜索法，按选优条件向前搜索，以达到目标。但当探索到某一步时，发现原先选择并不优或达不到目标，就退回一步重新选择，这种走不通就退回再走的技术为回溯法 ","date":"2017-02-05","objectID":"/algorithm/:2:6","tags":["算法","大纲"],"title":"算法概览","uri":"/algorithm/"},{"categories":["算法"],"content":"领域算法 ","date":"2017-02-05","objectID":"/algorithm/:3:0","tags":["算法","大纲"],"title":"算法概览","uri":"/algorithm/"},{"categories":["算法"],"content":"参考文章 关系型数据库是如何工作的 ","date":"2017-02-05","objectID":"/algorithm/:4:0","tags":["算法","大纲"],"title":"算法概览","uri":"/algorithm/"},{"categories":["数据结构"],"content":"具有层次感的数据结构","date":"2017-02-04","objectID":"/tree/","tags":["数据结构","大纲"],"title":"树","uri":"/tree/"},{"categories":["数据结构"],"content":"树\" 树 树是一种数据结构，它是n(n\u003e=0)个节点的有限集。n=0时称为空树。n\u003e0时，有限集的元素构成一个具有层次感的数据结构。 区别于线性表一对一的元素关系，树中的节点是一对多的关系。树具有以下特点: n\u003e0时，根节点是唯一的，不可能存在多个根节点。 每个节点有零个至多个子节点；除了根节点外，每个节点有且仅有一个父节点。根节点没有父节点。 ","date":"2017-02-04","objectID":"/tree/:0:0","tags":["数据结构","大纲"],"title":"树","uri":"/tree/"},{"categories":["数据结构"],"content":"树的相关概念 树例\" 树例 子树: 除了根节点外，每个子节点都可以分为多个不相交的子树。 孩子与双亲: 若一个结点有子树，那么该结点称为子树根的\"双亲”，子树的根是该结点的\"孩子”。 在图一中，B、H是A的孩子，A是B、H的双亲。 兄弟: 具有相同双亲的节点互为兄弟，例如B与H互为兄弟。 节点的度: 一个节点拥有子树的数目。例如A的度为2，B的度为1，C的度为3. 叶子: 没有子树，也即是度为0的节点。 分支节点: 除了叶子节点之外的节点，也即是度不为0的节点。 内部节点: 除了根节点之外的分支节点。 层次: 根节点为第一层，其余节点的层次等于其双亲节点的层次加1. 树的高度: 也称为树的深度，树中节点的最大层次。 有序树: 树中节点各子树之间的次序是重要的，不可以随意交换位置。 无序树: 树种节点各子树之间的次序是不重要的。可以随意交换位置。 森林: 0或多棵互不相交的树的集合。例如图二中的两棵树为森林。 ","date":"2017-02-04","objectID":"/tree/:1:0","tags":["数据结构","大纲"],"title":"树","uri":"/tree/"},{"categories":["数据结构"],"content":"二叉树 二叉树: 最多有两棵子树的树被称为二叉树。 二叉树\" 二叉树 斜树: 所有节点都只有左子树的二叉树叫做左斜树，所有节点都只有右子树的二叉树叫做右斜树。(本质就是链表) 斜树\" 斜树 满二叉树: 二叉树中所有非叶子结点的度都是2，且叶子结点都在同一层次上 满二叉树\" 满二叉树 完全二叉树: 如果一个二叉树与满二叉树前m个节点的结构相同，这样的二叉树被称为完全二叉树 完全二叉树\" 完全二叉树 ","date":"2017-02-04","objectID":"/tree/:2:0","tags":["数据结构","大纲"],"title":"树","uri":"/tree/"},{"categories":["数据结构"],"content":"二叉查找树 - BST 二叉查找树(Binary Search Tree)是指一棵空树或者具有下列性质的二叉树: 若任意节点的左子树不空，则左子树上所有节点的值均小于它的根节点的值； 若任意节点的右子树不空，则右子树上所有节点的值均大于它的根节点的值； 任意节点的左、右子树也分别为二叉查找树； 没有键值相等的节点。 二叉查找树相比于其他数据结构的优势在于查找、插入的时间复杂度较低为 O (logn) 。二叉查找树是基础性数据结构，用于构建更为抽象的数据结构，如集合、多重集、关联数组等。 二叉查找树\" 二叉查找树 ","date":"2017-02-04","objectID":"/tree/:3:0","tags":["数据结构","大纲"],"title":"树","uri":"/tree/"},{"categories":["数据结构"],"content":"平衡二叉树 - AVL 含有相同节点的二叉查找树可以有不同的形态，而二叉查找树的平均查找长度与树的深度有关，所以需要找出一个查找平均长度最小的一棵，那就是平衡二叉树，具有以下性质: 要么是棵空树，要么其根节点左右子树的深度之差的绝对值不超过1； 其左右子树也都是平衡二叉树； 二叉树节点的平衡因子定义为该节点的左子树的深度减去右子树的深度。则平衡二叉树的所有节点的平衡因子只可能是-1,0,1。 平衡二叉树\" 平衡二叉树 ","date":"2017-02-04","objectID":"/tree/:4:0","tags":["数据结构","大纲"],"title":"树","uri":"/tree/"},{"categories":["数据结构"],"content":"红黑树 红黑树也是一种自平衡的二叉查找树。 每个结点要么是红的要么是黑的。(红或黑) 根结点是黑的。 (根黑) 每个叶结点(叶结点即指树尾端NIL指针或NULL结点)都是黑的。 (叶黑) 如果一个结点是红的，那么它的两个儿子都是黑的。 (红子黑) 对于任意结点而言，其到叶结点树尾端NIL指针的每条路径都包含相同数目的黑结点。(路径下黑相同) 红黑树\" 红黑树 用法最广: Java ConcurrentHashMap \u0026 TreeMap C++ STL: map \u0026 set linux进程调度Completely Fair Scheduler,用红黑树管理进程控制块 epoll在内核中的实现，用红黑树管理事件块 nginx中，用红黑树管理timer等 ","date":"2017-02-04","objectID":"/tree/:5:0","tags":["数据结构","大纲"],"title":"树","uri":"/tree/"},{"categories":["数据结构"],"content":"红黑树与AVL树的比较 AVL树的时间复杂度虽然优于红黑树，但是对于现在的计算机，cpu太快，可以忽略性能差异 红黑树的插入删除比AVL树更便于控制操作 红黑树整体性能略优于AVL树(红黑树旋转情况少于AVL树) ","date":"2017-02-04","objectID":"/tree/:5:1","tags":["数据结构","大纲"],"title":"树","uri":"/tree/"},{"categories":["数据结构"],"content":"哈弗曼树 哈夫曼又称最优二叉树。是一种带权路径长度最短的二叉树，一般可以按下面步骤构建: 将所有左，右子树都为空的作为根节点。 在森林中选出两棵根节点的权值最小的树作为一棵新树的左，右子树，且置新树的附加根节点的权值为其左，右子树上根节点的权值之和。 注意，左子树的权值应小于右子树的权值。 从森林中删除这两棵树，同时把新树加入到森林中。 重复2，3步骤，直到森林中只有一棵树为止，此树便是哈夫曼树。 哈弗曼树\" 哈弗曼树 ","date":"2017-02-04","objectID":"/tree/:6:0","tags":["数据结构","大纲"],"title":"树","uri":"/tree/"},{"categories":["数据结构"],"content":"B树 B树(英语: B-tree)是一种自平衡的树，能够保持数据有序。这种数据结构能够让查找数据、顺序访问、插入数据及删除的动作，都在对数时间内完成。B树，概括来说是一种自平衡的m阶树，与自平衡二叉查找树不同，B树适用于读写相对大的数据块的存储系统，例如磁盘。 根结点至少有两个子女。 每个中间节点都包含k-1个元素和k个孩子，其中 m/2 \u003c= k \u003c= m 每一个叶子节点都包含k-1个元素，其中 m/2 \u003c= k \u003c= m 所有的叶子结点都位于同一层。 每个节点中的元素从小到大排列，节点当中k-1个元素正好是k个孩子包含的元素的值域分划。 B-Tree中的每个节点根据实际情况可以包含大量的关键字信息和分支，如下图所示为一个3阶的B-Tree: B树\" B树 ","date":"2017-02-04","objectID":"/tree/:7:0","tags":["数据结构","大纲"],"title":"树","uri":"/tree/"},{"categories":["数据结构"],"content":"B+树 B+ 树是一种树数据结构，通常用于关系型数据库(如Mysql)和操作系统的文件系统中。B+ 树的特点是能够保持数据稳定有序，其插入与修改拥有较稳定的对数时间复杂度。B+ 树元素自底向上插入，这与二叉树恰好相反。 在B树基础上，为叶子结点增加链表指针(B树+叶子有序链表)，所有关键字都在叶子结点 中出现，非叶子结点作为叶子结点的索引；B+树总是到叶子结点才命中。 b+树的非叶子节点不保存数据，只保存子树的临界值(最大或者最小)，所以同样大小的节点，b+树相对于b树能够有更多的分支，使得这棵树更加矮胖，查询时做的IO操作次数也更少。 将上一节中的B-Tree优化，由于B+Tree的非叶子节点只存储键值信息，假设每个磁盘块能存储4个键值及指针信息，则变成B+Tree后其结构如下图所示: B+树\" B+树 ","date":"2017-02-04","objectID":"/tree/:8:0","tags":["数据结构","大纲"],"title":"树","uri":"/tree/"},{"categories":["数据结构"],"content":"R树 R树是用来做空间数据存储的树状数据结构。例如给地理位置，矩形和多边形这类多维数据建立索引。 R树的核心思想是聚合距离相近的节点并在树结构的上一层将其表示为这些节点的最小外接矩形(MBR)，这个最小外接矩形就成为上一层的一个节点。因为所有节点都在它们的最小外接矩形中，所以跟某个矩形不相交的查询就一定跟这个矩形中的所有节点都不相交。叶子节点上的每个矩形都代表一个对象，节点都是对象的聚合，并且越往上层聚合的对象就越多。也可以把每一层看做是对数据集的近似，叶子节点层是最细粒度的近似，与数据集相似度100%，越往上层越粗糙。 ","date":"2017-02-04","objectID":"/tree/:9:0","tags":["数据结构","大纲"],"title":"树","uri":"/tree/"},{"categories":["数据结构"],"content":"散列是数组和链表的结合体","date":"2017-02-03","objectID":"/hashtable/","tags":["数据结构"],"title":"哈希表","uri":"/hashtable/"},{"categories":["数据结构"],"content":"定义 散列Hash是和顺序、链接和索引一样，是存储集合或者线性表的一种方法。 散列的基本思想是：以集合或线性表中的每个元素的关键字K为自变量，通过一个散列函数 h(K) 得到的结果，将这个结果解释为一块连续的存储空间（如数组）的地址（如数组下标），将这个元素存储到这个空间中。 h(K) 称为散列函数或者哈希函数，它实现了关键字到存储地址的映射，散列算法，变换成固定长度的输出，该输出就是散列值。h(K)的值 称为散列地址或者哈希地址。存储空间是线性表进行散列存储的空间，所以称之为散列表或者哈希表。 ","date":"2017-02-03","objectID":"/hashtable/:1:0","tags":["数据结构"],"title":"哈希表","uri":"/hashtable/"},{"categories":["数据结构"],"content":"释义 这种转换是一种压缩映射，也就是，散列值的空间通常远小于输入的空间，不同的输入可能会散列成相同的输出，所以不可能从散列值来唯一的确定输入值。简单的说就是一种将任意长度的消息压缩到某一固定长度的消息摘要的函数。 所有散列函数都有如下一个基本特性：根据同一散列函数计算出的散列值如果不同，那么输入值肯定也不同。但是，根据同一散列函数计算出的散列值如果相同，输入值不一定相同。 两个不同的输入值，根据同一散列函数计算出的散列值相同的现象叫做碰撞，衡量一个哈希函数的好坏的重要指标就是发生碰撞的概率以及发生碰撞的解决方案。 ","date":"2017-02-03","objectID":"/hashtable/:2:0","tags":["数据结构"],"title":"哈希表","uri":"/hashtable/"},{"categories":["数据结构"],"content":"常见的Hash函数 直接定址法：直接以关键字k或者k加上某个常数（k+c）作为哈希地址。 数字分析法：提取关键字中取值比较均匀的数字作为哈希地址。 除留余数法：用关键字k除以某个不大于哈希表长度m的数p，将所得余数作为哈希表地址。 分段叠加法：按照哈希表地址位数将关键字分成位数相等的几部分，其中最后一部分可以比较短。然后将这几部分相加，舍弃最高进位后的结果就是该关键字的哈希地址。 平方取中法：如果关键字各个部分分布都不均匀的话，可以先求出它的平方值，然后按照需求取中间的几位作为哈希地址。 伪随机数法：采用一个伪随机数当作哈希函数。 ","date":"2017-02-03","objectID":"/hashtable/:3:0","tags":["数据结构"],"title":"哈希表","uri":"/hashtable/"},{"categories":["数据结构"],"content":"解决碰撞方法 开放定址法：开放定址法就是一旦发生了冲突，就去寻找下一个空的散列地址，只要散列表足够大，空的散列地址总能找到，并将记录存入。 链地址法：将哈希表的每个单元作为链表的头结点，所有哈希地址为i的元素构成一个同义词链表。即发生冲突时就把该关键字链在以该单元为头结点的链表的尾部。 再哈希法：当哈希地址发生冲突用其他的函数计算另一个哈希函数地址，直到冲突不再产生为止。 建立公共溢出区：将哈希表分为基本表和溢出表两部分，发生冲突的元素都放入溢出表中。 ","date":"2017-02-03","objectID":"/hashtable/:4:0","tags":["数据结构"],"title":"哈希表","uri":"/hashtable/"},{"categories":["数据结构"],"content":"散列存储的缺点 计算散列地址需要花费时间，关键字不是整数还先要转换为整数。 占用更多的存储空间，开放定址法的装载因子小于1，链接法则需要空间存储指针。 只能按关键字查找，无法按非关键字查找。 ","date":"2017-02-03","objectID":"/hashtable/:5:0","tags":["数据结构"],"title":"哈希表","uri":"/hashtable/"},{"categories":["数据结构"],"content":"数组是用于储存多个相同类型数据的集合","date":"2017-02-02","objectID":"/linkedlist/","tags":["数据结构"],"title":"链表","uri":"/linkedlist/"},{"categories":["数据结构"],"content":"定义 链表是一种物理存储单元上非连续、非顺序的存储结构，数据元素的逻辑顺序是通过链表中的指针链接次序实现的。 ","date":"2017-02-02","objectID":"/linkedlist/:1:0","tags":["数据结构"],"title":"链表","uri":"/linkedlist/"},{"categories":["数据结构"],"content":"详解 链表的存在就是为了解决数组的增删复杂耗时，内存占用较大的问题。它并不需要一块连续的内存空间，它通过指针将一组零散的内存块串联起来。 根据指针的不同，有单链表，双向链表，循环链表之分。 数组和链表是相互补充的一对数据结构。 ","date":"2017-02-02","objectID":"/linkedlist/:2:0","tags":["数据结构"],"title":"链表","uri":"/linkedlist/"},{"categories":["数据结构"],"content":"优点： 操作指针即可删除该元素或者插入新元素，时间复杂度 O(1)。 链表因为元素不连续，而是靠指针指向下一个元素的位置，本身没有大小的限制，不存在数组的扩容问题，所以天然地支持动态扩容。 空间没有限制 插入删除元素很快 ","date":"2017-02-02","objectID":"/linkedlist/:3:0","tags":["数据结构"],"title":"链表","uri":"/linkedlist/"},{"categories":["数据结构"],"content":"缺点： 因为存储空间不连续，你无法根据一个索引算出对应元素的地址，所以不能随机访问。 由于每个元素必须存储指向前后元素位置的指针，会消耗相对更多的储存空间。 同时内存不连续，容易造成内存碎片。 存取速度很慢 ","date":"2017-02-02","objectID":"/linkedlist/:4:0","tags":["数据结构"],"title":"链表","uri":"/linkedlist/"},{"categories":["数据结构"],"content":"对比 ","date":"2017-02-02","objectID":"/linkedlist/:5:0","tags":["数据结构"],"title":"链表","uri":"/linkedlist/"},{"categories":["数据结构"],"content":"数组 数组存储区间是连续的，占用内存严重，故空间复杂的很大。但数组的二分查找时间复杂度小，为O(1)；数组的特点是：寻址容易，插入和删除困难。 ","date":"2017-02-02","objectID":"/linkedlist/:5:1","tags":["数据结构"],"title":"链表","uri":"/linkedlist/"},{"categories":["数据结构"],"content":"链表 链表存储区间离散，占用内存比较宽松，故空间复杂度很小，但时间复杂度很大，达O（N）。链表的特点是：寻址困难，插入和删除容易。 ","date":"2017-02-02","objectID":"/linkedlist/:5:2","tags":["数据结构"],"title":"链表","uri":"/linkedlist/"},{"categories":["数据结构"],"content":"哈希表 那么我们能不能综合两者的特性，做出一种寻址容易，插入删除也容易的数据结构？这就是我们要提起的哈希表。 ","date":"2017-02-02","objectID":"/linkedlist/:5:3","tags":["数据结构"],"title":"链表","uri":"/linkedlist/"},{"categories":["数据结构"],"content":"分类 单向链表 一个节点指向下一个节点。 双向链表 一个节点有两个指针域。 循环链表 能通过任何一个节点找到其他所有的节点，将两种(双向/单向)链表的最后一个结点指向第一个结点从而实现循环。 ","date":"2017-02-02","objectID":"/linkedlist/:6:0","tags":["数据结构"],"title":"链表","uri":"/linkedlist/"},{"categories":["数据结构"],"content":"数组是用于储存多个相同类型数据的集合","date":"2017-02-01","objectID":"/array/","tags":["数据结构"],"title":"数组","uri":"/array/"},{"categories":["数据结构"],"content":"定义 有限个相同数据类型的元素按顺序排列的集合为数组。 ","date":"2017-02-01","objectID":"/array/:1:0","tags":["数据结构"],"title":"数组","uri":"/array/"},{"categories":["数据结构"],"content":"特性 数组是相同数据类型的元素的集合。 数组中的各元素的存储是有先后顺序的，它们在内存中按照这个先后顺序连续存放在一起。 ","date":"2017-02-01","objectID":"/array/:2:0","tags":["数据结构"],"title":"数组","uri":"/array/"},{"categories":["数据结构"],"content":"优点： 由于是紧凑连续存储,可以随机访问，通过索引快速找到对应元素，而且相对节约存储空间，查询修改元素的效率O(1)。 ","date":"2017-02-01","objectID":"/array/:3:0","tags":["数据结构"],"title":"数组","uri":"/array/"},{"categories":["数据结构"],"content":"缺点： 正因为连续存储，内存空间必须一次性分配够，所以说数组如果要扩容，需要重新分配一块更大的空间，再把数据全部复制过去，时间复杂度 O(N)。 想在数组中间进行插入和删除，每次必须搬移后面的所有数据以保持连续，时间复杂度 O(N) ","date":"2017-02-01","objectID":"/array/:4:0","tags":["数据结构"],"title":"数组","uri":"/array/"},{"categories":["数据结构"],"content":"二维数组 二维数组也称为矩阵，因为是二维的，所以需要两个下标才能确定一个元素，即行下标和列下标。 ","date":"2017-02-01","objectID":"/array/:5:0","tags":["数据结构"],"title":"数组","uri":"/array/"},{"categories":["数据结构"],"content":"数据结构概览","date":"2017-01-15","objectID":"/datastruct/","tags":["数据结构","大纲"],"title":"数据结构概览","uri":"/datastruct/"},{"categories":["数据结构"],"content":"概览\" 概览 数据结构研究的是数据的存储方式，算法研究的是解决问题的思路。数据结构与算法是相辅相成的。 ","date":"2017-01-15","objectID":"/datastruct/:0:0","tags":["数据结构","大纲"],"title":"数据结构概览","uri":"/datastruct/"},{"categories":["数据结构"],"content":"常用存储结构 线性表，还可细分为顺序表(数组)、链表、栈和队列。 树结构，包括普通树，二叉树，二叉查找树等。 图存储结构。 ","date":"2017-01-15","objectID":"/datastruct/:0:1","tags":["数据结构","大纲"],"title":"数据结构概览","uri":"/datastruct/"},{"categories":["数据结构"],"content":"线性表 线性表并不是一种具体的存储结构，它包含顺序存储结构和链式存储结构，是顺序表和链表的统称。 线性表是一种线性结构，它是由零个或多个数据元素构成的有限序列。 线性表的特征是在一个序列中，除了头尾元素，每个元素都有且只有一个直接前驱，有且只有一个直接后继，而序列头元素没有直接前驱，序列尾元素没有直接后继。 数据结构中常见的线性结构有数组、单链表、双链表、循环链表等。线性表中的元素为某种相同的抽象数据类型。 线性表\" 线性表 如图 3a) 所示，将数据依次存储在连续的整块物理空间中，这种存储结构称为顺序存储结构（简称顺序表，数组）； 如图 3b) 所示，数据分散的存储在物理空间中，通过一根线保存着它们之间的逻辑关系，这种存储结构称为链式存储结构（简称链表）。 ","date":"2017-01-15","objectID":"/datastruct/:1:0","tags":["数据结构","大纲"],"title":"数据结构概览","uri":"/datastruct/"},{"categories":["数据结构"],"content":"数组和矩阵(顺序表) 数组是一种连续存储线性结构，元素类型相同，大小相等，数组是多维的，通过使用整型索引值来访问他们的元素，数组尺寸不能改变。 ","date":"2017-01-15","objectID":"/datastruct/:1:1","tags":["数据结构","大纲"],"title":"数据结构概览","uri":"/datastruct/"},{"categories":["数据结构"],"content":"链表 我们知道，使用顺序表（底层实现靠数组）时，需要提前申请一定大小的存储空间，这块存储空间的物理地址是连续的，链表则完全不同，使用链表存储数据时，是随用随申请，因此数据的存储位置是相互分离的，换句话说，数据的存储位置是随机的。 n个节点离散分配，彼此通过指针相连，每个节点只有一个前驱节点，每个节点只有一个后续节点，首节点没有前驱节点，尾节点没有后续节点。确定一个链表我们只需要头指针，通过头指针就可以把整个链表都能推出来。 ","date":"2017-01-15","objectID":"/datastruct/:1:2","tags":["数据结构","大纲"],"title":"数据结构概览","uri":"/datastruct/"},{"categories":["数据结构"],"content":"哈希表(散列) 散列表（Hash table，也叫哈希表），是根据关键码值(Key value)而直接进行访问的数据结构。也就是说，它通过把关键码值映射到表中一个位置来访问记录，以加快查找的速度。这个映射函数叫做散列函数，存放记录的数组叫做散列表。 ","date":"2017-01-15","objectID":"/datastruct/:1:3","tags":["数据结构","大纲"],"title":"数据结构概览","uri":"/datastruct/"},{"categories":["数据结构"],"content":"栈和队列 数组和链表都是线性存储结构的基础，栈和队列都是线性存储结构的应用，栈和队列隶属于线性表，是特殊的线性表，因为它们对线性表中元素的进出做了明确的要求。 栈（LIFO） 使用数组实现的叫静态栈 使用链表实现的叫动态栈 栈（FIFO） 使用数组实现的叫静态队列 使用链表实现的叫动态队列 ","date":"2017-01-15","objectID":"/datastruct/:1:4","tags":["数据结构","大纲"],"title":"数据结构概览","uri":"/datastruct/"},{"categories":["数据结构"],"content":"树存储结构 树存储结构适合存储具有“一对多”关系的数据。 树\" 树 ","date":"2017-01-15","objectID":"/datastruct/:2:0","tags":["数据结构","大纲"],"title":"数据结构概览","uri":"/datastruct/"},{"categories":["数据结构"],"content":"图存储结构 图存储结构适合存储具有“多对多”关系的数据。 图\" 图 ","date":"2017-01-15","objectID":"/datastruct/:3:0","tags":["数据结构","大纲"],"title":"数据结构概览","uri":"/datastruct/"},{"categories":["数据结构"],"content":"和线性表，树的差异: 线性表中我们把数据元素叫元素，树中将数据元素叫结点，在图中数据元素，我们则称之为顶点(Vertex)。 线性表可以没有元素，称为空表；树中可以没有节点，称为空树；但是，在图中不允许没有顶点(有穷非空性)。 线性表中的各元素是线性关系，树中的各元素是层次关系，而图中各顶点的关系是用边来表示(边集可以为空)。 ","date":"2017-01-15","objectID":"/datastruct/:3:1","tags":["数据结构","大纲"],"title":"数据结构概览","uri":"/datastruct/"},{"categories":["数据结构"],"content":"总结 我们知道，实际应用当中，我们经常使用的是查找和排序操作，这在我们的各种管理系统、数据库系统、操作系统等当中，十分常用。 数组 的下标寻址十分迅速，但计算机的内存是有限的，故数组的长度也是有限的，实际应用当中的数据往往十分庞大；而且无序数组的查找最坏情况需要遍历整个数组；后来人们提出了二分查找，二分查找要求数组的构造一定有序，二分法查找解决了普通数组查找复杂度过高的问题。任和一种数组无法解决的问题就是插入、删除操作比较复杂，因此，在一个增删查改比较频繁的数据结构中，数组不会被优先考虑 普通链表 由于它的结构特点被证明根本不适合进行查找 哈希表 是数组和链表的折中，同时它的设计依赖散列函数的设计，数组不能无限长、链表也不适合查找，所以也不适合大规模的查找 二叉查找树 因为可能退化成链表，同样不适合进行查找 AVL树 是为了解决可能退化成链表问题，但是AVL树的旋转过程非常麻烦，因此插入和删除很慢，也就是构建AVL树比较麻烦 红黑树 是平衡二叉树和AVL树的折中，因此是比较合适的。集合类中的Map、关联数组具有较高的查询效率，它们的底层实现就是红黑树。 多路查找树 是大规模数据存储中，实现索引查询这样一个实际背景下，树节点存储的元素数量是有限的(如果元素数量非常多的话，查找就退化成节点内部的线性查找了)，这样导致二叉查找树结构由于树的深度过大而造成磁盘I/O读写过于频繁，进而导致查询效率低下。 B树 与自平衡二叉查找树不同，B树适用于读写相对大的数据块的存储系统，例如磁盘。它的应用是文件系统及部分非关系型数据库索引。 B+树 在B树基础上，为叶子结点增加链表指针(B树+叶子有序链表)，所有关键字都在叶子结点 中出现，非叶子结点作为叶子结点的索引；B+树总是到叶子结点才命中。通常用于关系型数据库(如Mysql)和操作系统的文件系统中。 B*树 是B+树的变体，在B+树的非根和非叶子结点再增加指向兄弟的指针, 在B+树基础上，为非叶子结点也增加链表指针，将结点的最低利用率从1/2提高到2/3。 R树是用来做空间数据存储的树状数据结构。例如给地理位置，矩形和多边形这类多维数据建立索引。 Trie树 是自然语言处理中最常用的数据结构，很多字符串处理任务都会用到。Trie树本身是一种有限状态自动机，还有很多变体。什么模式匹配、正则表达式，都与这有关。 针对大量数据，如果在内存中作业优先考虑红黑树(map,set之类多为RB-tree实现)，如果在硬盘中作业优先考虑B系列树(B+, B, B)* ","date":"2017-01-15","objectID":"/datastruct/:4:0","tags":["数据结构","大纲"],"title":"数据结构概览","uri":"/datastruct/"},{"categories":["网络"],"content":"计算机网络","date":"2017-01-05","objectID":"/network/","tags":["网络","大纲"],"title":"计算机网络","uri":"/network/"},{"categories":["网络"],"content":" 一般网线传输的模拟信号需要通过猫(调制解调器)转换成数字信号，再经由路由器把信号发给PC端，如果PC端数量超过了路由器的连接上限就需要加装交换器。因此，家里有宽带就必须有猫，有多台电脑上网就必须要路由器，假如电脑很多，超过路由器的接口数就需要交换机扩展接口。 传输示例\" 传输示例 协议对照\" 协议对照 各层协议对照\" 各层协议对照 HTTP协议\" HTTP协议 DNS协议\" DNS协议 ","date":"2017-01-05","objectID":"/network/:0:0","tags":["网络","大纲"],"title":"计算机网络","uri":"/network/"},{"categories":["网络"],"content":"参考文章 7层协议 HTTP协议 DNS协议 知识点串联：输入URL到页面加载过程详解 ","date":"2017-01-05","objectID":"/network/:1:0","tags":["网络","大纲"],"title":"计算机网络","uri":"/network/"},{"categories":["理财"],"content":"投资纲领","date":"2016-01-01","objectID":"/investment/","tags":["理财"],"title":"投资纲领","uri":"/investment/"},{"categories":["理财"],"content":"总体策略 低估加倍 高估不买 高估卖出 好资产 + 好价格 + 长期持有 ","date":"2016-01-01","objectID":"/investment/:1:0","tags":["理财"],"title":"投资纲领","uri":"/investment/"},{"categories":["理财"],"content":"资产配置 ","date":"2016-01-01","objectID":"/investment/:2:0","tags":["理财"],"title":"投资纲领","uri":"/investment/"},{"categories":["理财"],"content":"购买标的 ","date":"2016-01-01","objectID":"/investment/:3:0","tags":["理财"],"title":"投资纲领","uri":"/investment/"},{"categories":["理财"],"content":"宽基指数（沪深300和中证500） 我们可以把沪深300和中证500这样的宽基指数作为「核心」资产，比如占整体仓位的 60% 以上，保证我们能够跟上中国经济的增长，投资到未来头部的公司。 40% 基于估值和增强型指数基金进一步提高仓位。 ","date":"2016-01-01","objectID":"/investment/:3:1","tags":["理财"],"title":"投资纲领","uri":"/investment/"},{"categories":["理财"],"content":"「卫星」资产 我们可以根据自己的判断或者市场的估值，加入一部分「卫星」资产。 主动基金（优秀基金精力管理的基金）中概互联基金 科创板（还需观看） 。 30% 分散投资给几个优秀的主动型基金经理。 ","date":"2016-01-01","objectID":"/investment/:3:2","tags":["理财"],"title":"投资纲领","uri":"/investment/"},{"categories":["理财"],"content":"债券 30% 的债券仓位，用债券基金以及有知有行未来推荐的其它「固收+」产品来进一步提高收益。 计算得出年化收益率：40% * 13% + 30% * 11% + 30% * 4% + 1% = 10.7%。 ","date":"2016-01-01","objectID":"/investment/:3:3","tags":["理财"],"title":"投资纲领","uri":"/investment/"},{"categories":["理财"],"content":"具体操作 ","date":"2016-01-01","objectID":"/investment/:4:0","tags":["理财"],"title":"投资纲领","uri":"/investment/"},{"categories":["理财"],"content":"每年一次大额买入 参考有知有行的「股市温度计」来确定自己一次性买入的仓位。 假如当年大额资金5万，当时股市温度为40处于中估状态，则先投入50%，计算得出当年大额买入资金为2.5万。 ","date":"2016-01-01","objectID":"/investment/:4:1","tags":["理财"],"title":"投资纲领","uri":"/investment/"},{"categories":["理财"],"content":"每年一次的再平衡 根据自定的家庭资产比例和当年股债实时状态，进行股债再平衡调整。 ","date":"2016-01-01","objectID":"/investment/:4:2","tags":["理财"],"title":"投资纲领","uri":"/investment/"},{"categories":["理财"],"content":"每月定投 参考有知有行的「股市温度计」，在中估时投入，低估时加倍，高估时停止买入 ","date":"2016-01-01","objectID":"/investment/:4:3","tags":["理财"],"title":"投资纲领","uri":"/investment/"},{"categories":["理财"],"content":"高估状态卖出部分锁定收益 A股的波动大，牛市之后往往出现暴跌，而浮亏越大，回本难度越大，甚至难度是呈指数级增长的。 ","date":"2016-01-01","objectID":"/investment/:4:4","tags":["理财"],"title":"投资纲领","uri":"/investment/"},{"categories":["反思"],"content":"写作促进思考","date":"2015-01-02","objectID":"/studyandthink/","tags":["反思"],"title":"学与思","uri":"/studyandthink/"},{"categories":["反思"],"content":"学而不思则罔，思而不学则殆 一味学习而不思考，就会因为不能深刻理解而不能合理有效利用学习的知识，甚至会陷入迷茫。 一味空想而不去进行实实在在地学习和钻研，则终究是沙上建塔，一无所得。 因此我们只有把学习和思考结合起来，才能学到切实有用的知识，否则就会收效甚微。 ","date":"2015-01-02","objectID":"/studyandthink/:0:1","tags":["反思"],"title":"学与思","uri":"/studyandthink/"},{"categories":["记录"],"content":"Markdown常用语法","date":"2015-01-01","objectID":"/mdgrammar/","tags":["Markdown"],"title":"Markdown语法","uri":"/mdgrammar/"},{"categories":["记录"],"content":"标题 #### 这是 H5 #### 这是 H5 ","date":"2015-01-01","objectID":"/mdgrammar/:0:1","tags":["Markdown"],"title":"Markdown语法","uri":"/mdgrammar/"},{"categories":["记录"],"content":"段落 这是一个段落。 这是另一个段落。 这是一个段落。 这是另一个段落。 ","date":"2015-01-01","objectID":"/mdgrammar/:0:2","tags":["Markdown"],"title":"Markdown语法","uri":"/mdgrammar/"},{"categories":["记录"],"content":"斜体 *这是斜体* 这是斜体 ","date":"2015-01-01","objectID":"/mdgrammar/:0:3","tags":["Markdown"],"title":"Markdown语法","uri":"/mdgrammar/"},{"categories":["记录"],"content":"粗体 **这是粗体** 这是粗体 ","date":"2015-01-01","objectID":"/mdgrammar/:0:4","tags":["Markdown"],"title":"Markdown语法","uri":"/mdgrammar/"},{"categories":["记录"],"content":"粗体+斜体 ***这是粗体+斜体*** 这是粗体+斜体 ","date":"2015-01-01","objectID":"/mdgrammar/:0:5","tags":["Markdown"],"title":"Markdown语法","uri":"/mdgrammar/"},{"categories":["记录"],"content":"删除线 ~~没有价值就会被抛弃~~ 没有价值就会被抛弃 ","date":"2015-01-01","objectID":"/mdgrammar/:0:6","tags":["Markdown"],"title":"Markdown语法","uri":"/mdgrammar/"},{"categories":["记录"],"content":"引用 \u003e Markdown是一种可以使用普通文本编辑器编写的标记语言，通过简单的标记语法，它可以使普通文本内容具有一定的格式。 Markdown是一种可以使用普通文本编辑器编写的标记语言，通过简单的标记语法，它可以使普通文本内容具有一定的格式。 ","date":"2015-01-01","objectID":"/mdgrammar/:0:7","tags":["Markdown"],"title":"Markdown语法","uri":"/mdgrammar/"},{"categories":["记录"],"content":"列表 * 学习 * 思考 * 创造 学习 思考 创造 ","date":"2015-01-01","objectID":"/mdgrammar/:0:8","tags":["Markdown"],"title":"Markdown语法","uri":"/mdgrammar/"},{"categories":["记录"],"content":"有序列表 1. 昨夜西风凋碧树。独上高楼，望尽天涯路。 2. 衣带渐宽终不悔，为伊消得人憔悴。 3. 众里寻他千百度。蓦然回首，那人却在，灯火阑珊处。 昨夜西风凋碧树。独上高楼，望尽天涯路。 衣带渐宽终不悔，为伊消得人憔悴。 众里寻他千百度。蓦然回首，那人却在，灯火阑珊处。 ","date":"2015-01-01","objectID":"/mdgrammar/:0:9","tags":["Markdown"],"title":"Markdown语法","uri":"/mdgrammar/"},{"categories":["记录"],"content":"分隔线 --------------------------------------- ","date":"2015-01-01","objectID":"/mdgrammar/:0:10","tags":["Markdown"],"title":"Markdown语法","uri":"/mdgrammar/"},{"categories":["记录"],"content":"链接 [百度](http://www.baidu.com/ \"百度一下\") 百度 ","date":"2015-01-01","objectID":"/mdgrammar/:0:11","tags":["Markdown"],"title":"Markdown语法","uri":"/mdgrammar/"},{"categories":["记录"],"content":"表格 | 账户 | 余额 | 类别 | | :------- | ----: | :---: | | 人民币 | 5百万 | 活期 | | 比特币 | 5个 | 数字资产 | | 股票基金 | 5亿 | 理财 | 账户 余额 类别 人民币 5百万 活期 比特币 5个 数字资产 股票基金 5亿 理财 ","date":"2015-01-01","objectID":"/mdgrammar/:0:12","tags":["Markdown"],"title":"Markdown语法","uri":"/mdgrammar/"},{"categories":["记录"],"content":"代码区域（四个空格） /** 这是一个Java代码区块 */ public static void main(String[] args) { System.out.println(\"Hello World\"); } ","date":"2015-01-01","objectID":"/mdgrammar/:0:13","tags":["Markdown"],"title":"Markdown语法","uri":"/mdgrammar/"},{"categories":["记录"],"content":"图像 ![](/images/star.png \"星辰大海\") 星辰大海 ","date":"2015-01-01","objectID":"/mdgrammar/:0:14","tags":["Markdown"],"title":"Markdown语法","uri":"/mdgrammar/"},{"categories":["反思"],"content":"舒缓生活","date":"2015-01-01","objectID":"/energy/","tags":["生活"],"title":"减缓焦虑，积聚生活正能量","uri":"/energy/"},{"categories":["反思"],"content":" 面对不断袭来的压力和信息，我们要做的，就是找到自己的节奏，建立一套稳定的模式，用来应对和处理种种事务。尽可能让一切「平稳」下来。 这也许需要一些取舍，一些选择、牺牲和放弃 —— 但一旦这套模式能够建立起来，一切都是值得的。 ","date":"2015-01-01","objectID":"/energy/:0:0","tags":["生活"],"title":"减缓焦虑，积聚生活正能量","uri":"/energy/"},{"categories":["反思"],"content":"思虑过载 变被动为主动，自己去决定「我要做什么」，重新找回「自主性」。 ","date":"2015-01-01","objectID":"/energy/:1:0","tags":["生活"],"title":"减缓焦虑，积聚生活正能量","uri":"/energy/"},{"categories":["反思"],"content":"前一天晚上做好安排 整理一遍任务清单，从收集/待办的池子中， 挑出5-6个最重要、最关键的任务，安排到第二天 ","date":"2015-01-01","objectID":"/energy/:1:1","tags":["生活"],"title":"减缓焦虑，积聚生活正能量","uri":"/energy/"},{"categories":["反思"],"content":"留出一定的宽裕度 做出取舍。该舍弃的，就果断舍弃。 与其把所有事情做到60分，不如把最重要的事情做到100分。 ","date":"2015-01-01","objectID":"/energy/:1:2","tags":["生活"],"title":"减缓焦虑，积聚生活正能量","uri":"/energy/"},{"categories":["反思"],"content":"聚焦在长期价值上 不妨这样问问自己：我可以做些什么，来摆脱目前这种忙碌的状态？ 无论是设计一套流程，还是把部分工作委托出去，又或者是把细碎的任务合并起来，还是优化、压缩任务步骤和时间……这些，长期来看都是更具价值的，也是你应该着重去聚焦的。 把它们作为你每天「最重要的事项」，想办法让自己能够抽身出来。 ","date":"2015-01-01","objectID":"/energy/:1:3","tags":["生活"],"title":"减缓焦虑，积聚生活正能量","uri":"/energy/"},{"categories":["反思"],"content":"被压榨感 什么是被压榨感？它是指：自己一直在劳动和付出，但却始终得不到反馈、认可和肯定，仿佛自己的付出都是无价值的。 去发现生活中微小的幸福感。 ","date":"2015-01-01","objectID":"/energy/:2:0","tags":["生活"],"title":"减缓焦虑，积聚生活正能量","uri":"/energy/"},{"categories":["反思"],"content":"决策疲劳 不要在晚上作出重要的决定。 通过给自己设立规则，让规则帮助自己作出决策。规则覆盖不到的地方，则用随机来解决。 ","date":"2015-01-01","objectID":"/energy/:3:0","tags":["生活"],"title":"减缓焦虑，积聚生活正能量","uri":"/energy/"},{"categories":["反思"],"content":"外在打扰 建立你的「第二大脑」，把思维外部化。 ","date":"2015-01-01","objectID":"/energy/:4:0","tags":["生活"],"title":"减缓焦虑，积聚生活正能量","uri":"/energy/"},{"categories":["反思"],"content":"信息过载 我们不断去追逐新信息，不断获取新鲜感的刺激，这本身是一个高耗能的行为 —— 但我们的大脑，会受到新鲜感的蛊惑，从而忽略和掩盖住这种耗能。 意识地克制自己，去做好信息的「反刍」，而非追逐新的信息。 试着把你记录的不同笔记放到一起，看看它们之间能产生什么联系，能否创造出新的火花。 在闲暇的碎片时间里，去反刍、回想自己记下的旧内容，尽量控制对新信息的摄入。 ","date":"2015-01-01","objectID":"/energy/:5:0","tags":["生活"],"title":"减缓焦虑，积聚生活正能量","uri":"/energy/"},{"categories":["反思"],"content":"tips 一定要睡好。 睡眠过程中的深度睡眠，能够有效促进腺苷到ATP的水合反应，为我们的机体储存能量、清除代谢垃圾。 请保证每天6小时以上不受干扰的睡眠，这极其重要。 多散步。 散步是最轻松有效的锻炼。不但能够促进血清素的合成，也能有效扩充大脑容量。波士顿大学的一项研究表明，每天步行1小时（约5000步），相当于大脑延缓衰老1年。 适当的运动。 每周 150 分钟一定强度的运动，能够有效提高心肺功能，从而提高每一天精力的上限。 这才是精力管理的关键 —— 上限太低，再怎么「管理」，也是无效的。 ","date":"2015-01-01","objectID":"/energy/:6:0","tags":["生活"],"title":"减缓焦虑，积聚生活正能量","uri":"/energy/"},{"categories":null,"content":"默哥","date":"2015-01-01","objectID":"/about/","tags":null,"title":"关于我","uri":"/about/"},{"categories":null,"content":"用写作触发思考。 ","date":"2015-01-01","objectID":"/about/:0:0","tags":null,"title":"关于我","uri":"/about/"},{"categories":null,"content":"记录点滴，反哺归真","date":"0001-01-01","objectID":"/archives/","tags":null,"title":"归档","uri":"/archives/"},{"categories":null,"content":"搜索页面","date":"0001-01-01","objectID":"/search/","tags":null,"title":"搜索","uri":"/search/"}]