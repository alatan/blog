[{"categories":["知识体系"],"content":"性能测试","date":"2020-05-10","objectID":"/pts/","tags":["性能测试"],"title":"性能测试","uri":"/pts/"},{"categories":["知识体系"],"content":"˚ 问题排查\" 问题排查 ","date":"2020-05-10","objectID":"/pts/:0:0","tags":["性能测试"],"title":"性能测试","uri":"/pts/"},{"categories":["知识体系"],"content":"测试指标 业务指标：如并发用户数、TPS（系统每秒处理事务数）、成功率、响应时间。 资源指标：如CPU资源利用率、内存利用率、I/O、内核参数（信号量、打开文件数）等。 应用指标：如空闲线程数、数据库连接数、GC/FULL GC次数、函数耗时等。 前端指标：如页面加载时间、网络时间（DNS、连接时间、传输时间等）。 ","date":"2020-05-10","objectID":"/pts/:0:1","tags":["性能测试"],"title":"性能测试","uri":"/pts/"},{"categories":["知识体系"],"content":"工具 APM工具（如ARMS）进行中间件、数据库、应用层面的问题定位。 ","date":"2020-05-10","objectID":"/pts/:0:2","tags":["性能测试"],"title":"性能测试","uri":"/pts/"},{"categories":["业务场景"],"content":"秒杀系统设计","date":"2020-05-07","objectID":"/flashsale/","tags":["架构设计"],"title":"秒杀(限时抢购)系统设计","uri":"/flashsale/"},{"categories":["业务场景"],"content":"参考文章 高性能秒杀系统设计 秒杀架构实践 百万级用户的抽奖系统 ","date":"2020-05-07","objectID":"/flashsale/:1:0","tags":["架构设计"],"title":"秒杀(限时抢购)系统设计","uri":"/flashsale/"},{"categories":["业务场景"],"content":"单点登录","date":"2020-05-06","objectID":"/sso/","tags":["架构设计"],"title":"单点登录","uri":"/sso/"},{"categories":["业务场景"],"content":" 单点登录（Single Sign On），简称为 SSO，是比较流行的企业业务整合的解决方案之一。SSO的定义是在多个应用系统中，用户只需要登录一次就可以访问所有相互信任的应用系统。 ","date":"2020-05-06","objectID":"/sso/:0:0","tags":["架构设计"],"title":"单点登录","uri":"/sso/"},{"categories":["业务场景"],"content":"参考文章 单点登录 单点登录总结 ","date":"2020-05-06","objectID":"/sso/:1:0","tags":["架构设计"],"title":"单点登录","uri":"/sso/"},{"categories":["SpringCloud"],"content":"Nacos解析","date":"2020-04-11","objectID":"/nacos/","tags":["SpringCloud","微服务"],"title":"Nacos解析","uri":"/nacos/"},{"categories":["SpringCloud"],"content":"临时实例和持久化实例。 在定义上区分临时实例和持久化实例的关键是健康检查的方式。 临时实例使用客户端上报模式，而持久化实例使用服务端反向探测模式。 临时实例需要能够自动摘除不健康实例，而且无需持久化存储实例，那么这种实例就适用于类 Gossip 的协议。 右边的持久化实例使用服务端探测的健康检查方式，因为客户端不会上报心跳，那么自然就不能去自动摘除下线的实例。 ","date":"2020-04-11","objectID":"/nacos/:1:0","tags":["SpringCloud","微服务"],"title":"Nacos解析","uri":"/nacos/"},{"categories":["SpringCloud"],"content":"实现对比 Zookeeper：保证CP，放弃可用性；一旦zookeeper集群中master节点宕了，则会重新选举leader，这个过程可能非常漫长，在这过程中服务不可用。 Eureka：保证AP，放弃一致性；Eureka集群中的各个节点都是平等的，一旦某个节点宕了，其他节点正常服务（一旦客户端发现注册失败，则将会连接集群中其他节点），虽然保证了可用性，但是每个节点的数据可能不是最新的。 Nacos：同时支持CP和AP，默认是AP，可以切换；AP模式下以临时实例注册，CP模式下服务永久实例注册。 ","date":"2020-04-11","objectID":"/nacos/:2:0","tags":["SpringCloud","微服务"],"title":"Nacos解析","uri":"/nacos/"},{"categories":["SpringCloud"],"content":"健康检查 ","date":"2020-04-11","objectID":"/nacos/:3:0","tags":["SpringCloud","微服务"],"title":"Nacos解析","uri":"/nacos/"},{"categories":["SpringCloud"],"content":"客户端健康检查 客户端健康检查主要关注客户端上报心跳的方式、服务端摘除不健康客户端的机制。 ","date":"2020-04-11","objectID":"/nacos/:3:1","tags":["SpringCloud","微服务"],"title":"Nacos解析","uri":"/nacos/"},{"categories":["SpringCloud"],"content":"服务端健康检查 而服务端健康检查，则关注探测客户端的方式、灵敏度及设置客户端健康状态的机制。 从实现复杂性来说，服务端探测肯定是要更加复杂的，因为需要服务端根据注册服务配置的健康检查方式，去执行相应的接口，判断相应的返回结果，并做好重试机制和线程池的管理。 这与客户端探测，只需要等待心跳，然后刷新 TTL 是不一样的。同时服务端健康检查无法摘除不健康实例，这意味着只要注册过的服务实例，如果不调用接口主动注销，这些服务实例都需要去维持健康检查的探测任务，而客户端则可以随时摘除不健康实例，减轻服务端的压力。 ","date":"2020-04-11","objectID":"/nacos/:3:2","tags":["SpringCloud","微服务"],"title":"Nacos解析","uri":"/nacos/"},{"categories":["SpringCloud"],"content":"Nacos实现配置管理和动态配置 添加对应spring-cloud-starter-alibaba-nacos-config依赖 使用原生注解@Value()导入配置 使用原生注解@RefreshScope刷新配置 根据自己业务场景做好多环境配置隔离(Namespace)、不同业务配置隔离(Group) 切记：命名空间和分组的配置一定要放在bootstrap.yml或者bootstrap.properties配置文件中 ","date":"2020-04-11","objectID":"/nacos/:4:0","tags":["SpringCloud","微服务"],"title":"Nacos解析","uri":"/nacos/"},{"categories":["SpringCloud"],"content":"参考文章 Nacos 注册中心的设计原理详解 Nacos 实现原理详解 Nacos 使用 ","date":"2020-04-11","objectID":"/nacos/:5:0","tags":["SpringCloud","微服务"],"title":"Nacos解析","uri":"/nacos/"},{"categories":["SpringCloud"],"content":"微服务最佳实践方案","date":"2020-04-10","objectID":"/springcloudalibaba/","tags":["SpringCloud","大纲"],"title":"Spring Cloud Alibaba","uri":"/springcloudalibaba/"},{"categories":["SpringCloud"],"content":"Spring Cloud Alibaba\" Spring Cloud Alibaba ","date":"2020-04-10","objectID":"/springcloudalibaba/:0:0","tags":["SpringCloud","大纲"],"title":"Spring Cloud Alibaba","uri":"/springcloudalibaba/"},{"categories":["SpringCloud"],"content":"组件 Spring Cloud - Gateway 网关 Spring Cloud - Ribbon 实现负载均衡 Spring Cloud - Feign 实现远程调用 Spring Cloud - Sleuth 实现调用链监控 Spring Cloud Alibaba - Nacos 实现注册中心/配置中心 Spring Cloud Alibaba - Sentinel 实现服务容错(限流，降级) Spring Cloud Alibaba - Seata 实现分布式事务 Spring Cloud Alibaba 组件\" Spring Cloud Alibaba 组件 ","date":"2020-04-10","objectID":"/springcloudalibaba/:1:0","tags":["SpringCloud","大纲"],"title":"Spring Cloud Alibaba","uri":"/springcloudalibaba/"},{"categories":["SpringCloud"],"content":"Nacos Nacos 是一个 Alibaba 开源的、易于构建云原生应用的动态服务发现、配置管理和服务管理平台。 Nacos 这个名字怎么读呢？它的音标为 /nɑ:kəʊs/。这个名字不是一个标准的单词，而是以下单词的首字母缩写：Name and Config Service。 ","date":"2020-04-10","objectID":"/springcloudalibaba/:2:0","tags":["SpringCloud","大纲"],"title":"Spring Cloud Alibaba","uri":"/springcloudalibaba/"},{"categories":["SpringCloud"],"content":"Nacos Discovery 使用 Spring Cloud Alibaba Nacos Discovery，可基于 Spring Cloud 的编程模型快速接入 Nacos 服务注册功能。 ","date":"2020-04-10","objectID":"/springcloudalibaba/:2:1","tags":["SpringCloud","大纲"],"title":"Spring Cloud Alibaba","uri":"/springcloudalibaba/"},{"categories":["SpringCloud"],"content":"配置中心 Nacos Config 使用 Spring Cloud Alibaba Nacos Config，可基于 Spring Cloud 的编程模型快速接入 Nacos 配置管理功能。 ","date":"2020-04-10","objectID":"/springcloudalibaba/:2:2","tags":["SpringCloud","大纲"],"title":"Spring Cloud Alibaba","uri":"/springcloudalibaba/"},{"categories":["SpringCloud"],"content":"Sentinel Sentinel 以流量为切入点，从流量控制、熔断降级、系统负载保护等多个维度保护服务的稳定性。 Sentinel 具有以下特征: 丰富的应用场景： Sentinel 承接了阿里巴巴近 10 年的双十一大促流量的核心场景，例如秒杀（即突发流量控制在系统容量可以承受的范围）、消息削峰填谷、实时熔断下游不可用应用等。 完备的实时监控： Sentinel 同时提供实时的监控功能。您可以在控制台中看到接入应用的单台机器秒级数据，甚至 500 台以下规模的集群的汇总运行情况。 广泛的开源生态： Sentinel 提供开箱即用的与其它开源框架/库的整合模块，例如与 Spring Cloud、Dubbo、gRPC 的整合。您只需要引入相应的依赖并进行简单的配置即可快速地接入 Sentinel。 完善的 SPI 扩展点： Sentinel 提供简单易用、完善的 SPI 扩展点。您可以通过实现扩展点，快速的定制逻辑。例如定制规则管理、适配数据源等。 ","date":"2020-04-10","objectID":"/springcloudalibaba/:3:0","tags":["SpringCloud","大纲"],"title":"Spring Cloud Alibaba","uri":"/springcloudalibaba/"},{"categories":["SpringCloud"],"content":"学习资料 Spring Cloud Alibaba 参考文档 Nacos Sentinel SkyWalking 分布式追踪 ","date":"2020-04-10","objectID":"/springcloudalibaba/:4:0","tags":["SpringCloud","大纲"],"title":"Spring Cloud Alibaba","uri":"/springcloudalibaba/"},{"categories":["SpringCloud"],"content":"Spring Cloud Hystrix","date":"2020-04-04","objectID":"/springcloud-hystrix/","tags":["SpringCloud","大纲"],"title":"Spring Cloud Hystrix 解析","uri":"/springcloud-hystrix/"},{"categories":["SpringCloud"],"content":"参考文章 Hystrix原理与实战 Hystrix原理与实战 Hystrix 源码分析及实践 ","date":"2020-04-04","objectID":"/springcloud-hystrix/:1:0","tags":["SpringCloud","大纲"],"title":"Spring Cloud Hystrix 解析","uri":"/springcloud-hystrix/"},{"categories":["SpringCloud"],"content":"Spring Cloud Eureka","date":"2020-04-03","objectID":"/springcloud-eureka/","tags":["SpringCloud","大纲"],"title":"Spring Cloud Eureka 解析","uri":"/springcloud-eureka/"},{"categories":["SpringCloud"],"content":"先来一波问题，然后看看Enueka是通过什么方式处理的。 Eureka注册中心使用什么样的方式来储存各个服务注册时发送过来的机器地址和端口号？ 各个服务找Eureka Server拉取注册表的时候，是什么样的频率？ 各个服务是如何拉取注册表的？ 对于一个有几百个服务，部署上千台机器的大型分布式系统来说，这套系统会对Eureka Server造成多大的访问压力？ Eureka Server从技术层面是如何抗住日千万级访问量的？ 基本知识点，各个服务内的Eureka Client组件，默认情况下，每隔30秒会发送一个请求到Eureka Server，来拉取最近有变化的服务信息 ","date":"2020-04-03","objectID":"/springcloud-eureka/:0:0","tags":["SpringCloud","大纲"],"title":"Spring Cloud Eureka 解析","uri":"/springcloud-eureka/"},{"categories":["SpringCloud"],"content":"Eureka Server设计精妙的注册表存储结构 维护注册表、拉取注册表、更新心跳时间，全部发生在内存里！这是Eureka Server非常核心的一个点。 ","date":"2020-04-03","objectID":"/springcloud-eureka/:1:0","tags":["SpringCloud","大纲"],"title":"Spring Cloud Eureka 解析","uri":"/springcloud-eureka/"},{"categories":["SpringCloud"],"content":"Eureka Server端优秀的多级缓存机制 尽可能保证了内存注册表数据不会出现频繁的读写冲突问题。 并且进一步保证对Eureka Server的大量请求，都是快速从纯内存走，性能极高。 ","date":"2020-04-03","objectID":"/springcloud-eureka/:2:0","tags":["SpringCloud","大纲"],"title":"Spring Cloud Eureka 解析","uri":"/springcloud-eureka/"},{"categories":["SpringCloud"],"content":"总结 通过上面的分析可以看到，Eureka通过设置适当的请求频率拉取注册表30秒间隔，发送心跳30秒间隔），可以保证一个大规模的系统每秒请求Eureka Server的次数在几百次。 同时通过纯内存的注册表，保证了所有的请求都可以在内存处理，确保了极高的性能 另外,多级缓存机制，确保了不会针对内存数据结构发生频繁的读写并发冲突操作，进一步提升性能。 ","date":"2020-04-03","objectID":"/springcloud-eureka/:3:0","tags":["SpringCloud","大纲"],"title":"Spring Cloud Eureka 解析","uri":"/springcloud-eureka/"},{"categories":["SpringCloud"],"content":"参考文章 Eureka 原理 Eureka 原理解析 深入学习 Eureka 原理 微服务注册中心如何承载大型系统的千万级访问 ","date":"2020-04-03","objectID":"/springcloud-eureka/:4:0","tags":["SpringCloud","大纲"],"title":"Spring Cloud Eureka 解析","uri":"/springcloud-eureka/"},{"categories":["SpringCloud"],"content":"Spring Cloud ","date":"2020-04-02","objectID":"/springcloud/","tags":["SpringCloud","大纲"],"title":"Spring Cloud","uri":"/springcloud/"},{"categories":["SpringCloud"],"content":" Spring 以 Bean（对象） 为中心，提供 IOC、AOP 等功能。 Spring Boot 以 Application（应用） 为中心，提供自动配置、监控等功能，专注于快速方便的开发单个微服务。 Spring Cloud 以 Service（服务） 为中心，关注全局的微服务协调整理治理框架，它将SpringBoot开发的一个个单体微服务整合并管理起来，为各个微服务之间提供，配置管理、服务发现、断路器、路由、微代理、事件总线、全局锁、决策竞选、分布式会话等等集成服务SpringBoot可以离开SpringCloud独立使用开发项目， 但是SpringCloud离不开SpringBoot ，属于依赖的关系。 Spring Cloud是目前最常用的微服务开发框架，Spring Cloud是一系列框架的有序集合。它利用Spring Boot的开发便利性巧妙地简化了分布式系统基础设施的开发，如服务发现注册、配置中心、消息总线、负载均衡、熔断保护、数据监控等，都可以用Spring Boot的开发风格做到一键启动和部署。Spring Cloud并没有重复制造轮子，它只是将各家公司开发的比较成熟、经得起实际考验的服务框架组合起来，通过Spring Boot风格进行再封装屏蔽掉了复杂的配置和实现原理，最终给开发者留出了一套简单易懂、易部署和易维护的分布式系统开发工具包。 ","date":"2020-04-02","objectID":"/springcloud/:0:0","tags":["SpringCloud","大纲"],"title":"Spring Cloud","uri":"/springcloud/"},{"categories":["SpringCloud"],"content":"版本对应 Spring Cloud Version Spring Boot Version Spring Cloud Alibaba Version Spring Cloud 2020.0.1 2.4.x 2021.1 Spring Cloud Hoxton 2.2.x, 2.3.x 2.2.x Spring Cloud Greenwich 2.1.x 2.1.x Spring Cloud Finchley 2.0.x 2.0.x(停止维护，建议升级) Spring Cloud Edgware 1.5.x 1.5.x(停止维护，建议升级) Spring Cloud Dalston 1.5.x 1.5.x(停止维护，建议升级) ","date":"2020-04-02","objectID":"/springcloud/:0:1","tags":["SpringCloud","大纲"],"title":"Spring Cloud","uri":"/springcloud/"},{"categories":["SpringCloud"],"content":"SpringCloud的基础功能 服务治理： Spring Cloud Eureka 服务容错保护： Spring Cloud Hystrix 客户端负载均衡： Spring Cloud Ribbon 基于Ribbon和Hystrix的声明式服务调用组件： Spring Cloud OpenFeign 整合了ribbon，具有负载均衡的能力。 整合了Hystrix，具有熔断的能力。 API网关服务：Spring Cloud Zuul 分布式配置中心： Spring Cloud Config Spring Cloud\" Spring Cloud ","date":"2020-04-02","objectID":"/springcloud/:1:0","tags":["SpringCloud","大纲"],"title":"Spring Cloud","uri":"/springcloud/"},{"categories":["SpringCloud"],"content":"服务治理-Eureka 为了解决微服务架构中的服务实例维护问题(ip地址)， 产生了大量的服务治理框架和产品。 这些框架和产品的实现都围绕着服务注册与服务发现机制来完成对微服务应用实例的自动化管理。 服务提供者 服务注册：启动的时候会通过发送REST请求的方式将自己注册到Eureka Server上，同时带上了自身服务的一些元数据信息。 服务续约：在注册完服务之后，服务提供者会维护一个心跳用来持续告诉Eureka Server: “我还活着” 服务下线：当服务实例进行正常的关闭操作时，它会触发一个服务下线的REST请求给Eureka Server, 告诉服务注册中心：“我要下线了 ”。 服务消费者 获取服务：当我们启动服务消费者的时候，它会发送一个REST请求给服务注册中心，来获取上面注册的服务清单 服务调用：服务消费者在获取服务清单后，通过服务名可以获得具体提供服务的实例名和该实例的元数据信息。在进行服务调用的时候，优先访问同处一个Zone中的服务提供方。 Eureka Server(服务注册中心)： 失效剔除：默认每隔一段时间（默认为60秒） 将当前清单中超时（默认为90秒）没有续约的服务剔除出去。 自我保护：EurekaServer 在运行期间，会统计心跳失败的比例在15分钟之内是否低于85%(通常由于网络不稳定导致)。 Eureka Server会将当前的实例注册信息保护起来， 让这些实例不会过期，不在删除注册表中的数据，当网络故障恢复后，Eureka Server 节点会自动退出自我保护模式。 ","date":"2020-04-02","objectID":"/springcloud/:2:0","tags":["SpringCloud","大纲"],"title":"Spring Cloud","uri":"/springcloud/"},{"categories":["SpringCloud"],"content":"Eureka 和 Zookeeper 作为注册中心的区别 Eureka取CAP的AP注重可用性，Zookeeper取CAP的CP注重一致性。 Zookeeper在选举期间注册服务瘫痪，虽然服务最终会恢复，但选举期间不可用。 eureka的自我保护机制，会导致一个结果就是不会再从注册列表移除因长时间没收到心跳而过期的服务。依然能接受新服务的注册和查询请求，但不会被同步到其他节点。不会服务瘫痪。 Zookeeper有Leader和Follower角色，Eureka各个节点平等。 Zookeeper采用过半数存活原则， reka采用自我保护机制解决分区 。 Eureka 本质是一个工程，Zookeeper只是一个进程。 Eureka还有一种自我保护机制，如果在15分钟内超过85%的节点都没有正常的心跳，那么Eureka就认为客户端与注册中心出现了网络故障。而不会像zookeeper那样使整个注册服务瘫痪。 CP 当向注册中心查询服务列表时，我们可以容忍注册中心返回的是几分钟以前的信息，但不能容忍直接down掉不可用。也就是说，服务注册功能对高可用性要求比较高，但zk会出现这样一种情况，当master节点因为网络故障与其他节点失去联系时，剩余节点会重新选leader。问题在于，选取leader时间过长，30 ~120s，且选取期间zk集群都不可用，这样就会导致选取期间注册服务瘫痪。在云部署的环境下，因网络问题使得zk集群失去master节点是较大概率会发生的事，虽然服务能够恢复，但是漫长的选取时间导致的注册长期不可用是不能容忍的。 AP Eureka保证 用性，Eureka各个节点是平等的，几个节点挂掉不会影响正常节点的工作，剩余的节点仍然可以提供注册和查询服务。而Eureka的客户端向某个Eureka注册或发现时发生连接失败，则会自动切换到其他节点，只要有一台Eureka还在，就能保证注册服务可用，只是查到的信息可能不是最新的。除此之外，Eureka还有自我保护机制，如果在15分钟内超过85%的节点没有正常的心跳，那么Eureka就认为客户端与注册中心发生了网络故障，此时会出现以下几种情况： Eureka不在从注册列表中移除因为长时间没有收到心跳而应该过期的服务。 Eureka仍然能够接受新服务的注册和查询请求，但是不会被同步到其他节点上（即保证当前节点仍然可用） 当网络稳定时，当前实例新的注册信息会被同步到其他节点。因此，Eureka可以很好的应对因网络故障导致部分节点失去联系的情况，而不会像Zookeeper那样使整个微服务瘫痪 ","date":"2020-04-02","objectID":"/springcloud/:2:1","tags":["SpringCloud","大纲"],"title":"Spring Cloud","uri":"/springcloud/"},{"categories":["SpringCloud"],"content":"Ribbon Ribbon客户端组件提供一系列完善的配置项如连接超时，重试等。简单的说，就是在配置文件中列出Load Balancer（简称LB）后面所有的机器，Ribbon会自动的帮助你基于某种规则（如简单轮询，随机连接等）去连接这些机器。我们也很容易使用Ribbon实现自定义的负载均衡算法。 将用户的请求平摊的分配到多个服务上 集中式LB即在服务的消费方和提供方之间使用独立的LB设施(可以是硬件，如F5, 也可以是软件，如nginx), 由该设施负责把访问请求通过某种策略转发至服务的提供方； 进程内LB将LB逻辑集成到消费方，消费方从服务注册中心获知有哪些地址可用，然后自己再从这些地址中选择出一个合适的服务器。 注意：Ribbon就属于进程内LB，它只是一个类库，集成于消费方进程，消费方 它来获取到服务提供方的地址。 ","date":"2020-04-02","objectID":"/springcloud/:3:0","tags":["SpringCloud","大纲"],"title":"Spring Cloud","uri":"/springcloud/"},{"categories":["SpringCloud"],"content":"Nginx与Ribbon的区别 Nginx是反向代理同时可以实现负载均衡，nginx拦截客户端请求采用负载均衡策略根据upstream配置进行转发，相当于请求通过nginx服务器进行转发。Ribbon是客户端负载均衡，从注册中心读取目标服务器信息，然后客户端采用轮询策略对服务直接访问，全程在客户端操作。 ","date":"2020-04-02","objectID":"/springcloud/:3:1","tags":["SpringCloud","大纲"],"title":"Spring Cloud","uri":"/springcloud/"},{"categories":["SpringCloud"],"content":"OpenFeign OpenFeign 是一个声明式的web服务客户端，让编写web服务客户端变的非常容易，只需要创建一个接口并在接口上添加注解即可，openFeign的前身是Feign，后者目前已经停更了。 OpenFeign 是SpringCloud在Feign的基础上支持了Spring MVC的注解，并通过动态代理的方式产生实现类来做负载均衡并进行调用其他服务。 ","date":"2020-04-02","objectID":"/springcloud/:4:0","tags":["SpringCloud","大纲"],"title":"Spring Cloud","uri":"/springcloud/"},{"categories":["SpringCloud"],"content":"OpenFeign工作原理 添加@EnableFeignClients注解开启对@FeignClient注解的扫描加载处理。根据Feign Client的开发规范，定义接口并添加@FeiginClient注解 当程序启动之后，会进行包扫描，扫描所有@FeignClient注解的接口，并将这些信息注入到IOC容器中。当定义的Feign接口被调用时，通过JDK的代理的方式生成具体的RequestTemplate。Feign会为每个接口方法创建一个RequestTemplate对象。该对象封装了HTTP请求需要的所有信息，例如请求参数名、请求方法等信息。 然后由RequestTemplate生成Request，把Request交给Client去处理，这里的Client可以是JDK原生的URLConnection、HttpClient或Okhttp。最后Client被封装到LoadBalanceClient类，看这个类的名字既可以知道是结合Ribbon负载均衡发起服务之间的调用，因为在OpenFeign中默认是已经整合了Ribbon了。 Ribbon和Feign的区别 Ribbon都是调用其他服务的，但方式不同。 启动类注解不同，Ribbon是@RibbonClient feign的是@EnableFeignClients 服务指定的位置不同，Ribbon是在@RibbonClient注解上声明，Feign则是在定义抽象方法的接口中使用@FeignClient声明。 调用方式不同，Ribbon需要自己构建http请求，模拟http请求然后使用RestTemplate发送给其他服务，步骤相当繁琐。Feign需要将调用的方法定义成抽象方法即可。 Ribbon是和Feign以及Eureka紧密协作 完成工作的，具体如下： 首先Ribbon会从 Eureka Client里获取到对应的服务注册表，也就知道了所有的服务都部署在了哪些机器上，在监听哪些端口号。 然后Ribbon就可以使用默认的Round Robin算法，从中选择一台机器 Feign就会针对这台机器，构造并发起请求。 Spring Cloud ReqFlow\" Spring Cloud ReqFlow ","date":"2020-04-02","objectID":"/springcloud/:4:1","tags":["SpringCloud","大纲"],"title":"Spring Cloud","uri":"/springcloud/"},{"categories":["SpringCloud"],"content":"Hystrix Hystrix 是一个延迟和容错库，旨在隔离远程系统，服务和第三方库的访问点，当出现故障是不可避免的故障时，停止级联故障并在复杂的分布式系统中实现弹性。 ","date":"2020-04-02","objectID":"/springcloud/:5:0","tags":["SpringCloud","大纲"],"title":"Spring Cloud","uri":"/springcloud/"},{"categories":["SpringCloud"],"content":"Hystrix有四种防雪崩方式: 服务降级：接口调用失败就调用本地的方法返回一个空 服务熔断：接口调用失败就会进入调用接口提前定义好的一个熔断的方法，返回错误信息 服务隔离：隔离服务之间相互影响 服务监控：在服务发生调用时,会将每秒请求数、成功请求数等运行指标记录下来。 线程池数量 = 每秒请求数量 * 业务处理时间 + 备用线程数量 ","date":"2020-04-02","objectID":"/springcloud/:5:1","tags":["SpringCloud","大纲"],"title":"Spring Cloud","uri":"/springcloud/"},{"categories":["SpringCloud"],"content":"大致的工作流如下： 构建一个HystrixCommand对象，用于封装请求，并在构造方法配置请求被执行需要的参数 执行命令，Hystrix提供了几种执行命令的方法，比较常用到的是synchrous和asynchrous 判断电路是否被打开，如果被打开，直接进入fallback方法 判断线程池/队列/信号量是否已经满，如果满了，直接进入fallback方法 执行run方法，一般是HystrixCommand.run()，进入实际的业务调用，执行超时或者执行失败抛出未提前预计的异常时，直接进入fallback方法 无论中间走到哪一步都会进行上报metrics，统计出熔断器的监控指标 fallback方法也分实现和备用的环节 最后是返回请求响应 服务熔断 服务熔断：当下游的服务因为某种原因突然变得不可用或响应过慢，上游服务为了保证自己整体服务的可用性，不再继续调用目标服务，直接返回，快速释放资源。如果目标服务情况好转则恢复调用。 是在服务降级的基础上更直接的一种保护方式，需要说明的是熔断其实是一个框架级的处理，那么这套熔断机制的设计，基本上业内用的是断路器模式 在Hystrix中，对应配置如下： //滑动窗口的大小（当在一个统计时间范围内的请求失败数量达到设定值），默认为20 circuitBreaker.requestVolumeThreshold //错误率，默认50%（当前的请求错误率达到设定的错误率阈值） circuitBreaker.errorThresholdPercentage //过多长时间，熔断器再次检测是否开启，默认为5000，即5s钟（在设定时间（sleepWindowInMilliseconds）后尝试恢复。） circuitBreaker.sleepWindowInMilliseconds 每当20个请求中，有50%失败时，熔断器就会打开，此时再调用此服务，将会直接返回失败，不再调远程服务。直到5s钟之后，重新检测该触发条件，判断是否把熔断器关闭，或者继续打开。 这些属于框架层级的实现，我们只要实现对应接口就好！ ","date":"2020-04-02","objectID":"/springcloud/:5:2","tags":["SpringCloud","大纲"],"title":"Spring Cloud","uri":"/springcloud/"},{"categories":["SpringCloud"],"content":"网关 网关相当于一个网络服务架构的入口，所有网络请求必须通过网关转发到具体的服务。 反向代理 这个是所有网关，包括nginx的基本功能。除了能够对服务进行整形，网关一个非常重要的附加收益，就是对后端的服务细节进行了屏蔽。 反向代理同时会带有负载均衡的功能，包括带权重的流量分配。 鉴权 就是权限认证，也就是常说的权限系统。由于鉴权服务有非常高的相似性，就可以进行抽象处理，放在网关层。 比如https协议的统一接入，分布式session的处理问题，新的登录鉴权通道的接入等。 流量控制 流量控制如果分散到每个服务里去做，就是一种灾难，网关是最适合的地方。 流量控制通常有多种策略，对后端服务进行屏蔽。非正常请求和超出负载能力的请求，都会被快速拦截在外，为系统的稳定性提供了必不可少的支持。 流量控制有单机限流和分布式限流两种方式，后者控制更加精细一些，spring cloud gateway都有提供。 熔断 熔断与流控的主要区别，在于前者在一段时间内，服务“不可用”，而后者仅概率性失败。 除了服务之间的调用涉及到熔断，在网关层的熔断，作用范围会更大，需要对服务进行准确的分级。 灰度控制 网关的一个终极功能，就是实现服务的灰度发布。比如常说的AB test，就是一种灰度发布方式。 灰度会进行精细化控制，比如针对一类用户，某个物理区域，特定请求路径，特定模块，随机百分比等方面的一些灰度控制等。 灰度是一个整体架构配合的结果，但协调的入口就是网关，通过对请求头或者参数加入一些特定的标志，就可以对每个请求进行划分，决定是否落入灰度。 日志监控 网关是最适合进行日志监控的地方。通过对访问日志的精细分析，能够得到很多有价值的数据，进而对后端服务的优化提供决策依据。 比如，某个“业务”的访问趋势，运营数据，QPS峰值，同比、环比等。 路由转发 ","date":"2020-04-02","objectID":"/springcloud/:6:0","tags":["SpringCloud","大纲"],"title":"Spring Cloud","uri":"/springcloud/"},{"categories":["SpringCloud"],"content":"总结 Eureka：各个服务启动时，Eureka Client都会将服务注册到Eureka Server，并且Eureka Client还可以反过来从Eureka Server拉取注册表，从而知道其他服务在哪里 Ribbon：服务间发起请求的时候，基于Ribbon做负载均衡，从一个服务的多台机器中选择一台 Feign：基于Feign的动态代理机制，根据注解和选择的机器，拼接请求URL地址，发起请求 Hystrix：发起请求是通过Hystrix的线程池来走的，不同的服务走不同的线程池，实现了不同服务调用的隔离，避免了服务雪崩的问题 Zuul：如果前端、移动端要调用后端系统，统一从Zuul网关进入，由Zuul网关转发请求给对应的服务 ","date":"2020-04-02","objectID":"/springcloud/:7:0","tags":["SpringCloud","大纲"],"title":"Spring Cloud","uri":"/springcloud/"},{"categories":["SpringCloud"],"content":"参考文章 Spring Cloud底层原理 ","date":"2020-04-02","objectID":"/springcloud/:8:0","tags":["SpringCloud","大纲"],"title":"Spring Cloud","uri":"/springcloud/"},{"categories":["SpringCloud"],"content":"学习资料 Spring Cloud中文网 Spring-cloud 教程 [Spring Cloud Gateway 原理介绍和应用 ](https://tech.yangqianguan.com/60e27b0e2078082a378ec5ed/ ","date":"2020-04-02","objectID":"/springcloud/:9:0","tags":["SpringCloud","大纲"],"title":"Spring Cloud","uri":"/springcloud/"},{"categories":["Dubbo"],"content":"Dubbo总结","date":"2020-04-01","objectID":"/dubbo/","tags":["Dubbo","大纲"],"title":"Dubbo总结","uri":"/dubbo/"},{"categories":["Dubbo"],"content":" Apache Dubbo 是一款微服务开发框架，它提供了 RPC通信 与 微服务治理 两大关键能力。这意味着，使用 Dubbo 开发的微服务，将具备相互之间的远程发现与通信能力， 同时利用 Dubbo 提供的丰富服务治理能力，可以实现诸如服务发现、负载均衡、流量调度等服务治理诉求。同时 Dubbo 是高度可扩展的，用户几乎可以在任意功能点去定制自己的实现，以改变框架的默认行为来满足自己的业务需求。 服务是 Dubbo 中的核心概念，一个服务代表一组 RPC 方法的集合，服务是面向用户编程、服务发现机制等的基本单位。 Dubbo 开发的基本流程是：用户定义 RPC 服务，通过约定的配置 方式将 RPC 声明为 Dubbo 服务，然后就可以基于服务 API 进行编程了。对服务提供者来说是提供 RPC 服务的具体实现，而对服务消费者来说则是使用特定数据发起服务调用。 ","date":"2020-04-01","objectID":"/dubbo/:0:0","tags":["Dubbo","大纲"],"title":"Dubbo总结","uri":"/dubbo/"},{"categories":["Dubbo"],"content":"服务发现 服务发现，即消费端自动发现服务地址列表的能力，是微服务框架需要具备的关键能力，借助于自动化的服务发现，微服务之间可以在无需感知对端部署位置与 IP 地址的情况下实现通信。 实现服务发现的方式有很多种，Dubbo 提供的是一种 Client-Based 的服务发现机制，通常还需要部署额外的第三方注册中心组件来协调服务发现过程，如常用的 Nacos、Consul、Zookeeper 等，Dubbo 自身也提供了对多种注册中心组件的对接，用户可以灵活选择。 服务发现\" 服务发现 服务发现的一个核心组件是注册中心，Provider 注册地址到注册中心，Consumer 从注册中心读取和订阅 Provider 地址列表。 因此，要启用服务发现，需要为 Dubbo 增加注册中心配置： 以 dubbo-spring-boot-starter 使用方式为例，增加 registry 配置 # application.propertiesdubboregistryaddress:zookeeper://127.0.0.1:2181 ","date":"2020-04-01","objectID":"/dubbo/:1:0","tags":["Dubbo","大纲"],"title":"Dubbo总结","uri":"/dubbo/"},{"categories":["Dubbo"],"content":"服务流量管理 流量管理的本质是将请求根据制定好的路由规则分发到应用服务上，如下图所示： 流量管理\" 流量管理 Dubbo提供了支持mesh方式的流量管理策略，可以很容易实现 A/B测试、金丝雀发布、蓝绿发布等能力。 Dubbo将整个流量管理分成VirtualService和DestinationRule两部分。当Consumer接收到一个请求时，会根据VirtualService中定义的DubboRoute和DubboRouteDetail匹配到对应的DubboDestination中的subnet，最后根据DestinationRule中配置的subnet信息中的labels找到对应需要具体路由的Provider集群。其中： VirtualService主要处理入站流量分流的规则，支持服务级别和方法级别的分流。 DubboRoute主要解决服务级别的分流问题。同时，还提供的重试机制、超时、故障注入、镜像流量等能力。 DubboRouteDetail主要解决某个服务中方法级别的分流问题。支持方法名、方法参数、参数个数、参数类型、header等各种维度的分流能力。同时也支持方法级的重试机制、超时、故障注入、镜像流量等能力。 DubboDestination用来描述路由流量的目标地址，支持host、port、subnet等方式。 DestinationRule主要处理目标地址规则，可以通过hosts、subnet等方式关联到Provider集群。同时可以通过trafficPolicy来实现负载均衡。 这种设计理念很好的解决流量分流和目标地址之间的耦合问题。不仅将配置规则进行了简化有效避免配置冗余的问题，还支持VirtualService和DestinationRule的任意组合，可以非常灵活的支持各种业务使用场景。 ","date":"2020-04-01","objectID":"/dubbo/:2:0","tags":["Dubbo","大纲"],"title":"Dubbo总结","uri":"/dubbo/"},{"categories":["Dubbo"],"content":"参考文章 Dubbo 文档 一文带你搞懂RPC核心原理 Dubbo技术详细介绍 Dubbo技术详细介绍 ","date":"2020-04-01","objectID":"/dubbo/:3:0","tags":["Dubbo","大纲"],"title":"Dubbo总结","uri":"/dubbo/"},{"categories":["高并发"],"content":"高并发和分布式中的幂等处理","date":"2020-03-01","objectID":"/idempotence/","tags":["高并发"],"title":"幂等","uri":"/idempotence/"},{"categories":["高并发"],"content":" 幂等就是：一个操作不论执行多少次，产生的效果和返回的结果都是一样的。 ","date":"2020-03-01","objectID":"/idempotence/:0:0","tags":["高并发"],"title":"幂等","uri":"/idempotence/"},{"categories":["高并发"],"content":"业务场景 ","date":"2020-03-01","objectID":"/idempotence/:1:0","tags":["高并发"],"title":"幂等","uri":"/idempotence/"},{"categories":["高并发"],"content":"查询操作 查询一次和查询多次，在数据不变的情况下，查询结果是一样的。select是天然的幂等操作。 ","date":"2020-03-01","objectID":"/idempotence/:1:1","tags":["高并发"],"title":"幂等","uri":"/idempotence/"},{"categories":["高并发"],"content":"删除操作 删除操作也是幂等的，删除一次和多次删除都是把数据删除。(注意可能返回结果不一样，删除的数据不存在，返回0，删除的数据多条，返回结果多个) ","date":"2020-03-01","objectID":"/idempotence/:1:2","tags":["高并发"],"title":"幂等","uri":"/idempotence/"},{"categories":["高并发"],"content":"新增操作 唯一索引或唯一组合索引来防止新增数据存在脏数据（当表存在唯一索引，并发时新增报错时，再查询一次就可以了，数据应该已经存在了，返回结果即可） ","date":"2020-03-01","objectID":"/idempotence/:1:3","tags":["高并发"],"title":"幂等","uri":"/idempotence/"},{"categories":["高并发"],"content":"防止页面重复提交（token机制） 业务要求：页面的数据只能被点击提交一次 发生原因：由于重复点击或者网络重发，或者nginx重发等情况会导致数据被重复提交 处理流程： 用户访问页面时，浏览器自动发起获取token请求。 服务端生成token，保存到redis中，然后返回给浏览器。 用户通过浏览器发起请求时，携带该token。 在redis中查询该token是否存在，如果不存在，说明是第一次请求，做则后续的数据操作。 如果存在，说明是重复请求，则直接返回成功。 在redis中token会在过期时间之后，被自动删除。 解决办法： 集群环境：采用token加redis（redis单线程的，处理需要排队） 单JVM环境：采用token加redis或token加jvm内存 token特点：要申请，一次有效性，可以限流。 redis要用删除操作来判断token，删除成功代表token校验通过，如果用select+delete来校验token，存在并发问题，不建议使用。 ","date":"2020-03-01","objectID":"/idempotence/:1:4","tags":["高并发"],"title":"幂等","uri":"/idempotence/"},{"categories":["高并发"],"content":"对外提供接口的api保证幂等 如银联提供的付款接口：需要接入商户提交付款请求时附带：source来源，seq序列号，source+seq在数据库里面做唯一索引，防止多次付款，(并发时，只能处理一个请求)。 对外提供接口为了支持幂等调用，接口有两个字段必须传，一个是来源source，一个是来源方序列号seq，这个两个字段在服务提供方系统里面做联合唯一索引，这样当第三方调用时，先在本方系统里面查询一下，是否已经处理过，返回相应处理结果；没有处理过，进行相应处理，返回结果。注意，为了幂等友好，一定要先查询一下，是否处理过该笔业务，不查询直接插入业务系统，会报错，但实际已经处理了。 ","date":"2020-03-01","objectID":"/idempotence/:1:5","tags":["高并发"],"title":"幂等","uri":"/idempotence/"},{"categories":["高并发"],"content":"解决方案 ","date":"2020-03-01","objectID":"/idempotence/:2:0","tags":["高并发"],"title":"幂等","uri":"/idempotence/"},{"categories":["高并发"],"content":"悲观锁 获取数据的时候加锁获取 select * from table_xxx where id='xxx' for update; 注意：id字段一定是主键或者唯一索引，不然是锁表，会死人的，悲观锁使用时一般伴随事务一起使用，数据锁定时间可能会很长，根据实际情况选用。 ","date":"2020-03-01","objectID":"/idempotence/:2:1","tags":["高并发"],"title":"幂等","uri":"/idempotence/"},{"categories":["高并发"],"content":"乐观锁 乐观锁只是在更新数据那一刻锁表，其他时间不锁表，所以相对于悲观锁，效率更高。 乐观锁的实现方式多种多样可以通过version或者其他状态条件： 通过版本号实现 update table_xxx set name=#name#,version=version+1 where version=#version#; -- 优化后的 update table_xxx set name=#name#,version=version+1 where id=#id# and version=#version#; 通过条件限制 update table_xxx set avai_amount=avai_amount-#subAmount# where avai_amount-#subAmount# \u003e= 0; -- 优化后的 update table_xxx set avai_amount=avai_amount-#subAmount# where id=#id# and avai_amount-#subAmount# \u003e= 0 要求：quality-#subQuality# \u003e= ，这个情景适合不用版本号，只更新是做数据安全校验，适合库存模型，扣份额和回滚份额，性能更高 注意：乐观锁的更新操作，最好用主键或者唯一索引来更新,这样是行锁，否则更新时会锁表，上面两个sql改成下面优化后的 ","date":"2020-03-01","objectID":"/idempotence/:2:2","tags":["高并发"],"title":"幂等","uri":"/idempotence/"},{"categories":["高并发"],"content":"分布式锁 其实前面介绍过的加唯一索引或者加防重表，本质是使用了数据库的分布式锁，也属于分布式锁的一种。但由于数据库分布式锁的性能不太好，我们可以改用：redis或zookeeper。 拿插入数据的例子，如果是分布是系统，构建全局唯一索引比较困难，例如唯一性的字段没法确定，这时候可以引入分布式锁，通过第三方的系统(redis或zookeeper)，在业务系统插入数据或者更新数据，获取分布式锁，然后做操作，之后释放锁，这样其实是把多线程并发的锁的思路，引入多多个系统，也就是分布式系统中得解决思路。 要点：某个长流程处理过程要求不能并发执行，可以在流程执行之前根据某个标志(用户ID+后缀等)获取分布式锁，其他流程执行时获取锁就会失败，也就是同一时间该流程只能有一个能执行成功，执行完成后，释放分布式锁(分布式锁要第三方系统提供) ","date":"2020-03-01","objectID":"/idempotence/:2:3","tags":["高并发"],"title":"幂等","uri":"/idempotence/"},{"categories":["高并发"],"content":"select + insert 并发不高的后台系统，或者一些任务JOB，为了支持幂等，支持重复执行，简单的处理方法是，先查询下一些关键数据，判断是否已经执行过，没有查询到再进行业务处理，核心高并发流程不要用这种方法。 ","date":"2020-03-01","objectID":"/idempotence/:2:4","tags":["高并发"],"title":"幂等","uri":"/idempotence/"},{"categories":["高并发"],"content":"状态机幂等 在设计单据相关的业务，或者是任务相关的业务，肯定会涉及到状态机(状态变更图)，就是业务单据上面有个状态，状态在不同的情况下会发生变更，一般情况下存在有限状态机，这时候，如果状态机已经处于下一个状态，这时候来了一个上一个状态的变更，理论上是不能够变更的，这样的话，保证了有限状态机的幂等。 ","date":"2020-03-01","objectID":"/idempotence/:2:5","tags":["高并发"],"title":"幂等","uri":"/idempotence/"},{"categories":["分布式"],"content":"分布式ID","date":"2020-02-06","objectID":"/distributedid/","tags":["分布式"],"title":"分布式ID","uri":"/distributedid/"},{"categories":["分布式"],"content":" 在复杂分布式系统中，往往需要对大量的数据和消息进行唯一标识。 概括下来，那业务系统对ID号的要求有哪些呢？ 全局唯一：不能出现重复的ID号，既然是唯一标识，这是最基本的要求。 趋势递增：在MySQL InnoDB引擎中使用的是聚集索引，由于多数RDBMS使用B-tree的数据结构来存储索引数据，在主键的选择上面我们应该尽量使用有序的主键保证写入性能。 单调递增：保证下一个ID一定大于上一个ID，例如事务版本号、IM增量消息、排序等特殊需求。 信息安全：如果ID是连续的，恶意用户的扒取工作就非常容易做了，直接按照顺序下载指定URL即可；如果是订单号就更危险了，竞对可以直接知道我们一天的单量。所以在一些应用场景下，会需要ID无规则、不规则。 高可用：平均延迟和TP999延迟都要尽可能低；可用性5个9； 高QPS。 ","date":"2020-02-06","objectID":"/distributedid/:0:0","tags":["分布式"],"title":"分布式ID","uri":"/distributedid/"},{"categories":["分布式"],"content":"UUID UUID是通用唯一识别码（Universally Unique Identifier)的缩写，开放软件基金会(OSF)规范定义了包括网卡MAC地址、时间戳、名字空间（Namespace）、随机或伪随机数、时序等元素。利用这些元素来生成UUID。 UUID是由128位二进制组成，一般转换成十六进制，然后用String表示。在java中有个UUID类,在他的注释中我们看见这里有4种不同的UUID的生成策略: randomly 基于随机数生成UUID，由于Java中的随机数是伪随机数，其重复的概率是可以被计算出来的。这个一般我们用下面的代码获取基于随机数的UUID: time-based 基于时间的UUID,这个一般是通过当前时间，随机数，和本地Mac地址来计算出来，自带的JDK包并没有这个算法的我们在一些UUIDUtil中，比如我们的log4j.core.util，会重新定义UUID的高位和低位。 DCE security:DCE安全的UUID。 name-based：基于名字的UUID，通过计算名字和名字空间的MD5来计算UUID。 ","date":"2020-02-06","objectID":"/distributedid/:1:0","tags":["分布式"],"title":"分布式ID","uri":"/distributedid/"},{"categories":["分布式"],"content":"UUID的优点 通过本地生成，没有经过网络I/O，性能较快 无序，无法预测他的生成顺序。(当然这个也是他的缺点之一) ","date":"2020-02-06","objectID":"/distributedid/:1:1","tags":["分布式"],"title":"分布式ID","uri":"/distributedid/"},{"categories":["分布式"],"content":"UUID的缺点 128位二进制一般转换成36位的16进制，太长了只能用String存储，空间占用较多。 不能生成递增有序的数字 ","date":"2020-02-06","objectID":"/distributedid/:1:2","tags":["分布式"],"title":"分布式ID","uri":"/distributedid/"},{"categories":["分布式"],"content":"适用场景 UUID的适用场景为不担心过多的空间占用，以及不需要生成有递增趋势的数字。在Log4j里面他在UuidPatternConverter中加入了UUID来标识每一条日志。 ","date":"2020-02-06","objectID":"/distributedid/:1:3","tags":["分布式"],"title":"分布式ID","uri":"/distributedid/"},{"categories":["分布式"],"content":"数据库主键自增 大家对于唯一标识最容易想到的就是主键自增，这个也是我们最常用的方法。例如我们有个订单服务，那么把订单id设置为主键自增即可。 ","date":"2020-02-06","objectID":"/distributedid/:2:0","tags":["分布式"],"title":"分布式ID","uri":"/distributedid/"},{"categories":["分布式"],"content":"优点 简单方便，有序递增，方便排序和分页 ","date":"2020-02-06","objectID":"/distributedid/:2:1","tags":["分布式"],"title":"分布式ID","uri":"/distributedid/"},{"categories":["分布式"],"content":"缺点 分库分表会带来问题，需要进行改造。 并发性能不高，受限于数据库的性能。 简单递增容易被其他人猜测利用，比如你有一个用户服务用的递增，那么其他人可以根据分析注册的用户ID来得到当天你的服务有多少人注册，从而就能猜测出你这个服务当前的一个大概状况。 数据库宕机服务不可用。 ","date":"2020-02-06","objectID":"/distributedid/:2:2","tags":["分布式"],"title":"分布式ID","uri":"/distributedid/"},{"categories":["分布式"],"content":"适用场景 根据上面可以总结出来，当数据量不多，并发性能不高的时候这个很适合，比如一些to B的业务，商家注册这些，商家注册和用户注册不是一个数量级的，所以可以数据库主键递增。如果对顺序递增强依赖，那么也可以使用数据库主键自增。 ","date":"2020-02-06","objectID":"/distributedid/:2:3","tags":["分布式"],"title":"分布式ID","uri":"/distributedid/"},{"categories":["分布式"],"content":"Redis Redis中有两个命令Incr，IncrBy,因为Redis是单线程的所以能保证原子性。 ","date":"2020-02-06","objectID":"/distributedid/:3:0","tags":["分布式"],"title":"分布式ID","uri":"/distributedid/"},{"categories":["分布式"],"content":"优点 性能比数据库好，能满足有序递增。 ","date":"2020-02-06","objectID":"/distributedid/:3:1","tags":["分布式"],"title":"分布式ID","uri":"/distributedid/"},{"categories":["分布式"],"content":"缺点 由于redis是内存的KV数据库，即使有AOF和RDB，但是依然会存在数据丢失，有可能会造成ID重复。 依赖于redis，redis要是不稳定，会影响ID生成。 ","date":"2020-02-06","objectID":"/distributedid/:3:2","tags":["分布式"],"title":"分布式ID","uri":"/distributedid/"},{"categories":["分布式"],"content":"适用 由于其性能比数据库好，但是有可能会出现ID重复和不稳定，这一块如果可以接受那么就可以使用。也适用于到了某个时间，比如每天都刷新ID，那么这个ID就需要重置，通过(Incr Today)，每天都会从0开始加。 ","date":"2020-02-06","objectID":"/distributedid/:3:3","tags":["分布式"],"title":"分布式ID","uri":"/distributedid/"},{"categories":["分布式"],"content":"雪花算法-Snowflake Snowflake是Twitter提出来的一个算法，其目的是生成一个64bit的整数 Snowflake\" Snowflake 1bit:一般是符号位，不做处理 41bit:用来记录时间戳，这里可以记录69年，如果设置好起始时间比如今年是2018年，那么可以用到2089年，到时候怎么办？要是这个系统能用69年，我相信这个系统早都重构了好多次了。 10bit:10bit用来记录机器ID，总共可以记录1024台机器，一般用前5位代表数据中心，后面5位是某个数据中心的机器ID 12bit:循环位，用来对同一个毫秒之内产生不同的ID，12位可以最多记录4095个，也就是在同一个机器同一毫秒最多记录4095个，多余的需要进行等待下毫秒。 上面只是一个将64bit划分的标准，当然也不一定这么做，可以根据不同业务的具体场景来划分，比如下面给出一个业务场景： 服务目前QPS10万，预计几年之内会发展到百万。 当前机器三地部署，上海，北京，深圳都有。 当前机器10台左右，预计未来会增加至百台。 这个时候我们根据上面的场景可以再次合理的划分62bit,QPS几年之内会发展到百万，那么每毫秒就是千级的请求，目前10台机器那么每台机器承担百级的请求，为了保证扩展，后面的循环位可以限制到1024，也就是2^10，那么循环位10位就足够了。 机器三地部署我们可以用3bit总共8来表示机房位置，当前的机器10台，为了保证扩展到百台那么可以用7bit 128来表示，时间位依然是41bit,那么还剩下64-10-3-7-41-1 = 2bit,还剩下2bit可以用来进行扩展。 ","date":"2020-02-06","objectID":"/distributedid/:4:0","tags":["分布式"],"title":"分布式ID","uri":"/distributedid/"},{"categories":["分布式"],"content":"适用场景 当我们需要无序不能被猜测的ID，并且需要一定高性能，且需要long型，那么就可以使用我们雪花算法。比如常见的订单ID，用雪花算法别人就发猜测你每天的订单量是多少。 ","date":"2020-02-06","objectID":"/distributedid/:4:1","tags":["分布式"],"title":"分布式ID","uri":"/distributedid/"},{"categories":["分布式"],"content":"一个简单的Snowflake public class IdWorker{ private long workerId; private long datacenterId; private long sequence = 0; /** * 2018/9/29日，从此时开始计算，可以用到2089年 */ private long twepoch = 1538211907857L; private long workerIdBits = 5L; private long datacenterIdBits = 5L; private long sequenceBits = 12L; private long workerIdShift = sequenceBits; private long datacenterIdShift = sequenceBits + workerIdBits; private long timestampLeftShift = sequenceBits + workerIdBits + datacenterIdBits; // 得到0000000000000000000000000000000000000000000000000000111111111111 private long sequenceMask = -1L ^ (-1L \u003c\u003c sequenceBits); private long lastTimestamp = -1L; public IdWorker(long workerId, long datacenterId){ this.workerId = workerId; this.datacenterId = datacenterId; } public synchronized long nextId() { long timestamp = timeGen(); //时间回拨，抛出异常 if (timestamp \u003c lastTimestamp) { System.err.printf(\"clock is moving backwards. Rejecting requests until %d.\", lastTimestamp); throw new RuntimeException(String.format(\"Clock moved backwards. Refusing to generate id for %d milliseconds\", lastTimestamp - timestamp)); } if (lastTimestamp == timestamp) { sequence = (sequence + 1) \u0026 sequenceMask; if (sequence == 0) { timestamp = tilNextMillis(lastTimestamp); } } else { sequence = 0; } lastTimestamp = timestamp; return ((timestamp - twepoch) \u003c\u003c timestampLeftShift) | (datacenterId \u003c\u003c datacenterIdShift) | (workerId \u003c\u003c workerIdShift) | sequence; } /** * 当前ms已经满了 * @param lastTimestamp * @return */ private long tilNextMillis(long lastTimestamp) { long timestamp = timeGen(); while (timestamp \u003c= lastTimestamp) { timestamp = timeGen(); } return timestamp; } private long timeGen(){ return System.currentTimeMillis(); } public static void main(String[] args) { IdWorker worker = new IdWorker(1,1); for (int i = 0; i \u003c 30; i++) { System.out.println(worker.nextId()); } } } ","date":"2020-02-06","objectID":"/distributedid/:4:2","tags":["分布式"],"title":"分布式ID","uri":"/distributedid/"},{"categories":["分布式"],"content":"防止时钟回拨 因为机器的原因会发生时间回拨，我们的雪花算法是强依赖我们的时间的，如果时间发生回拨，有可能会生成重复的ID，在我们上面的nextId中我们用当前时间和上一次的时间进行判断，如果当前时间小于上一次的时间那么肯定是发生了回拨，普通的算法会直接抛出异常,这里我们可以对其进行优化,一般分为两个情况: 如果时间回拨时间较短，比如配置5ms以内，那么可以直接等待一定的时间，让机器的时间追上来。 如果时间的回拨时间较长，我们不能接受这么长的阻塞等待，那么又有两个策略: 直接拒绝，抛出异常，打日志，通知RD时钟回滚。 利用扩展位，上面我们讨论过不同业务场景位数可能用不到那么多，那么我们可以把扩展位数利用起来了，比如当这个时间回拨比较长的时候，我们可以不需要等待，直接在扩展位加1。2位的扩展位允许我们有3次大的时钟回拨，一般来说就够了，如果其超过三次我们还是选择抛出异常，打日志。 通过上面的几种策略可以比较的防护我们的时钟回拨，防止出现回拨之后大量的异常出现。下面是修改之后的代码，这里修改了时钟回拨的逻辑: snowID改进\" snowID改进 ","date":"2020-02-06","objectID":"/distributedid/:4:3","tags":["分布式"],"title":"分布式ID","uri":"/distributedid/"},{"categories":["分布式"],"content":"Leaf——美团点评分布式ID生成系统 Leaf——美团点评分布式ID生成系统 ","date":"2020-02-06","objectID":"/distributedid/:5:0","tags":["分布式"],"title":"分布式ID","uri":"/distributedid/"},{"categories":["分布式"],"content":"参考文章 分布式ID ","date":"2020-02-06","objectID":"/distributedid/:6:0","tags":["分布式"],"title":"分布式ID","uri":"/distributedid/"},{"categories":["分布式"],"content":"分布式事务","date":"2020-02-05","objectID":"/distributedtransaction/","tags":["分布式"],"title":"分布式事务","uri":"/distributedtransaction/"},{"categories":["分布式"],"content":"数据库事务-本地事务 传统的单服务器，单关系型数据库下的事务，就是本地事务。本地事务由资源管理器管理，JDBC事务就是一个非常典型的本地事务。 ","date":"2020-02-05","objectID":"/distributedtransaction/:1:0","tags":["分布式"],"title":"分布式事务","uri":"/distributedtransaction/"},{"categories":["分布式"],"content":"事务ACID特性的实现思想 原子性：是使用 undo log来实现的，如果事务执行过程中出错或者用户执行了rollback，系统通过undo log日志返回事务开始的状态。 持久性：使用 redo log来实现，只要redo log日志持久化了，当系统崩溃，即可通过redo log把数据恢复。 隔离性：通过锁以及MVCC,使事务相互隔离开。 一致性：通过回滚、恢复，以及并发情况下的隔离性，从而实现一致性。 ","date":"2020-02-05","objectID":"/distributedtransaction/:1:1","tags":["分布式"],"title":"分布式事务","uri":"/distributedtransaction/"},{"categories":["分布式"],"content":"分布式事务 分布式事务是指事务的参与者、支持事务的服务器、资源服务器以及事务管理器分别位于不同的分布式系统的不同节点之上。 ","date":"2020-02-05","objectID":"/distributedtransaction/:2:0","tags":["分布式"],"title":"分布式事务","uri":"/distributedtransaction/"},{"categories":["分布式"],"content":"微服务架构下的分布式事务 用户下单购买礼物，礼物数据库、金币数据库、订单数据库在不同节点上，用本地事务是不可以的，那么如何保证不同数据库（节点）上的数据一致性呢？这就需要分布式事务啦 ","date":"2020-02-05","objectID":"/distributedtransaction/:2:1","tags":["分布式"],"title":"分布式事务","uri":"/distributedtransaction/"},{"categories":["分布式"],"content":"分库分表下的分布式事务 随着业务的发展，数据库的数据日益庞大，超过千万级别的数据，我们就需要对它分库分表（以前公司是用mycat分库分表，后来用sharding-jdbc）。一分库，数据又分布在不同节点上啦，比如有的在深圳机房，有的在北京机房~你再想用本地事务去保证，已经无动于衷啦~还是需要分布式事务啦。 比如A转10块给B，A的账户数据是在北京机房，B的账户数据是在深圳机房。流程如下： ","date":"2020-02-05","objectID":"/distributedtransaction/:2:2","tags":["分布式"],"title":"分布式事务","uri":"/distributedtransaction/"},{"categories":["分布式"],"content":"分布式事务理论（CAP和BASE） 如果说到事务，ACID是传统数据库常用的设计理念，追求强一致性模型，关系数据库的ACID模型拥有高一致性+可用性，所以很难进行分区，所以在微服务中ACID已经是无法支持，我们还是回到CAP去寻求解决方案，不过根据上面的讨论，CAP定理中，要么只能CP，要么只能AP，如果我们追求数据的一致性而忽略可用性这个在微服务中肯定是行不通的，如果我们追求可用性而忽略一致性，那么在一些重要的数据（例如支付，金额）肯定出现漏洞百出，这个也是无法接受。所以我们既要一致性，也要可用性。 都要是无法实现的，但我们能不能在一致性上作出一些妥协，不追求强一致性，转而追求最终一致性，所以引入BASE理论，在分布式事务中，BASE最重要是为CAP提出了最终一致性的解决方案，BASE强调牺牲高一致性，从而获取肯用性，数据允许在一段时间内不一致，只要保证最终一致性就可以了。 这就是分布式事务等理论基础，即实现最终一致性。 ","date":"2020-02-05","objectID":"/distributedtransaction/:3:0","tags":["分布式"],"title":"分布式事务","uri":"/distributedtransaction/"},{"categories":["分布式"],"content":"分布式事务的几种解决方案 ","date":"2020-02-05","objectID":"/distributedtransaction/:4:0","tags":["分布式"],"title":"分布式事务","uri":"/distributedtransaction/"},{"categories":["分布式"],"content":"2PC(二阶段提交)方案/XA 事务的提交分为两个阶段：准备阶段和提交执行方案。 二阶段提交成功的情况 准备阶段，事务管理器向每个资源管理器发送准备消息，如果资源管理器的本地事务操作执行成功，则返回成功。 提交执行阶段，如果事务管理器收到了所有资源管理器回复的成功消息，则向每个资源管理器发送提交消息，RM 根据 TM 的指令执行提交。 二阶段提交失败的情况 准备阶段，事务管理器向每个资源管理器发送准备消息，如果资源管理器的本地事务操作执行成功，则返回成功，如果执行失败，则返回失败。 提交执行阶段，如果事务管理器收到了任何一个资源管理器失败的消息，则向每个资源管理器发送回滚消息。资源管理器根据事务管理器的指令回滚本地事务操作，释放所有事务处理过程中使用的锁资源。 ","date":"2020-02-05","objectID":"/distributedtransaction/:4:1","tags":["分布式"],"title":"分布式事务","uri":"/distributedtransaction/"},{"categories":["分布式"],"content":"二阶段提交优缺点 单点问题：如果事务管理器出现故障，资源管理器将一直处于锁定状态。 性能问题：所有资源管理器在事务提交阶段处于同步阻塞状态，占用系统资源，一直到提交完成，才释放资源，容易导致性能瓶颈。 数据一致性问题：如果有的资源管理器收到提交的消息，有的没收到，那么会导致数据不一致问题。 ","date":"2020-02-05","objectID":"/distributedtransaction/:4:2","tags":["分布式"],"title":"分布式事务","uri":"/distributedtransaction/"},{"categories":["分布式"],"content":"TCC（Try、Confirm、Cancel） TCC 采用了补偿机制，其核心思想是：针对每个操作，都要注册一个与其对应的确认和补偿（撤销）操作。 TCC（Try-Confirm-Cancel）模型 TCC（Try-Confirm-Cancel）是通过对业务逻辑的分解来实现分布式事务。针对一个具体的业务服务，TCC 分布式事务模型需要业务系统都实现一下三段逻辑： try阶段： 尝试去执行，完成所有业务的一致性检查，预留必须的业务资源。 Confirm阶段： 该阶段对业务进行确认提交，不做任何检查，因为try阶段已经检查过了，默认Confirm阶段是不会出错的。 Cancel 阶段： 若业务执行失败，则进入该阶段，它会释放try阶段占用的所有业务资源，并回滚Confirm阶段执行的所有操作。 TCC优缺点 TCC方案让应用可以自定义数据库操作的粒度，降低了锁冲突，可以提升性能，但是也有以下缺点： 应用侵入性强，try、confirm、cancel三个阶段都需要业务逻辑实现。 需要根据网络、系统故障等不同失败原因实现不同的回滚策略，实现难度大，一般借助TCC开源框架，ByteTCC，TCC-transaction，Himly。 在 Try 阶段，是对业务系统进行检查及资源预览，比如订单和存储操作，需要检查库存剩余数量是否够用，并进行预留，预留操作的话就是新建一个可用库存数量字段，Try 阶段操作是对这个可用库存数量进行操作。 基于 TCC 实现分布式事务，会将原来只需要一个接口就可以实现的逻辑拆分为 Try、Confirm、Cancel 三个接口，所以代码实现复杂度相对较高。 TCC 需要事务接口提供 try, confirm, cancel 三个接口，提高了编程的复杂性。依赖于业务方来配合提供这样的接口，推行难度大，所以一般不推荐使用这种方式。 ","date":"2020-02-05","objectID":"/distributedtransaction/:4:3","tags":["分布式"],"title":"分布式事务","uri":"/distributedtransaction/"},{"categories":["分布式"],"content":"本地消息表 核心思想就是将分布式事务拆分成本地事务进行处理 当系统 A 被其他系统调用发生数据库表更操作，首先会更新数据库的业务表，其次会往相同数据库的消息表中插入一条数据，两个操作发生在同一个事务中 系统 A 的脚本定期轮询本地消息往 mq 中写入一条消息，如果消息发送失败会进行重试 系统 B 消费 mq 中的消息，并处理业务逻辑。如果本地事务处理失败，会在继续消费 mq 中的消息进行重试，如果业务上的失败，可以通知系统 A 进行回滚操作 本地消息表实现的条件： 消费者与生成者的接口都要支持幂等 生产者需要额外的创建消息表 需要提供补偿逻辑，如果消费者业务失败，需要生产者支持回滚操作 容错机制： 步骤 1 失败时，事务直接回滚 步骤 2、3 写 mq 与消费 mq 失败会进行重试 步骤 3 业务失败系统 B 向系统 A 发起事务回滚操作 此方案的核心是将需要分布式处理的任务通过消息日志的方式来异步执行。消息日志可以存储到本地文本、数据库或消息队列，再通过业务规则自动或人工发起重试。人工重试更多的是应用于支付场景，通过对账系统对事后问题的处理。 实际方案 跨行转账可通过该方案实现。 用户 A 向用户 B 发起转账，首先系统会扣掉用户 A 账户中的金额，将该转账消息写入消息表中，如果事务执行失败则转账失败，如果转账成功，系统中会有定时轮询消息表，往 mq 中写入转账消息，失败重试。mq 消息会被实时消费并往用户 B 中账户增加转账金额，执行失败会不断重试。 ","date":"2020-02-05","objectID":"/distributedtransaction/:4:4","tags":["分布式"],"title":"分布式事务","uri":"/distributedtransaction/"},{"categories":["分布式"],"content":"最大努力通知 最大努力通知是最简单的一种柔性事务，适用于一些最终一致性时间敏感度低的业务，且被动方处理结果 不影响主动方的处理结果。 方案流程 系统 A 本地事务执行完之后，发送个消息到 MQ； 这里会有个专门消费 MQ 的服务，这个服务会消费 MQ 并调用系统 B 的接口； 要是系统 B 执行成功就 ok 了；要是系统 B 执行失败了，那么最大努力通知服务就定时尝试重新调用系统 B, 反复 N 次，最后还是不行就放弃。 实际方案 最大努力通知最常见的场景就是支付回调，支付服务收到第三方服务支付成功通知后，先更新自己库中订单支付状态，然后同步通知订单服务支付成功。如果此次同步通知失败，会通过异步脚步不断重试地调用订单服务的接口。 ","date":"2020-02-05","objectID":"/distributedtransaction/:4:5","tags":["分布式"],"title":"分布式事务","uri":"/distributedtransaction/"},{"categories":["分布式"],"content":"可靠消息最终一致性 大致流程如下： 可靠消息最终一致性\" 可靠消息最终一致性 A 系统先向 mq 发送一条 prepare 消息，如果 prepare 消息发送失败，则直接取消操作 如果消息发送成功，则执行本地事务 如果本地事务执行成功，则想 mq 发送一条 confirm 消息，如果发送失败，则发送回滚消息 B 系统定期消费 mq 中的 confirm 消息，执行本地事务，并发送 ack 消息。如果 B 系统中的本地事务失败，会一直不断重试，如果是业务失败，会向 A 系统发起回滚请求 mq 会定期轮询所有 prepared 消息调用系统 A 提供的接口查询消息的处理情况，如果该 prepare 消息本地事务处理成功，则重新发送 confirm 消息，否则直接回滚该消息 该方案与本地消息最大的不同是去掉了本地消息表，其次本地消息表依赖消息表重试写入 mq 这一步由本方案中的轮询 prepare 消息状态来重试或者回滚该消息替代。其实现条件与余容错方案基本一致。目前市面上实现该方案的只有阿里的 RocketMq。 实际方案 目前市面上支持该方案的 mq 只有阿里的 rocketmq, 该方案应用场景也比较多，比如用户注册成功后发送邮件、电商系统给用户发送优惠券等需要保证最终一致性的场景 ","date":"2020-02-05","objectID":"/distributedtransaction/:4:6","tags":["分布式"],"title":"分布式事务","uri":"/distributedtransaction/"},{"categories":["分布式"],"content":"Saga事务 核心思想是将长事务拆分为多个本地短事务，由Saga事务协调器协调，如果正常结束那就正常完成，如果某个步骤失败，则根据相反顺序一次调用补偿操作。 分布式事务方案 - SAGA模式 ","date":"2020-02-05","objectID":"/distributedtransaction/:4:7","tags":["分布式"],"title":"分布式事务","uri":"/distributedtransaction/"},{"categories":["分布式"],"content":"参考文章 分布式事务，这一篇就够了 详解分布式事务 分布式事务基础篇 蚂蚁金服分布式事务实践解析 ","date":"2020-02-05","objectID":"/distributedtransaction/:5:0","tags":["分布式"],"title":"分布式事务","uri":"/distributedtransaction/"},{"categories":["分布式"],"content":"分布式锁","date":"2020-02-04","objectID":"/distributedlock/","tags":["分布式"],"title":"分布式锁","uri":"/distributedlock/"},{"categories":["分布式"],"content":"基于数据库 基于数据库表数据记录做唯一约束 上面这种简单的实现有以下几个问题： 这把锁强依赖数据库的可用性，数据库是一个单点，一旦数据库挂掉，会导致业务系统不可用。 这把锁没有失效时间，一旦解锁操作失败，就会导致锁记录一直在数据库中，其他线程无法再获得到锁。 这把锁只能是非阻塞的，因为数据的insert操作，一旦插入失败就会直接报错。没有获得锁的线程并不会进入排队队列，要想再次获得锁就要再次触发获得锁操作。 这把锁是非重入的，同一个线程在没有释放锁之前无法再次获得该锁。因为数据中数据已经存在了。 不过这种方式对于单主却无法自动切换主从的mysql来说，基本就无法现实P分区容错性，（Mysql自动主从切换在目前并没有十分完美的解决方案）。可以说这种方式强依赖于数据库的可用性，数据库写操作是一个单点，一旦数据库挂掉，就导致锁的不可用。这种方式基本不在CAP的一个讨论范围。 ","date":"2020-02-04","objectID":"/distributedlock/:1:0","tags":["分布式"],"title":"分布式锁","uri":"/distributedlock/"},{"categories":["分布式"],"content":"基于Redis 使用redis的setNX()用于分布式锁。（原子性） setnx key value Expire_time 获取到锁 返回 1 ， 获取失败 返回 0 * 返回1，说明该进程获得锁，SETNX将键 lock.id 的值设置为锁的超时时间，当前时间 +加上锁的有效时间。 * 返回0，说明其他进程已经获得了锁，进程不能进入临界区。进程可以在一个循环中不断地尝试 SETNX 操作，以获得锁。 protected boolean getLock(String lockKey, int time,TimeUnit timeUnit) { // 使用redis的setNX命令实现分布式锁 boolean isSuccess = redisTemplate.opsForValue().setIfAbsent(lockKey, \"lock\"); // 防止进程中断导致redis分布锁死锁，检查是否设置了超时时间。 Long timeLeft = redisTemplate.getExpire(lockKey); if (isSuccess || timeLeft \u003c 0) { // 设置失效时间（最好与该任务执行频率时间一致）：如果执行期间宕机，5分钟后也能被另一机器获得lock redisTemplate.expire(lockKey, time, timeUnit); } return isSuccess; } 为了解决数据库锁的主从切换的问题，可以选择redis集群，或者是 sentinel 哨兵模式，实现主从故障转移，当master节点出现故障，哨兵会从slave中选取节点，重新变成新的master节点。 哨兵模式故障转移是由sentinel集群进行监控判断，当maser出现异常即复制中止，重新推选新slave成为master，sentinel在重新进行选举并不保证主从数据复制完毕具备一致性。 所以redis的复制模式是属于AP的模式。保证可用性，在主从复制中“主”有数据，但是可能“从”还没有数据，这个时候，一旦主挂掉或者网络抖动等各种原因，可能会切换到“从”节点，这个时候可能会导致两个业务县城同时获取得两把锁 能不能使用redis作为分布式锁，这个本身就不是redis的问题，还是取决于业务场景，我们先要自己确认我们的场景是适合 AP 还是 CP ， 如果在社交发帖等场景下，我们并没有非常强的事务一致性问题，redis提供给我们高性能的AP模型是非常适合的，但如果是交易类型，对数据一致性非常敏感的场景，我们可能要寻在一种更加适合的 CP 模型 ","date":"2020-02-04","objectID":"/distributedlock/:2:0","tags":["分布式"],"title":"分布式锁","uri":"/distributedlock/"},{"categories":["分布式"],"content":"Redis分布式锁如何续期，建议使用redisson客户端（可以自动续期） ","date":"2020-02-04","objectID":"/distributedlock/:2:1","tags":["分布式"],"title":"分布式锁","uri":"/distributedlock/"},{"categories":["分布式"],"content":"基于ZooKeeper 每个客户端对某个方法加锁时，在zookeeper上的与该方法对应的指定节点的目录下，生成一个唯一的临时有序节点。 判断是否获取锁的方式很简单，只需要判断有序节点中序号最小的一个。 当释放锁的时候，只需将这个临时节点删除即可。同时，排队的节点需要监听排在自己之前的节点，这样能在节点释放时候接收到回调通知，让其获得锁。zk的session由客户端管理，其可以避免服务宕机导致的锁无 法释放，而产生的死锁问题，不需要关注锁超时。 刚刚也分析过，redis其实无法确保数据的一致性，先来看ZooKeeper是否合适作为我们需要的分布式锁，首先zk的模式是CP模型，也就是说，当zk锁提供给我们进行访问的时候，在zk集群中能确保这把锁在zk的每一个节点都存在。 ","date":"2020-02-04","objectID":"/distributedlock/:3:0","tags":["分布式"],"title":"分布式锁","uri":"/distributedlock/"},{"categories":["分布式"],"content":"zk分布式锁的代码实现 zk官方提供的客户端并不支持分布式锁的直接实现，我们需要自己写代码去利用zk的这几个特性去进行实现。 zk分布式锁\" zk分布式锁 ","date":"2020-02-04","objectID":"/distributedlock/:3:1","tags":["分布式"],"title":"分布式锁","uri":"/distributedlock/"},{"categories":["分布式"],"content":"究竟该用CP还是AP的分布式锁 首先得了解清楚我们使用分布式锁的场景，为何使用分布式锁，用它来帮我们解决什么问题，先聊场景后聊分布式锁的技术选型。 无论是Redis，zk，例如Redis的AP模型会限制很多使用场景，但它却拥有了几者中最高的性能，ZooKeeper的分布式锁要比Redis可靠很多，但他繁琐的实现机制导致了它的性能不如Redis，而且zk会随着集群的扩大而性能更加下降。 ","date":"2020-02-04","objectID":"/distributedlock/:4:0","tags":["分布式"],"title":"分布式锁","uri":"/distributedlock/"},{"categories":["分布式"],"content":"参考文章 分布式锁，是选择AP还是选择CP 分布式锁总结 基于 Redis 的分布式锁 Redis分布式锁如何续期 分布式锁高并发优化实践 ","date":"2020-02-04","objectID":"/distributedlock/:5:0","tags":["分布式"],"title":"分布式锁","uri":"/distributedlock/"},{"categories":["分布式"],"content":"分布式基础介绍","date":"2020-02-03","objectID":"/distributed/","tags":["分布式","大纲"],"title":"分布式概览","uri":"/distributed/"},{"categories":["分布式"],"content":"分布式理论基础 ","date":"2020-02-03","objectID":"/distributed/:1:0","tags":["分布式","大纲"],"title":"分布式概览","uri":"/distributed/"},{"categories":["分布式"],"content":"CAP CAP 理论是分布式中基础理论，有三个重要指标：一致性、可用性、分区容错性。 一致性（Consistency）：一致性意思就是写操作之后进行读操作无论在哪个节点都需要返回写操作的值 可用性（Availability）：非故障的节点在合理的时间内返回合理的响应 分区容错性（Partition Tolerance）：当网络出现分区后，系统依然能够继续履行职责 在分布式的环境下，网络无法做到100%可靠，有可能出现故障，因此分区是一个必须的选项，如果选择了CA而放弃了P，若发生分区现象，为了保证C，系统需要禁止写入，此时就与A发生冲突，如果是为了保证A，则会出现正常的分区可以写入数据，有故障的分区不能写入数据，则与C就冲突了。因此分布式系统理论上不可能选择CA架构，而必须选择CP或AP架构。 ","date":"2020-02-03","objectID":"/distributed/:1:1","tags":["分布式","大纲"],"title":"分布式概览","uri":"/distributed/"},{"categories":["分布式"],"content":"BASE（最终一致性） BASE是对CAP 理论中强一致性和可用性权衡的结果，其来源于对大规模互联网系统分布式实践的总结，是基于CAP定理逐步演化而来的，其核心思想是即使无法做到强一致性(Strong consistency)，每个应用都可以根据自身的业务特点，采用适当的方式来使系统达到最终一致性(Eventual consistency)。 BASE理论是对CAP的延伸和补充，是对CAP中的AP方案的一个补充，即在选择AP方案的情况下，如何更好的最终达到C。 BASE是基本可用，柔性状态，最终一致性三个短语的缩写，核心的思想是即使无法做到强一致性，但应用可以采用适合的方式达到最终一致性。 多数情况下，其实我们也并非一定要求强一致性，部分业务可以容忍一定程度的延迟一致，所以为了兼顾效率，发展出来了最终一致性理论BASE BA-基本可用(Basically Available)：基本可用是指分布式系统在出现故障的时候，允许损失部分可用性，即保证核心可用。 S-软状态(Soft State)：软状态是指允许系统存在中间状态，而该中间状态不会影响系统整体可用性。分布式存储中一般一份数据至少会有三个副本，允许不同节点间副本同步的延时就是软状态的体现。 E-最终一致性(Eventual Consistency)：最终一致性是指系统中的所有数据副本经过一定时间后，最终能够达到一致的状态。弱一致性和强一致性相反，最终一致性是弱一致性的一种特殊情况。 ","date":"2020-02-03","objectID":"/distributed/:1:2","tags":["分布式","大纲"],"title":"分布式概览","uri":"/distributed/"},{"categories":["分布式"],"content":"一致性算法 分布式架构的核心就在一致性的实现和妥协，那么如何设计一套算法来保证不同节点之间的通信和数据达到无限趋向一致性，就非常重要了。 ","date":"2020-02-03","objectID":"/distributed/:2:0","tags":["分布式","大纲"],"title":"分布式概览","uri":"/distributed/"},{"categories":["分布式"],"content":"参考文章 分布式架构知识体系 通过一个订单查看微服务整个流程 分布式整体概览从CAP说起 ","date":"2020-02-03","objectID":"/distributed/:3:0","tags":["分布式","大纲"],"title":"分布式概览","uri":"/distributed/"},{"categories":["分布式"],"content":"学习资料 分布式系统合集 ","date":"2020-02-03","objectID":"/distributed/:4:0","tags":["分布式","大纲"],"title":"分布式概览","uri":"/distributed/"},{"categories":["知识体系"],"content":"微服务介绍","date":"2020-02-02","objectID":"/microservices/","tags":["大纲"],"title":"微服务介绍","uri":"/microservices/"},{"categories":["知识体系"],"content":" 微服务架构（MicroServices Architecture，MSA）：微服务架构可以看做是面向服务架构和分布式服务架构的拓展，使用更细粒度的服务（所以叫微服务）和一组设计准则来考虑大规模的复杂系统架构设计。系统中的各个微服务可被独立部署，各个微服务之间是松耦合的。每个微服务仅关注于完成一件任务并很好地完成该任务。在所有情况下，每个任务代表着一个小的业务能力。 ","date":"2020-02-02","objectID":"/microservices/:0:0","tags":["大纲"],"title":"微服务介绍","uri":"/microservices/"},{"categories":["知识体系"],"content":"常见的微服务组件及概念 服务注册：服务提供方将自己调用地址注册到服务注册中心，让服务调用方能够方便地找到自己。 服务发现：服务调用方从服务注册中心找到自己需要调用的服务的地址。 负载均衡：服务提供方一般以多实例的形式提供服务，负载均衡功能能够让服务调用方连接到合适的服务节点。并且，节点选择的工作对服务调用方来说是透明的。 服务网关：服务网关是服务调用的唯一入口，可以在这个组件是实现用户鉴权、动态路由、灰度发布、A/B 测试、负载限流等功能。 配置中心：将本地化的配置信息（properties, xml, yaml 等）注册到配置中心，实现程序包在开发、测试、生产环境的无差别性，方便程序包的迁移。 API 管理：以方便的形式编写及更新 API 文档，并以方便的形式供调用者查看和测试。 集成框架：微服务组件都以职责单一的程序包对外提供服务，集成框架以配置的形式将所有微服务组件（特别是管理端组件）集成到统一的界面框架下，让用户能够在统一的界面中使用系统。 分布式事务：对于重要的业务，需要通过分布式事务技术（TCC、高可用消息服务、最大努力通知）保证数据的一致性。 调用链：记录完成一个业务逻辑时调用到的微服务，并将这种串行或并行的调用关系展示出来。在系统出错时，可以方便地找到出错点。 支撑平台：系统微服务化后，系统变得更加碎片化，系统的部署、运维、监控等都比单体架构更加复杂，那么，就需要将大部分的工作自动化。现在，可以通过 Docker 等工具来中和这些微服务架构带来的弊端。 例如持续集成、蓝绿发布、健康检查、性能健康等等。严重点，以我们两年的实践经验，可以这么说，如果没有合适的支撑平台或工具，就不要使用微服务架构。 ","date":"2020-02-02","objectID":"/microservices/:1:0","tags":["大纲"],"title":"微服务介绍","uri":"/microservices/"},{"categories":["知识体系"],"content":"微服务架构的优点 降低系统复杂度：每个服务都比较简单，只关注于一个业务功能。 松耦合：微服务架构方式是松耦合的，每个微服务可由不同团队独立开发，互不影响。 跨语言：只要符合服务 API 契约，开发人员可以自由选择开发技术。这就意味着开发人员可以采用新技术编写或重构服务，由于服务相对较小，所以这并不会对整体应用造成太大影响。 独立部署：微服务架构可以使每个微服务独立部署。开发人员无需协调对服务升级或更改的部署。这些更改可以在测试通过后立即部署。所以微服务架构也使得 CI／CD 成为可能。 Docker 容器：和 Docker 容器结合的更好。 DDD 领域驱动设计：和 DDD 的概念契合，结合开发会更好。 ","date":"2020-02-02","objectID":"/microservices/:2:0","tags":["大纲"],"title":"微服务介绍","uri":"/microservices/"},{"categories":["知识体系"],"content":"微服务架构的缺点 微服务强调了服务大小，但实际上这并没有一个统一的标准：业务逻辑应该按照什么规则划分为微服务，这本身就是一个经验工程。有些开发者主张 10-100 行代码就应该建立一个微服务。微服务的目标是充分分解应用程序，以促进敏捷开发和持续集成部署。 微服务的分布式特点带来的复杂性：开发人员需要基于 RPC 或者消息实现微服务之间的调用和通信，而这就使得服务之间的发现、服务调用链的跟踪和质量问题变得的相当棘手。 分区的数据库体系和分布式事务：更新多个业务实体的业务交易相当普遍，不同服务可能拥有不同的数据库。CAP 原理的约束，使得我们不得不放弃传统的强一致性，而转而追求最终一致性，这个对开发人员来说是一个挑战。 测试挑战：传统的单体WEB应用只需测试单一的 REST API 即可，而对微服务进行测试，需要启动它依赖的所有其他服务。这种复杂性不可低估。 跨多个服务的更改：比如在传统单体应用中，若有 A、B、C 三个服务需要更改，A 依赖 B，B 依赖 C。我们只需更改相应的模块，然后一次性部署即可。但是在微服务架构中，我们需要仔细规划和* 调每个服务的变更部署。我们需要先更新 C，然后更新 B，最后更新 A。 部署复杂：微服务由不同的大量服务构成。每种服务可能拥有自己的配置、应用实例数量以及基础服务地址。这里就需要不同的配置、部署、扩展和监控组件。此外，我们还需要服务发现机制，以便服* 可以发现与其通信的其他服务的地址。因此，成功部署微服务应用需要开发人员有更好地部署策略和高度自动化的水平。 总结（问题和挑战）：API Gateway、服务间调用、服务发现、服务容错、服务部署、数据调用。 不过，现在很多微服务的框架（比如 Spring Cloud、Dubbo）已经很好的解决了上面的问题。 ","date":"2020-02-02","objectID":"/microservices/:3:0","tags":["大纲"],"title":"微服务介绍","uri":"/microservices/"},{"categories":["知识体系"],"content":"微服务常见问题 ","date":"2020-02-02","objectID":"/microservices/:4:0","tags":["大纲"],"title":"微服务介绍","uri":"/microservices/"},{"categories":["知识体系"],"content":"服务雪崩 服务雪崩效应产生的原因：因为Tomcat默认情况下只有一个线程池来维护客户端发送的所有的请求，这时候某一接口在某一时刻被大量访问就会占据tomcat线程池中的所有线程，其他请求处于等待状态，无法连接到服务接口。 服务雪崩解决方案-1.服务降级 当客户端请求服务器端的时候，防止客户端一直等待，不会处理业务逻辑代码，直接返回一个友好的提示给客户端。 熔断和降级的区别，其实应该要这么理解: 服务降级有很多种降级方式！如开关降级、限流降级、熔断降级! 服务熔断属于降级方式的一种！ 服务雪崩解决方案-2.服务熔断 服务熔断：当下游的服务因为某种原因突然变得不可用或响应过慢，上游服务为了保证自己整体服务的可用性，不再继续调用目标服务，直接返回，快速释放资源。如果目标服务情况好转则恢复调用。 是在服务降级的基础上更直接的一种保护方式，需要说明的是熔断其实是一个框架级的处理，那么这套熔断机制的设计，基本上业内用的是断路器模式 服务雪崩解决方案-3.服务隔离 是Hystrix为隔离的服务开启一个独立的线程池，这样在高并发的情况下不会影响其他服务。服务隔离有线程池和信号量两种实现方式，一般使用线程池方式。 ","date":"2020-02-02","objectID":"/microservices/:4:1","tags":["大纲"],"title":"微服务介绍","uri":"/microservices/"},{"categories":["知识体系"],"content":"微服务的三个阶段 仅使用注册发现，基于SpringCloud或者Dubbo进行开发。 使用了限流、降级、熔断等服务治理策略，并配备完整服务工具和平台。 Service Mesh将服务治理作为通用组件，下沉到平台层实现，应用层仅仅关注业务逻辑，平台层可以根据业务监控自动调度和参数调整，实现AIOps和智能调度。 微服务更像是一个服务之间的生态，专注于服务治理等方面，而服务网格更专注于服务之间的通信，以及和 DevOps 更好的结合。 ","date":"2020-02-02","objectID":"/microservices/:5:0","tags":["大纲"],"title":"微服务介绍","uri":"/microservices/"},{"categories":["知识体系"],"content":"参考文章 https://www.cnblogs.com/xishuai/p/microservices-and-service-mesh.html https://www.infoq.cn/article/xveohtcortxrspcf2ldd https://segmentfault.com/a/1190000039672263 https://mp.weixin.qq.com/s/9w2W6mojhBWGwR9QmGUvvg RPC基本原理 ","date":"2020-02-02","objectID":"/microservices/:6:0","tags":["大纲"],"title":"微服务介绍","uri":"/microservices/"},{"categories":["知识体系"],"content":"互联网三高架构：高并发、高性能、高可用、高扩展","date":"2020-02-01","objectID":"/3h/","tags":["高并发","大纲"],"title":"高并发系统设计","uri":"/3h/"},{"categories":["知识体系"],"content":"软件开发通常会提到一个名词 “三高”，即高并发、高性能、高可用。 具体的指标定义，如：高并发方面要求QPS 大于10万；高性能方面要求请求延迟小于 100 ms；高可用方面要高于 99.99%。 三高\" 三高 ","date":"2020-02-01","objectID":"/3h/:0:0","tags":["高并发","大纲"],"title":"高并发系统设计","uri":"/3h/"},{"categories":["知识体系"],"content":"高并发 高并发（High Concurrency）是互联网分布式系统架构设计中必须考虑的因素之一，它通常是指，通过设计保证系统能够同时并行处理很多请求。高并发相关常用的一些指标有响应时间（Response Time），吞吐量（Throughput），每秒查询率QPS（Query Per Second），并发用户数等。 高并发\" 高并发 高并发架构设计\" 高并发架构设计 ","date":"2020-02-01","objectID":"/3h/:1:0","tags":["高并发","大纲"],"title":"高并发系统设计","uri":"/3h/"},{"categories":["知识体系"],"content":"系统拆分 将一个系统拆分为多个子系统，用 dubbo 来搞。然后每个系统连一个数据库，这样本来就一个库，现在多个数据库，不也可以扛高并发么。 ","date":"2020-02-01","objectID":"/3h/:1:1","tags":["高并发","大纲"],"title":"高并发系统设计","uri":"/3h/"},{"categories":["知识体系"],"content":"读写分离 读写分离，这个就是说大部分时候数据库可能也是读多写少，没必要所有请求都集中在一个库上吧，可以搞个主从架构，主库写入，从库读取，搞一个读写分离。读流量太多的时候，还可以加更多的从库。 ","date":"2020-02-01","objectID":"/3h/:1:2","tags":["高并发","大纲"],"title":"高并发系统设计","uri":"/3h/"},{"categories":["知识体系"],"content":"分库分表 分库分表，可能到了最后数据库层面还是免不了抗高并发的要求，好吧，那么就将一个数据库拆分为多个库，多个库来扛更高的并发；然后将一个表拆分为多个表，每个表的数据量保持少一点，提高 sql 跑的性能。 ","date":"2020-02-01","objectID":"/3h/:1:3","tags":["高并发","大纲"],"title":"高并发系统设计","uri":"/3h/"},{"categories":["知识体系"],"content":"缓存 缓存，必须得用缓存。大部分的高并发场景，都是读多写少，那你完全可以在数据库和缓存里都写一份，然后读的时候大量走缓存不就得了。毕竟人家 redis 轻轻松松单机几万的并发。所以你可以考虑考虑你的项目里，那些承载主要请求的读场景，怎么用缓存来抗高并发。 ","date":"2020-02-01","objectID":"/3h/:1:4","tags":["高并发","大纲"],"title":"高并发系统设计","uri":"/3h/"},{"categories":["知识体系"],"content":"消息队列 MQ，必须得用 MQ。可能你还是会出现高并发写的场景，比如说一个业务操作里要频繁搞数据库几十次，增删改增删改，疯了。那高并发绝对搞挂你的系统，你要是用 redis 来承载写那肯定不行，人家是缓存，数据随时就被 LRU 了，数据格式还无比简单，没有事务支持。所以该用 mysql 还得用 mysql 啊。那你咋办？用 MQ 吧，大量的写请求灌入 MQ 里，排队慢慢玩儿，后边系统消费后慢慢写，控制在 mysql 承载范围之内。所以你得考虑考虑你的项目里，那些承载复杂写业务逻辑的场景里，如何用 MQ 来异步写，提升并发性。MQ 单机抗几万并发也是 ok 的，这个之前还特意说过。 ","date":"2020-02-01","objectID":"/3h/:1:5","tags":["高并发","大纲"],"title":"高并发系统设计","uri":"/3h/"},{"categories":["知识体系"],"content":"ElasticSearch Elasticsearch，简称 es。es 是分布式的，可以随便扩容，分布式天然就可以支撑高并发，因为动不动就可以扩容加机器来扛更高的并发。那么一些比较简单的查询、统计类的操作，可以考虑用 es 来承载，还有一些全文搜索类的操作，也可以考虑用 es 来承载。 ","date":"2020-02-01","objectID":"/3h/:1:6","tags":["高并发","大纲"],"title":"高并发系统设计","uri":"/3h/"},{"categories":["知识体系"],"content":"高性能 性能体现了系统的并行处理能力，在有限的硬件投入下，提高性能意味着节省成本。同时，性能也反映了用户体验，响应时间分别是100毫秒和1秒，给用户的感受是完全不同的。 高性能\" 高性能 ","date":"2020-02-01","objectID":"/3h/:2:0","tags":["高并发","大纲"],"title":"高并发系统设计","uri":"/3h/"},{"categories":["知识体系"],"content":"高可用 表示系统可以正常服务的时间。一个全年不停机、无故障；另一个隔三差五出线上事故、宕机，用户肯定选择前者。另外，如果系统只能做到90%可用，也会大大拖累业务。 高可用\" 高可用 ","date":"2020-02-01","objectID":"/3h/:3:0","tags":["高并发","大纲"],"title":"高并发系统设计","uri":"/3h/"},{"categories":["知识体系"],"content":"高扩展 表示系统的扩展能力，流量高峰时能否在短时间内完成扩容，更平稳地承接峰值流量，比如双11活动、明星离婚等热点事件。 ","date":"2020-02-01","objectID":"/3h/:4:0","tags":["高并发","大纲"],"title":"高并发系统设计","uri":"/3h/"},{"categories":["知识体系"],"content":"常用指标 ","date":"2020-02-01","objectID":"/3h/:5:0","tags":["高并发","大纲"],"title":"高并发系统设计","uri":"/3h/"},{"categories":["知识体系"],"content":"吞吐量 在了解qps、tps、rt、并发数之前，首先我们应该明确一个系统的吞吐量到底代表什么含义，一般来说，系统吞吐量指的是系统的抗压、负载能力，代表一个系统每秒钟能承受的最大用户访问量。 一个系统的吞吐量通常由qps（tps）、并发数来决定，每个系统对这两个值都有一个相对极限值，只要某一项达到最大值，系统的吞吐量就上不去了。 系统吞吐量几个重要参数：QPS（TPS）、并发数、响应时间。 QPS（TPS）：（Query Per Second）每秒钟request/事务 数量 并发数： 系统同时处理的request/事务数 响应时间： 一般取平均响应时间 理解了上面三个要素的意义之后，就能推算出它们之间的关系： QPS（TPS）= 并发数/平均响应时间 并发数 = QPS*平均响应时间 ","date":"2020-02-01","objectID":"/3h/:5:1","tags":["高并发","大纲"],"title":"高并发系统设计","uri":"/3h/"},{"categories":["知识体系"],"content":"QPS，每秒查询 QPS：Queries Per Second意思是“每秒查询率”，是一台服务器每秒能够相应的查询次数，是对一个特定的查询服务器在规定时间内所处理流量多少的衡量标准。 互联网中，作为域名系统服务器的机器的性能经常用每秒查询率来衡量。 ","date":"2020-02-01","objectID":"/3h/:5:2","tags":["高并发","大纲"],"title":"高并发系统设计","uri":"/3h/"},{"categories":["知识体系"],"content":"TPS，每秒事务 TPS：是TransactionsPerSecond的缩写，也就是事务数/秒。它是软件测试结果的测量单位。一个事务是指一个客户机向服务器发送请求然后服务器做出反应的过程。客户机在发送请求时开始计时，收到服务器响应后结束计时，以此来计算使用的时间和完成的事务个数。 QPS vs TPS：QPS基本类似于TPS，但是不同的是，对于一个页面的一次访问，形成一个TPS；但一次页面请求，可能产生多次对服务器的请求，服务器对这些请求，就可计入“QPS”之中。如，访问一个页面会请求服务器2次，一次访问，产生一个“T”，产生2个“Q”。 ","date":"2020-02-01","objectID":"/3h/:5:3","tags":["高并发","大纲"],"title":"高并发系统设计","uri":"/3h/"},{"categories":["知识体系"],"content":"RT，响应时间 响应时间：执行一个请求从开始到最后收到响应数据所花费的总体时间,即从客户端发起请求到收到服务器响应结果的时间。 响应时间RT(Response-time)，是一个系统最重要的指标之一，它的数值大小直接反应了系统的快慢。 ","date":"2020-02-01","objectID":"/3h/:5:4","tags":["高并发","大纲"],"title":"高并发系统设计","uri":"/3h/"},{"categories":["知识体系"],"content":"并发数 并发数是指系统同时能处理的请求数量，这个也是反应了系统的负载能力。 ","date":"2020-02-01","objectID":"/3h/:5:5","tags":["高并发","大纲"],"title":"高并发系统设计","uri":"/3h/"},{"categories":["知识体系"],"content":"最佳线程数、QPS、RT 单线程QPS公式：QPS=1000ms/RT 对同一个系统而言，支持的线程数越多，QPS越高。假设一个RT是80ms,则可以很容易的计算出QPS,QPS = 1000/80 = 12.5 多线程场景，如果把服务端的线程数提升到2，那么整个系统的QPS则为 2*（1000/80） = 25, 可见QPS随着线程的增加而线性增长，那QPS上不去就加线程呗，听起来很有道理，公司也说的通，但是往往现实并非如此。 QPS和RT的真实关系 我们想象的QPS、RT关系如下， 最佳线程数量 刚好消耗完服务器的瓶颈资源的临界线程数，公式如下 最佳线程数量 =（（线程等待时间+线程cpu时间）/线程cpu时间）* cpu数量 特性： 在达到最佳线程数的时候，线程数量继续递增，则QPS不变，而响应时间变长，持续递增线程数量，则QPS开始下降。 每个系统都有其最佳线程数量，但是不同状态下，最佳线程数量是会变化的。 瓶颈资源可以是CPU,可以是内存，可以是锁资源，IO资源：超过最佳线程数-导致资源的竞争，超过最佳线程数-响应时间递增。 ","date":"2020-02-01","objectID":"/3h/:5:6","tags":["高并发","大纲"],"title":"高并发系统设计","uri":"/3h/"},{"categories":["知识体系"],"content":"参考文章 理解透彻高并发 关于负载均衡的一切 高并发架构设计的16招 并发常用指标 ","date":"2020-02-01","objectID":"/3h/:6:0","tags":["高并发","大纲"],"title":"高并发系统设计","uri":"/3h/"},{"categories":["业务场景"],"content":"系统设计","date":"2020-01-03","objectID":"/businessdesign/","tags":["架构设计"],"title":"业务架构合集","uri":"/businessdesign/"},{"categories":["业务场景"],"content":"业务场景 对账系统 有赞零售财务中台架构设计与实践 百万TPS支付账务系统的设计与实现 高效的风控规则引擎 ","date":"2020-01-03","objectID":"/businessdesign/:1:0","tags":["架构设计"],"title":"业务架构合集","uri":"/businessdesign/"},{"categories":["业务场景"],"content":"最佳实践 最佳实践 服务化 ","date":"2020-01-03","objectID":"/businessdesign/:2:0","tags":["架构设计"],"title":"业务架构合集","uri":"/businessdesign/"},{"categories":["业务场景"],"content":"架构设计 如何进行系统分析与设计 系统架构 领域驱动分层架构与对象模型 常见的软件架构套路 ","date":"2020-01-03","objectID":"/businessdesign/:3:0","tags":["架构设计"],"title":"业务架构合集","uri":"/businessdesign/"},{"categories":["业务场景"],"content":"项目结构 互联网分层架构的本质 项目应该如何正确分层 分层架构 ","date":"2020-01-03","objectID":"/businessdesign/:4:0","tags":["架构设计"],"title":"业务架构合集","uri":"/businessdesign/"},{"categories":["业务场景"],"content":"技术选型 技术选型 ","date":"2020-01-03","objectID":"/businessdesign/:5:0","tags":["架构设计"],"title":"业务架构合集","uri":"/businessdesign/"},{"categories":["业务场景"],"content":"DevOps ","date":"2020-01-03","objectID":"/businessdesign/:6:0","tags":["架构设计"],"title":"业务架构合集","uri":"/businessdesign/"},{"categories":["知识体系"],"content":"Java架构演变历史","date":"2020-01-02","objectID":"/javaarchhistory/","tags":["大纲"],"title":"Java架构演变历史","uri":"/javaarchhistory/"},{"categories":["知识体系"],"content":"Java网站架构演变过程，大致分为5个阶段，分别为单体架构、集群架构、分布式架构、SOA架构和微服务架构。 ","date":"2020-01-02","objectID":"/javaarchhistory/:0:0","tags":["大纲"],"title":"Java架构演变历史","uri":"/javaarchhistory/"},{"categories":["知识体系"],"content":"单体架构 应用、数据库、文件都部署在一台机器上。简单来讲其实就是我们熟知的SSM架构(Spring+SpringMVC+MyBatis)，把所有的业务模块都放在一个应用中开发，这里面又衍生出三层架构，即表示层、业务逻辑层和数据库访问层，虽然在软件设计中划分了经典的三层模型，但是对业务场景没有划分，一个典型的单体应用就是将所有的业务场景的表示层、业务逻辑层和数据访问层放在一个工程项目中，最终经过编译、打包，部署在一台服务器上。 单体架构优点 部署简单: 由于是完整的结构体，可以直接部署在一个服务器上即可。 技术单一: 项目不需要复杂的技术栈，往往一套熟悉的技术栈就可以完成开发。 用人成本低: 单个程序员可以完成业务接口到数据库的整个流程。 单体架构缺点 系统启动慢： 一个进程包含了所有的业务逻辑，涉及到的启动模块过多，导致系统的启动、重启时间周期过长; 系统错误隔离性差、可用性差：任何一个模块的错误均可能造成整个系统的宕机; 可伸缩性差：系统的扩容只能只对这个应用进行扩容，不能做到对某个功能点进行扩容; 线上问题修复周期长：任何一个线上问题修复需要对整个应用系统进行全面升级。 ","date":"2020-01-02","objectID":"/javaarchhistory/:0:1","tags":["大纲"],"title":"Java架构演变历史","uri":"/javaarchhistory/"},{"categories":["知识体系"],"content":"集群架构（cluster） 不同服务器部署同一套应用程序对外提供服务，实现服务的负载均衡或者互备(热备，主从)。同一种组件的多个实例，形成逻辑上的整体。单个节点可以提供完整服务，集群是物理形态。 集群架构相关技术点 应用和数据分离(大量用户高并发的访问导致系统性能越来越差，数据存储空间开始出现不足) 缓存的使用(QPS持续提高，为了降低接口访问时间、提高服务性能和并发，根据二八定律可以将80%的数据缓存) 负载均衡器的代理服务器 数据库读写分离 反向代理和CDN加速 负载平衡 集群就是把一个的事情交给多个人去做，假如要做1000个产品给一个人做要10天，我叫10个人做就是一天，这就是集群，负载均衡的话就是用来控制集群，他把做的最多的人让他慢慢做休息会，把做的最少的人让他加量让他做多点。 ","date":"2020-01-02","objectID":"/javaarchhistory/:0:2","tags":["大纲"],"title":"Java架构演变历史","uri":"/javaarchhistory/"},{"categories":["知识体系"],"content":"分布式架构 服务的不同模块部署在不同的机器上，单个节点不能提供完整服务，需要多节点协调提供服务(相同组件部署在不同节点，节点间通过交互信息协作提供服务)，分布式强调的是工作方式。 分布式相关技术点 业务分库分表 业务模块拆分成子项目 NoSQL和搜索引擎对可伸缩的分布式特性具有更好的支持，应用服务器通过一个统一的数据访问模块访问各种数据，减轻应用程序管理诸多数据源的麻烦。 ","date":"2020-01-02","objectID":"/javaarchhistory/:0:3","tags":["大纲"],"title":"Java架构演变历史","uri":"/javaarchhistory/"},{"categories":["知识体系"],"content":"SOA架构 面向服务的设计架构，其中包含多个服务，服务之间通过相互依赖最终提供一系列的功能。一个服务通常以独立的形式存在于操作系统进程中。各个服务之间通过网络调用。 中心化实现：ESB(企业服务总线)，各服务通过ESB进行交互，解决异构系统之间的连通性，通过协议转换，消息解析，消息路由把服务提供者的数据传送到服务消费者。 去中心化实现：微服务 ","date":"2020-01-02","objectID":"/javaarchhistory/:0:4","tags":["大纲"],"title":"Java架构演变历史","uri":"/javaarchhistory/"},{"categories":["知识体系"],"content":"微服务架构(在SOA上做的升华) 微服务就是一个独立的职责单一的服务应用程序，微服务架构强调业务需要彻底组件化和服务化，原有的单个业务系统会拆分为多个可独立开发，设计，运行的小应用。这些小应用通过服务完成交互和集成。 优点 每个服务直接足够内聚，代码容易理解 开发效率高，一个服务只做一件事，适合小团队开发 松耦合，有功能意义的服务。 可以用不同语言开发，面向接口编程。 易于第三方集成 微服务只是业务逻辑的代码，不会和HTML,CSS或其他界 可以灵活搭配，连接公共库/连接独立库 缺点 分布式系统的责任性 多服务运维难度加大。 系统部署依赖，服务间通信成本，数据一致 ，系统集成测试，性能监控。 服务间通信成本 数据一致性 系统集成测试 性能监控 ","date":"2020-01-02","objectID":"/javaarchhistory/:0:5","tags":["大纲"],"title":"Java架构演变历史","uri":"/javaarchhistory/"},{"categories":["知识体系"],"content":"Service Mesh 架构（集中管理微服务中非业务相关内容，让微服务更加专注于业务处理） 最初，流量管理和控制能力（比如图例中的熔断、服务发现）是和业务逻辑耦合在一起，即便以引用包的方式被调用，依然解决不了异构系统无法重用的问题。 流控功能和业务耦合相当不美好，于是出现了提供这些功能的公共库和框架。但这些库通常比较复杂，无论是学习使用，与业务系统整合、维护都会带来很大的成本。 为避免花费太多时间开发和维护这些通用库，人们希望流量控制能力可以下沉到网络通讯栈的层面，但几乎无法实现。 于是另一种思路出现，就是将这些功能独立成一个代理，由它先接管业务服务的流量，处理完成后再转发给业务服务本身，这就是 Sidecar 模式。 为统一管理 Sidecar，该模式进一步进化，形成网络拓扑，增加了控制平面，演变成 Service Mesh（最后的网格图中，绿色代表业务服务，蓝色代表 sidecar 服务）。 业务系统的核心价值应该是业务本身，而不是服务，微服务只是一种实现手段，实现业务才是目标。现有的微服务架构下，为解决可能出现的网络通信问题，提升系统的弹性，开发人员不得不花费大量时间和精力去实现流量控制相关的非业务需求，不能聚焦在业务本身。 而 Service Mesh 的出现解决了这一问题，带来了下面 2 个变革： 解决了微服务框架中的服务流量管理的痛点，使开发人员专注于业务本身； 将服务通信及相关管控功能从业务程序中分离并下层到基础设施层，使其和业务系统完全解耦。 小结 解耦是软件开发中永恒的主题，开发人员对消除重复的偏执是推动软件、以及架构模式演进的主要动力。而 Service Mesh 的核心价值就是将服务通信功能从业务逻辑中解耦，并下沉为基础设施，由控制平面统一管理。 有人将 Service Mesh、Kubernetes 和 Serverless 技术称为云原生应用开发的三驾马车。 Kubernetes 是云应用实际意义上的操作系统； Service Mesh 将服务通信功能剥离，实现了与业务的解耦； Serverless 让你不用关心应用的服务器。 这三项技术让我们有能力实现应用开发的终极目标，那就是：只关注业务本身。而它们，也会引领我们通向未来云原生应用的诗和远方。 详细介绍：Service Mesh 浅析：从概念、产品到实践 ","date":"2020-01-02","objectID":"/javaarchhistory/:0:6","tags":["大纲"],"title":"Java架构演变历史","uri":"/javaarchhistory/"},{"categories":["知识体系"],"content":"参考文章 大型互联网架构演化简史 亿级流量高并发是怎么抗住的 ","date":"2020-01-02","objectID":"/javaarchhistory/:1:0","tags":["大纲"],"title":"Java架构演变历史","uri":"/javaarchhistory/"},{"categories":["知识体系"],"content":"Java知识大纲","date":"2020-01-01","objectID":"/javaoutline/","tags":["大纲"],"title":"Java知识大纲","uri":"/javaoutline/"},{"categories":["知识体系"],"content":"基础 ","date":"2020-01-01","objectID":"/javaoutline/:1:0","tags":["大纲"],"title":"Java知识大纲","uri":"/javaoutline/"},{"categories":["知识体系"],"content":"数据结构与算法 数组、链表、二叉树、队列、栈的各种操作（性能，场景） 二分查找和各种变种的二分查找 各类排序算法以及复杂度分析（快排、归并、堆） 各类算法题（手写） 理解并可以分析时间和空间复杂度。 动态规划（笔试回回有。。）、贪心。 红黑树、AVL树、Hash树、Tire树、B树、B+树。 图算法（比较少，也就两个最短路径算法理解吧） ","date":"2020-01-01","objectID":"/javaoutline/:1:1","tags":["大纲"],"title":"Java知识大纲","uri":"/javaoutline/"},{"categories":["知识体系"],"content":"操作系统 进程通信IPC（几种方式），与线程区别 OS的几种策略（页面置换，进程调度等，每个里面有几种算法） 互斥与死锁相关的 linux常用命令（问的时候都会给具体某一个场景） Linux内核相关（select、poll、epoll） ","date":"2020-01-01","objectID":"/javaoutline/:1:2","tags":["大纲"],"title":"Java知识大纲","uri":"/javaoutline/"},{"categories":["知识体系"],"content":"网络基础 OSI7层模型（TCP4层） 每层的协议 url到页面的过程 HTTP http/https 1.0、1.1、2.0 get/post 以及幂等性 http 协议头相关 网络攻击（CSRF、XSS） TCP/IP 三次握手、四次挥手 拥塞控制（过程、阈值） 流量控制与滑动窗口 TCP与UDP比较 子网划分（一般只有笔试有） DDos攻击 (B)IO/NIO/AIO 三者原理，各个语言是怎么实现的 Netty Linux内核select poll epoll ","date":"2020-01-01","objectID":"/javaoutline/:1:3","tags":["大纲"],"title":"Java知识大纲","uri":"/javaoutline/"},{"categories":["知识体系"],"content":"数据库 索引（包括分类及优化方式，失效条件，底层结构） sql语法（join，union，子查询，having，group by） 引擎对比（InnoDB，MyISAM） 数据库的锁（行锁，表锁，页级锁，意向锁，读锁，写锁，悲观锁，乐观锁，以及加锁的select sql方式） 隔离级别，依次解决的问题（脏读、不可重复读、幻读） 事务的ACID B树、B+树 优化（explain，慢查询，show profile） 数据库的范式。 分库分表，主从复制，读写分离。 Nosql相关（redis和mem***d区别之类的，如果你熟悉redis，redis还有一堆要问的） ","date":"2020-01-01","objectID":"/javaoutline/:1:4","tags":["大纲"],"title":"Java知识大纲","uri":"/javaoutline/"},{"categories":["知识体系"],"content":"编译原理 ","date":"2020-01-01","objectID":"/javaoutline/:1:5","tags":["大纲"],"title":"Java知识大纲","uri":"/javaoutline/"},{"categories":["知识体系"],"content":"Java ","date":"2020-01-01","objectID":"/javaoutline/:2:0","tags":["大纲"],"title":"Java知识大纲","uri":"/javaoutline/"},{"categories":["知识体系"],"content":"Java基础 把我之后的面经过一遍，Java感觉覆盖的就差不多了，不过下面还是分个类。 Java基础（面向对象、四个特性、重载重写、static和final等等很多东西） 集合（HashMap、ConcurrentHashMap、各种List，最好结合源码看） 并发和多线程（线程池、SYNC和Lock锁机制、线程通信、volatile、ThreadLocal、CyclicBarrier、Atom包、CountDownLatch、AQS、CAS原理等等） JVM（内存模型、GC垃圾回收，包括分代，GC算法，收集器、类加载和双亲委派、JVM调优，内存泄漏和内存溢出） IO/NIO相关 反射和***、异常、Java8相关、序列化 设计模式（常用的，jdk中有的） Web相关（servlet、cookie/session、Spring\u003cAOP、IOC、MVC、事务、动态***\u003e、Mybatis、Tomcat、Hibernate等） ","date":"2020-01-01","objectID":"/javaoutline/:2:1","tags":["大纲"],"title":"Java知识大纲","uri":"/javaoutline/"},{"categories":["知识体系"],"content":"并发编程 ","date":"2020-01-01","objectID":"/javaoutline/:2:2","tags":["大纲"],"title":"Java知识大纲","uri":"/javaoutline/"},{"categories":["知识体系"],"content":"JVM ","date":"2020-01-01","objectID":"/javaoutline/:2:3","tags":["大纲"],"title":"Java知识大纲","uri":"/javaoutline/"},{"categories":["知识体系"],"content":"性能优化 性能指标体系 JVM调优 Tomcat调优 MySQL调优 ","date":"2020-01-01","objectID":"/javaoutline/:2:4","tags":["大纲"],"title":"Java知识大纲","uri":"/javaoutline/"},{"categories":["知识体系"],"content":"故障排除 ","date":"2020-01-01","objectID":"/javaoutline/:2:5","tags":["大纲"],"title":"Java知识大纲","uri":"/javaoutline/"},{"categories":["知识体系"],"content":"最佳实践 ","date":"2020-01-01","objectID":"/javaoutline/:3:0","tags":["大纲"],"title":"Java知识大纲","uri":"/javaoutline/"},{"categories":["知识体系"],"content":"重构 ","date":"2020-01-01","objectID":"/javaoutline/:3:1","tags":["大纲"],"title":"Java知识大纲","uri":"/javaoutline/"},{"categories":["知识体系"],"content":"设计模式 ","date":"2020-01-01","objectID":"/javaoutline/:3:2","tags":["大纲"],"title":"Java知识大纲","uri":"/javaoutline/"},{"categories":["知识体系"],"content":"开发框架 Spring体系 MyBatis ","date":"2020-01-01","objectID":"/javaoutline/:3:3","tags":["大纲"],"title":"Java知识大纲","uri":"/javaoutline/"},{"categories":["知识体系"],"content":"常见业务 支付幂等性 减库存 秒杀 分布式锁 redis实现的分布式锁。 应该保证互斥性（在任何时候只有一个客户端持有锁。使用setnx）。 不能死锁（设置过期时间）。 保证上锁和解锁是同一个客户端（设置不同的value值）。 业务时间太长。导致锁过期（设置看门狗。自动续锁）。 锁的重入性（使用redis的hset）。 分布式事务 分布式缓存 ","date":"2020-01-01","objectID":"/javaoutline/:3:4","tags":["大纲"],"title":"Java知识大纲","uri":"/javaoutline/"},{"categories":["知识体系"],"content":"中间价 ","date":"2020-01-01","objectID":"/javaoutline/:4:0","tags":["大纲"],"title":"Java知识大纲","uri":"/javaoutline/"},{"categories":["知识体系"],"content":"消息队列 ","date":"2020-01-01","objectID":"/javaoutline/:4:1","tags":["大纲"],"title":"Java知识大纲","uri":"/javaoutline/"},{"categories":["知识体系"],"content":"缓存 本地缓存 分布式缓存 ","date":"2020-01-01","objectID":"/javaoutline/:4:2","tags":["大纲"],"title":"Java知识大纲","uri":"/javaoutline/"},{"categories":["知识体系"],"content":"ELK ","date":"2020-01-01","objectID":"/javaoutline/:4:3","tags":["大纲"],"title":"Java知识大纲","uri":"/javaoutline/"},{"categories":["知识体系"],"content":"数据库 分库分表 数据同步 数据库连接池 ","date":"2020-01-01","objectID":"/javaoutline/:4:4","tags":["大纲"],"title":"Java知识大纲","uri":"/javaoutline/"},{"categories":["知识体系"],"content":"分布式 CAP原理和BASE理论。 Nosql与KV存储（redis，hbase，mongodb，mem***d等） 服务化理论（包括服务发现、治理等，zookeeper、etcd、springcloud微服务、） 负载均衡（原理、cdn、一致性hash） RPC框架（包括整体的一些框架理论，通信的netty，序列化协议thrift，protobuff等） 消息队列（原理、kafka，activeMQ，rocketMQ） 分布式存储系统（GFS、HDFS、fastDFS）、存储模型（skipList、LSM等） 分布式事务、分布式锁等 ","date":"2020-01-01","objectID":"/javaoutline/:5:0","tags":["大纲"],"title":"Java知识大纲","uri":"/javaoutline/"},{"categories":["知识体系"],"content":"四大理论 拜占庭将军问题 CAP 理论 ACID 理论 BASE 理论 ","date":"2020-01-01","objectID":"/javaoutline/:5:1","tags":["大纲"],"title":"Java知识大纲","uri":"/javaoutline/"},{"categories":["知识体系"],"content":"八大协议/算法 Paxos 算法 Raft 算法 一致性 Hash 算法 Gossip 协议算法 Quorum NWR 算法 FBFT 算法 POW 算法 ZAB 协议 ","date":"2020-01-01","objectID":"/javaoutline/:5:2","tags":["大纲"],"title":"Java知识大纲","uri":"/javaoutline/"},{"categories":["知识体系"],"content":"大数据与数据分析： hadoop生态圈(hive、hbase、hdfs、zookeeper、storm、kafka) spark体系 语言：python、R、scala 搜索引擎与技术 ","date":"2020-01-01","objectID":"/javaoutline/:6:0","tags":["大纲"],"title":"Java知识大纲","uri":"/javaoutline/"},{"categories":["知识体系"],"content":"工具 版本管理 Git 项目管理 Maven/Gradle 代码质量管理 Sonar 持续集成部署 Jenkins\u0026GitLab CI/CD 监控系统 测试 Postman Jmeter VisualVM ","date":"2020-01-01","objectID":"/javaoutline/:7:0","tags":["大纲"],"title":"Java知识大纲","uri":"/javaoutline/"},{"categories":["Spring"],"content":"SpringBoot总结","date":"2019-04-03","objectID":"/springboot/","tags":["Spring","大纲"],"title":"SpringBoot总结","uri":"/springboot/"},{"categories":["Spring"],"content":" 使用了特定的方式来进行配置，从而使开发人员不再需要定义样板化的配置，简化Spring应用的初始搭建以及开发过程。简单理解，就是SpringBoot其实不是什么新的框架，它默认配置了很多框架的使用方式，就像Maven整合了所有的Jar包，Spring Boot整合了所有的框架。 ","date":"2019-04-03","objectID":"/springboot/:0:0","tags":["Spring","大纲"],"title":"SpringBoot总结","uri":"/springboot/"},{"categories":["Spring"],"content":"SpringBoot 的启动过程 开始源码分析，先从 SpringBoot 的启动类的 run() 方法开始看，以下是调用链：SpringApplication.run() -\u003e run(new Class[]{primarySource}, args) -\u003e new SpringApplication(primarySources)).run(args)。 一直在run，终于到重点了，我们直接看 new SpringApplication(primarySources)).run(args) 这个方法。 public static ConfigurableApplicationContext run(Class\u003c?\u003e[] primarySources, String[] args) { return new SpringApplication(primarySources).run(args); } 上面的方法主要包括两大步骤： 创建 SpringApplication 对象。 运行 run() 方法。 ","date":"2019-04-03","objectID":"/springboot/:1:0","tags":["Spring","大纲"],"title":"SpringBoot总结","uri":"/springboot/"},{"categories":["Spring"],"content":"创建 SpringApplication 对象 public SpringApplication(ResourceLoader resourceLoader, Class... primarySources) { this.sources = new LinkedHashSet(); this.bannerMode = Mode.CONSOLE; this.logStartupInfo = true; this.addCommandLineProperties = true; this.addConversionService = true; this.headless = true; this.registerShutdownHook = true; this.additionalProfiles = new HashSet(); this.isCustomEnvironment = false; this.resourceLoader = resourceLoader; Assert.notNull(primarySources, \"PrimarySources must not be null\"); // 保存主配置类（这里是一个数组，说明可以有多个主配置类） this.primarySources = new LinkedHashSet(Arrays.asList(primarySources)); // 判断当前是否是一个 Web 应用 this.webApplicationType = WebApplicationType.deduceFromClasspath(); // 从类路径下找到 META/INF/Spring.factories 配置的所有 ApplicationContextInitializer，然后保存起来 this.setInitializers(this.getSpringFactoriesInstances(ApplicationContextInitializer.class)); // 从类路径下找到 META/INF/Spring.factories 配置的所有 ApplicationListener，然后保存起来 this.setListeners(this.getSpringFactoriesInstances(ApplicationListener.class)); // 从多个配置类中找到有 main 方法的主配置类（只有一个） this.mainApplicationClass = this.deduceMainApplicationClass(); } ","date":"2019-04-03","objectID":"/springboot/:1:1","tags":["Spring","大纲"],"title":"SpringBoot总结","uri":"/springboot/"},{"categories":["Spring"],"content":"运行 run() 方法 public ConfigurableApplicationContext run(String... args) { // 创建计时器 StopWatch stopWatch = new StopWatch(); stopWatch.start(); // 声明 IOC 容器 ConfigurableApplicationContext context = null; Collection\u003cSpringBootExceptionReporter\u003e exceptionReporters = new ArrayList(); this.configureHeadlessProperty(); // 从类路径下找到 META/INF/Spring.factories 获取 SpringApplicationRunListeners SpringApplicationRunListeners listeners = this.getRunListeners(args); // 回调所有 SpringApplicationRunListeners 的 starting() 方法 listeners.starting(); Collection exceptionReporters; try { // 封装命令行参数 ApplicationArguments applicationArguments = new DefaultApplicationArguments(args); // 准备环境，包括创建环境，创建环境完成后回调 SpringApplicationRunListeners#environmentPrepared()方法，表示环境准备完成 ConfigurableEnvironment environment = this.prepareEnvironment(listeners, applicationArguments); this.configureIgnoreBeanInfo(environment); // 打印 Banner Banner printedBanner = this.printBanner(environment); // 创建 IOC 容器（决定创建 web 的 IOC 容器还是普通的 IOC 容器） context = this.createApplicationContext(); exceptionReporters = this.getSpringFactoriesInstances(SpringBootExceptionReporter.class, new Class[]{ConfigurableApplicationContext.class}, context); /* * 准备上下文环境，将 environment 保存到 IOC 容器中，并且调用 applyInitializers() 方法 * applyInitializers() 方法回调之前保存的所有的 ApplicationContextInitializer 的 initialize() 方法 * 然后回调所有的 SpringApplicationRunListener#contextPrepared() 方法 * 最后回调所有的 SpringApplicationRunListener#contextLoaded() 方法 */ this.prepareContext(context, environment, listeners, applicationArguments, printedBanner); // 刷新容器，IOC 容器初始化（如果是 Web 应用还会创建嵌入式的 Tomcat），扫描、创建、加载所有组件的地方 this.refreshContext(context); // 从 IOC 容器中获取所有的 ApplicationRunner 和 CommandLineRunner 进行回调 this.afterRefresh(context, applicationArguments); stopWatch.stop(); if (this.logStartupInfo) { (new StartupInfoLogger(this.mainApplicationClass)).logStarted(this.getApplicationLog(), stopWatch); } // 调用 所有 SpringApplicationRunListeners#started()方法 listeners.started(context); this.callRunners(context, applicationArguments); } catch (Throwable var10) { this.handleRunFailure(context, var10, exceptionReporters, listeners); throw new IllegalStateException(var10); } try { listeners.running(context); return context; } catch (Throwable var9) { this.handleRunFailure(context, var9, exceptionReporters, (SpringApplicationRunListeners)null); throw new IllegalStateException(var9); } } ","date":"2019-04-03","objectID":"/springboot/:1:2","tags":["Spring","大纲"],"title":"SpringBoot总结","uri":"/springboot/"},{"categories":["Spring"],"content":"总结 run() 阶段主要就是回调本节开头提到过的4个监听器中的方法与加载项目中组件到 IOC 容器中，而所有需要回调的监听器都是从类路径下的 META/INF/Spring.factories 中获取，从而达到启动前后的各种定制操作。 ","date":"2019-04-03","objectID":"/springboot/:1:3","tags":["Spring","大纲"],"title":"SpringBoot总结","uri":"/springboot/"},{"categories":["Spring"],"content":"SpringBoot 自动配置的原理 ","date":"2019-04-03","objectID":"/springboot/:2:0","tags":["Spring","大纲"],"title":"SpringBoot总结","uri":"/springboot/"},{"categories":["Spring"],"content":"@SpringBootApplication @Target({ElementType.TYPE}) @Retention(RetentionPolicy.RUNTIME) @Documented @Inherited @SpringBootConfiguration @EnableAutoConfiguration @ComponentScan(excludeFilters = {@Filter(type = FilterType.CUSTOM,classes = {TypeExcludeFilter.class} ), @Filter(type = FilterType.CUSTOM, classes = {AutoConfigurationExcludeFilter.class})}) public @interface SpringBootApplication { @SpringBootConfiguration：我们点进去以后可以发现底层是Configuration注解，说白了就是支持JavaConfig的方式来进行配置(使用Configuration配置类等同于XML文件)。 @ComponentScan：就是扫描注解，默认是扫描当前类下的package。将@Controller/@Service/@Component/@Repository等注解加载到IOC容器中。 @EnableAutoConfiguration ：开启自动配置功能 ","date":"2019-04-03","objectID":"/springboot/:2:1","tags":["Spring","大纲"],"title":"SpringBoot总结","uri":"/springboot/"},{"categories":["Spring"],"content":"@EnableAutoConfiguration 详解 @Target({ElementType.TYPE}) @Retention(RetentionPolicy.RUNTIME) @Documented @Inherited @AutoConfigurationPackage @Import({AutoConfigurationImportSelector.class}) public @interface EnableAutoConfiguration { @AutoConfigurationPackage：自动配置包 @Import：给IOC容器导入组件 AutoConfigurationPackage 详解 从字面意思理解就是自动配置包。点进去可以看到就是一个 @Import 注解：@Import({Registrar.class})，导入了一个 Registrar 的组件。 @Target({ElementType.TYPE}) @Retention(RetentionPolicy.RUNTIME) @Documented @Inherited @Import({Registrar.class}) public @interface AutoConfigurationPackage { } 我们可以发现，依靠的还是 @Import注解，再点进去查看，我们发现重要的就是以下的代码： public void registerBeanDefinitions(AnnotationMetadata metadata, BeanDefinitionRegistry registry) { AutoConfigurationPackages.register(registry, (new AutoConfigurationPackages.PackageImport(metadata)).getPackageName()); } @AutoConfigurationPackage 注解就是将主配置类（@SpringBootConfiguration标注的类）的所在包及下面所有子包里面的所有组件扫描到Spring容器中。所以说，默认情况下主配置类包及子包以外的组件，Spring 容器是扫描不到的。 在默认的情况下就是将：主配置类(@SpringBootApplication)的所在包及其子包里边的组件扫描到Spring容器中，看完这句话，会不会觉得，这不就是ComponentScan的功能吗？这俩不就重复了吗？ 比如说，你用了Spring Data JPA，可能会在实体类上写@Entity注解。这个@Entity注解由 @AutoConfigurationPackage 扫描并加载，而我们平时开发用的@Controller/@Service/@Component/@Repository这些注解是由ComponentScan来扫描并加载的。简单理解：这二者扫描的对象是不一样的。 AutoConfigurationImportSelector AutoConfigurationImportSelector\" AutoConfigurationImportSelector 调用链：在 getAutoConfigurationEntry() -\u003e getCandidateConfigurations() -\u003e loadFactoryNames(), 在这里 loadFactoryNames() 方法传入了 EnableAutoConfiguration.class 这个参数。 loadFactoryNames() 中关键的三步： 从当前项目的类路径中获取所有 META-INF/spring.factories 这个文件下的信息。 将上面获取到的信息封装成一个 Map 返回。 从返回的 Map 中通过刚才传入的 EnableAutoConfiguration.class 参数，获取该 key 下的所有值。 loadFactoryNames\" loadFactoryNames 一般每导入一个第三方的依赖，除了本身的jar包以外，还会有一个 xxx-spring-boot-autoConfigure，这个就是第三方依赖自己编写的自动配置类 spring.factories\" spring.factories 可以看到 EnableAutoConfiguration 下面有很多类，这些就是我们项目进行自动配置的类。 将类路径下 META-INF/spring.factories 里面配置的所有 EnableAutoConfiguration 的值加入到 Spring 容器中。 Spring会继续的处理这些自动配置类，也就是处理这些配置类中的@Configuration、@Import这些注解，继续递归处理这些注解，最后把相关的Bean都注册到容器中。 HttpEncodingAutoConfiguration 通过上面方式，所有的自动配置类就被导进主配置类中了。以 HttpEncodingAutoConfiguration为例来看一个自动配置类是怎么工作的。 @Configuration @EnableConfigurationProperties({HttpProperties.class}) @ConditionalOnWebApplication( type = Type.SERVLET ) @ConditionalOnClass({CharacterEncodingFilter.class}) @ConditionalOnProperty( prefix = \"spring.http.encoding\", value = {\"enabled\"}, matchIfMissing = true ) public class HttpEncodingAutoConfiguration { @Configuration：标记为配置类。 @ConditionalOnWebApplication：web应用下才生效。 @ConditionalOnClass：指定的类（依赖）存在才生效。 @ConditionalOnProperty：主配置文件中存在指定的属性才生效。 @EnableConfigurationProperties({HttpProperties.class})：启动指定类的ConfigurationProperties功能；将配置文件中对应的值和 HttpProperties 绑定起来；并把 HttpProperties 加入到 IOC 容器中。 因为 @EnableConfigurationProperties({HttpProperties.class}) 把配置文件中的配置项与当前 HttpProperties 类绑定上了。然后在 HttpEncodingAutoConfiguration 中又引用了 HttpProperties ，所以最后就能在 HttpEncodingAutoConfiguration 中使用配置文件中的值了。最终通过 @Bean 和一些条件判断往容器中添加组件，实现自动配置。（当然该Bean中属性值是从 HttpProperties 中获取） HttpProperties HttpProperties 通过 @ConfigurationProperties 注解将配置文件与自身属性绑定。 所有在配置文件中能配置的属性都是在 xxxProperties 类中封装着；配置文件能配置什么就可以参照某个功能对应的这个属性类。 @ConfigurationProperties( prefix = \"spring.http\" )// 从配置文件中获取指定的值和bean的属性进行绑定 public class HttpProperties { ","date":"2019-04-03","objectID":"/springboot/:2:2","tags":["Spring","大纲"],"title":"SpringBoot总结","uri":"/springboot/"},{"categories":["Spring"],"content":"总结 @SpringBootApplication 上有三个注解： @SpringBootConfiguration ，@EnableAutoConfiguration ，@ComponentScan ，@EnableAutoConfiguration 是关键(启用自动配置)，内部实际上就去加载 META-INF/spring.factories 文件的信息，然后筛选出以 EnableAutoConfiguration 为key的数据，加载到IOC容器中，实现自动配置功能。 ","date":"2019-04-03","objectID":"/springboot/:2:3","tags":["Spring","大纲"],"title":"SpringBoot总结","uri":"/springboot/"},{"categories":["Spring"],"content":"参考文章 *. Spring Boot 总结 ","date":"2019-04-03","objectID":"/springboot/:3:0","tags":["Spring","大纲"],"title":"SpringBoot总结","uri":"/springboot/"},{"categories":["Spring"],"content":"SpringMVC总结","date":"2019-04-02","objectID":"/springmvc/","tags":["Spring","大纲"],"title":"SpringMVC总结","uri":"/springmvc/"},{"categories":["Spring"],"content":"SpringMVC 执行流程 用户请求发送到前端控制器DispatcherServlet。 前端控制器DispatcherServlet接收到请求后，DispatcherServlet会使用HandlerMapping来处理，HandlerMapping会查找到具体进行处理请求的Handler对象。 HandlerMapping找到对应的Handler之后，并不是返回一个Handler原始对象，而是一个Handler执行链，在这个执行链中包括了拦截器和处理请求的Handler。HandlerMapping返回一个执行链给DispatcherServlet。 DispatcherServlet接收到执行链之后，会调用Handler适配器去执行Handler。 Handler适配器执行完成Handler（也就是我们写的Controller）之后会得到一个ModelAndView，并返回给DispatcherServlet。 DispatcherServlet接收到Handler适配器返回的ModelAndView之后，会根据其中的视图名调用视图解析器。 视图解析器根据逻辑视图名解析成一个真正的View视图，并返回给DispatcherServlet。 DispatcherServlet接收到视图之后，会根据上面的ModelAndView中的model来进行视图中数据的填充，也就是所谓的视图渲染。 渲染完成之后，DispatcherServlet就可以将结果返回给用户了。 ","date":"2019-04-02","objectID":"/springmvc/:1:0","tags":["Spring","大纲"],"title":"SpringMVC总结","uri":"/springmvc/"},{"categories":["Spring"],"content":"Spring总结","date":"2019-04-01","objectID":"/spring/","tags":["Spring","大纲"],"title":"Spring总结","uri":"/spring/"},{"categories":["Spring"],"content":" Spring 是一种轻量级开发框架，旨在提高开发人员的开发效率以及系统的可维护性。 我们一般说 Spring 框架指的都是 Spring Framework，它是很多模块的集合，使用这些模块可以很方便地协助我们进行开发。这些模块是：核心容器、数据访问/集成、Web、AOP（面向切面编程）、工具、消息和测试模块。比如：Core Container 中的 Core 组件是Spring 所有组件的核心，Beans 组件和 Context 组件是实现IOC和依赖注入的基础，AOP组件用来实现面向切面编程。 Spring 官网列出的 Spring 的 6 个特征: 核心技术 ：依赖注入(DI)，AOP，事件(events)，资源，i18n，验证，数据绑定，类型转换，SpEL。 测试 ：模拟对象，TestContext框架，Spring MVC 测试，WebTestClient。 数据访问 ：事务，DAO支持，JDBC，ORM，编组XML。 Web支持 : Spring MVC和Spring WebFlux Web框架。 集成 ：远程处理，JMS，JCA，JMX，电子邮件，任务，调度，缓存。 语言 ：Kotlin，Groovy，动态语言。 Spring模块\" Spring模块 ","date":"2019-04-01","objectID":"/spring/:0:0","tags":["Spring","大纲"],"title":"Spring总结","uri":"/spring/"},{"categories":["Spring"],"content":"IOC ","date":"2019-04-01","objectID":"/spring/:1:0","tags":["Spring","大纲"],"title":"Spring总结","uri":"/spring/"},{"categories":["Spring"],"content":"IOC容器初始化过程 BeanFactory和ApplicationContext是Spring中两种很重要的容器，前者提供了最基本的依赖注入的支持，后者在继承前者的基础上进行了功能的拓展，增加了事件传播，资源访问，国际化的支持等功能。同时两者的生命周期也稍微有些不同。 Spring IOC容器初始化过程分为Resource定位，载入解析，注册。IOC容器初始化过程中不包含Bean的依赖注入。Bean的依赖注入一般会发生在第一次通过getBean向容器索取Bean的时候。 IOC容器初始化过程\" IOC容器初始化过程 关键步骤 IOC容器初始化入口是在构造方法中调用refresh开始的。 通过ResourceLoader来完成资源文件位置的定位，DefaultResourceLoader是默认的实现，同时上下文本身就给除了ResourceLoader的实现。 创建的IOC容器是DefaultListableBeanFactory。 IOC对Bean的管理和依赖注入功能的实现是通过对其持有的BeanDefinition进行相关操作来完成的。 通过BeanDefinitionReader来完成定义信息的解析和Bean信息的注册。 XmlBeanDefinitionReader是BeanDefinitionReader的实现了，通过它来解析xml配置中的bean定义。 实际的处理过程是委托给BeanDefinitionParserDelegate来完成的。得到Bean的定义信息，这些信息在Spring中使用BeanDefinition对象来表示。 BeanDefinition的注册是由BeanDefinitionRegistry实现的registerBeanDefiition方法进行的。内部使用ConcurrentHashMap来保存BeanDefiition。 Spring解决循环依赖的过程总结 Spring在初始化Bean的时候，会先初始化当前Bean所依赖的Bean，如果两个Bean互相依赖，就产生了循环依赖，Spring针对循环依赖的办法是：提前曝光加上三个缓存singletonObjects、earlySingletonObjects、singletonFactories。 假设当前Bean是A，A依赖的Bean是B，B又依赖A。 提前曝光的意思就是，当前Bean A实例化完，还没有初始化完就先把当前Bean曝光出去，在B初始化需要依赖A的时候，就先拿到提前曝光的A，这样就可以继续将B初始化完成，然后返回A继续进行初始化。 循环依赖解决只针对单例Bean。 总结 Spring启动。 加载配置文件，xml、JavaConfig、注解、其他形式等等，将描述我们自己定义的和Spring内置的定义的Bean加载进来。 加载完配置文件后将配置文件转化成统一的Resource来处理。 使用Resource解析将我们定义的一些配置都转化成Spring内部的标识形式：BeanDefinition。 在低级的容器BeanFactory中，到这里就可以宣告Spring容器初始化完成了，Bean的初始化是在我们使用Bean的时候触发的；在高级的容器ApplicationContext中，会自动触发那些1. lazy-init=false的单例Bean，让Bean以及依赖的Bean进行初始化的流程，初始化完成Bean之后高级容器也初始化完成了。 在我们的应用中使用Bean。 Spring容器关闭，销毁各个Bean。 ","date":"2019-04-01","objectID":"/spring/:1:1","tags":["Spring","大纲"],"title":"Spring总结","uri":"/spring/"},{"categories":["Spring"],"content":"SpringBean生命周期 SpringBean生命周期\" SpringBean生命周期 手动或者自动的触发获取一个Bean，使用BeanFactory的时候需要我们代码自己获取Bean，ApplicationContext则是在IOC启动的时候自动初始化一个Bean。 IOC会根据BeanDefinition来实例化这个Bean，如果这个Bean还有依赖其他的Bean则会先初始化依赖的Bean，这里又涉及到了循环依赖的解决。实例化Bean的时候根据工厂方法、构造方法或者简单初始化等选择具体的实例来进行实例化，最终都是使用反射进行实例化。 Bean实例化完成，也就是一个对象实例化完成后，会继续填充这个Bean的各个属性，也是使用反射机制将属性设置到Bean中去。 填充完属性后，会调用各种Aware方法，将需要的组件设置到当前Bean中。BeanFactory这种低级容器需要我们手动注册Aware接口，而ApplicationContext这种高级容器在IOC启动的时候就自动给我们注册了Aware等接口。 接下来如果Bean实现了PostProcessor一系列的接口，会先调用其中的postProcessBeforeInitialization方法。BeanFactory这种低级容器需要我们手动注册PostProcessor接口，而ApplicationContext这种高级容器在IOC启动的时候就自动给我们注册了PostProcessor等接口。 如果Bean实现了InitializingBean接口，则会调用对应的afterPropertiesSet方法。 如果Bean设置了init-method属性，则会调用init-method指定的方法。 接下来如果Bean实现了PostProcessor一系列的接口，会先调用其中的postProcessAfterInitialization方法。BeanFactory这种低级容器需要我们手动注册PostProcessor接口，而 ApplicationContext这种高级容器在IOC启动的时候就自动给我们注册了PostProcessor等接口。 到这里Bean就可以使用了。 容器关闭的时候需要销毁Bean。 如果Bean实现了DisposableBean，则调用destroy方法。 如果Bean配置了destroy-method属性，则调用指定的destroy-method方法。 ","date":"2019-04-01","objectID":"/spring/:1:2","tags":["Spring","大纲"],"title":"Spring总结","uri":"/spring/"},{"categories":["Spring"],"content":"AOP Spring AOP流程大致上可以分为三个阶段：标签解析和AutoProxyCreator的注册、AOP代理的创建、代理的使用。 ","date":"2019-04-01","objectID":"/spring/:2:0","tags":["Spring","大纲"],"title":"Spring总结","uri":"/spring/"},{"categories":["Spring"],"content":"标签解析和AutoProxyCreator的注册 在Spring的扩展点中，最早期的扩展点是NamespaceHandler，这个阶段是在解析成BeanDefinition的阶段。Spring在这里完成自定义标签的解析工作，比如aop、tx等等。AOP功能在这里注册了自己的NamespaceHandler以及BeanDefinitionParser，用来将AOP标签转换成BeanDefinition交给IOC容器管理。 ","date":"2019-04-01","objectID":"/spring/:2:1","tags":["Spring","大纲"],"title":"Spring总结","uri":"/spring/"},{"categories":["Spring"],"content":"关于AutoProxyCreator的理解 同时在这里也会注册一个AutoProxyCreator，这个组件是用来在后面Bean的初始化过程中生成代理的。这个AutoProxtCreator实现了一个接口是：SmartInstantiationAwareBeanPostProcessor，看起来很眼熟，SmartInstantiationAwareBeanPostProcessor这个接口的父接口是：InstantiationAwareBeanPostProcessor，而InstantiationAwareBeanPostProcessor的父接口是BeanPostProcessor，到这里我们可能就大概明白了。 我们知道实现了BeanPostProcessor接口的类会在Bean初始化过程中的填充属性之后这一步被调用，调用的方法是postProcessBeforeInitialization和postProcessAfterInitialization。但是Spring干嘛还要衍生出那么多子接口呢？通过接口的名字我们可以看到不同，那些接口名字都含有一个关键词：Instantiation实例化，并不是初始化Initialization，也就是说这些接口中的方法调用是要在Bean实例化的时候进行处理。在Bean的生命周期中，我们知道Bean的实例化是Bean初始化步骤中最早的一步，所以对于Instantiation等方法的处理会比Initialization要早。 试想一下，我们自己写这些逻辑的时候，会在什么时候去创建AOP代理？第一个时间点：在Bean实例化之前，我就通过创建代理的逻辑直接返回一个代理好的实例，就不用继续走Bean初始化的后面的步骤了；第二个时间点：在Bean初始化之后，也就是走完了所有的Bean初始化过程后生成了一个完整的Bean，我再进行代理的创建。Spring就是这么处理的，要么我就不用Spring创建Bean，我直接返回一个代理，要么我就等Spring创建完成一个Bean再返回一个代理。Spring还有会另外一个触发点创建代理：getEarlyBeanReference，用来在解决循环依赖时提前曝光的Bean的代理生成，暂时不做说明。 ","date":"2019-04-01","objectID":"/spring/:2:2","tags":["Spring","大纲"],"title":"Spring总结","uri":"/spring/"},{"categories":["Spring"],"content":"AOP代理创建 明确了代理创建的时间点，就可以继续看AOP代理的创建过程了。 筛选出所有适合当前Bean的通知器，也就是所有的Advisor、Advise、Interceptor。 选择使用JDK还是CGLIB来进行创建代理。 使用具体的代理实现来创建代理。 ","date":"2019-04-01","objectID":"/spring/:2:3","tags":["Spring","大纲"],"title":"Spring总结","uri":"/spring/"},{"categories":["Spring"],"content":"代理的使用 获取当前调用方法的拦截器链，包含了所有将要执行的advice。 如果没有任何拦截器，直接执行目标方法。 如果有拦截器存在，则将拦截器和目标方法封装成一个MethodInvocation，递归调用proceed方法进行调用。 上面的处理中还有对目标对象的自我方法调用实施增强的处理，比如平时遇到的问题：在同一个类中一个方法调用另外一个带事务注解的方法，事务不会生效；在同一个类中一个方法调用另外一个带缓存注解的方法，缓存不会生效。 以上就是大概的流程，总结一下就是：AOP实现使用的是动态代理和拦截器链。 ","date":"2019-04-01","objectID":"/spring/:2:4","tags":["Spring","大纲"],"title":"Spring总结","uri":"/spring/"},{"categories":["Spring"],"content":"动态代理实现步骤 实现InvocationHandler接口创建自己的调用处理器 给Proxy类提供ClassLoader和代理接口类型数组创建动态代理类 以调用处理器类型为参数，利用反射机制得到动态代理类的构造函数 以调用处理器对象为参数，利用动态代理类的构造函数创建动态代理类对象 ","date":"2019-04-01","objectID":"/spring/:2:5","tags":["Spring","大纲"],"title":"Spring总结","uri":"/spring/"},{"categories":["Spring"],"content":"学习资料 AOP介绍 ","date":"2019-04-01","objectID":"/spring/:3:0","tags":["Spring","大纲"],"title":"Spring总结","uri":"/spring/"},{"categories":["数据库"],"content":"MyBatis总结","date":"2019-03-03","objectID":"/mybatis/","tags":["数据库","MyBatis","框架","大纲"],"title":" MyBatis总结","uri":"/mybatis/"},{"categories":["数据库"],"content":"MyBatis框架整体设计\" MyBatis框架整体设计 ","date":"2019-03-03","objectID":"/mybatis/:0:0","tags":["数据库","MyBatis","框架","大纲"],"title":" MyBatis总结","uri":"/mybatis/"},{"categories":["数据库"],"content":"接口层-和数据库交互的方式 MyBatis和数据库的交互有两种方式： 使用传统的MyBatis提供的API； 使用Mapper接口； ","date":"2019-03-03","objectID":"/mybatis/:1:0","tags":["数据库","MyBatis","框架","大纲"],"title":" MyBatis总结","uri":"/mybatis/"},{"categories":["数据库"],"content":"参考文章 常见问题 ","date":"2019-03-03","objectID":"/mybatis/:2:0","tags":["数据库","MyBatis","框架","大纲"],"title":" MyBatis总结","uri":"/mybatis/"},{"categories":["缓存"],"content":"Redis概览","date":"2019-03-02","objectID":"/redis/","tags":["缓存","大纲"],"title":"Redis概览","uri":"/redis/"},{"categories":["缓存"],"content":"Redis总览\" Redis总览 Redis是一款内存高速缓存数据库。Redis全称为：Remote Dictionary Server（远程数据服务. ，Redis是一种支持key-value等多种数据结构的存储系统。可用于缓存，事件发布或订阅，高速队列等场景。支持网络，提供字符串，哈希，列表，队列，集合结构直接存取，基于内存，可持久化。 ","date":"2019-03-02","objectID":"/redis/:0:0","tags":["缓存","大纲"],"title":"Redis概览","uri":"/redis/"},{"categories":["缓存"],"content":"单线程的redis为什么这么快 纯内存操作 单线程操作，避免了频繁的上下文切换 采用了非阻塞I/O多路复用机制 ","date":"2019-03-02","objectID":"/redis/:1:0","tags":["缓存","大纲"],"title":"Redis概览","uri":"/redis/"},{"categories":["缓存"],"content":"基础数据类型 Redis所有的key（键. 都是字符串。我们在谈基础数据结构时，讨论的是存储值的数据类型，主要包括常见的5种数据类型，分别是：String、List、Set、Zset、Hash 结构类型 结构存储的值 结构的读写能力 String字符串 可以是字符串、整数或浮点数 对整个字符串或字符串的一部分进行操作；对整数或浮点数进行自增或自减操作； List列表 一个链表，链表上的每个节点都包含一个字符串 对链表的两端进行push和pop操作，读取单个或多个元素；根据值查找或删除元素； Set集合 包含字符串的无序集合 字符串的集合，包含基础的方法有看是否存在添加、获取、删除；还包含计算交集、并集、差集等 Hash散列 包含键值对的无序散列表 包含方法有添加、获取、删除单个元素 Zset有序集合 和散列一样，用于存储键值对 字符串成员与浮点数分数之间的有序映射；元素的排列顺序由分数的大小决定；包含方法有添加、获取、删除单个元素以及根据分值范围或成员来获取元素 ","date":"2019-03-02","objectID":"/redis/:2:0","tags":["缓存","大纲"],"title":"Redis概览","uri":"/redis/"},{"categories":["缓存"],"content":"持久化 为了防止数据丢失以及服务重启时能够恢复数据，Redis支持数据的持久化，主要分为两种方式，分别是RDB和AOF; 当然实际场景下还会使用这两种的混合模式 ","date":"2019-03-02","objectID":"/redis/:3:0","tags":["缓存","大纲"],"title":"Redis概览","uri":"/redis/"},{"categories":["缓存"],"content":"RDB 持久化 RDB 就是 Redis DataBase 的缩写，中文名为快照/内存快照，RDB持久化是把当前进程数据生成快照保存到磁盘上的过程，由于是某一时刻的快照，那么快照中的值要早于或者等于内存中的值。 触发方式 手动触发 save命令：阻塞当前Redis服务器，直到RDB过程完成为止，对于内存 比较大的实例会造成长时间阻塞，线上环境不建议使用 bgsave命令：Redis进程执行fork操作创建子进程，RDB持久化过程由子进程负责，完成后自动结束。阻塞只发生在fork阶段，一般时间很短 bgsave命令具体流程如下： redis客户端执行bgsave命令或者自动触发bgsave命令； 主进程判断当前是否已经存在正在执行的子进程，如果存在，那么主进程直接返回； 如果不存在正在执行的子进程，那么就fork一个新的子进程进行持久化数据，fork过程是阻塞的，fork操作完成后主进程即可执行其他操作； 子进程先将数据写入到临时的rdb文件中，待快照数据写入完成后再原子替换旧的rdb文件； 同时发送信号给主进程，通知主进程rdb持久化完成，主进程更新相关的统计信息（info Persitence下的rdb_*相关选项. 。 自动触发 在以下4种情况时会自动触发 redis.conf中配置save m n，即在m秒内有n次修改时，自动触发bgsave生成rdb文件； 主从复制时，从节点要从主节点进行全量复制时也会触发bgsave操作，生成当时的快照发送到从节点； 执行debug reload命令重新加载redis时也会触发bgsave操作； 默认情况下执行shutdown命令时，如果没有开启aof持久化，那么也会触发bgsave操作； RDB优缺点 优点 RDB文件是某个时间节点的快照，默认使用LZF算法进行压缩，压缩后的文件体积远远小于内存大小，适用于备份、全量复制等场景； Redis加载RDB文件恢复数据要远远快于AOF方式； 缺点 RDB方式实时性不够，无法做到秒级的持久化； 每次调用bgsave都需要fork子进程，fork子进程属于重量级操作，频繁执行成本较高； RDB文件是二进制的，没有可读性，AOF文件在了解其结构的情况下可以手动修改或者补全； 版本兼容RDB文件问题； ","date":"2019-03-02","objectID":"/redis/:3:1","tags":["缓存","大纲"],"title":"Redis概览","uri":"/redis/"},{"categories":["缓存"],"content":"AOF 持久化 Redis是“写后”日志，Redis先执行命令，把数据写入内存，然后才记录日志。日志里记录的是Redis收到的每一条命令，这些命令是以文本形式保存。PS: 大多数的数据库采用的是写前日志（WAL. ，例如MySQL，通过写前日志和两阶段提交，实现数据和逻辑的一致性。 ","date":"2019-03-02","objectID":"/redis/:3:2","tags":["缓存","大纲"],"title":"Redis概览","uri":"/redis/"},{"categories":["缓存"],"content":"RDB和AOF混合方式（4.0版本) Redis 4.0 中提出了一个混合使用 AOF 日志和内存快照的方法。简单来说，内存快照以一定的频率执行，在两次快照之间，使用 AOF 日志记录这期间的所有命令操作。 ","date":"2019-03-02","objectID":"/redis/:3:3","tags":["缓存","大纲"],"title":"Redis概览","uri":"/redis/"},{"categories":["缓存"],"content":"从持久化中恢复数据 流程如下： redis重启时判断是否开启aof，如果开启了aof，那么就优先加载aof文件； 如果aof存在，那么就去加载aof文件，加载成功的话redis重启成功，如果aof文件加载失败，那么会打印日志表示启动失败，此时可以去修复aof文件后重新启动； 若aof文件不存在，那么redis就会转而去加载rdb文件，如果rdb文件不存在，redis直接启动成功； 如果rdb文件存在就会去加载rdb文件恢复数据，如加载失败则打印日志提示启动失败，如加载成功，那么redis重启成功，且使用rdb文件恢复数据； 那么为什么会优先加载AOF呢？因为AOF保存的数据更完整，通过上面的分析我们知道AOF基本上最多损失1s的数据。 ","date":"2019-03-02","objectID":"/redis/:3:4","tags":["缓存","大纲"],"title":"Redis概览","uri":"/redis/"},{"categories":["缓存"],"content":"Redis事务 Redis 事务的本质是一组命令的集合。事务支持一次执行多个命令，一个事务中所有命令都会被序列化。在事务执行过程，会按照顺序串行化执行队列中的命令，其他客户端提交的命令请求不会插入到事务执行命令序列中。 总结说：redis事务就是一次性、顺序性、排他性的执行一个队列中的一系列命令。 ","date":"2019-03-02","objectID":"/redis/:4:0","tags":["缓存","大纲"],"title":"Redis概览","uri":"/redis/"},{"categories":["缓存"],"content":"高可用：主从复制 我们知道要避免单点故障，即保证高可用，便需要冗余（副本. 方式提供集群服务。而Redis 提供了主从库模式，以保证数据副本的一致，主从库之间采用的是读写分离的方式。 主从复制，是指将一台Redis服务器的数据，复制到其他的Redis服务器。前者称为主节点(master)，后者称为从节点(slave)；数据的复制是单向的，只能由主节点到从节点。 读操作：主库、从库都可以接收； 写操作：首先到主库执行，然后，主库将写操作同步给从库。 主从复制的作用主要包括： 数据冗余：主从复制实现了数据的热备份，是持久化之外的一种数据冗余方式。 故障恢复：当主节点出现问题时，可以由从节点提供服务，实现快速的故障恢复；实际上是一种服务的冗余。 负载均衡：在主从复制的基础上，配合读写分离，可以由主节点提供写服务，由从节点提供读服务（即写Redis数据时应用连接主节点，读Redis数据时应用连接从节点. ，分担服务器负载；尤其是在写少读多的场景下，通过多个从节点分担读负载，可以大大提高Redis服务器的并发量。 高可用基石：除了上述作用以外，主从复制还是哨兵和集群能够实施的基础，因此说主从复制是Redis高可用的基础。 ","date":"2019-03-02","objectID":"/redis/:5:0","tags":["缓存","大纲"],"title":"Redis概览","uri":"/redis/"},{"categories":["缓存"],"content":"主从复制原理 全量复制 当我们启动多个 Redis 实例的时候，它们相互之间就可以通过 replicaof（Redis 5.0 之前使用 slaveof. 命令形成主库和从库的关系，之后会按照三个阶段完成数据的第一次同步。 全量复制\" 全量复制 增量复制 增量复制\" 增量复制 ","date":"2019-03-02","objectID":"/redis/:5:1","tags":["缓存","大纲"],"title":"Redis概览","uri":"/redis/"},{"categories":["缓存"],"content":"高可用：哨兵机制（Redis Sentinel） 如果主节点出现故障该怎么办呢？ 在 Redis 主从集群中，哨兵机制是实现主从库自动切换的关键机制，它有效地解决了主从复制模式下故障转移的问题。 主要功能： 监控（Monitoring）：哨兵会不断地检查主节点和从节点是否运作正常。 自动故障转移（Automatic failover）：当主节点不能正常工作时，哨兵会开始自动故障转移操作，它会将失效主节点的其中一个从节点升级为新的主节点，并让其他从节点改为复制新的主节点。 配置提供者（Configuration provider）：客户端在初始化时，通过连接哨兵来获得当前Redis服务的主节点地址。 通知（Notification）：哨兵可以将故障转移的结果发送给客户端。 ","date":"2019-03-02","objectID":"/redis/:6:0","tags":["缓存","大纲"],"title":"Redis概览","uri":"/redis/"},{"categories":["缓存"],"content":"高可拓展：分片技术（Redis Cluster) 主从复制和哨兵机制保障了高可用，就读写分离而言虽然slave节点扩展了主从的读并发能力，但是写能力和存储能力是无法进行扩展，就只能是master节点能够承载的上限。如果面对海量数据那么必然需要构建master（主节点分片)之间的集群，同时必然需要牺牲高可用（主从复制和哨兵机制）能力，即每个master分片节点还需要有slave节点，这是分布式系统中典型的纵向扩展（集群的分片技术）的体现；所以在Redis 3.0版本中对应的设计就是Redis Cluster。 ","date":"2019-03-02","objectID":"/redis/:7:0","tags":["缓存","大纲"],"title":"Redis概览","uri":"/redis/"},{"categories":["缓存"],"content":"方案 事前：Redis 高可用，主从+哨兵，Redis cluster，避免全盘崩溃。 事中：本地 ehcache 缓存 + Hystrix 限流+降级，避免MySQL被打死。 事后：Redis 持久化 RDB+AOF，一旦重启，自动从磁盘上加载数据，快速恢复缓存数据。 ","date":"2019-03-02","objectID":"/redis/:8:0","tags":["缓存","大纲"],"title":"Redis概览","uri":"/redis/"},{"categories":["缓存"],"content":"参考文章 持久化 高可用：主从复制 缓存问题 3种常用的缓存读写策略 缓存那些事 ","date":"2019-03-02","objectID":"/redis/:9:0","tags":["缓存","大纲"],"title":"Redis概览","uri":"/redis/"},{"categories":["缓存"],"content":"Redis","date":"2019-03-01","objectID":"/cache/","tags":["缓存","大纲"],"title":"缓存概览","uri":"/cache/"},{"categories":["缓存"],"content":"缓存问题 Redis最常用的一个场景就是作为缓存，在实践中可能会有哪些问题？比如一致性, 穿击, 穿透, 雪崩, 污染等。 ","date":"2019-03-01","objectID":"/cache/:1:0","tags":["缓存","大纲"],"title":"缓存概览","uri":"/cache/"},{"categories":["缓存"],"content":"缓存穿透 缓存穿透是指缓存和数据库中都没有的数据，而用户不断发起请求。由于缓存是不命中时被动写的，并且出于容错考虑，如果从存储层查不到数据则不写入缓存，这将导致这个不存在的数据每次请求都要到存储层去查询，失去了缓存的意义。 在流量大时，可能DB就挂掉了，要是有人利用不存在的key频繁攻击我们的应用，这就是漏洞。如发起为id为“-1”的数据或id为特别大不存在的数据。这时的用户很可能是攻击者，攻击会导致数据库压力过大。 解决方案： 接口层增加校验，如用户鉴权校验，id做基础校验，id\u003c=0的直接拦截； 从缓存取不到的数据，在数据库中也没有取到，这时也可以将key-value对写为key-null，缓存有效时间可以设置短点，如30秒（设置太长会导致正常情况也没法使用. 。这样可以防止攻击用户反复用同一个id暴力攻击 布隆过滤器。bloomfilter就类似于一个hash set，用于快速判某个元素是否存在于集合中，其典型的应用场景就是快速判断一个key是否存在于某容器，不存在就直接返回。布隆过滤器的关键就在于hash算法和容器大小。 ","date":"2019-03-01","objectID":"/cache/:1:1","tags":["缓存","大纲"],"title":"缓存概览","uri":"/cache/"},{"categories":["缓存"],"content":"缓存击穿 缓存击穿是指缓存中没有但数据库中有的数据（一般是缓存时间到期)，这时由于并发用户特别多，同时读缓存没读到数据，又同时去数据库去取数据，引起数据库压力瞬间增大，造成过大压力。 解决方案 设置热点数据永远不过期。 接口限流与熔断，降级。重要的接口一定要做好限流策略，防止用户恶意刷接口，同时要降级准备，当接口中的某些服务不可用时候，进行熔断，失败快速返回机制。 加互斥锁. ","date":"2019-03-01","objectID":"/cache/:1:2","tags":["缓存","大纲"],"title":"缓存概览","uri":"/cache/"},{"categories":["缓存"],"content":"缓存雪崩 缓存雪崩是指缓存中数据大批量到过期时间，而查询数据量巨大，引起数据库压力过大甚至down机。和缓存击穿不同的是，缓存击穿指并发查同一条数据，缓存雪崩是不同数据都过期了，很多数据都查不到从而查数据库。 解决方案： 缓存数据的过期时间设置随机，防止同一时间大量数据过期现象发生。 如果缓存数据库是分布式部署，将热点数据均匀分布在不同的缓存数据库中。 设置热点数据永远不过期。 ","date":"2019-03-01","objectID":"/cache/:1:3","tags":["缓存","大纲"],"title":"缓存概览","uri":"/cache/"},{"categories":["缓存"],"content":"缓存污染（或满了) 缓存污染问题说的是缓存中一些只会被访问一次或者几次的的数据，被访问完后，再也不会被访问到，但这部分数据依然留存在缓存中，消耗缓存空间。 缓存污染会随着数据的持续增加而逐渐显露，随着服务的不断运行，缓存中会存在大量的永远不会再次被访问的数据。缓存空间是有限的，如果缓存空间满了，再往缓存里写数据时就会有额外开销，影响Redis性能。这部分额外开销主要是指写的时候判断淘汰策略，根据淘汰策略去选择要淘汰的数据，然后进行删除操作。 缓存淘汰策略 不淘汰 noevictionv4.0后默认的。 对设置了过期时间的数据中进行淘汰 随机：volatile-random ttl：volatile-ttl 越早过期的数据越优先被选择。 lru：volatile-lru LRU算法：LRU 算法的全称是 Least Recently Used，按照最近最少使用的原则来筛选数据。这种模式下会使用 LRU 算法筛选设置了过期时间的键值对。 lfu：volatile-lfu LFU 算法：LFU 缓存策略是在 LRU 策略基础上，为每个数据增加了一个计数器，来统计这个数据的访问次数。当使用 LFU 策略筛选淘汰数据时，首先会根据数据的访问次数进行筛选，把访问次数最低的数据淘汰出缓存。如果两个数据的访问次数相同，LFU 策略再比较这两个数据的访问时效性，把距离上一次访问时间更久的数据淘汰出缓存。 全部数据进行淘汰 随机：allkeys-random lru：allkeys-lru lfu：allkeys-lfu ","date":"2019-03-01","objectID":"/cache/:1:4","tags":["缓存","大纲"],"title":"缓存概览","uri":"/cache/"},{"categories":["缓存"],"content":"数据库和缓存一致性 方案：队列 + 重试机制 流程如下所示 更新数据库数据； 缓存因为种种问题删除失败 将需要删除的key发送至消息队列 自己消费消息，获得需要删除的key 继续重试删除操作，直到成功 然而，该方案有一个缺点，对业务线代码造成大量的侵入。于是有了方案二，在方案二中，启动一个订阅程序去订阅数据库的binlog，获得需要操作的数据。在应用程序中，另起一段程序，获得这个订阅程序传来的信息，进行删除缓存操作。 方案：异步更新缓存(基于订阅binlog的同步机制) MySQL binlog增量订阅消费+消息队列+增量数据更新到redis 读Redis：热数据基本都在Redis 写MySQL: 增删改都是操作MySQL 更新Redis数据：MySQL的数据操作binlog，来更新到Redis 读取binlog后分析 ，利用消息队列,推送更新各台的redis缓存数据。 这样一旦MySQL中产生了新的写入、更新、删除等操作，就可以把binlog相关的消息推送至Redis，Redis再根据binlog中的记录，对Redis进行更新。 其实这种机制，很类似MySQL的主从备份机制，因为MySQL的主备也是通过binlog来实现的数据一致性。 这里可以结合使用canal(阿里的一款开源框架)，通过该框架可以对MySQL的binlog进行订阅，而canal正是模仿了mysql的slave数据库的备份请求，使得Redis的数据更新达到了相同的效果。 当然，这里的消息推送工具你也可以采用别的第三方：kafka、rabbitMQ等来实现推送更新Redis。 ","date":"2019-03-01","objectID":"/cache/:1:5","tags":["缓存","大纲"],"title":"缓存概览","uri":"/cache/"},{"categories":["缓存"],"content":"参考文章 缓存那些事 缓存修炼之路 ","date":"2019-03-01","objectID":"/cache/:2:0","tags":["缓存","大纲"],"title":"缓存概览","uri":"/cache/"},{"categories":["MQ"],"content":"Kafka","date":"2019-02-05","objectID":"/mq-kafka/","tags":["MQ","大纲"],"title":"Kafka","uri":"/mq-kafka/"},{"categories":["MQ"],"content":" Kafka 是一个分布式消息引擎与流处理平台，经常用做企业的消息总线、实时数据管道，有的还把它当做存储系统来使用。早期 Kafka 的定位是一个高吞吐的分布式消息系统，目前则演变成了一个成熟的分布式消息引擎，以及流处理平台。 使用消息队列不可能是单机的（必然是分布式or集群） Kafka天然是分布式的，往一个topic丢数据，实际上就是往多个broker的partition存储数据 数据写到消息队列，可能会存在数据丢失问题，数据在消息队列需要持久化 Kafka会将partition以消息日志的方式(落磁盘)存储起来，通过 顺序访问IO和缓存(等到一定的量或时间)才真正把数据写到磁盘上，来提高速度。 想要保证消息（数据）是有序的，怎么做？ Kafka会将数据写到partition，单个partition的写入是有顺序的。如果要保证全局有序，那只能写入一个partition中。如果要消费也有序，消费者也只能有一个。 ","date":"2019-02-05","objectID":"/mq-kafka/:0:0","tags":["MQ","大纲"],"title":"Kafka","uri":"/mq-kafka/"},{"categories":["MQ"],"content":"Kafka术语 Producer：生产者，消息产生和发送端。 Broker：Kafka 实例，多个 broker 组成一个 Kafka 集群，通常一台机器部署一个 Kafka 实例，一个实例挂了不影响其他实例。 Consumer：消费者，拉取消息进行消费。 一个 topic 可以让若干个消费者进行消费，若干个消费者组成一个 Consumer Group 即消费组，一条消息只能被消费组中一个 Consumer 消费。 Topic：主题，服务端消息的逻辑存储单元。一个 topic 通常包含若干个 Partition 分区。 Partition：topic 的分区，分布式存储在各个 broker 中， 实现发布与订阅的负载均衡。若干个分区可以被若干个 Consumer 同时消费，达到消费者高吞吐量。一个分区拥有多个副本（Replica），这是Kafka在可靠性和可用性方面的设计，后面会重点介绍。 message：消息，或称日志消息，是 Kafka 服务端实际存储的数据，每一条消息都由一个 key、一个 value 以及消息时间戳 timestamp 组成。 offset：偏移量，分区中的消息位置，由 Kafka 自身维护，Consumer 消费时也要保存一份 offset 以维护消费过的消息位置。 ","date":"2019-02-05","objectID":"/mq-kafka/:1:0","tags":["MQ","大纲"],"title":"Kafka","uri":"/mq-kafka/"},{"categories":["MQ"],"content":"Kafka特点 高吞吐、低延时：这是 Kafka 显著的特点，Kafka 能够达到百万级的消息吞吐量，延迟可达毫秒级； 持久化存储：Kafka 的消息最终持久化保存在磁盘之上，提供了顺序读写以保证性能，并且通过 Kafka 的副本机制提高了数据可靠性。 分布式可扩展：Kafka 的数据是分布式存储在不同 broker 节点的，以 topic 组织数据并且按 partition 进行分布式存储，整体的扩展性都非常好。 高容错性：集群中任意一个 broker 节点宕机，Kafka 仍能对外提供服务。 ","date":"2019-02-05","objectID":"/mq-kafka/:2:0","tags":["MQ","大纲"],"title":"Kafka","uri":"/mq-kafka/"},{"categories":["MQ"],"content":"Kafka消息发送机制 ","date":"2019-02-05","objectID":"/mq-kafka/:3:0","tags":["MQ","大纲"],"title":"Kafka","uri":"/mq-kafka/"},{"categories":["MQ"],"content":"异步发送 Kafka 自从 0.8.2 版本就引入了新版本 Producer API，新版 Producer 完全是采用异步方式发送消息。生产端构建的 ProducerRecord 先是经过 keySerializer、valueSerializer 序列化后，再是经过 Partition 分区器处理，决定消息落到 topic 具体某个分区中，最后把消息发送到客户端的消息缓冲池 accumulator 中，交由一个叫作 Sender 的线程发送到 broker 端。 这里缓冲池 accumulator 的最大大小由参数 buffer.memory 控制，默认是 32M，当生产消息的速度过快导致 buffer 满了的时候，将阻塞 max.block.ms 时间，超时抛异常，所以 buffer 的大小可以根据实际的业务情况进行适当调整。 ","date":"2019-02-05","objectID":"/mq-kafka/:3:1","tags":["MQ","大纲"],"title":"Kafka","uri":"/mq-kafka/"},{"categories":["MQ"],"content":"批量发送 发送到缓冲 buffer 中消息将会被分为一个一个的 batch，分批次的发送到 broker 端，批次大小由参数 batch.size 控制，默认16KB。这就意味着正常情况下消息会攒够 16KB 时才会批量发送到 broker 端，所以一般减小 batch 大小有利于降低消息延时，增加 batch 大小有利于提升吞吐量。 那么生成端消息是不是必须要达到一个 batch 大小时，才会批量发送到服务端呢？答案是否定的，Kafka 生产端提供了另一个重要参数 linger.ms，该参数控制了 batch 最大的空闲时间，超过该时间的 batch 也会被发送到 broker 端。 ","date":"2019-02-05","objectID":"/mq-kafka/:3:2","tags":["MQ","大纲"],"title":"Kafka","uri":"/mq-kafka/"},{"categories":["MQ"],"content":"消息重试 此外，Kafka 生产端支持重试机制，对于某些原因导致消息发送失败的，比如网络抖动，开启重试后 Producer 会尝试再次发送消息。该功能由参数 retries 控制，参数含义代表重试次数，默认值为 0 表示不重试，建议设置大于 0 比如 3。 ","date":"2019-02-05","objectID":"/mq-kafka/:3:3","tags":["MQ","大纲"],"title":"Kafka","uri":"/mq-kafka/"},{"categories":["MQ"],"content":"Kafka 副本机制 副本机制也称 Replication 机制是 Kafka 实现高可靠、高可用的基础。Kafka 中有 leader 和 follower 两类副本。 ","date":"2019-02-05","objectID":"/mq-kafka/:4:0","tags":["MQ","大纲"],"title":"Kafka","uri":"/mq-kafka/"},{"categories":["MQ"],"content":"Kafka 副本作用 Kafka 默认只会给分区设置一个副本，由 broker 端参数 default.replication.factor 控制，默认值为 1，通常我们会修改该默认值，或者命令行创建 topic 时指定 replication-factor 参数，生产建议设置 3 副本。副本作用主要有两方面： 消息冗余存储，提高 Kafka 数据的可靠性； 提高 Kafka 服务的可用性，follower 副本能够在 leader 副本挂掉或者 broker 宕机的时候参与 leader 选举，继续对外提供读写服务。 ","date":"2019-02-05","objectID":"/mq-kafka/:4:1","tags":["MQ","大纲"],"title":"Kafka","uri":"/mq-kafka/"},{"categories":["MQ"],"content":"关于读写分离 这里要说明的是 Kafka 并不支持读写分区，生产消费端所有的读写请求都是由 leader 副本处理的，follower 副本的主要工作就是从 leader 副本处异步拉取消息，进行消息数据的同步，并不对外提供读写服务。 Kafka 之所以这样设计，主要是为了保证读写一致性，因为副本同步是一个异步的过程，如果当 follower 副本还没完全和 leader 同步时，从 follower 副本读取数据可能会读不到最新的消息。 ","date":"2019-02-05","objectID":"/mq-kafka/:4:2","tags":["MQ","大纲"],"title":"Kafka","uri":"/mq-kafka/"},{"categories":["MQ"],"content":"ISR 副本集合 Kafka 为了维护分区副本的同步，引入 ISR（In-Sync Replicas ）副本集合的概念，ISR 是分区中正在与 leader 副本进行同步的 replica 列表，且必定包含 leader 副本。 ISR 列表是持久化在 Zookeeper 中的，任何在 ISR 列表中的副本都有资格参与 leader 选举。 ISR 列表是动态变化的，并不是所有的分区副本都在 ISR 列表中，哪些副本会被包含在 ISR 列表中呢？副本被包含在 ISR 列表中的条件是由参数 replica.lag.time.max.ms 控制的，参数含义是副本同步落后于 leader 的最大时间间隔，默认10s，意思就是说如果某一 follower 副本中的消息比 leader 延时超过10s，就会被从 ISR 中排除。Kafka 之所以这样设计，主要是为了减少消息丢失，只有与 leader 副本进行实时同步的 follower 副本才有资格参与 leader 选举，这里指相对实时。 ","date":"2019-02-05","objectID":"/mq-kafka/:4:3","tags":["MQ","大纲"],"title":"Kafka","uri":"/mq-kafka/"},{"categories":["MQ"],"content":"Unclean leader 选举 既然 ISR 是动态变化的，所以 ISR 列表就有为空的时候，ISR 为空说明 leader 副本也“挂掉”了，此时 Kafka 就要重新选举出新的 leader。但 ISR 为空，怎么进行 leader 选举呢？ Kafka 把不在 ISR 列表中的存活副本称为“非同步副本”，这些副本中的消息远远落后于 leader，如果选举这种副本作为 leader 的话就可能造成数据丢失。Kafka broker 端提供了一个参数 unclean.leader.election.enable，用于控制是否允许非同步副本参与 leader 选举；如果开启，则当 ISR 为空时就会从这些副本中选举新的 leader，这个过程称为 Unclean leader 选举。 前面也提及了，如果开启 Unclean leader 选举，可能会造成数据丢失，但保证了始终有一个 leader 副本对外提供服务；如果禁用 Unclean leader 选举，就会避免数据丢失，但这时分区就会不可用。这就是典型的 CAP 理论，即一个系统不可能同时满足一致性（Consistency）、可用性（Availability）和分区容错性（Partition Tolerance）中的两个。所以在这个问题上，Kafka 赋予了我们选择 C 或 A 的权利。 我们可以根据实际的业务场景选择是否开启 Unclean leader选举，这里建议关闭 Unclean leader 选举，因为通常数据的一致性要比可用性重要的多。 ","date":"2019-02-05","objectID":"/mq-kafka/:4:4","tags":["MQ","大纲"],"title":"Kafka","uri":"/mq-kafka/"},{"categories":["MQ"],"content":"Kafka控制器 控制器（Controller）是 Kafka 的核心组件，它的主要作用是在 Zookeeper 的帮助下管理和协调整个 Kafka 集群。集群中任意一个 broker 都能充当控制器的角色，但在运行过程中，只能有一个 broker 成为控制器。 这里先介绍下 Zookeeper，因为控制器的产生依赖于 Zookeeper 的 ZNode 模型和 Watcher 机制。Zookeeper 的数据模型是类似 Unix 操作系统的 ZNode Tree 即 ZNode 树，ZNode 是 Zookeeper 中的数据节点，是 Zookeeper 存储数据的最小单元，每个 ZNode 可以保存数据，也可以挂载子节点，根节点是 /。基本的拓扑图如下： Zookeeper 有两类 ZNode 节点，分别是持久性节点和临时节点。持久性节点是指客户端与 Zookeeper 断开会话后，该节点依旧存在，直到执行删除操作才会清除节点。临时节点的生命周期是和客户端的会话绑定在一起，客户端与 Zookeeper 断开会话后，临时节点就会被自动删除。 Watcher 机制是 Zookeeper 非常重要的特性，它可以在 ZNode 节点上绑定监听事件，比如可以监听节点数据变更、节点删除、子节点状态变更等事件，通过这个事件机制，可以基于 ZooKeeper 实现分布式锁、集群管理等功能。 ","date":"2019-02-05","objectID":"/mq-kafka/:5:0","tags":["MQ","大纲"],"title":"Kafka","uri":"/mq-kafka/"},{"categories":["MQ"],"content":"控制器选举 当集群中的任意 broker 启动时，都会尝试去 Zookeeper 中创建 /controller 节点，第一个成功创建 /controller 节点的 broker 则会被指定为控制器，其他 broker 则会监听该节点的变化。当运行中的控制器突然宕机或意外终止时，其他 broker 能够快速地感知到，然后再次尝试创建 /controller 节点，创建成功的 broker 会成为新的控制器。 ","date":"2019-02-05","objectID":"/mq-kafka/:5:1","tags":["MQ","大纲"],"title":"Kafka","uri":"/mq-kafka/"},{"categories":["MQ"],"content":"控制器功能 前面我们也说了，控制器主要作用是管理和协调 Kafka 集群，那么 Kafka 控制器都做了哪些事情呢，具体如下： 主题管理：创建、删除 topic，以及增加 topic 分区等操作都是由控制器执行。 分区重分配：执行 Kafka 的 reassign 脚本对 topic 分区重分配的操作，也是由控制器实现。 Preferred leader 选举：这里有一个概念叫 Preferred replica 即优先副本，表示的是分配副本中的第一个副本。Preferred leader 选举就是指 Kafka 在某些情况下出现 leader 负载不均衡时，会选择 preferred 副本作为新 leader 的一种方案。这也是控制器的职责范围。 集群成员管理：控制器能够监控新 broker 的增加，broker 的主动关闭与被动宕机，进而做其他工作。这里也是利用前面所说的 Zookeeper 的 ZNode 模型和 Watcher 机制，控制器会监听 Zookeeper 中 /brokers/ids 下临时节点的变化。 数据服务：控制器上保存了最全的集群元数据信息，其他所有 broker 会定期接收控制器发来的元数据更新请求，从而更新其内存中的缓存数据。 从上面内容我们大概知道，控制器可以说是 Kafka 的心脏，管理和协调着整个 Kafka 集群，因此控制器自身的性能和稳定性就变得至关重要。 社区在这方面做了大量工作，特别是在 0.11 版本中对控制器进行了重构，其中最大的改进把控制器内部多线程的设计改成了单线程加事件队列的方案，消除了多线程的资源消耗和线程安全问题，另外一个改进是把之前同步操作 Zookeeper 改为了异步操作，消除了 Zookeeper 端的性能瓶颈，大大提升了控制器的稳定性。 ","date":"2019-02-05","objectID":"/mq-kafka/:5:2","tags":["MQ","大纲"],"title":"Kafka","uri":"/mq-kafka/"},{"categories":["MQ"],"content":"Kafka消费端Rebalance机制 就 Kafka 消费端而言，有一个难以避免的问题就是消费者的重平衡即 Rebalance。Rebalance 是让一个消费组的所有消费者就如何消费订阅 topic 的所有分区达成共识的过程，在 Rebalance 过程中，所有 Consumer 实例都会停止消费，等待 Rebalance 的完成。因为要停止消费等待重平衡完成，因此 Rebalance 会严重影响消费端的 TPS，是应当尽量避免的。 ","date":"2019-02-05","objectID":"/mq-kafka/:6:0","tags":["MQ","大纲"],"title":"Kafka","uri":"/mq-kafka/"},{"categories":["MQ"],"content":"Rebalance 发生条件 关于何时会发生 Rebalance，总结起来有三种情况： 消费组的消费者成员数量发生变化 消费主题的数量发生变化 消费主题的分区数量发生变化 其中后两种情况一般是计划内的，比如为了提高消息吞吐量增加 topic 分区数，这些情况一般是不可避免的，后面我们会重点讨论如何避免因为组内消费者成员数发生变化导致的 Rebalance。 ","date":"2019-02-05","objectID":"/mq-kafka/:6:1","tags":["MQ","大纲"],"title":"Kafka","uri":"/mq-kafka/"},{"categories":["MQ"],"content":"Kafka协调器 在介绍如何避免 Rebalance 问题之前，先来认识下 Kafka 的协调器 Coordinator，和之前 Kafka 控制器类似，Coordinator 也是 Kafka 的核心组件。 主要有两类 Kafka 协调器： 组协调器（Group Coordinator） 消费者协调器（Consumer Coordinator） Kafka 为了更好的实现消费组成员管理、位移管理，以及 Rebalance 等，broker 服务端引入了组协调器（Group Coordinator），消费端引入了消费者协调器（Consumer Coordinator）。每个 broker 启动的时候，都会创建一个 GroupCoordinator 实例，负责消费组注册、消费者成员记录、offset 等元数据操作，这里也可以看出每个 broker 都有自己的 Coordinator 组件。另外，每个 Consumer 实例化时，同时会创建一个 ConsumerCoordinator 实例，负责消费组下各个消费者和服务端组协调器之前的通信。可以用下图表示协调器原理： 客户端的消费者协调器 Consumer Coordinator 和服务端的组协调器 Group Coordinator 会通过心跳不断保持通信。 ","date":"2019-02-05","objectID":"/mq-kafka/:6:2","tags":["MQ","大纲"],"title":"Kafka","uri":"/mq-kafka/"},{"categories":["MQ"],"content":"如何避免消费组 Rebalance 接下来我们讨论下如何避免组内消费者成员发生变化导致的 Rebalance。组内成员发生变化无非就两种情况，一种是有新的消费者加入，通常是我们为了提高消费速度增加了消费者数量，比如增加了消费线程或者多部署了一份消费程序，这种情况可以认为是正常的；另一种是有消费者退出，这种情况多是和我们消费端代码有关，是我们要重点避免的。 正常情况下，每个消费者都会定期向组协调器 Group Coordinator 发送心跳，表明自己还在存活，如果消费者不能及时的发送心跳，组协调器会认为该消费者已经“死”了，就会导致消费者离组引发 Rebalance 问题。这里涉及两个消费端参数：session.timeout.ms 和 heartbeat.interval.ms，含义分别是组协调器认为消费组存活的期限，和消费者发送心跳的时间间隔，其中 heartbeat.interval.ms 默认值是3s，session.timeout.ms 在 0.10.1 版本之前默认 30s，之后默认 10s。 另外，0.10.1 版本还有两个值得注意的地方： 从该版本开始，Kafka 维护了单独的心跳线程，之前版本中 Kafka 是使用业务主线程发送的心跳。 增加了一个重要的参数 max.poll.interval.ms，表示 Consumer 两次调用 poll 方法拉取数据的最大时间间隔，默认值 5min，对于那些忙于业务逻辑处理导致超过 max.poll.interval.ms 时间的消费者将会离开消费组，此时将发生一次 Rebalance。 此外，如果 Consumer 端频繁 FullGC 也可能会导致消费端长时间停顿，从而引发 Rebalance。因此，我们总结如何避免消费组 Rebalance 问题，主要从以下几方面入手： 合理配置 session.timeout.ms 和 heartbeat.interval.ms，建议 0.10.1 之前适当调大 session 超时时间尽量规避 Rebalance。 根据实际业务调整 max.poll.interval.ms，通常建议调大避免 Rebalance，但注意 0.10.1 版本之前没有该参数。 监控消费端的 GC 情况，避免由于频繁 FullGC 导致线程长时间停顿引发 Rebalance。 合理调整以上参数，可以减少生产环境中 Rebalance 发生的几率，提升 Consumer 端的 TPS 和稳定性。 ","date":"2019-02-05","objectID":"/mq-kafka/:6:3","tags":["MQ","大纲"],"title":"Kafka","uri":"/mq-kafka/"},{"categories":["MQ"],"content":"常见问题 ","date":"2019-02-05","objectID":"/mq-kafka/:7:0","tags":["MQ","大纲"],"title":"Kafka","uri":"/mq-kafka/"},{"categories":["MQ"],"content":"Kafka 为什么这么快 Kafka 的消息是保存或缓存在磁盘上的，一般认为在磁盘上读写数据是会降低性能的，因为寻址会比较消耗时间，但是实际上，Kafka 的特性之一就是高吞吐率。Kafka 之所以能这么快，无非是：「顺序写磁盘、大量使用内存页 、零拷贝技术的使用」 它把所有的消息都变成一个批量的文件，并且进行合理的批量压缩，减少网络 IO 损耗，通过 mmap 提高 I/O 速度。写入数据的时候由于单个 Partion 是末尾添加，所以速度最优；读取数据的时候配合 Sendfile 直接暴力输出。 ","date":"2019-02-05","objectID":"/mq-kafka/:7:1","tags":["MQ","大纲"],"title":"Kafka","uri":"/mq-kafka/"},{"categories":["MQ"],"content":"参考链接 深入浅出Kafka Kafka分区和副本 Kafka原理和实践 Kafka整理 Kafka为什么快 ","date":"2019-02-05","objectID":"/mq-kafka/:8:0","tags":["MQ","大纲"],"title":"Kafka","uri":"/mq-kafka/"},{"categories":["分布式"],"content":"ZooKeeper","date":"2019-02-04","objectID":"/zookeeper/","tags":["分布式"],"title":"ZooKeeper","uri":"/zookeeper/"},{"categories":["分布式"],"content":"简介 ZooKeeper主要服务于分布式系统，可以用ZooKeeper来做：统一配置管理、统一命名服务、分布式锁、集群管理。 使用分布式系统就无法避免对节点管理的问题(需要实时感知节点的状态、对节点进行统一管理等等)，而由于这些问题处理起来可能相对麻烦和提高了系统的复杂性，ZooKeeper作为一个能够通用解决这些问题的中间件就应运而生了。 ","date":"2019-02-04","objectID":"/zookeeper/:1:0","tags":["分布式"],"title":"ZooKeeper","uri":"/zookeeper/"},{"categories":["分布式"],"content":"ZooKeeper数据结构 ZooKeeper的数据结构，跟Unix文件系统非常类似，可以看做是一颗树，每个节点叫做ZNode。每一个节点可以通过路径来标识，结构图如下： ZooKeeper\" ZooKeeper 那ZooKeeper这颗\"树\"有什么特点呢？？ZooKeeper的节点我们称之为Znode，Znode分为两种类型： 短暂/临时(Ephemeral)：当客户端和服务端断开连接后，所创建的Znode(节点)会自动删除 持久(Persistent)：当客户端和服务端断开连接后，所创建的Znode(节点)不会删除 ","date":"2019-02-04","objectID":"/zookeeper/:2:0","tags":["分布式"],"title":"ZooKeeper","uri":"/zookeeper/"},{"categories":["分布式"],"content":"监听器 在上面我们已经简单知道了ZooKeeper的数据结构了，ZooKeeper还配合了监听器才能够做那么多事的。 常见的监听场景有以下两项： 监听Znode节点的数据变化 监听子节点的增减变化 zookeeperWatch\" zookeeperWatch 通过监听+Znode节点(持久/短暂[临时])，ZooKeeper就可以玩出这么多花样了。 ","date":"2019-02-04","objectID":"/zookeeper/:2:1","tags":["分布式"],"title":"ZooKeeper","uri":"/zookeeper/"},{"categories":["分布式"],"content":"统一配置管理 我们可以将common.yml这份配置放在ZooKeeper的Znode节点中，系统A、B、C监听着这个Znode节点有无变更，如果变更了，及时响应。 zookeeperConfig\" zookeeperConfig ","date":"2019-02-04","objectID":"/zookeeper/:2:2","tags":["分布式"],"title":"ZooKeeper","uri":"/zookeeper/"},{"categories":["分布式"],"content":"统一命名服务 zookeeperNaming\" zookeeperNaming ","date":"2019-02-04","objectID":"/zookeeper/:2:3","tags":["分布式"],"title":"ZooKeeper","uri":"/zookeeper/"},{"categories":["分布式"],"content":"集群管理。 还是以我们三个系统A、B、C为例，在ZooKeeper中创建临时节点即可： zookeeperCluster2\" zookeeperCluster2 只要系统A挂了，那/groupMember/A这个节点就会删除，通过监听groupMember下的子节点，系统B和C就能够感知到系统A已经挂了。(新增也是同理) 除了能够感知节点的上下线变化，ZooKeeper还可以实现动态选举Master的功能。(如果集群是主从架构模式下) 原理也很简单，如果想要实现动态选举Master的功能，Znode节点的类型是带顺序号的临时节点(EPHEMERAL_SEQUENTIAL)就好了。 Zookeeper会每次选举最小编号的作为Master，如果Master挂了，自然对应的Znode节点就会删除。然后让新的最小编号作为Master，这样就可以实现动态选举的功能了。 ","date":"2019-02-04","objectID":"/zookeeper/:2:4","tags":["分布式"],"title":"ZooKeeper","uri":"/zookeeper/"},{"categories":["分布式"],"content":"分布式锁 参考分布式锁 ","date":"2019-02-04","objectID":"/zookeeper/:2:5","tags":["分布式"],"title":"ZooKeeper","uri":"/zookeeper/"},{"categories":["分布式"],"content":"ZooKeeper 的一些重要概念 ZooKeeper 本身就是一个分布式程序（只要半数以上节点存活，ZooKeeper 就能正常服务）。 为了保证高可用，最好是以集群形态来部署 ZooKeeper，这样只要集群中大部分机器是可用的（能够容忍一定的机器故障），那么 ZooKeeper 本身仍然是可用的。 ZooKeeper 将数据保存在内存中，这也就保证了 高吞吐量和低延迟（但是内存限制了能够存储的容量不太大，此限制也是保持znode中存储的数据量较小的进一步原因）。 ZooKeeper 是高性能的。 在“读”多于“写”的应用程序中尤其地高性能，因为“写”会导致所有的服务器间同步状态。（“读”多于“写”是协调服务的典型场景。） ZooKeeper有临时节点的概念。 当创建临时节点的客户端会话一直保持活动，瞬时节点就一直存在。而当会话终结时，瞬时节点被删除。持久节点是指一旦这个ZNode被创建了，除非主动进行ZN 移除操作，否则这个ZNode将一直保存在Zookeeper上。 ZooKeeper 底层其实只提供了两个功能： 管理（存储、读取）用户程序提交的数据； 为用户程序提交数据节点监听服务。 ","date":"2019-02-04","objectID":"/zookeeper/:3:0","tags":["分布式"],"title":"ZooKeeper","uri":"/zookeeper/"},{"categories":["分布式"],"content":"可构建集群 为了保证高可用，最好是以集群形态来部署 ZooKeeper，这样只要集群中大部分机器是可用的（能够容忍一定的机器故障），那么zookeeper本身仍然是可用的。 客户端在使用 ZooKeeper 时，需要知道集群机器列表，通过与集群中的某一台机器建立 TCP 连接来使用服务，客户端使用这个TCP链接来发送请求、获取结果、获取监听事件以及发送心跳包。如果这个连接异常断开了，客户端可以连接到另外的机器上。 ZooKeeper 官方提供的架构图： ZooKeeper\" ZooKeeper 上图中每一个Server代表一个安装Zookeeper服务的服务器。组成 ZooKeeper 服务的服务器都会在内存中维护当前的服务器状态，并且每台服务器之间都互相保持着通信。集群间通过 Zab 协议（Zookeeper Atomic Broadcast）来保持数据的一致性。 ","date":"2019-02-04","objectID":"/zookeeper/:4:0","tags":["分布式"],"title":"ZooKeeper","uri":"/zookeeper/"},{"categories":["分布式"],"content":"ZooKeeper 集群角色介绍 最典型集群模式： Master/Slave 模式（主备模式）。在这种模式中，通常 Master服务器作为主服务器提供写服务，其他的 Slave 服务器从服务器通过异步复制的方式获取 Master 服务器最新的数据提供读服务。 但是，在 ZooKeeper 中没有选择传统的 Master/Slave 概念，而是引入了Leader、Follower 和 Observer 三种角色。如下图所示 ZookeeperCluster\" ZookeeperCluster ZooKeeper 集群中的所有机器通过一个 Leader 选举过程来选定一台称为 “Leader” 的机器，Leader 既可以为客户端提供写服务又能提供读服务。除了 Leader 外，Follower 和 Observer 都只能提供读服务。Follower 和 Observer 唯一的区别在于 Observer 机器不参与 Leader 的选举过程，也不参与写操作的“过半写成功”策略，因此 Observer 机器可以在不影响写性能的情况下提升集群的读性能。 zookeeperRole\" zookeeperRole ","date":"2019-02-04","objectID":"/zookeeper/:5:0","tags":["分布式"],"title":"ZooKeeper","uri":"/zookeeper/"},{"categories":["分布式"],"content":"为什么最好使用奇数台服务器构成 ZooKeeper 集群 我们知道在Zookeeper中 Leader 选举算法采用了Zab协议。Zab核心思想是当多数 Server 写成功，则任务数据写成功。 如果有3个Server，则最多允许1个Server 挂掉。 如果有4个Server，则同样最多允许1个Server挂掉。 既然3个或者4个Server，同样最多允许1个Server挂掉，那么它们的可靠性是一样的，所以选择奇数个ZooKeeper Server即可，这里选择3个Server。 ","date":"2019-02-04","objectID":"/zookeeper/:5:1","tags":["分布式"],"title":"ZooKeeper","uri":"/zookeeper/"},{"categories":["分布式"],"content":"ZooKeeper \u0026ZAB 协议\u0026Paxos算法 Paxos 算法应该可以说是 ZooKeeper 的灵魂了。但是，ZooKeeper 并没有完全采用 Paxos算法 ，而是使用 ZAB 协议作为其保证数据一致性的核心算法。另外，在ZooKeeper的官方文档中也指出，ZAB协议并不像 Paxos 算法那样，是一种通用的分布式一致性算法，它是一种特别为Zookeeper设计的崩溃可恢复的原子消息广播算法。 ","date":"2019-02-04","objectID":"/zookeeper/:6:0","tags":["分布式"],"title":"ZooKeeper","uri":"/zookeeper/"},{"categories":["分布式"],"content":"ZAB 协议介绍 ZAB（ZooKeeper Atomic Broadcast 原子广播） 协议是为分布式协调服务 ZooKeeper 专门设计的一种支持崩溃恢复的原子广播协议。 在 ZooKeeper 中，主要依赖 ZAB 协议来实现分布式数据一致性，基于该协议，ZooKeeper 实现了一种主备模式的系统架构来保持集群中各个副本之间的数据一致性。 ","date":"2019-02-04","objectID":"/zookeeper/:6:1","tags":["分布式"],"title":"ZooKeeper","uri":"/zookeeper/"},{"categories":["分布式"],"content":"ZAB 协议两种基本的模式：崩溃恢复和消息广播 ZAB协议包括两种基本的模式，分别是崩溃恢复和消息广播。当整个服务框架在启动过程中，或是当 Leader 服务器出现网络中断、崩溃退出与重启等异常情况时，ZAB 协议就会进人恢复模式并选举产生新的Leader服务器。当选举产生了新的 Leader 服务器，同时集群中已经有过半的机器与该Leader服务器完成了状态同步之后，ZAB协议就会退出恢复模式。其中，所谓的状态同步是指数据同步，用来保证集群中存在过半的机器能够和Leader服务器的数据状态保持一致。 **当集群中已经有过半的Follower服务器完成了和Leader服务器的状态同步，那么整个服务框架就可以进人消息广播模式了。**当一台同样遵守ZAB协议的服务器启动后加人到集群中时，如果此时集群中已经存在一个Leader服务器在负责进行消息广播，那么新加人的服务器就会自觉地进人数据恢复模式：找到Leader所在的服务器，并与其进行数据同步，然后一起参与到消息广播流程中去。正如上文介绍中所说的，ZooKeeper设计成只允许唯一的一个Leader服务器来进行事务请求的处理。Leader服务器在接收到客户端的事务请求后，会生成对应的事务提案并发起一轮广播协议；而如果集群中的其他机器接收到客户端的事务请求，那么这些非Leader服务器会首先将这个事务请求转发给Leader服务器。 关于 ZAB 协议\u0026Paxos算法 需要讲和理解的东西太多了，说实话，笔主到现在不太清楚这俩兄弟的具体原理和实现过程。推荐阅读下面两篇文章： 图解 Paxos 一致性协议 Zookeeper ZAB 协议分析 关于如何使用 zookeeper 实现分布式锁，可以查看下面这篇文章： Zookeeper ZAB 协议分析 ","date":"2019-02-04","objectID":"/zookeeper/:6:2","tags":["分布式"],"title":"ZooKeeper","uri":"/zookeeper/"},{"categories":["分布式"],"content":"参考文章 zookepper概览 zookepper介绍 阿里巴巴为什么不用 ZooKeeper 做服务发现 ","date":"2019-02-04","objectID":"/zookeeper/:7:0","tags":["分布式"],"title":"ZooKeeper","uri":"/zookeeper/"},{"categories":["MQ"],"content":"RocketMQ","date":"2019-02-03","objectID":"/mq-rocket/","tags":["MQ","大纲"],"title":"RocketMQ","uri":"/mq-rocket/"},{"categories":["MQ"],"content":"特性 支持顺序消息 顺序消息\" 顺序消息 支持事务 事务\" 事务 ","date":"2019-02-03","objectID":"/mq-rocket/:0:1","tags":["MQ","大纲"],"title":"RocketMQ","uri":"/mq-rocket/"},{"categories":["MQ"],"content":"参考链接 RocketMQ 入门教程 ","date":"2019-02-03","objectID":"/mq-rocket/:1:0","tags":["MQ","大纲"],"title":"RocketMQ","uri":"/mq-rocket/"},{"categories":["MQ"],"content":"RabbitMQ","date":"2019-02-02","objectID":"/mq-rabbitmq/","tags":["MQ","大纲"],"title":"RabbitMQ","uri":"/mq-rabbitmq/"},{"categories":["MQ"],"content":"不作为重点 ","date":"2019-02-02","objectID":"/mq-rabbitmq/:0:0","tags":["MQ","大纲"],"title":"RabbitMQ","uri":"/mq-rabbitmq/"},{"categories":["MQ"],"content":"参考链接 ","date":"2019-02-02","objectID":"/mq-rabbitmq/:1:0","tags":["MQ","大纲"],"title":"RabbitMQ","uri":"/mq-rabbitmq/"},{"categories":["MQ"],"content":"消息队列","date":"2019-02-01","objectID":"/mq/","tags":["MQ","大纲"],"title":"消息队列","uri":"/mq/"},{"categories":["MQ"],"content":"概述 消息队列（Message Queue，简称 MQ）是构建分布式互联网应用的基础设施，消息队列已经逐渐成为企业IT系统内部通信的核心手段。它具有低耦合、可靠投递、广播、流量控制、最终一致性等一系列功能，成为异步RPC的主要手段之一。 消息队列应用\" 消息队列应用 ","date":"2019-02-01","objectID":"/mq/:1:0","tags":["MQ","大纲"],"title":"消息队列","uri":"/mq/"},{"categories":["MQ"],"content":"使用场景 ","date":"2019-02-01","objectID":"/mq/:2:0","tags":["MQ","大纲"],"title":"消息队列","uri":"/mq/"},{"categories":["MQ"],"content":"业务解耦 解耦是消息队列要解决的最本质问题。所谓解耦，简单点讲就是一个事务，只关心核心的流程。而需要依赖其他系统但不那么重要的事情，有通知即可，无需等待结果。换句话说，基于消息的模型，关心的是“通知”，而非“处理”。 比如在美团旅游，我们有一个产品中心，产品中心上游对接的是主站、移动后台、旅游供应链等各个数据源；下游对接的是筛选系统、API系统等展示系统。当上游的数据发生变更的时候，如果不使用消息系统，势必要调用我们的接口来更新数据，就特别依赖产品中心接口的稳定性和处理能力。但其实，作为旅游的产品中心，也许只有对于旅游自建供应链，产品中心更新成功才是他们关心的事情。而对于团购等外部系统，产品中心更新成功也好、失败也罢，并不是他们的职责所在。他们只需要保证在信息变更的时候通知到我们就好了。 而我们的下游，可能有更新索引、刷新缓存等一系列需求。对于产品中心来说，这也不是我们的职责所在。说白了，如果他们定时来拉取数据，也能保证数据的更新，只是实时性没有那么强。但使用接口方式去更新他们的数据，显然对于产品中心来说太过于“重量级”了，只需要发布一个产品ID变更的通知，由下游系统来处理，可能更为合理。 再举一个例子，对于我们的订单系统，订单最终支付成功之后可能需要给用户发送短信积分什么的，但其实这已经不是我们系统的核心流程了。如果外部系统速度偏慢（比如短信网关速度不好），那么主流程的时间会加长很多，用户肯定不希望点击支付过好几分钟才看到结果。那么我们只需要通知短信系统“我们支付成功了”，不一定非要等待它处理完成。 ","date":"2019-02-01","objectID":"/mq/:2:1","tags":["MQ","大纲"],"title":"消息队列","uri":"/mq/"},{"categories":["MQ"],"content":"异步处理 多应用对消息队列中同一消息进行处理，应用间并发处理消息，相比串行处理，减少处理时间； ","date":"2019-02-01","objectID":"/mq/:2:2","tags":["MQ","大纲"],"title":"消息队列","uri":"/mq/"},{"categories":["MQ"],"content":"限流削峰，错峰流控 试想上下游对于事情的处理能力是不同的。比如，Web前端每秒承受上千万的请求，并不是什么神奇的事情，只需要加多一点机器，再搭建一些LVS负载均衡设备和Nginx等即可。但数据库的处理能力却十分有限，即使使用SSD加分库分表，单机的处理能力仍然在万级。由于成本的考虑，我们不能奢求数据库的机器数量追上前端。 这种问题同样存在于系统和系统之间，如短信系统可能由于短板效应，速度卡在网关上（每秒几百次请求），跟前端的并发量不是一个数量级。但用户晚上个半分钟左右收到短信，一般是不会有太大问题的。如果没有消息队列，两个系统之间通过协商、滑动窗口等复杂的方案也不是说不能实现。但系统复杂性指数级增长，势必在上游或者下游做存储，并且要处理定时、拥塞等一系列问题。而且每当有处理能力有差距的时候，都需要单独开发一套逻辑来维护这套逻辑。所以，利用中间系统转储两个系统的通信内容，并在下游系统有能力处理这些消息的时候，再处理这些消息，是一套相对较通用的方式。 总而言之，消息队列不是万能的。对于需要强事务保证而且延迟敏感的，RPC是优于消息队列的。 对于一些无关痛痒，或者对于别人非常重要但是对于自己不是那么关心的事情，可以利用消息队列去做。 支持最终一致性的消息队列，能够用来处理延迟不那么敏感的“分布式事务”场景，而且相对于笨重的分布式事务，可能是更优的处理方式。 当上下游系统处理能力存在差距的时候，利用消息队列做一个通用的“漏斗”。在下游有能力处理的时候，再进行分发。 如果下游有很多系统关心你的系统发出的通知的时候，果断地使用消息队列吧。 广泛应用于秒杀或抢购活动中，避免流量过大导致应用系统挂掉的情况； ","date":"2019-02-01","objectID":"/mq/:2:3","tags":["MQ","大纲"],"title":"消息队列","uri":"/mq/"},{"categories":["MQ"],"content":"最终一致性 最终一致性不是消息队列的必备特性，但确实可以依靠消息队列来做最终一致性的事情。 ","date":"2019-02-01","objectID":"/mq/:2:4","tags":["MQ","大纲"],"title":"消息队列","uri":"/mq/"},{"categories":["MQ"],"content":"投递模式 ","date":"2019-02-01","objectID":"/mq/:3:0","tags":["MQ","大纲"],"title":"消息队列","uri":"/mq/"},{"categories":["MQ"],"content":"点对点模式（Point-to-Point， Queue） Point-to-Point，点对点通信模型。PTP是基于队列(Queue)的，一个队列可以有多个生产者，和多个消费者。消息服务器按照收到消息的先后顺序，将消息放到队列中。队列中的每一条消息，只能由一个消费者进行消费，消费之后就会从队列中移除。 ","date":"2019-02-01","objectID":"/mq/:3:1","tags":["MQ","大纲"],"title":"消息队列","uri":"/mq/"},{"categories":["MQ"],"content":"发布/订阅模式（publish/subscribe，topic） 每个消息可以有多个订阅者； 发布者和订阅者之间有时间上的依赖性。针对某个主题（Topic）的订阅者，它必须创建一个订阅者之后，才能消费发布者的消息。 为了消费消息，订阅者需要提前订阅该角色主题，并保持在线运行； ","date":"2019-02-01","objectID":"/mq/:3:2","tags":["MQ","大纲"],"title":"消息队列","uri":"/mq/"},{"categories":["MQ"],"content":"Partition模型 生产者发送消息到某个Topic中时，最终选择其中一个Partition进行发送。你可以将Parition模型中的分区，理解为PTP模型的队列，不同的是，PTP模型中的队列存储的是所有的消息，而每个Partition只会存储部分数据。 对于消息者，此时多了一个消费者组的概念，Paritition会在同一个消费者组下的消费者中进行分配，每个消费者只消费分配给自己的Paritition。上图演示了不同的消费者可能会分配到不同数量的Paritition。 Paritition模式巧妙的将PTP模型和Pub/Sub模型结合在了一起： ","date":"2019-02-01","objectID":"/mq/:3:3","tags":["MQ","大纲"],"title":"消息队列","uri":"/mq/"},{"categories":["MQ"],"content":"Transfer模型 Paritition模型中的消费者组概念很有用，同一个Topic下的消息可以由多个不同业务方进行消费，只要使用不同的消费者组即可，不同消费者组消费到的位置单独记录，互不影响。 但是，Paritition模型还是限制了消费者数量不能多于分区数。 ","date":"2019-02-01","objectID":"/mq/:3:4","tags":["MQ","大纲"],"title":"消息队列","uri":"/mq/"},{"categories":["MQ"],"content":"设计一个简单的消息队列 一般来讲，设计消息队列的整体思路是先build一个整体的数据流,例如producer发送给broker,broker发送给consumer,consumer回复消费确认，broker删除/备份消息等。 利用RPC将数据流串起来。然后考虑RPC的高可用性，尽量做到无状态，方便水平扩展。 之后考虑如何承载消息堆积，然后在合适的时机投递消息，而处理堆积的最佳方式，就是存储，存储的选型需要综合考虑性能/可靠性和开发维护成本等诸多因素。 为了实现广播功能，我们必须要维护消费关系，可以利用zk/config server等保存消费关系。 在完成了上述几个功能后，消息队列基本就实现了。然后我们可以考虑一些高级特性，如可靠投递，事务特性，性能优化等。 下面我们会以设计消息队列时重点考虑的模块为主线，穿插灌输一些消息队列的特性实现方法，来具体分析设计实现一个消息队列时的方方面面。 ","date":"2019-02-01","objectID":"/mq/:4:0","tags":["MQ","大纲"],"title":"消息队列","uri":"/mq/"},{"categories":["MQ"],"content":"RPC通信协议 刚才讲到，所谓消息队列，无外乎两次RPC加一次转储，当然需要消费端最终做消费确认的情况是三次RPC。既然是RPC，就必然牵扯出一系列话题，什么负载均衡啊、服务发现啊、通信协议啊、序列化协议啊，等等。在这一块，我的强烈建议是不要重复造轮子。利用公司现有的RPC框架：Thrift也好，Dubbo也好，或者是其他自定义的框架也好。因为消息队列的RPC，和普通的RPC没有本质区别。当然了，自主利用Memchached或者Redis协议重新写一套RPC框架并非不可（如MetaQ使用了自己封装的Gecko NIO框架，卡夫卡也用了类似的协议）。但实现成本和难度无疑倍增。排除对效率的极端要求，都可以使用现成的RPC框架。 简单来讲，服务端提供两个RPC服务，一个用来接收消息，一个用来确认消息收到。并且做到不管哪个server收到消息和确认消息，结果一致即可。当然这中间可能还涉及跨IDC的服务的问题。这里和RPC的原则是一致的，尽量优先选择本机房投递。你可能会问，如果producer和consumer本身就在两个机房了，怎么办？首先，broker必须保证感知的到所有consumer的存在。其次，producer尽量选择就近的机房就好了。 ","date":"2019-02-01","objectID":"/mq/:4:1","tags":["MQ","大纲"],"title":"消息队列","uri":"/mq/"},{"categories":["MQ"],"content":"高可用 其实所有的高可用，是依赖于RPC和存储的高可用来做的。先来看RPC的高可用，美团的基于MTThrift的RPC框架，阿里的Dubbo等，其本身就具有服务自动发现，负载均衡等功能。而消息队列的高可用，只要保证broker接受消息和确认消息的接口是幂等的，并且consumer的几台机器处理消息是幂等的，这样就把消息队列的可用性，转交给RPC框架来处理了。 那么怎么保证幂等呢？最简单的方式莫过于共享存储。broker多机器共享一个DB或者一个分布式文件/kv系统，则处理消息自然是幂等的。就算有单点故障，其他节点可以立刻顶上。另外failover可以依赖定时任务的补偿，这是消息队列本身天然就可以支持的功能。存储系统本身的可用性我们不需要操太多心，放心大胆的交给DBA们吧！ 对于不共享存储的队列，如Kafka使用分区加主备模式，就略微麻烦一些。需要保证每一个分区内的高可用性，也就是每一个分区至少要有一个主备且需要做数据的同步，关于这块HA的细节，可以参考下篇pull模型消息系统设计。 ","date":"2019-02-01","objectID":"/mq/:4:2","tags":["MQ","大纲"],"title":"消息队列","uri":"/mq/"},{"categories":["MQ"],"content":"服务端承载消息堆积的能力 消息到达服务端如果不经过任何处理就到接收者了，broker就失去了它的意义。为了满足我们错峰/流控/最终可达等一系列需求，把消息存储下来，然后选择时机投递就显得是顺理成章的了。 只是这个存储可以做成很多方式。比如存储在内存里，存储在分布式KV里，存储在磁盘里，存储在数据库里等等。但归结起来，主要有持久化和非持久化两种。 持久化的形式能更大程度地保证消息的可靠性（如断电等不可抗外力），并且理论上能承载更大限度的消息堆积（外存的空间远大于内存）。 但并不是每种消息都需要持久化存储。很多消息对于投递性能的要求大于可靠性的要求，且数量极大（如日志）。这时候，消息不落地直接暂存内存，尝试几次failover，最终投递出去也未尝不可。 市面上的消息队列普遍两种形式都支持。当然具体的场景还要具体结合公司的业务来看。 ","date":"2019-02-01","objectID":"/mq/:4:3","tags":["MQ","大纲"],"title":"消息队列","uri":"/mq/"},{"categories":["MQ"],"content":"存储子系统的选择 我们来看看如果需要数据落地的情况下各种存储子系统的选择。理论上，从速度来看，文件系统\u003e分布式KV（持久化）\u003e分布式文件系统\u003e数据库，而可靠性却截然相反。还是要从支持的业务场景出发作出最合理的选择，如果你们的消息队列是用来支持支付/交易等对可靠性要求非常高，但对性能和量的要求没有这么高，而且没有时间精力专门做文件存储系统的研究，DB是最好的选择。 但是DB受制于IOPS，如果要求单broker 5位数以上的QPS性能，基于文件的存储是比较好的解决方案。整体上可以采用数据文件+索引文件的方式处理，具体这块的设计比较复杂，可以参考下篇的存储子系统设计。 分布式KV（如MongoDB，HBase）等，或者持久化的Redis，由于其编程接口较友好，性能也比较可观，如果在可靠性要求不是那么高的场景，也不失为一个不错的选择。 ","date":"2019-02-01","objectID":"/mq/:4:4","tags":["MQ","大纲"],"title":"消息队列","uri":"/mq/"},{"categories":["MQ"],"content":"消费关系解析 现在我们的消息队列初步具备了转储消息的能力。下面一个重要的事情就是解析发送接收关系，进行正确的消息投递了。 市面上的消息队列定义了一堆让人晕头转向的名词，如JMS 规范中的Topic/Queue，Kafka里面的Topic/Partition/ConsumerGroup，RabbitMQ里面的Exchange等等。抛开现象看本质，无外乎是单播与广播的区别。所谓单播，就是点到点；而广播，是一点对多点。当然，对于互联网的大部分应用来说，组间广播、组内单播是最常见的情形。 消息需要通知到多个业务集群，而一个业务集群内有很多台机器，只要一台机器消费这个消息就可以了。 当然这不是绝对的，很多时候组内的广播也是有适用场景的，如本地缓存的更新等等。另外，消费关系除了组内组间，可能会有多级树状关系。这种情况太过于复杂，一般不列入考虑范围。所以，一般比较通用的设计是支持组间广播，不同的组注册不同的订阅。组内的不同机器，如果注册一个相同的ID，则单播；如果注册不同的ID(如IP地址+端口)，则广播。 至于广播关系的维护，一般由于消息队列本身都是集群，所以都维护在公共存储上，如config server、zookeeper等。维护广播关系所要做的事情基本是一致的: 发送关系的维护。 发送关系变更时的通知。 ","date":"2019-02-01","objectID":"/mq/:4:5","tags":["MQ","大纲"],"title":"消息队列","uri":"/mq/"},{"categories":["MQ"],"content":"队列高级特性设计 ","date":"2019-02-01","objectID":"/mq/:5:0","tags":["MQ","大纲"],"title":"消息队列","uri":"/mq/"},{"categories":["MQ"],"content":"常用消息队列对比 消息队列对比\" 消息队列对比 ","date":"2019-02-01","objectID":"/mq/:6:0","tags":["MQ","大纲"],"title":"消息队列","uri":"/mq/"},{"categories":["MQ"],"content":"常见问题 ","date":"2019-02-01","objectID":"/mq/:7:0","tags":["MQ","大纲"],"title":"消息队列","uri":"/mq/"},{"categories":["MQ"],"content":"消息去重 去重原则：保持幂等性，不管来多少条重复消息，最后处理的结果都一样，需要业务端来实现。 幂等性：就是用户对于同一操作发起的一次请求或者多次请求的结果是一致的，不会因为多次点击而产生了副作用，数据库的结果都是唯一的，不可变的。 去重策略：保证每条消息都有唯一编号(比如唯一流水号)，且保证消息处理成功与去重表的日志同时出现。 幂等性具体方案：强一致性通过DB实现，弱一致性通过Reids实现。 建立一个消息表，拿到这个消息做数据库的insert操作。给这个消息做一个唯一主键或者唯一约束，那么就算出现重复消费的情况，就会导致主键冲突，那么就不再处理这条消息。 ","date":"2019-02-01","objectID":"/mq/:7:1","tags":["MQ","大纲"],"title":"消息队列","uri":"/mq/"},{"categories":["MQ"],"content":"消息丢失 生产者需要处理好Broker的响应，出错情况下利用重试、报警等手段。 Broker需要控制响应的时机，单机情况下是消息刷盘后返回响应，集群多副本情况下，即发送至两个副本及以上的情况下再返回响应。 消费者需要在执行完真正的业务逻辑之后再返回响应给Broker。 但是要注意消息可靠性增强了，性能就下降了，等待消息刷盘、多副本同步后返回都会影响性能。因此还是看业务，例如日志的传输可能丢那么一两条关系不大，因此没必要等消息刷盘再响应。 ","date":"2019-02-01","objectID":"/mq/:7:2","tags":["MQ","大纲"],"title":"消息队列","uri":"/mq/"},{"categories":["MQ"],"content":"消息最终一致性（分布式事务） 消息中间件可以作为用来实现分布式事务的一种手段，但其本身并不提供全局分布式事务的功能。 具体实现主要是用“记录”和“补偿”的方式。在做所有的不确定的事情之前，先把事情记录下来，然后去做不确定的事情，结果可能是：成功、失败或是不确定，“不确定”（例如超时等）可以等价为失败。成功就可以把记录的东西清理掉了，对于失败和不确定，可以依靠定时任务等方式把所有失败的事情重新搞一遍，直到成功为止。 回到刚才的例子，系统在A扣钱成功的情况下，把要给B“通知”这件事记录在库里（为了保证最高的可靠性可以把通知B系统加钱和扣钱成功这两件事维护在一个本地事务里），通知成功则删除这条记录，通知失败或不确定则依靠定时任务补偿性地通知我们，直到我们把状态更新成正确的为止。 整个这个模型依然可以基于RPC来做，但可以抽象成一个统一的模型，基于消息队列来做一个“企业总线”。 具体来说，本地事务维护业务变化和通知消息，一起落地（失败则一起回滚），然后RPC到达broker，在broker成功落地后，RPC返回成功，本地消息可以删除。否则本地消息一直靠定时任务轮询不断重发，这样就保证了消息可靠落地broker。 broker往consumer发送消息的过程类似，一直发送消息，直到consumer发送消费成功确认。 我们先不理会重复消息的问题，通过两次消息落地加补偿，下游是一定可以收到消息的。然后依赖状态机版本号等方式做判重，更新自己的业务，就实现了最终一致性。 ","date":"2019-02-01","objectID":"/mq/:7:3","tags":["MQ","大纲"],"title":"消息队列","uri":"/mq/"},{"categories":["MQ"],"content":"参考文章 消息队列设计精要 消息队列选型对比 ","date":"2019-02-01","objectID":"/mq/:8:0","tags":["MQ","大纲"],"title":"消息队列","uri":"/mq/"},{"categories":["Java基础"],"content":"JVM详解","date":"2018-05-01","objectID":"/jvm/","tags":["JVM","大纲"],"title":"JVM详解","uri":"/jvm/"},{"categories":["Java基础"],"content":"JVM概览\" JVM概览 ","date":"2018-05-01","objectID":"/jvm/:0:0","tags":["JVM","大纲"],"title":"JVM详解","uri":"/jvm/"},{"categories":["Java基础"],"content":"Class文件的结构属性 类的结构\" 类的结构 ","date":"2018-05-01","objectID":"/jvm/:1:0","tags":["JVM","大纲"],"title":"JVM详解","uri":"/jvm/"},{"categories":["Java基础"],"content":"Java类加载机制 ","date":"2018-05-01","objectID":"/jvm/:2:0","tags":["JVM","大纲"],"title":"JVM详解","uri":"/jvm/"},{"categories":["Java基础"],"content":"类的生命周期 类的生命周期\" 类的生命周期 ","date":"2018-05-01","objectID":"/jvm/:2:1","tags":["JVM","大纲"],"title":"JVM详解","uri":"/jvm/"},{"categories":["Java基础"],"content":"类加载器 启动类加载器: Bootstrap ClassLoader，负责加载存放在JDK\\jre\\lib(JDK代表JDK的安装目录，下同)下，或被-Xbootclasspath参数指定的路径中的，并且能被虚拟机识别的类库(如rt.jar，所有的java.*开头的类均被Bootstrap ClassLoader加载)。启动类加载器是无法被Java程序直接引用的。 扩展类加载器: Extension ClassLoader，该加载器由sun.misc.Launcher$ExtClassLoader实现，它负责加载JDK\\jre\\lib\\ext目录中，或者由java.ext.dirs系统变量指定的路径中的所有类库(如javax.*开头的类)，开发者可以直接使用扩展类加载器。 应用程序类加载器: Application ClassLoader，该类加载器由sun.misc.Launcher$AppClassLoader来实现，它负责加载用户类路径(ClassPath)所指定的类，开发者可以直接使用该类加载器，如果应用程序中没有自定义过自己的类加载器，一般情况下这个就是程序中默认的类加载器。 ","date":"2018-05-01","objectID":"/jvm/:2:2","tags":["JVM","大纲"],"title":"JVM详解","uri":"/jvm/"},{"categories":["Java基础"],"content":"JVM类加载机制 全盘负责，当一个类加载器负责加载某个Class时，该Class所依赖的和引用的其他Class也将由该类加载器负责载入，除非显示使用另外一个类加载器来载入 父类委托，先让父类加载器试图加载该类，只有在父类加载器无法加载该类时才尝试从自己的类路径中加载该类 缓存机制，缓存机制将会保证所有加载过的Class都会被缓存，当程序中需要使用某个Class时，类加载器先从缓存区寻找该Class，只有缓存区不存在，系统才会读取该类对应的二进制数据，并将其转换成Class对象，存入缓存区。这就是为什么修改了Class后，必须重启JVM，程序的修改才会生效 双亲委派机制, 如果一个类加载器收到了类加载的请求，它首先不会自己去尝试加载这个类，而是把请求委托给父加载器去完成，依次向上，因此，所有的类加载请求最终都应该被传递到顶层的启动类加载器中，只有当父加载器在它的搜索范围中没有找到所需的类时，即无法完成该加载，子加载器才会尝试自己去加载该类。 ","date":"2018-05-01","objectID":"/jvm/:2:3","tags":["JVM","大纲"],"title":"JVM详解","uri":"/jvm/"},{"categories":["Java基础"],"content":"JVM 内存结构 JVM内存结构\" JVM内存结构 栈是运行时的单位，而堆是存储的单位。（栈解决程序的运行问题，即程序如何执行，或者说如何处理数据。堆解决的是数据存储的问题，即数据怎么放、放在哪。） Java虚拟机栈用于管理Java方法的调用，而本地方法栈用于管理本地方法的调用。 ","date":"2018-05-01","objectID":"/jvm/:3:0","tags":["JVM","大纲"],"title":"JVM详解","uri":"/jvm/"},{"categories":["Java基础"],"content":"程序计数器 它是一块很小的内存空间，几乎可以忽略不计。也是运行速度最快的存储区域 在 JVM 规范中，每个线程都有它自己的程序计数器，是线程私有的，生命周期与线程的生命周期一致 任何时间一个线程都只有一个方法在执行，也就是所谓的当前方法。如果当前线程正在执行的是 Java 方法，程序计数器记录的是 JVM 字节码指令地址，如果是执行 native 方法，则是未指定值（undefined） 它是程序控制流的指示器，分支、循环、跳转、异常处理、线程恢复等基础功能都需要依赖这个计数器来完成 字节码解释器工作时就是通过改变这个计数器的值来选取下一条需要执行的字节码指令 它是唯一一个在 JVM 规范中没有规定任何 OutOfMemoryError 情况的区域 ","date":"2018-05-01","objectID":"/jvm/:3:1","tags":["JVM","大纲"],"title":"JVM详解","uri":"/jvm/"},{"categories":["Java基础"],"content":"虚拟机栈 是线程私有的，生命周期和线程一致。 主管 Java 程序的运行，它保存方法的局部变量、部分结果，并参与方法的调用和返回。 栈是一种快速有效的分配存储方式，访问速度仅次于程序计数器。 JVM 直接对虚拟机栈的操作只有两个：每个方法执行，伴随着入栈（进栈/压栈），方法执行结束出栈。 栈不存在垃圾回收问题。 ","date":"2018-05-01","objectID":"/jvm/:3:2","tags":["JVM","大纲"],"title":"JVM详解","uri":"/jvm/"},{"categories":["Java基础"],"content":"本地方法栈 Java 虚拟机栈用于管理 Java 方法的调用，而本地方法栈用于管理本地方法的调用 本地方法栈也是线程私有的 允许线程固定或者可动态扩展的内存大小 如果线程请求分配的栈容量超过本地方法栈允许的最大容量，Java 虚拟机将会抛出一个 StackOverflowError 异常 如果本地方法栈可以动态扩展，并且在尝试扩展的时候无法申请到足够的内存，或者在创建新的线程时没有足够的内存去创建对应的本地方法栈，那么 Java虚拟机将会抛出一个OutofMemoryError异常 本地方法是使用 C 语言实现的 它的具体做法是 Native Method Stack 中登记 native 方法，在 Execution Engine 执行时加载本地方法库当某个线程调用一个本地方法时，它就进入了一个全新的并且不再受虚拟机限制的世界。它和虚拟机拥有同样的权限。 本地方法可以通过本地方法接口来访问虚拟机内部的运行时数据区，它甚至可以直接使用本地处理器中的寄存器，直接从本地内存的堆中分配任意数量的内存 并不是所有 JVM 都支持本地方法。因为 Java 虚拟机规范并没有明确要求本地方法栈的使用语言、具体实现方式、数据结构等。 如果 JVM 产品不打算支持 native 方法，也可以无需实现本地方法栈 在 Hotspot JVM 中，直接将本地方法栈和虚拟机栈合二为一 ","date":"2018-05-01","objectID":"/jvm/:3:3","tags":["JVM","大纲"],"title":"JVM详解","uri":"/jvm/"},{"categories":["Java基础"],"content":"堆内存 为了进行高效的垃圾回收，虚拟机把堆内存逻辑上划分成三块区域（分代的唯一理由就是优化 GC 性能）： 新生带（年轻代）：新对象和没达到一定年龄的对象都在新生代 老年代（养老区）：被长时间使用的对象，老年代的内存空间应该要比年轻代更大 元空间（JDK1.8 之前叫永久代）：像一些方法中的操作临时对象等，JDK1.8 之前是占用 JVM 内存，JDK1.8 之后直接使用物理内存 年轻代 年轻代是所有新对象创建的地方。当填充年轻代时，执行垃圾收集。这种垃圾收集称为 Minor GC。年轻一代被分为三个部分——伊甸园（Eden Memory）和两个幸存区（Survivor Memory，被称为from/to或s0/s1），默认比例是8:1:1 大多数新创建的对象都位于 Eden 内存空间中 当 Eden 空间被对象填充时，执行Minor GC，并将所有幸存者对象移动到一个幸存者空间中 Minor GC 检查幸存者对象，并将它们移动到另一个幸存者空间。所以每次，一个幸存者空间总是空的 经过多次 GC 循环后存活下来的对象被移动到老年代。通常，这是通过设置年轻一代对象的年龄阈值来实现的，然后他们才有资格提升到老一代 老年代 旧的一代内存包含那些经过许多轮小型 GC 后仍然存活的对象。通常，垃圾收集是在老年代内存满时执行的。老年代垃圾收集称为 主GC（Major GC），通常需要更长的时间。 大对象直接进入老年代（大对象是指需要大量连续内存空间的对象）。这样做的目的是避免在 Eden 区和两个Survivor 区之间发生大量的内存拷贝 堆内存空间\" 堆内存空间 ","date":"2018-05-01","objectID":"/jvm/:3:4","tags":["JVM","大纲"],"title":"JVM详解","uri":"/jvm/"},{"categories":["Java基础"],"content":"元空间\u0026方法区 方法区（method area）只是 JVM 规范中定义的一个概念，用于存储类信息、常量池、静态变量、JIT编译后的代码等数据，并没有规定如何去实现它，不同的厂商有不同的实现。而永久代（PermGen）是 Hotspot 虚拟机特有的概念， Java8 的时候又被元空间取代了，永久代和元空间都可以理解为方法区的落地实现。 永久代物理是堆的一部分，和新生代，老年代地址是连续的（受垃圾回收器管理），而元空间存在于本地内存（我们常说的堆外内存，不受垃圾回收器管理），这样就不受 JVM 限制了，也比较难发生OOM（都会有溢出异常） Java7 中我们通过-XX:PermSize 和 -xx:MaxPermSize 来设置永久代参数，Java8 之后，随着永久代的取消，这些参数也就随之失效了，改为通过-XX:MetaspaceSize 和 -XX:MaxMetaspaceSize 用来设置元空间参数 存储内容不同，元空间存储类的元信息，静态变量和常量池等并入堆中。相当于永久代的数据被分到了堆和元空间中 如果方法区域中的内存不能用于满足分配请求，则 Java 虚拟机抛出 OutOfMemoryError JVM 规范说方法区在逻辑上是堆的一部分，但目前实际上是与 Java 堆分开的（Non-Heap） 所以对于方法区，Java8 之后的变化： 移除了永久代（PermGen），替换为元空间（Metaspace）； 永久代中的 class metadata 转移到了 native memory（本地内存，而不是虚拟机）； 永久代中的 interned Strings 和 class static variables 转移到了 Java heap； 永久代参数 （PermSize MaxPermSize） -\u003e 元空间参数（MetaspaceSize MaxMetaspaceSize 对象在堆中的生命周期 在 JVM 内存模型的堆中，堆被划分为新生代和老年代 新生代又被进一步划分为 Eden区 和 Survivor区，Survivor 区由 From Survivor 和 To Survivor 组成 当创建一个对象时，对象会被优先分配到新生代的 Eden 区 此时 JVM 会给对象定义一个对象年轻计数器（-XX:MaxTenuringThreshold） 当 Eden 空间不足时，JVM 将执行新生代的垃圾回收（Minor GC） JVM 会把存活的对象转移到 Survivor 中，并且对象年龄 +1 对象在 Survivor 中同样也会经历 Minor GC，每经历一次 Minor GC，对象年龄都会+1 如果分配的对象超过了-XX:PetenureSizeThreshold，对象会直接被分配到老年代 对象的分配过程 为对象分配内存是一件非常严谨和复杂的任务，JVM 的设计者们不仅需要考虑内存如何分配、在哪里分配等问题，并且由于内存分配算法和内存回收算法密切相关，所以还需要考虑 GC 执行完内存回收后是否会在内存空间中产生内存碎片。 new 的对象先放在伊甸园区，此区有大小限制 当伊甸园的空间填满时，程序又需要创建对象，JVM 的垃圾回收器将对伊甸园区进行垃圾回收（Minor GC），将伊甸园区中的不再被其他对象所引用的对象进行销毁。再加载新的对象放到伊甸园区 然后将伊甸园中的剩余对象移动到幸存者 0 区 如果再次触发垃圾回收，此时上次幸存下来的放到幸存者 0 区，如果没有回收，就会放到幸存者 1 区 如果再次经历垃圾回收，此时会重新放回幸存者 0 区，接着再去幸存者 1 区 什么时候才会去养老区呢？ 默认是 15 次回收标记 在养老区，相对悠闲。当养老区内存不足时，再次触发 Major GC，进行养老区的内存清理 若养老区执行了 Major GC 之后发现依然无法进行对象的保存，就会产生 OOM 异常 ","date":"2018-05-01","objectID":"/jvm/:3:5","tags":["JVM","大纲"],"title":"JVM详解","uri":"/jvm/"},{"categories":["Java基础"],"content":"JVM内存模型(JMM) Java内存模型，其实是保证了Java程序在各种平台下对内存的访问都能够得到一致效果的机制及规范。目的是解决由于多线程通过共享内存进行通信时，存在的原子性、可见性（缓存一致性）以及有序性问题。 ","date":"2018-05-01","objectID":"/jvm/:4:0","tags":["JVM","大纲"],"title":"JVM详解","uri":"/jvm/"},{"categories":["Java基础"],"content":"并发编程模型的分类 在并发编程中，我们需要处理两个关键问题：线程之间如何通信及线程之间如何同步（这里的线程是指并发执行的活动实体）。通信是指线程之间以何种机制来交换信息。在命令式编程中，线程之间的通信机制有两种：共享内存和消息传递。 在共享内存的并发模型里，线程之间共享程序的公共状态，线程之间通过写 - 读内存中的公共状态来隐式进行通信。在消息传递的并发模型里，线程之间没有公共状态，线程之间必须通过明确的发送消息来显式进行通信。 同步是指程序用于控制不同线程之间操作发生相对顺序的机制。在共享内存并发模型里，同步是显式进行的。程序员必须显式指定某个方法或某段代码需要在线程之间互斥执行。在消息传递的并发模型里，由于消息的发送必须在消息的接收之前，因此同步是隐式进行的。 Java 的并发采用的是共享内存模型，Java 线程之间的通信总是隐式进行，整个通信过程对程序员完全透明。如果编写多线程程序的 Java 程序员不理解隐式进行的线程之间通信的工作机制，很可能会遇到各种奇怪的内存可见性问题。 ","date":"2018-05-01","objectID":"/jvm/:4:1","tags":["JVM","大纲"],"title":"JVM详解","uri":"/jvm/"},{"categories":["Java基础"],"content":"Java 内存模型的抽象 JMM 通过控制主内存与每个线程的本地内存之间的交互，来为 java 程序员提供内存可见性保证。 Java 线程之间的通信由 Java 内存模型（本文简称为 JMM）控制，JMM 决定一个线程对共享变量的写入何时对另一个线程可见。从抽象的角度来看，JMM 定义了线程和主内存之间的抽象关系：线程之间的共享变量存储在主内存（main memory）中，每个线程都有一个私有的本地内存（local memory），本地内存中存储了该线程以读 / 写共享变量的副本。本地内存是 JMM 的一个抽象概念，并不真实存在。它涵盖了缓存，写缓冲区，寄存器以及其他的硬件和编译器优化。Java内存模型的抽象示意图如下： Java内存模型的抽象示意图\" Java内存模型的抽象示意图 ","date":"2018-05-01","objectID":"/jvm/:4:2","tags":["JVM","大纲"],"title":"JVM详解","uri":"/jvm/"},{"categories":["Java基础"],"content":"重排序 在执行程序时为了提高性能，编译器和处理器常常会对指令做重排序。重排序分三种类型： 编译器优化的重排序。编译器在不改变单线程程序语义的前提下，可以重新安排语句的执行顺序。 指令级并行的重排序。现代处理器采用了指令级并行技术（Instruction-Level Parallelism， ILP）来将多条指令重叠执行。如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序。 内存系统的重排序。由于处理器使用缓存和读 / 写缓冲区，这使得加载和存储操作看上去可能是在乱序执行。 从 java 源代码到最终实际执行的指令序列，会分别经历下面三种重排序： JMM指令重排序\" JMM指令重排序 上述的 1 属于编译器重排序，2 和 3 属于处理器重排序。这些重排序都可能会导致多线程程序出现内存可见性问题。对于编译器，JMM 的编译器重排序规则会禁止特定类型的编译器重排序（不是所有的编译器重排序都要禁止）。对于处理器重排序，JMM 的处理器重排序规则会要求 java 编译器在生成指令序列时，插入特定类型的内存屏障（memory barriers，intel 称之为 memory fence）指令，通过内存屏障指令来禁止特定类型的处理器重排序（不是所有的处理器重排序都要禁止）。 JMM属于语言级的内存模型，它确保在不同的编译器和不同的处理器平台之上，通过禁止特定类型的编译器重排序和处理器重排序，为程序员提供一致的内存可见性保证。 ","date":"2018-05-01","objectID":"/jvm/:4:3","tags":["JVM","大纲"],"title":"JVM详解","uri":"/jvm/"},{"categories":["Java基础"],"content":"处理器重排序与内存屏障指令 为了保证内存可见性，java编译器在生成指令序列的适当位置会插入内存屏障指令来禁止特定类型的处理器重排序。 StoreLoad Barriers 是一个“全能型”的屏障，它同时具有其他三个屏障的效果。现代的多处理器大都支持该屏障（其他类型的屏障不一定被所有处理器支持）。执行该屏障开销会很昂贵，因为当前处理器通常要把写缓冲区中的数据全部刷新到内存中（buffer fully flush）。 ","date":"2018-05-01","objectID":"/jvm/:4:4","tags":["JVM","大纲"],"title":"JVM详解","uri":"/jvm/"},{"categories":["Java基础"],"content":"happens-before 从 JDK5 开始，java 使用新的 JSR -133 内存模型（本文除非特别说明，针对的都是 JSR- 133 内存模型）。JSR-133 提出了 happens-before 的概念，通过这个概念来阐述操作之间的内存可见性。如果一个操作执行的结果需要对另一个操作可见，那么这两个操作之间必须存在 happens-before 关系。这里提到的两个操作既可以是在一个线程之内，也可以是在不同线程之间。 与程序员密切相关的 happens-before 规则如下： 程序顺序规则：一个线程中的每个操作，happens- before 于该线程中的任意后续操作。 监视器锁规则：对一个监视器锁的解锁，happens- before 于随后对这个监视器锁的加锁。 volatile 变量规则：对一个 volatile 域的写，happens- before 于任意后续对这个 volatile 域的读。 传递性：如果 A happens- before B，且 B happens- before C，那么 A happens- before C。 ","date":"2018-05-01","objectID":"/jvm/:4:5","tags":["JVM","大纲"],"title":"JVM详解","uri":"/jvm/"},{"categories":["Java基础"],"content":"Java垃圾回收 ","date":"2018-05-01","objectID":"/jvm/:5:0","tags":["JVM","大纲"],"title":"JVM详解","uri":"/jvm/"},{"categories":["Java基础"],"content":"判断一个对象是否可被回收 引用计数算法 给对象添加一个引用计数器，当对象增加一个引用时计数器加 1，引用失效时计数器减 1。引用计数为 0 的对象可被回收。 两个对象出现循环引用的情况下，此时引用计数器永远不为 0，导致无法对它们进行回收。 正因为循环引用的存在，因此 Java 虚拟机不使用引用计数算法。 可达性分析算法 通过 GC Roots 作为起始点进行搜索，能够到达到的对象都是存活的，不可达的对象可被回收，Java 虚拟机使用该算法来判断对象是否可被回收，在 Java 中 GC Roots 一般包含以下内容: 虚拟机栈中引用的对象 本地方法栈中引用的对象 方法区中类静态属性引用的对象 方法区中的常量引用的对象 方法区的回收 因为方法区主要存放永久代对象，而永久代对象的回收率比新生代低很多，因此在方法区上进行回收性价比不高。 主要是对常量池的回收和对类的卸载，在大量使用反射、动态代理、CGLib 等 ByteCode 框架、动态生成 JSP 以及 OSGi 这类频繁自定义 ClassLoader 的场景都需要虚拟机具备类卸载功能，以保证不会出现内存溢出。 类的卸载条件很多，需要满足以下三个条件，并且满足了也不一定会被卸载: 该类所有的实例都已经被回收，也就是堆中不存在该类的任何实例。 加载该类的 ClassLoader 已经被回收。 该类对应的 Class 对象没有在任何地方被引用，也就无法在任何地方通过反射访问该类方法。 finalize() finalize() 类似 C++ 的析构函数，用来做关闭外部资源等工作。但是 try-finally 等方式可以做的更好，并且该方法运行代价高昂，不确定性大，无法保证各个对象的调用顺序，因此最好不要使用。 当一个对象可被回收时，如果需要执行该对象的 finalize() 方法，那么就有可能通过在该方法中让对象重新被引用，从而实现自救。自救只能进行一次，如果回收的对象之前调用了 finalize() 方法自救，后面回收时不会调用 finalize() 方法。 ","date":"2018-05-01","objectID":"/jvm/:5:1","tags":["JVM","大纲"],"title":"JVM详解","uri":"/jvm/"},{"categories":["Java基础"],"content":"垃圾回收算法 标记 - 清除 将存活的对象进行标记，然后清理掉未被标记的对象。 不足: 标记和清除过程效率都不高； 会产生大量不连续的内存碎片，导致无法给大对象分配内存。 标记 - 整理 让所有存活的对象都向一端移动，然后直接清理掉端边界以外的内存。 复制 将内存划分为大小相等的两块，每次只使用其中一块，当这一块内存用完了就将还存活的对象复制到另一块上面，然后再把使用过的内存空间进行一次清理。 主要不足是只使用了内存的一半。 现在的商业虚拟机都采用这种收集算法来回收新生代，但是并不是将新生代划分为大小相等的两块，而是分为一块较大的 Eden 空间和两块较小的 Survivor 空间，每次使用 Eden 空间和其中一块 Survivor。在回收时，将 Eden 和 Survivor 中还存活着的对象一次性复制到另一块 Survivor 空间上，最后清理 Eden 和使用过的那一块 Survivor。 HotSpot 虚拟机的 Eden 和 Survivor 的大小比例默认为 8:1，保证了内存的利用率达到 90%。如果每次回收有多于 10% 的对象存活，那么一块 Survivor 空间就不够用了，此时需要依赖于老年代进行分配担保，也就是借用老年代的空间存储放不下的对象。 分代收集 现在的商业虚拟机采用分代收集算法，它根据对象存活周期将内存划分为几块，不同块采用适当的收集算法。 一般将堆分为新生代和老年代。 新生代使用: 复制算法 老年代使用: 标记 - 清除 或者 标记 - 整理 算法 ","date":"2018-05-01","objectID":"/jvm/:5:2","tags":["JVM","大纲"],"title":"JVM详解","uri":"/jvm/"},{"categories":["Java基础"],"content":"垃圾收集器 垃圾收集器\" 垃圾收集器 垃圾收集器对比\" 垃圾收集器对比 ","date":"2018-05-01","objectID":"/jvm/:5:3","tags":["JVM","大纲"],"title":"JVM详解","uri":"/jvm/"},{"categories":["Java基础"],"content":"内存分配与回收策略 Minor GC 和 Full GC Minor GC: 发生在新生代上，因为新生代对象存活时间很短，因此 Minor GC 会频繁执行，执行的速度一般也会比较快。 Full GC: 发生在老年代上，老年代对象其存活时间长，因此 Full GC 很少执行，执行速度会比 Minor GC 慢很多。 针对 HotSpot VM 的实现，它里面的 GC 按照回收区域又分为两大类：部分收集（Partial GC），整堆收集（Full GC） 部分收集：不是完整收集整个 Java 堆的垃圾收集。其中又分为： 新生代收集（Minor GC/Young GC）：只是新生代的垃圾收集 老年代收集（Major GC/Old GC）：只是老年代的垃圾收集 目前，只有 CMS GC 会有单独收集老年代的行为 很多时候 Major GC 会和 Full GC 混合使用，需要具体分辨是老年代回收还是整堆回收 混合收集（Mixed GC）：收集整个新生代以及部分老年代的垃圾收集 目前只有 G1 GC 会有这种行为 整堆收集（Full GC）：收集整个 Java 堆和方法区的垃圾 内存分配策略 对象优先在 Eden 分配 大对象直接进入老年代 长期存活的对象进入老年代 动态对象年龄判定 空间分配担保 ","date":"2018-05-01","objectID":"/jvm/:5:4","tags":["JVM","大纲"],"title":"JVM详解","uri":"/jvm/"},{"categories":["Java基础"],"content":"JVM 调优参数 ","date":"2018-05-01","objectID":"/jvm/:6:0","tags":["JVM","大纲"],"title":"JVM详解","uri":"/jvm/"},{"categories":["Java基础"],"content":"JVM参数 -Xms 堆最小值 -Xmx 堆最大堆值。-Xms与-Xmx 的单位默认字节都是以k、m做单位的。 通常这两个配置参数相等，避免每次空间不足，动态扩容带来的影响。 -Xmn 新生代大小 -Xss 每个线程池的堆栈大小。 在jdk5以上的版本，每个线程堆栈大小为1m，jdk5以前的版本是每个线程池大小为256k。一般在相同物理内存下，如果减少－xss值会产生更大的线程数，但不同的操作系统对进程内线程数是有限制的，是不能无限生成。 -XX:NewRatio 设置新生代与老年代比值，-XX:NewRatio=4 表示新生代与老年代所占比例为1:4 ，新生代占比整个堆的五分之一。如果设置了-Xmn的情况下，该参数是不需要在设置的。 -XX:PermSize 设置持久代初始值，默认是物理内存的六十四分之一 -XX:MaxPermSize 设置持久代最大值，默认是物理内存的四分之一 -XX:MaxTenuringThreshold 新生代中对象存活次数，默认15。(若对象在eden区，经历一次MinorGC后还活着，则被移动到Survior区，年龄加1。以后，对象每次经历MinorGC，年龄都加1。达到阀值，则移入老年代) -XX:SurvivorRatio Eden区与Subrvivor区大小的比值，如果设置为8，两个Subrvivor区与一个Eden区的比值为2:8，一个Survivor区占整个新生代的十分之一 -XX:+UseFastAccessorMethods 原始类型快速优化 -XX:+AggressiveOpts 编译速度加快 -XX:PretenureSizeThreshold 对象超过多大值时直接在老年代中分配 ","date":"2018-05-01","objectID":"/jvm/:6:1","tags":["JVM","大纲"],"title":"JVM详解","uri":"/jvm/"},{"categories":["Java基础"],"content":"最佳实践 Xmn用于设置新生代的大小。过小会增加Minor GC频率，过大会减小老年代的大小。一般设为整个堆空间的1/4或1/3. XX:SurvivorRatio用于设置新生代中survivor空间(from/to)和eden空间的大小比例；XX:TargetSurvivorRatio表示，当经历Minor GC后，survivor空间占有量(百分比)超过它的时候，就会压缩进入老年代(当然，如果survivor空间不够，则直接进入老年代)。默认值为50%。 为了性能考虑，一开始尽量将新生代对象留在新生代，避免新生的大对象直接进入老年代。因为新生对象大部分都是短期的，这就造成了老年代的内存浪费，并且回收代价也高(Full GC发生在老年代和方法区Perm) 当Xms=Xmx，可以使得堆相对稳定，避免不停震荡 一般来说，MaxPermSize设为64MB可以满足绝大多数的应用了。若依然出现方法区溢出，则可以设为128MB。若128MB还不能满足需求，那么就应该考虑程序优化了，减少动态类的产生。 ","date":"2018-05-01","objectID":"/jvm/:6:2","tags":["JVM","大纲"],"title":"JVM详解","uri":"/jvm/"},{"categories":["Java基础"],"content":"JVM分析和问题排查 ","date":"2018-05-01","objectID":"/jvm/:7:0","tags":["JVM","大纲"],"title":"JVM详解","uri":"/jvm/"},{"categories":["Java基础"],"content":"参考文章 https://www.pdai.tech/md/java/jvm/java-jvm-jmm.html https://www.pdai.tech/md/java/jvm/java-jvm-struct.html https://www.pdai.tech/md/java/jvm/java-jvm-x-introduce.html ","date":"2018-05-01","objectID":"/jvm/:8:0","tags":["JVM","大纲"],"title":"JVM详解","uri":"/jvm/"},{"categories":["Java基础"],"content":"ConcurrentHashMap详解","date":"2018-04-10","objectID":"/concurrenthashmap/","tags":["数据结构"],"title":"ConcurrentHashMap详解","uri":"/concurrenthashmap/"},{"categories":["Java基础"],"content":"ConcurrentHashMap详解 ","date":"2018-04-10","objectID":"/concurrenthashmap/:0:0","tags":["数据结构"],"title":"ConcurrentHashMap详解","uri":"/concurrenthashmap/"},{"categories":["Java基础"],"content":"AbstractQueuedSynchronizer详解","date":"2018-04-05","objectID":"/abstractqueuedsynchronizer/","tags":["并发编程"],"title":"AbstractQueuedSynchronizer详解","uri":"/abstractqueuedsynchronizer/"},{"categories":["Java基础"],"content":"AQS\" AQS 上图中有颜色的为Method，无颜色的为Attribution。 总的来说，AQS框架共分为五层，自上而下由浅入深，从AQS对外暴露的API到底层基础数据。 当有自定义同步器接入时，只需重写第一层所需要的部分方法即可，不需要关注底层具体的实现流程。当自定义同步器进行加锁或者解锁操作时，先经过第一层的API进入AQS内部方法，然后经过第二层进行锁的获取，接着对于获取锁失败的流程，进入第三层和第四层的等待队列处理，而这些处理方式均依赖于第五层的基础数据提供层。 ","date":"2018-04-05","objectID":"/abstractqueuedsynchronizer/:0:0","tags":["并发编程"],"title":"AbstractQueuedSynchronizer详解","uri":"/abstractqueuedsynchronizer/"},{"categories":["Java基础"],"content":"原理概览 AQS核心思想是，如果被请求的共享资源空闲，那么就将当前请求资源的线程设置为有效的工作线程，将共享资源设置为锁定状态；如果共享资源被占用，就需要一定的阻塞等待唤醒机制来保证锁分配。这个机制主要用的是CLH队列的变体实现的，将暂时获取不到锁的线程加入到队列中。 CLH(Craig,Landin,and Hagersten)队列是一个虚拟的双向队列(虚拟的双向队列即不存在队列实例，仅存在结点之间的关联关系)。AQS是将每条请求共享资源的线程封装成一个CLH锁队列的一个结点(Node)来实现锁的分配。 AQS使用一个Volatile的int类型的成员变量来表示同步状态，通过内置的FIFO队列来完成资源获取的排队工作，通过CAS完成对State值的修改。 private volatile int state;//共享变量，使用volatile修饰保证线程可见性 ","date":"2018-04-05","objectID":"/abstractqueuedsynchronizer/:1:0","tags":["并发编程"],"title":"AbstractQueuedSynchronizer详解","uri":"/abstractqueuedsynchronizer/"},{"categories":["Java基础"],"content":"AQS数据结构 AQS数据结构\" AQS数据结构 ","date":"2018-04-05","objectID":"/abstractqueuedsynchronizer/:2:0","tags":["并发编程"],"title":"AbstractQueuedSynchronizer详解","uri":"/abstractqueuedsynchronizer/"},{"categories":["Java基础"],"content":"线程两种资源共享方式 Share(共享)：多个线程可同时执行，如Semaphore/CountDownLatch。Semaphore、CountDownLatCh、 CyclicBarrier、ReadWriteLock。 Exclusive(独占)：只有一个线程能执行，如ReentrantLock。又可分为公平锁和非公平锁： 公平锁：按照线程在队列中的排队顺序，先到者先拿到锁 非公平锁：当线程要获取锁时，无视队列顺序直接去抢锁，谁抢到就是谁的 ReentrantReadWriteLock可以看成是组合式，因为ReentrantReadWriteLock是读写锁允许多个线程同时对某一资源进行读。 不同的自定义同步器争用共享资源的方式也不同。自定义同步器在实现时只需要实现共享资源state的获取与释放方式即可，至于具体线程等待队列的维护(如获取资源失败入队/唤醒出队等)，AQS已经在上层已经帮我们实现好了。 ","date":"2018-04-05","objectID":"/abstractqueuedsynchronizer/:2:1","tags":["并发编程"],"title":"AbstractQueuedSynchronizer详解","uri":"/abstractqueuedsynchronizer/"},{"categories":["Java基础"],"content":"属性值的含义 waitStatus 当前节点在队列中的状态 thread 表示处于该节点的线程 prev 前驱指针 predecessor 返回前驱节点，没有的话抛出npe nextWaiter 指向下一个处于CONDITION状态的节点（由于本篇文章不讲述Condition Queue队列，这个指针不多介绍） next 后继指针 ","date":"2018-04-05","objectID":"/abstractqueuedsynchronizer/:2:2","tags":["并发编程"],"title":"AbstractQueuedSynchronizer详解","uri":"/abstractqueuedsynchronizer/"},{"categories":["Java基础"],"content":"waitStatus（节点状态） 0，表示当前节点在sync queue中，等待着获取锁。 SIGNAL 为-1，表示线程已经准备好了，就等资源释放了,表示当前节点的后继节点包含的线程需要运行，需要进行unpark操作。 CANCELLED 为1，表示线程获取锁的请求已经取消了 CONDITION 为-2，表示当前节点在等待condition，也就是在condition queue中，节点线程等待唤醒 PROPAGATE 为-3，表示当前场景下后续的acquireShared能够得以执行。 AQS独占模式加锁\" AQS独占模式加锁 AQS共享模式加锁\" AQS共享模式加锁 ","date":"2018-04-05","objectID":"/abstractqueuedsynchronizer/:2:3","tags":["并发编程"],"title":"AbstractQueuedSynchronizer详解","uri":"/abstractqueuedsynchronizer/"},{"categories":["Java基础"],"content":"AQS重要方法与ReentrantLock的关联 ","date":"2018-04-05","objectID":"/abstractqueuedsynchronizer/:3:0","tags":["并发编程"],"title":"AbstractQueuedSynchronizer详解","uri":"/abstractqueuedsynchronizer/"},{"categories":["Java基础"],"content":"方法 AQS使用了模板方法模式，自定义同步器时需要重写下面几个AQS提供的模板方法 protected boolean isHeldExclusively() 该线程是否正在独占资源。只有用到Condition才需要去实现它。 protected boolean tryAcquire(int arg) 独占方式。arg为获取锁的次数，尝试获取资源，成功则返回True，失败则返回False。 protected boolean tryRelease(int arg) 独占方式。arg为释放锁的次数，尝试释放资源，成功则返回True，失败则返回False。 protected int tryAcquireShared(int arg) 共享方式。arg为获取锁的次数，尝试获取资源。负数表示失败；0表示成功，但没有剩余可用资源；正数表示成功，且有剩余资源。 protected boolean tryReleaseShared(int arg) 共享方式。arg为释放锁的次数，尝试释放资源，如果释放后允许唤醒后续等待结点返回True，否则返回False。 默认情况下，每个方法都抛出 UnsupportedOperationException。 这些方法的实现必须是内部线程安全的，并且通常应该简短而不是阻塞。AQS类中的其他方法都是final ，所以无法被其他类使用，只有这几个方法可以被其他类使用。 以ReentrantLock为例，state初始化为0，表示未锁定状态。A线程lock()时，会调用tryAcquire()独占该锁并将state+1。此后，其他线程再tryAcquire()时就会失败，直到A线程unlock()到state=0(即释放锁)为止，其它线程才有机会获取该锁。当然，释放锁之前，A线程自己是可以重复获取此锁的(state会累加)，这就是可重入的概念。但要注意，获取多少次就要释放多么次，这样才能保证state是能回到零态的。 一般来说，自定义同步器要么是独占方式，要么是共享方式，它们也只需实现tryAcquire-tryRelease、tryAcquireShared-tryReleaseShared中的一种即可。AQS也支持自定义同步器同时实现独占和共享两种方式，如ReentrantReadWriteLock。ReentrantLock是独占锁，所以实现了tryAcquire-tryRelease。 以非公平锁为例，这里主要阐述一下非公平锁与AQS之间方法的关联之处，具体每一处核心方法的作用会在文章后面详细进行阐述。 ReentrantLock加锁流程\" ReentrantLock加锁流程 为了帮助大家理解ReentrantLock和AQS之间方法的交互过程，以非公平锁为例，我们将加锁和解锁的交互流程单独拎出来强调一下，以便于对后续内容的理解。 ReentrantLock流程梳理\" ReentrantLock流程梳理 ","date":"2018-04-05","objectID":"/abstractqueuedsynchronizer/:3:1","tags":["并发编程"],"title":"AbstractQueuedSynchronizer详解","uri":"/abstractqueuedsynchronizer/"},{"categories":["Java基础"],"content":"加锁： 通过ReentrantLock的加锁方法Lock进行加锁操作。 会调用到内部类Sync的Lock方法，由于Sync#lock是抽象方法，根据ReentrantLock初始化选择的公平锁和非公平锁，执行相关内部类的Lock方法，本质上都会执行AQS的Acquire方法。 AQS的Acquire方法会执行tryAcquire方法，但是由于tryAcquire需要自定义同步器实现，因此执行了ReentrantLock中的tryAcquire方法，由于ReentrantLock是通过公平锁和非公平锁内部类实现的tryAcquire方法，因此会根据锁类型不同，执行不同的tryAcquire。 tryAcquire是获取锁逻辑，获取失败后，会执行框架AQS的后续逻辑，跟ReentrantLock自定义同步器无关。 ","date":"2018-04-05","objectID":"/abstractqueuedsynchronizer/:3:2","tags":["并发编程"],"title":"AbstractQueuedSynchronizer详解","uri":"/abstractqueuedsynchronizer/"},{"categories":["Java基础"],"content":"解锁： 通过ReentrantLock的解锁方法Unlock进行解锁。 Unlock会调用内部类Sync的Release方法，该方法继承于AQS。 Release中会调用tryRelease方法，tryRelease需要自定义同步器实现，tryRelease只在ReentrantLock中的Sync实现，因此可以看出，释放锁的过程，并不区分是否为公平锁。 释放成功后，所有处理由AQS框架完成，与自定义同步器无关。 通过上面的描述，大概可以总结出ReentrantLock加锁解锁时API层核心方法的映射关系。 ReentrantLock映射关系\" ReentrantLock映射关系 ","date":"2018-04-05","objectID":"/abstractqueuedsynchronizer/:3:3","tags":["并发编程"],"title":"AbstractQueuedSynchronizer详解","uri":"/abstractqueuedsynchronizer/"},{"categories":["Java基础"],"content":"通过ReentrantLock理解AQS ReentrantLock中公平锁和非公平锁在底层是相同的，这里以非公平锁为例进行分析。 // java.util.concurrent.locks.ReentrantLock static final class NonfairSync extends Sync { ... final void lock() { if (compareAndSetState(0, 1)) setExclusiveOwnerThread(Thread.currentThread()); else acquire(1); } ... } // java.util.concurrent.locks.AbstractQueuedSynchronizer public final void acquire(int arg) { if (!tryAcquire(arg) \u0026\u0026 acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt(); } // java.util.concurrent.locks.AbstractQueuedSynchronizer protected boolean tryAcquire(int arg) { throw new UnsupportedOperationException(); } 可以看出，这里只是AQS的简单实现，具体获取锁的实现方法是由各自的公平锁和非公平锁单独实现的（以ReentrantLock为例）。如果该方法返回了True，则说明当前线程获取锁成功，就不用往后执行了；如果获取失败，就需要加入到等待队列中。下面会详细解释线程是何时以及怎样被加入进等待队列中的。 ","date":"2018-04-05","objectID":"/abstractqueuedsynchronizer/:4:0","tags":["并发编程"],"title":"AbstractQueuedSynchronizer详解","uri":"/abstractqueuedsynchronizer/"},{"categories":["Java基础"],"content":"线程加入等待队列 加入队列的时机 当执行Acquire(1)时，会通过tryAcquire获取锁。在这种情况下，如果获取锁失败，就会调用addWaiter加入到等待队列中去。 如何加入队列 获取锁失败后，会执行addWaiter(Node.EXCLUSIVE)加入等待队列，具体实现方法如下： // java.util.concurrent.locks.AbstractQueuedSynchronizer private Node addWaiter(Node mode) { Node node = new Node(Thread.currentThread(), mode); // Try the fast path of enq; backup to full enq on failure Node pred = tail; if (pred != null) { node.prev = pred; if (compareAndSetTail(pred, node)) { pred.next = node; return node; } } enq(node); return node; } private final boolean compareAndSetTail(Node expect, Node update) { return unsafe.compareAndSwapObject(this, tailOffset, expect, update); } 主要的流程如下： 通过当前的线程和锁模式新建一个节点。 Pred指针指向尾节点Tail。 将New中Node的Prev指针指向Pred。 通过compareAndSetTail方法，完成尾节点的设置。这个方法主要是对tailOffset和Expect进行比较，如果tailOffset的Node和Expect的Node地址是相同的，那么设置Tail的值为Update的值。 如果Pred指针是Null（说明等待队列中没有元素），或者当前Pred指针和Tail指向的位置不同（说明被别的线程已经修改），就需要看一下Enq的方法。 // java.util.concurrent.locks.AbstractQueuedSynchronizer private Node enq(final Node node) { for (;;) { Node t = tail; if (t == null) { // Must initialize if (compareAndSetHead(new Node())) tail = head; } else { node.prev = t; if (compareAndSetTail(t, node)) { t.next = node; return t; } } } } 如果没有被初始化，需要进行初始化一个头结点出来。但请注意，初始化的头结点并不是当前线程节点，而是调用了无参构造函数的节点。如果经历了初始化或者并发导致队列中有元素，则与之前的方法相同。其实，addWaiter就是一个在双端链表添加尾节点的操作，需要注意的是，双端链表的头结点是一个无参构造函数的头结点。 总结一下，线程获取锁的时候，过程大体如下： 当没有线程获取到锁时，线程1获取锁成功。 线程2申请锁，但是锁被线程1占有。 如果再有线程要获取锁，依次在队列中往后排队即可。 等待队列中线程出队列时机 回到最初的源码： // java.util.concurrent.locks.AbstractQueuedSynchronizer public final void acquire(int arg) { if (!tryAcquire(arg) \u0026\u0026 acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt(); } 上文解释了addWaiter方法，这个方法其实就是把对应的线程以Node的数据结构形式加入到双端队列里，返回的是一个包含该线程的Node。 而这个Node会作为参数，进入到acquireQueued方法中。acquireQueued方法可以对排队中的线程进行“获锁”操作。 总的来说，一个线程获取锁失败了，被放入等待队列，acquireQueued会把放入队列中的线程不断去获取锁，直到获取成功或者不再需要获取（中断）。 下面我们从“何时出队列？”和“如何出队列？”两个方向来分析一下acquireQueued源码： // java.util.concurrent.locks.AbstractQueuedSynchronizer final boolean acquireQueued(final Node node, int arg) { // 标记是否成功拿到资源 boolean failed = true; try { // 标记等待过程中是否中断过 boolean interrupted = false; // 开始自旋，要么获取锁，要么中断 for (;;) { // 获取当前节点的前驱节点 final Node p = node.predecessor(); // 如果p是头结点，说明当前节点在真实数据队列的首部，就尝试获取锁（别忘了头结点是虚节点） if (p == head \u0026\u0026 tryAcquire(arg)) { // 获取锁成功，头指针移动到当前node setHead(node); p.next = null; // help GC failed = false; return interrupted; } // 说明p为头节点且当前没有获取到锁（可能是非公平锁被抢占了）或者是p不为头结点，这个时候就要判断当前node是否要被阻塞（被阻塞条件：前驱节点的waitStatus为-1），防止无限循环浪费资源。具体两个方法下面细细分析 if (shouldParkAfterFailedAcquire(p, node) \u0026\u0026 parkAndCheckInterrupt()) interrupted = true; } } finally { if (failed) cancelAcquire(node); } } 注：setHead方法是把当前节点置为虚节点，但并没有修改waitStatus，因为它是一直需要用的数据。 // java.util.concurrent.locks.AbstractQueuedSynchronizer private void setHead(Node node) { head = node; node.thread = null; node.prev = null; } // java.util.concurrent.locks.AbstractQueuedSynchronizer // 靠前驱节点判断当前线程是否应该被阻塞 private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) { // 获取头结点的节点状态 int ws = pred.waitStatus; // 说明头结点处于唤醒状态 if (ws == Node.SIGNAL) return true; // 通过枚举值我们知道waitStatus\u003e0是取消状态 if (ws \u003e 0) { do { // 循环向前查找取消节点，把取消节点从队列中剔除 node.prev = pred = pred.prev; } while (pred.waitStatus \u003e 0); pred.next = node; } else { // 设置前任节点等待状态为SIGNAL compareAndSetWaitStatus(pred, ws, Node.SIGNAL); } return false; } parkAndCheckInterrupt主要用于挂起当前线程，阻塞调用栈，返回当前线程的中断状态。 // java.util.concurrent.locks.AbstractQueuedSynchronizer private final boolean parkAndCheckInterrupt() { LockSupport.park(this); return Thread.interrupted(); } 上述方法的流程图如下： AQS加锁流程1\" AQS加锁流程1 从上图可以看出，跳出当前循环的条件是当“前置节点是头结点，且当前线程获取锁成功”。为了防止因死循环导致CPU资源被浪费，我们会判断前置节点的状态来决定是否要将当前线程挂起，具体挂起流程用流程图表示如下（shouldParkAfterFailedAcquire流程）： AQS加锁流程2\" AQS加锁流程2 从队列中释放节点的疑虑打消了，那么又有新问题了： shouldParkAfterFailedAcquire中取消节点是怎么生成的呢？什么时候会把一个节点的waitStatus设置为-1？ 是在什么时间释放节点通知到被挂起的线程呢 CANCELLED状态节点生成 acquireQueued方法中的Finally代码： // java.util.concurrent.locks.AbstractQueuedSynchronizer final boolean acquireQueued(final Node node, int arg) { boolean failed","date":"2018-04-05","objectID":"/abstractqueuedsynchronizer/:4:1","tags":["并发编程"],"title":"AbstractQueuedSynchronizer详解","uri":"/abstractqueuedsynchronizer/"},{"categories":["Java基础"],"content":"如何解锁 我们已经剖析了加锁过程中的基本流程，接下来再对解锁的基本流程进行分析。由于ReentrantLock在解锁的时候，并不区分公平锁和非公平锁，所以我们直接看解锁的源码： // java.util.concurrent.locks.ReentrantLock public void unlock() { sync.release(1); } // java.util.concurrent.locks.AbstractQueuedSynchronizer // 可以看到，本质释放锁的地方，是通过框架来完成的。 public final boolean release(int arg) { if (tryRelease(arg)) { Node h = head; if (h != null \u0026\u0026 h.waitStatus != 0) unparkSuccessor(h); return true; } return false; } //在ReentrantLock里面的公平锁和非公平锁的父类Sync定义了可重入锁的释放锁机制。 // java.util.concurrent.locks.ReentrantLock.Sync // 方法返回当前锁是不是没有被线程持有 protected final boolean tryRelease(int releases) { // 减少可重入次数 int c = getState() - releases; // 当前线程不是持有锁的线程，抛出异常 if (Thread.currentThread() != getExclusiveOwnerThread()) throw new IllegalMonitorStateException(); boolean free = false; // 如果持有线程全部释放，将当前独占锁所有线程设置为null，并更新state if (c == 0) { free = true; setExclusiveOwnerThread(null); } setState(c); return free; } // java.util.concurrent.locks.AbstractQueuedSynchronizer public final boolean release(int arg) { // 上边自定义的tryRelease如果返回true，说明该锁没有被任何线程持有 if (tryRelease(arg)) { // 获取头结点 Node h = head; // 头结点不为空并且头结点的waitStatus不是初始化节点情况，解除线程挂起状态 if (h != null \u0026\u0026 h.waitStatus != 0) unparkSuccessor(h); return true; } return false; } //再看一下unparkSuccessor方法 // java.util.concurrent.locks.AbstractQueuedSynchronizer private void unparkSuccessor(Node node) { // 获取头结点waitStatus int ws = node.waitStatus; if (ws \u003c 0) compareAndSetWaitStatus(node, ws, 0); // 获取当前节点的下一个节点 Node s = node.next; // 如果下个节点是null或者下个节点被cancelled，就找到队列最开始的非cancelled的节点 if (s == null || s.waitStatus \u003e 0) { s = null; // 就从尾部节点开始找，到队首，找到队列第一个waitStatus\u003c0的节点。 for (Node t = tail; t != null \u0026\u0026 t != node; t = t.prev) if (t.waitStatus \u003c= 0) s = t; } // 如果当前节点的下个节点不为空，而且状态\u003c=0，就把当前节点unpark if (s != null) LockSupport.unpark(s.thread); } // 为什么要从后往前找第一个非Cancelled的节点呢？原因如下。 // 之前的addWaiter方法： // java.util.concurrent.locks.AbstractQueuedSynchronizer private Node addWaiter(Node mode) { Node node = new Node(Thread.currentThread(), mode); // Try the fast path of enq; backup to full enq on failure Node pred = tail; if (pred != null) { node.prev = pred; if (compareAndSetTail(pred, node)) { pred.next = node; return node; } } enq(node); return node; } 我们从这里可以看到，节点入队并不是原子操作，也就是说，node.prev = pred; compareAndSetTail(pred, node) 这两个地方可以看作Tail入队的原子操作，但是此时pred.next = node;还没执行，如果这个时候执行了unparkSuccessor方法，就没办法从前往后找了，所以需要从后往前找。还有一点原因，在产生CANCELLED状态节点的时候，先断开的是Next指针，Prev指针并未断开，因此也是必须要从后往前遍历才能够遍历完全部的Node。 综上所述，如果是从前往后找，由于极端情况下入队的非原子操作和CANCELLED节点产生过程中断开Next指针的操作，可能会导致无法遍历所有的节点。所以，唤醒对应的线程后，对应的线程就会继续往下执行。继续执行acquireQueued方法以后，中断如何处理？ ","date":"2018-04-05","objectID":"/abstractqueuedsynchronizer/:4:2","tags":["并发编程"],"title":"AbstractQueuedSynchronizer详解","uri":"/abstractqueuedsynchronizer/"},{"categories":["Java基础"],"content":"中断恢复后的执行流程 唤醒后，会执行return Thread.interrupted();，这个函数返回的是当前执行线程的中断状态，并清除。 // java.util.concurrent.locks.AbstractQueuedSynchronizer private final boolean parkAndCheckInterrupt() { LockSupport.park(this); return Thread.interrupted(); } 再回到acquireQueued代码，当parkAndCheckInterrupt返回True或者False的时候，interrupted的值不同，但都会执行下次循环。如果这个时候获取锁成功，就会把当前interrupted返回。 // java.util.concurrent.locks.AbstractQueuedSynchronizer final boolean acquireQueued(final Node node, int arg) { boolean failed = true; try { boolean interrupted = false; for (;;) { final Node p = node.predecessor(); if (p == head \u0026\u0026 tryAcquire(arg)) { setHead(node); p.next = null; // help GC failed = false; return interrupted; } if (shouldParkAfterFailedAcquire(p, node) \u0026\u0026 parkAndCheckInterrupt()) interrupted = true; } } finally { if (failed) cancelAcquire(node); } } 如果acquireQueued为True，就会执行selfInterrupt方法。 // java.util.concurrent.locks.AbstractQueuedSynchronizer static void selfInterrupt() { Thread.currentThread().interrupt(); } 该方法其实是为了中断线程。但为什么获取了锁以后还要中断线程呢？这部分属于Java提供的协作式中断知识内容，感兴趣同学可以查阅一下。这里简单介绍一下： 当中断线程被唤醒时，并不知道被唤醒的原因，可能是当前线程在等待中被中断，也可能是释放了锁以后被唤醒。因此我们通过Thread.interrupted()方法检查中断标记（该方法返回了当前线程的中断状态，并将当前线程的中断标识设置为False），并记录下来，如果发现该线程被中断过，就再中断一次。 线程在等待资源的过程中被唤醒，唤醒后还是会不断地去尝试获取锁，直到抢到锁为止。也就是说，在整个流程中，并不响应中断，只是记录中断记录。最后抢到锁返回了，那么如果被中断过的话，就需要补充一次中断。 ","date":"2018-04-05","objectID":"/abstractqueuedsynchronizer/:4:3","tags":["并发编程"],"title":"AbstractQueuedSynchronizer详解","uri":"/abstractqueuedsynchronizer/"},{"categories":["Java基础"],"content":"AbstractQueuedSynchronizer总结 对于AbstractQueuedSynchronizer的分析，最核心的就是sync queue的分析。 每一个结点都是由前一个结点唤醒 当结点发现前驱结点是head并且尝试获取成功，则会轮到该线程运行。 condition queue中的结点向sync queue中转移是通过条件的signal()操作完成的。 当结点的状态为SIGNAL时，表示后面的结点需要运行。 ","date":"2018-04-05","objectID":"/abstractqueuedsynchronizer/:5:0","tags":["并发编程"],"title":"AbstractQueuedSynchronizer详解","uri":"/abstractqueuedsynchronizer/"},{"categories":["Java基础"],"content":"参考文章 从ReentrantLock的实现看AQS的原理及应用 锁核心类AQS详解 ","date":"2018-04-05","objectID":"/abstractqueuedsynchronizer/:6:0","tags":["并发编程"],"title":"AbstractQueuedSynchronizer详解","uri":"/abstractqueuedsynchronizer/"},{"categories":["Java基础"],"content":"LockSupport详解","date":"2018-04-04","objectID":"/locksupport/","tags":["并发编程"],"title":"LockSupport详解","uri":"/locksupport/"},{"categories":["Java基础"],"content":"LockSupport简介 LockSupport用来创建锁和其他同步类的基本线程阻塞原语。简而言之，当调用LockSupport.park时，表示当前线程将会等待，直至获得许可，当调用LockSupport.unpark时，必须把等待获得许可的线程作为参数进行传递，好让此线程继续运行。 ","date":"2018-04-04","objectID":"/locksupport/:1:0","tags":["并发编程"],"title":"LockSupport详解","uri":"/locksupport/"},{"categories":["Java基础"],"content":"核心函数分析 在分析LockSupport函数之前，先引入sun.misc.Unsafe类中的park和unpark函数，因为LockSupport的核心函数都是基于Unsafe类中定义的park和unpark函数，下面给出两个函数的定义: public native void park(boolean isAbsolute, long time); public native void unpark(Thread thread); 说明: 对两个函数的说明如下: park函数，阻塞线程，并且该线程在下列情况发生之前都会被阻塞: ① 调用unpark函数，释放该线程的许可。② 该线程被中断。③ 设置的时间到了。并且，当time为绝对时间时，isAbsolute为true，否则，isAbsolute为false。当time为0时，表示无限等待，直到unpark发生。 unpark函数，释放线程的许可，即激活调用park后阻塞的线程。这个函数不是安全的，调用这个函数时要确保线程依旧存活。 ","date":"2018-04-04","objectID":"/locksupport/:2:0","tags":["并发编程"],"title":"LockSupport详解","uri":"/locksupport/"},{"categories":["Java基础"],"content":"park函数 park函数有两个重载版本，方法摘要如下 public static void park()； public static void park(Object blocker)； 说明: 两个函数的区别在于park()函数没有没有blocker，即没有设置线程的parkBlocker字段。park(Object)型函数如下。 public static void park(Object blocker) { // 获取当前线程 Thread t = Thread.currentThread(); // 设置Blocker setBlocker(t, blocker); // 获取许可 UNSAFE.park(false, 0L); // 重点方法：重新可运行后再此设置Blocker，其他线程执行unpark()后继续 setBlocker(t, null); } 说明: 调用park函数时，首先获取当前线程，然后设置当前线程的parkBlocker字段，即调用setBlocker函数，之后调用Unsafe类的park函数，之后再调用setBlocker函数。 那么问题来了，为什么要在此park函数中要调用两次setBlocker函数呢? 原因其实很简单，调用park函数时，当前线程首先设置好parkBlocker字段，然后再调用Unsafe的park函数，此后，当前线程就已经阻塞了，等待该线程的unpark函数被调用，所以后面的一个setBlocker函数无法运行，unpark函数被调用，该线程获得许可后，就可以继续运行了，也就运行第二个setBlocker，把该线程的parkBlocker字段设置为null，这样就完成了整个park函数的逻辑。如果没有第二个setBlocker，那么之后没有调用park(Object blocker)，而直接调用getBlocker函数，得到的还是前一个park(Object blocker)设置的blocker，显然是不符合逻辑的。 总之，必须要保证在park(Object blocker)整个函数执行完后，该线程的parkBlocker字段又恢复为null。所以，park(Object)型函数里必须要调用setBlocker函数两次。 setBlocker方法如下: private static void setBlocker(Thread t, Object arg) { // 设置线程t的parkBlocker字段的值为arg UNSAFE.putObject(t, parkBlockerOffset, arg); } ","date":"2018-04-04","objectID":"/locksupport/:2:1","tags":["并发编程"],"title":"LockSupport详解","uri":"/locksupport/"},{"categories":["Java基础"],"content":"unpark函数 此函数表示如果给定线程的许可尚不可用，则使其可用。如果线程在 park 上受阻塞，则它将解除其阻塞状态。否则，保证下一次调用 park 不会受阻塞。如果给定线程尚未启动，则无法保证此操作有任何效果。具体函数如下: public static void unpark(Thread thread) { if (thread != null) // 线程为不空 UNSAFE.unpark(thread); // 释放该线程许可 } ","date":"2018-04-04","objectID":"/locksupport/:2:2","tags":["并发编程"],"title":"LockSupport详解","uri":"/locksupport/"},{"categories":["Java基础"],"content":"更深入的理解 ","date":"2018-04-04","objectID":"/locksupport/:3:0","tags":["并发编程"],"title":"LockSupport详解","uri":"/locksupport/"},{"categories":["Java基础"],"content":"Thread.sleep()和Object.wait()的区别 Thread.sleep()不会释放占有的锁，Object.wait()会释放占有的锁； Thread.sleep()必须传入时间，Object.wait()可传可不传，不传表示一直阻塞下去； Thread.sleep()到时间了会自动唤醒，然后继续执行； Object.wait()不带时间的，需要另一个线程使用Object.notify()唤醒； Object.wait()带时间的，假如没有被notify，到时间了会自动唤醒，这时又分好两种情况，一是立即获取到了锁，线程自然会继续执行；二是没有立即获取锁，线程进入同步队列等待获取锁； 其实，他们俩最大的区别就是Thread.sleep()不会释放锁资源，Object.wait()会释放锁资源。 ","date":"2018-04-04","objectID":"/locksupport/:3:1","tags":["并发编程"],"title":"LockSupport详解","uri":"/locksupport/"},{"categories":["Java基础"],"content":"Thread.sleep()和Condition.await()的区别 Condition.await()和Object.wait()的原理是基本一致的，不同的是Condition.await()底层是调用LockSupport.park()来实现阻塞当前线程的。 实际上，它在阻塞当前线程之前还干了两件事，一是把当前线程添加到条件队列中，二是“完全”释放锁，也就是让state状态变量变为0，然后才是调用LockSupport.park()阻塞当前线程。 ","date":"2018-04-04","objectID":"/locksupport/:3:2","tags":["并发编程"],"title":"LockSupport详解","uri":"/locksupport/"},{"categories":["Java基础"],"content":"Thread.sleep()和LockSupport.park()的区别 LockSupport.park()还有几个兄弟方法——parkNanos()、parkUtil()等，我们这里说的park()方法统称这一类方法。 从功能上来说，Thread.sleep()和LockSupport.park()方法类似，都是阻塞当前线程的执行，且都不会释放当前线程占有的锁资源。 Thread.sleep()没法从外部唤醒，只能自己醒过来； LockSupport.park()方法可以被另一个线程调用LockSupport.unpark()方法唤醒； Thread.sleep()方法声明上抛出了InterruptedException中断异常，所以调用者需要捕获这个异常或者再抛出； LockSupport.park()方法不需要捕获中断异常； Thread.sleep()本身就是一个native方法； LockSupport.park()底层是调用的Unsafe的native方法 ","date":"2018-04-04","objectID":"/locksupport/:3:3","tags":["并发编程"],"title":"LockSupport详解","uri":"/locksupport/"},{"categories":["Java基础"],"content":"Object.wait()和LockSupport.park()的区别 二者都会阻塞当前线程的运行，他们有什么区别呢? 经过上面的分析相信你一定很清楚了，真的吗? 往下看！ Object.wait()方法需要在synchronized块中执行； LockSupport.park()可以在任意地方执行； Object.wait()方法声明抛出了中断异常，调用者需要捕获或者再抛出； LockSupport.park()不需要捕获中断异常； Object.wait()不带超时的，需要另一个线程执行notify()来唤醒，但不一定继续执行后续内容； LockSupport.park()不带超时的，需要另一个线程执行unpark()来唤醒，一定会继续执行后续内容； 如果在wait()之前执行了notify()会怎样? 抛出IllegalMonitorStateException异常； 如果在park()之前执行了unpark()会怎样? 线程不会被阻塞，直接跳过park()，继续执行后续内容； park()/unpark()底层的原理是“二元信号量”，你可以把它相像成只有一个许可证的Semaphore，只不过这个信号量在重复执行unpark()的时候也不会再增加许可证，最多只有一个许可证。 ","date":"2018-04-04","objectID":"/locksupport/:3:4","tags":["并发编程"],"title":"LockSupport详解","uri":"/locksupport/"},{"categories":["Java基础"],"content":"LockSupport.park()不会释放锁资源 LockSupport.park()不会释放锁资源，它只负责阻塞当前线程，释放锁资源实际上是在Condition的await()方法中实现的。 ","date":"2018-04-04","objectID":"/locksupport/:3:5","tags":["并发编程"],"title":"LockSupport详解","uri":"/locksupport/"},{"categories":["Java基础"],"content":"synchronized详解","date":"2018-04-03","objectID":"/synchronized/","tags":["并发编程"],"title":"synchronized(无锁→偏向锁→轻量级锁→重量级锁)","uri":"/synchronized/"},{"categories":["Java基础"],"content":"synchronized的使用 ","date":"2018-04-03","objectID":"/synchronized/:1:0","tags":["并发编程"],"title":"synchronized(无锁→偏向锁→轻量级锁→重量级锁)","uri":"/synchronized/"},{"categories":["Java基础"],"content":"对象锁 包括方法锁(默认锁对象为this,当前实例对象)和同步代码块锁(自己指定锁对象) ","date":"2018-04-03","objectID":"/synchronized/:1:1","tags":["并发编程"],"title":"synchronized(无锁→偏向锁→轻量级锁→重量级锁)","uri":"/synchronized/"},{"categories":["Java基础"],"content":"类锁 指synchronize修饰静态的方法或指定锁对象为Class对象 ","date":"2018-04-03","objectID":"/synchronized/:1:2","tags":["并发编程"],"title":"synchronized(无锁→偏向锁→轻量级锁→重量级锁)","uri":"/synchronized/"},{"categories":["Java基础"],"content":"注意点 一把锁只能同时被一个线程获取，没有获得锁的线程只能等待。 每个实例都对应有自己的一把锁(this),不同实例之间互不影响；例外：当锁对象是*.class以及synchronized修饰的是static方法的时候，所有对象共用同一把锁 。 synchronized修饰的方法，无论方法正常执行完毕还是抛出异常，都会释放锁。 ","date":"2018-04-03","objectID":"/synchronized/:1:3","tags":["并发编程"],"title":"synchronized(无锁→偏向锁→轻量级锁→重量级锁)","uri":"/synchronized/"},{"categories":["Java基础"],"content":"synchronized原理分析 ","date":"2018-04-03","objectID":"/synchronized/:2:0","tags":["并发编程"],"title":"synchronized(无锁→偏向锁→轻量级锁→重量级锁)","uri":"/synchronized/"},{"categories":["Java基础"],"content":"加锁和释放锁的原理 Monitorenter和Monitorexit指令，会让对象在执行，使其锁计数器加1或者减1。每一个对象在同一时间只与一个monitor(锁)相关联，而一个monitor在同一时间只能被一个线程获得，一个对象在尝试获得与这个对象相关联的Monitor锁的所有权的时候，monitorenter指令会发生如下3中情况之一： monitor计数器为0，意味着目前还没有被获得，那这个线程就会立刻获得然后把锁计数器+1，一旦+1，别的线程再想获取，就需要等待 如果这个monitor已经拿到了这个锁的所有权，又重入了这把锁，那锁计数器就会累加，变成2，并且随着重入的次数，会一直累加 这把锁已经被别的线程获取了，等待锁释放 monitorexit指令：释放对于monitor的所有权，释放过程很简单，就是将monitor的计数器减1，如果减完以后，计数器不是0，则代表刚才是重入进来的，当前线程还继续持有这把锁的所有权，如果计数器变成0，则代表当前线程不再拥有该monitor的所有权，即释放锁。 schronized-moniter\" schronized-moniter 该图可以看出，任意线程对Object的访问，首先要获得Object的监视器，如果获取失败，该线程就进入同步状态，线程状态变为BLOCKED，当Object的监视器占有者释放后，在同步队列中得线程就会有机会重新获取该监视器。 ","date":"2018-04-03","objectID":"/synchronized/:2:1","tags":["并发编程"],"title":"synchronized(无锁→偏向锁→轻量级锁→重量级锁)","uri":"/synchronized/"},{"categories":["Java基础"],"content":"可重入原理：加锁次数计数器 上面的demo中在执行完同步代码块之后紧接着再会去执行一个静态同步方法，而这个方法锁的对象依然就这个类对象，那么这个正在执行的线程还需要获取该锁吗? 答案是不必的，从上图中就可以看出来，执行静态同步方法的时候就只有一条monitorexit指令，并没有monitorenter获取锁的指令。这就是锁的重入性，即在同一锁程中，线程不需要再次获取同一把锁。 synchronized先天具有重入性。每个对象拥有一个计数器，当线程获取该对象锁后，计数器就会加一，释放锁后就会将计数器减一。 ","date":"2018-04-03","objectID":"/synchronized/:2:2","tags":["并发编程"],"title":"synchronized(无锁→偏向锁→轻量级锁→重量级锁)","uri":"/synchronized/"},{"categories":["Java基础"],"content":"保证可见性的原理：内存模型和happens-before规则 Synchronized的happens-before规则，即监视器锁规则：对同一个监视器的解锁，happens-before于对该监视器的加锁。继续来看代码： public class MonitorDemo { private int a = 0; public synchronized void writer() { // 1 a++; // 2 } // 3 public synchronized void reader() { // 4 int i = a; // 5 } // 6 } 该代码的happens-before关系如图所示： happens-before\" happens-before 在图中每一个箭头连接的两个节点就代表之间的happens-before关系，黑色的是通过程序顺序规则推导出来，红色的为监视器锁规则推导而出：线程A释放锁happens-before线程B加锁，蓝色的则是通过程序顺序规则和监视器锁规则推测出来happens-befor关系，通过传递性规则进一步推导的happens-before关系。现在我们来重点关注2 happens-before 5，通过这个关系我们可以得出什么? 根据happens-before的定义中的一条:如果A happens-before B，则A的执行结果对B可见，并且A的执行顺序先于B。线程A先对共享变量A进行加一，由2 happens-before 5关系可知线程A的执行结果对线程B可见即线程B所读取到的a的值为1。 ","date":"2018-04-03","objectID":"/synchronized/:2:3","tags":["并发编程"],"title":"synchronized(无锁→偏向锁→轻量级锁→重量级锁)","uri":"/synchronized/"},{"categories":["Java基础"],"content":"JVM中锁的优化 简单来说在JVM中monitorenter和monitorexit字节码依赖于底层的操作系统的Mutex Lock来实现的。 但是由于使用Mutex Lock需要将当前线程挂起并从用户态切换到内核态来执行，这种切换的代价是非常昂贵的；然而在现实中的大部分情况下，同步方法是运行在单线程环境(无锁竞争环境)如果每次都调用Mutex Lock那么将严重的影响程序的性能。 不过在jdk1.6中对锁的实现引入了大量的优化，如锁粗化(Lock Coarsening)、锁消除(Lock Elimination)、轻量级锁(Lightweight Locking)、偏向锁(Biased Locking)、适应性自旋(Adaptive Spinning)等技术来减少锁操作的开销。 ","date":"2018-04-03","objectID":"/synchronized/:3:0","tags":["并发编程"],"title":"synchronized(无锁→偏向锁→轻量级锁→重量级锁)","uri":"/synchronized/"},{"categories":["Java基础"],"content":"锁优化 锁粗化(Lock Coarsening)：也就是减少不必要的紧连在一起的unlock，lock操作，将多个连续的锁扩展成一个范围更大的锁。 锁消除(Lock Elimination)：通过运行时JIT编译器的逃逸分析来消除一些没有在当前同步块以外被其他线程共享的数据的锁保护，通过逃逸分析也可以在线程本地Stack上进行对象空间的分配(同时还可以减少Heap上的垃圾收集开销)。 偏向锁(Biased Locking)：是为了在无锁竞争的情况下避免在锁获取过程中执行不必要的CAS原子指令，因为CAS原子指令虽然相对于重量级锁来说开销比较小但还是存在非常可观的本地延迟。 轻量级锁(Lightweight Locking)：这种锁实现的背后基于这样一种假设，即在真实的情况下我们程序中的大部分同步代码一般都处于无锁竞争状态(即单线程执行环境)，在无锁竞争的情况下完全可以避免调用操作系统层面的重量级互斥锁，取而代之的是在monitorenter和monitorexit中只需要依靠一条CAS原子指令就可以完成锁的获取及释放。当存在锁竞争的情况下，执行CAS指令失败的线程将调用操作系统互斥锁进入到阻塞状态，当锁被释放的时候被唤醒(具体处理步骤下面详细讨论)。 自适应自旋锁(Adaptive Spinning)：当线程在获取轻量级锁的过程中执行CAS操作失败时，在进入与monitor相关联的操作系统重量级锁(mutex semaphore)前会进入忙等待(Spinning)然后再次尝试，当尝试一定的次数后如果仍然没有成功则调用与该monitor关联的semaphore(即互斥锁)进入到阻塞状态。 ","date":"2018-04-03","objectID":"/synchronized/:3:1","tags":["并发编程"],"title":"synchronized(无锁→偏向锁→轻量级锁→重量级锁)","uri":"/synchronized/"},{"categories":["Java基础"],"content":"锁的类型 在Java SE 1.6里Synchronied同步锁，一共有四种状态：无锁、偏向锁、轻量级所、重量级锁，它会随着竞争情况逐渐升级。 锁可以升级但是不可以降级，目的是为了提供获取锁和释放锁的效率。 锁膨胀方向(不可逆)： 无锁 → 偏向锁 → 轻量级锁 → 重量级锁 流程：偏向锁通过对比Mark Word解决加锁问题，避免执行CAS操作。而轻量级锁是通过用CAS操作和自旋来解决加锁问题，避免线程阻塞和唤醒而影响性能。重量级锁是将除了拥有锁的线程以外的线程都阻塞。 下面是各个过程的详细介绍： ","date":"2018-04-03","objectID":"/synchronized/:3:2","tags":["并发编程"],"title":"synchronized(无锁→偏向锁→轻量级锁→重量级锁)","uri":"/synchronized/"},{"categories":["Java基础"],"content":"自旋锁与自适应自旋锁 自旋锁对比非自旋锁\" 自旋锁对比非自旋锁 自旋锁 引入背景：大家都知道，在没有加入锁优化时，Synchronized是一个非常“胖大”的家伙。在多线程竞争锁时，当一个线程获取锁时，它会阻塞所有正在竞争的线程，这样对性能带来了极大的影响。在挂起线程和恢复线程的操作都需要转入内核态中完成，这些操作对系统的并发性能带来了很大的压力。同时HotSpot团队注意到在很多情况下，共享数据的锁定状态只会持续很短的一段时间，为了这段时间去挂起和恢复阻塞线程并不值得。在如今多处理器环境下，完全可以让另一个没有获取到锁的线程在门外等待一会(自旋)，但不放弃CPU的执行时间。等待持有锁的线程是否很快就会释放锁。为了让线程等待，我们只需要让线程执行一个忙循环(自旋)，这便是自旋锁由来的原因。 自旋锁早在JDK1.4 中就引入了，只是当时默认时关闭的。在JDK 1.6后默认为开启状态。 自旋锁本质上与阻塞并不相同，先不考虑其对多处理器的要求，如果锁占用的时间非常的短，那么自旋锁的性能会非常的好，相反，其会带来更多的性能开销(因为在线程自旋时，始终会占用CPU的时间片，如果锁占用的时间太长，那么自旋的线程会白白消耗掉CPU资源)。 因此自旋等待的时间必须要有一定的限度，如果自选超过了限定的次数仍然没有成功获取到锁，就应该使用传统的方式去挂起线程了，在JDK定义中，自旋锁默认的自旋次数为10次，用户可以使用参数-XX:PreBlockSpin来更改。 可是现在又出现了一个问题：如果线程锁在线程自旋刚结束就释放掉了锁，那么是不是有点得不偿失。所以这时候我们需要更加聪明的锁来实现更加灵活的自旋。来提高并发的性能。(这里则需要自适应自旋锁) 自适应自旋锁 在JDK 1.6中引入了自适应自旋锁。这就意味着自旋的时间不再固定了，而是由前一次在同一个锁上的自旋时间及锁的拥有者的状态来决定的。 如果在同一个锁对象上，自旋等待刚刚成功获取过锁，并且持有锁的线程正在运行中，那么JVM会认为该锁自旋获取到锁的可能性很大，会自动增加等待时间。 比如增加到100此循环。相反，如果对于某个锁，自旋很少成功获取锁。那再以后要获取这个锁时将可能省略掉自旋过程，以避免浪费处理器资源。 有了自适应自旋，JVM对程序的锁的状态预测会越来越准备，JVM也会越来越聪明。 ","date":"2018-04-03","objectID":"/synchronized/:3:3","tags":["并发编程"],"title":"synchronized(无锁→偏向锁→轻量级锁→重量级锁)","uri":"/synchronized/"},{"categories":["Java基础"],"content":"锁消除 锁消除时指虚拟机即时编译器再运行时，对一些代码上要求同步，但是被检测到不可能存在共享数据竞争的锁进行消除。 锁消除的主要判定依据来源于逃逸分析的数据支持。意思就是：JVM会判断在一段程序中的同步明显不会逃逸出去从而被其他线程访问到，那JVM就把它们当作栈上数据对待，认为这些数据时线程独有的，不需要加同步。此时就会进行锁消除。 ​ 当然在实际开发中，我们很清楚的知道那些地方时线程独有的，不需要加同步锁，但是在Java API中有很多方法都是加了同步的，那么此时JVM会判断这段代码是否需要加锁。如果数据并不会逃逸，则会进行锁消除。比如如下操作：在操作String类型数据时，由于String是一个不可变类，对字符串的连接操作总是通过生成的新的String对象来进行的。因此Javac编译器会对String连接做自动优化。在JDK 1.5之前会使用StringBuffer对象的连续append()操作，在JDK 1.5及以后的版本中，会转化为StringBuidler对象的连续append()操作。 public static String test03(String s1, String s2, String s3) { String s = s1 + s2 + s3; return s; } 上述代码使用javap 编译结果 锁消除\" 锁消除 众所周知，StringBuilder不是安全同步的，但是在上述代码中，JVM判断该段代码并不会逃逸，则将该代码带默认为线程独有的资源，并不需要同步，所以执行了锁消除操作。(还有Vector中的各种操作也可实现锁消除。在没有逃逸出数据安全防卫内) ","date":"2018-04-03","objectID":"/synchronized/:3:4","tags":["并发编程"],"title":"synchronized(无锁→偏向锁→轻量级锁→重量级锁)","uri":"/synchronized/"},{"categories":["Java基础"],"content":"锁粗化 ​原则上，我们都知道在加同步锁时，尽可能的将同步块的作用范围限制到尽量小的范围(只在共享数据的实际作用域中才进行同步，这样是为了使得需要同步的操作数量尽可能变小。在存在锁同步竞争中，也可以使得等待锁的线程尽早的拿到锁)。 ​大部分上述情况是完美正确的，但是如果存在连串的一系列操作都对同一个对象反复加锁和解锁，甚至加锁操作时出现在循环体中的，那即使没有线程竞争，频繁地进行互斥同步操作也会导致不必要地性能操作。 ","date":"2018-04-03","objectID":"/synchronized/:3:5","tags":["并发编程"],"title":"synchronized(无锁→偏向锁→轻量级锁→重量级锁)","uri":"/synchronized/"},{"categories":["Java基础"],"content":"偏向锁 引入背景：在大多实际环境下，锁不仅不存在多线程竞争，而且总是由同一个线程多次获取，那么在同一个线程反复获取所释放锁中，其中并还没有锁的竞争，那么这样看上去，多次的获取锁和释放锁带来了很多不必要的性能开销和上下文切换。 ​ 为了解决这一问题，HotSpot的作者在Java SE1.6中对Synchronized进行了优化，引入了偏向锁。 当一个线程访问同步快并获取锁时，会在对象头和栈帧中的锁记录里存储锁偏向的线程ID，以后该线程在进入和退出同步块时不需要进行CAS操作来加锁和解锁。只需要简单地测试一下对象头的Mark Word里是否存储着指向当前线程的偏向锁。如果成功，表示线程已经获取到了锁。 偏向锁1\" 偏向锁1 偏向锁的撤销 偏向锁使用了一种等待竞争出现才会释放锁的机制，所以当其他线程尝试获取偏向锁时，持有偏向锁的线程才会释放锁。 但是偏向锁的撤销需要等到全局安全点(就是当前线程没有正在执行的字节码)。 它会首先暂停拥有偏向锁的线程，然后检查持有偏向锁的线程是否活着。 如果线程不处于活动状态，直接将对象头设置为无锁状态。 如果线程活着，JVM会遍历栈帧中的锁记录，栈帧中的锁记录和对象头要么偏向于其他线程，要么恢复到无锁状态或者标记对象不适合作为偏向锁。 偏向锁2\" 偏向锁2 ","date":"2018-04-03","objectID":"/synchronized/:3:6","tags":["并发编程"],"title":"synchronized(无锁→偏向锁→轻量级锁→重量级锁)","uri":"/synchronized/"},{"categories":["Java基础"],"content":"轻量级锁 引入背景：这种锁实现的背后基于这样一种假设，即在真实的情况下我们程序中的大部分同步代码一般都处于无锁竞争状态(即单线程执行环境)，在无锁竞争的情况下完全可以避免调用操作系统层面的重量级互斥锁，取而代之的是在monitorenter和monitorexit中只需要依靠一条CAS原子指令就可以完成锁的获取及释放。当存在锁竞争的情况下，执行CAS指令失败的线程将调用操作系统互斥锁进入到阻塞状态，当锁被释放的时候被唤醒。 ​在JDK 1.6之后引入的轻量级锁，需要注意的是轻量级锁并不是替代重量级锁的，而是对在大多数情况下同步块并不会有竞争出现提出的一种优化。 它可以减少重量级锁对线程的阻塞带来地线程开销，从而提高并发性能。 ​如果要理解轻量级锁，那么必须先要了解HotSpot虚拟机中对象头的内存布局。 在对象头中(Object Header)存在两部分： 第一部分用于存储对象自身的运行时数据，HashCode、GCAge、锁标记位、是否为偏向锁等。一般为32位或者64位(视操作系统位数定)。官方称之为Mark Word，它是实现轻量级锁和偏向锁的关键。 另外一部分存储的是指向方法区对象类型数据的指针(Klass Point)，如果对象是数组的话，还会有一个额外的部分用于存储数据的长度。 轻量级锁加锁 在线程执行同步块之前，JVM会先在当前线程的栈帧中创建一个名为锁记录(Lock Record)的空间，用于存储锁对象目前的Mark Word的拷贝(JVM会将对象头中的Mark Word拷贝到锁记录中，官方称为Displaced Mark Ward)这个时候线程堆栈与对象头的状态如图： 轻量级锁加锁1\" 轻量级锁加锁1 如上图所示：如果当前对象没有被锁定，那么锁标志位位01状态，JVM在执行当前线程时，首先会在当前线程栈帧中创建锁记录Lock Record的空间用于存储锁对象目前的Mark Word的拷贝。 ​ 然后，虚拟机使用CAS操作将标记字段Mark Word拷贝到锁记录中，并且将Mark Word更新为指向Lock Record的指针。如果更新成功了，那么这个线程就有用了该对象的锁，并且对象Mark Word的锁标志位更新为(Mark Word中最后的2bit)00，即表示此对象处于轻量级锁定状态，如图： 轻量级锁加锁2\" 轻量级锁加锁2 如果这个更新操作失败，JVM会检查当前的Mark Word中是否存在指向当前线程的栈帧的指针，如果有，说明该锁已经被获取，可以直接调用。如果没有，则说明该锁被其他线程抢占了。 如果有两条以上的线程竞争同一个锁，那轻量级锁就不再有效，直接膨胀位重量级锁，没有获得锁的线程会被阻塞。此时，锁的标志位为10，Mark Word中存储的是指向重量级锁的指针。 ​ 轻量级解锁时，会使用原子的CAS操作将Displaced Mark Word替换回到对象头中，如果成功，则表示没有发生竞争关系。如果失败，表示当前锁存在竞争关系。锁就会膨胀成重量级锁。两个线程同时争夺锁，导致锁膨胀的流程图如下： 轻量级锁加锁3\" 轻量级锁加锁3 ","date":"2018-04-03","objectID":"/synchronized/:3:7","tags":["并发编程"],"title":"synchronized(无锁→偏向锁→轻量级锁→重量级锁)","uri":"/synchronized/"},{"categories":["Java基础"],"content":"锁的优缺点对比 锁 优点 缺点 使用场景 偏向锁 加锁和解锁不需要CAS操作，没有额外的性能消耗，和执行非同步方法相比仅存在纳秒级的差距 如果线程间存在锁竞争，会带来额外的锁撤销的消耗 适用于只有一个线程访问同步快的场景 轻量级锁 竞争的线程不会阻塞，提高了响应速度 如线程成始终得不到锁竞争的线程，使用自旋会消耗CPU性能 追求响应时间，同步快执行速度非常快 重量级锁 线程竞争不适用自旋，不会消耗CPU 线程阻塞，响应时间缓慢，在多线程下，频繁的获取释放锁，会带来巨大的性能消耗 追求吞吐量，同步快执行速度较长 锁对比\" 锁对比 ","date":"2018-04-03","objectID":"/synchronized/:3:8","tags":["并发编程"],"title":"synchronized(无锁→偏向锁→轻量级锁→重量级锁)","uri":"/synchronized/"},{"categories":["Java基础"],"content":"synchronized与Lock ","date":"2018-04-03","objectID":"/synchronized/:4:0","tags":["并发编程"],"title":"synchronized(无锁→偏向锁→轻量级锁→重量级锁)","uri":"/synchronized/"},{"categories":["Java基础"],"content":"synchronized的缺陷 效率低：锁的释放情况少，只有代码执行完毕或者异常结束才会释放锁；试图获取锁的时候不能设定超时，不能中断一个正在使用锁的线程，相对而言，Lock可以中断和设置超时 不够灵活：加锁和释放的时机单一，每个锁仅有一个单一的条件(某个对象)，相对而言，读写锁更加灵活 无法知道是否成功获得锁，相对而言，Lock可以拿到状态。 ","date":"2018-04-03","objectID":"/synchronized/:4:1","tags":["并发编程"],"title":"synchronized(无锁→偏向锁→轻量级锁→重量级锁)","uri":"/synchronized/"},{"categories":["Java基础"],"content":"Lock解决相应问题 Lock类这里不做过多解释，主要看里面的4个方法: lock(): 加锁 unlock(): 解锁 tryLock(): 尝试获取锁，返回一个boolean值 tryLock(long,TimeUtil): 尝试获取锁，可以设置超时 Synchronized只有锁只与一个条件(是否获取锁)相关联，不灵活，后来Condition与Lock的结合解决了这个问题。 多线程竞争一个锁时，其余未得到锁的线程只能不停的尝试获得锁，而不能中断。高并发的情况下会导致性能下降。ReentrantLock的lockInterruptibly()方法可以优先考虑响应中断。 一个线程等待时间过长，它可以中断自己，然后ReentrantLock响应这个中断，不再让这个线程继续等待。有了这个机制，使用ReentrantLock时就不会像synchronized那样产生死锁了。 ","date":"2018-04-03","objectID":"/synchronized/:4:2","tags":["并发编程"],"title":"synchronized(无锁→偏向锁→轻量级锁→重量级锁)","uri":"/synchronized/"},{"categories":["Java基础"],"content":"再深入理解 synchronized是通过软件(JVM)实现的，简单易用，即使在JDK5之后有了Lock，仍然被广泛地使用。 ","date":"2018-04-03","objectID":"/synchronized/:5:0","tags":["并发编程"],"title":"synchronized(无锁→偏向锁→轻量级锁→重量级锁)","uri":"/synchronized/"},{"categories":["Java基础"],"content":"使用synchronized注意点 避免死锁 锁对象不能为空，因为锁的信息都保存在对象头里 作用域不宜过大，影响程序执行的速度，控制范围过大，编写代码也容易出错 在能选择的情况下，既不要用Lock也不要用synchronized关键字，用java.util.concurrent包中的各种各样的类，如果不用该包下的类，在满足业务的情况下，可以使用synchronized关键，因为代码量少，避免出错 ","date":"2018-04-03","objectID":"/synchronized/:5:1","tags":["并发编程"],"title":"synchronized(无锁→偏向锁→轻量级锁→重量级锁)","uri":"/synchronized/"},{"categories":["Java基础"],"content":"synchronized是公平锁吗？ synchronized实际上是非公平的，新来的线程有可能立即获得监视器，而在等待区中等候已久的线程可能再次等待，不过这种抢占的方式可以预防饥饿。 ","date":"2018-04-03","objectID":"/synchronized/:5:2","tags":["并发编程"],"title":"synchronized(无锁→偏向锁→轻量级锁→重量级锁)","uri":"/synchronized/"},{"categories":["Java基础"],"content":"参考文章 synchronized详解 不可不说的Java“锁”事 ","date":"2018-04-03","objectID":"/synchronized/:6:0","tags":["并发编程"],"title":"synchronized(无锁→偏向锁→轻量级锁→重量级锁)","uri":"/synchronized/"},{"categories":["Java基础"],"content":"JUC并发编程利器","date":"2018-04-02","objectID":"/juc/","tags":["并发编程","大纲"],"title":"JUC-并发编程利器","uri":"/juc/"},{"categories":["Java基础"],"content":"JUC概览\" JUC概览 ","date":"2018-04-02","objectID":"/juc/:0:0","tags":["并发编程","大纲"],"title":"JUC-并发编程利器","uri":"/juc/"},{"categories":["Java基础"],"content":"Lock框架和Tools类 Lock框架和Tools类\" Lock框架和Tools类 ","date":"2018-04-02","objectID":"/juc/:1:0","tags":["并发编程","大纲"],"title":"JUC-并发编程利器","uri":"/juc/"},{"categories":["Java基础"],"content":"接口Condition Condition为接口类型，它将 Object 监视器方法(wait、notify 和 notifyAll)分解成截然不同的对象，以便通过将这些对象与任意Lock实现组合使用，为每个对象提供多个等待set (wait-set)。其中，Lock替代了synchronized方法和语句的使用，Condition替代了Object监视器方法的使用。可以通过await(),signal()来休眠/唤醒线程。 ","date":"2018-04-02","objectID":"/juc/:1:1","tags":["并发编程","大纲"],"title":"JUC-并发编程利器","uri":"/juc/"},{"categories":["Java基础"],"content":"接口Lock Lock为接口类型，Lock实现提供了比使用synchronized方法和语句可获得的更广泛的锁定操作。此实现允许更灵活的结构，可以具有差别很大的属性，可以支持多个相关的Condition对象。 ","date":"2018-04-02","objectID":"/juc/:1:2","tags":["并发编程","大纲"],"title":"JUC-并发编程利器","uri":"/juc/"},{"categories":["Java基础"],"content":"接口ReadWriteLock ReadWriteLock为接口类型， 维护了一对相关的锁，一个用于只读操作，另一个用于写入操作。只要没有 writer，读取锁可以由多个 reader 线程同时保持。写入锁是独占的。 ","date":"2018-04-02","objectID":"/juc/:1:3","tags":["并发编程","大纲"],"title":"JUC-并发编程利器","uri":"/juc/"},{"categories":["Java基础"],"content":"抽象类AbstractOwnableSynchonizer AbstractOwnableSynchonizer为抽象类，可以由线程以独占方式拥有的同步器。此类为创建锁和相关同步器(伴随着所有权的概念)提供了基础。AbstractOwnableSynchronizer 类本身不管理或使用此信息。但是，子类和工具可以使用适当维护的值帮助控制和监视访问以及提供诊断。 ","date":"2018-04-02","objectID":"/juc/:1:4","tags":["并发编程","大纲"],"title":"JUC-并发编程利器","uri":"/juc/"},{"categories":["Java基础"],"content":"抽象类AbstractQueuedLongSynchronizer(long) AbstractQueuedLongSynchronizer为抽象类，以 long 形式维护同步状态的一个 AbstractQueuedSynchronizer 版本。此类具有的结构、属性和方法与 AbstractQueuedSynchronizer 完全相同，但所有与状态相关的参数和结果都定义为 long 而不是 int。当创建需要 64 位状态的多级别锁和屏障等同步器时，此类很有用。 ","date":"2018-04-02","objectID":"/juc/:1:5","tags":["并发编程","大纲"],"title":"JUC-并发编程利器","uri":"/juc/"},{"categories":["Java基础"],"content":"核心抽象类AbstractQueuedSynchronizer(int) AbstractQueuedSynchronizer为抽象类，其为实现依赖于先进先出 (FIFO) 等待队列的阻塞锁和相关同步器(信号量、事件，等等)提供一个框架。此类的设计目标是成为依靠单个原子int值来表示状态的大多数同步器的一个有用基础。 ","date":"2018-04-02","objectID":"/juc/:1:6","tags":["并发编程","大纲"],"title":"JUC-并发编程利器","uri":"/juc/"},{"categories":["Java基础"],"content":"锁常用类LockSupport LockSupport为常用类，主要作用就是挂起线程，唤醒线程。LockSupport的功能和\"Thread中的 Thread.suspend()和Thread.resume()有点类似”，LockSupport中的park() 和 unpark() 的作用分别是阻塞线程和解除阻塞线程。但是park()和unpark()不会遇到“Thread.suspend 和 Thread.resume所可能引发的死锁”问题。 该流程在购物APP上非常常见，当你准备支付时放弃，会有一个支付失效，在支付失效期内可以随时回来支付，过期后需要重新选取支付商品。 这里基于LockSupport中park和unpark控制线程状态，实现的等待通知机制。 public class LockAPI04 { public static void main(String[] args) throws Exception { OrderPay orderPay = new OrderPay(\"UnPaid\") ; Thread orderThread = new Thread(orderPay) ; orderThread.start(); Thread.sleep(3000); orderPay.changeState(\"Pay\"); LockSupport.unpark(orderThread); } } class OrderPay implements Runnable { // 支付状态 private String orderState ; public OrderPay (String orderState){ this.orderState = orderState ; } public synchronized void changeState (String orderState){ this.orderState = orderState ; } @Override public void run() { if (orderState.equals(\"UnPaid\")){ System.out.println(\"订单待支付...\"+orderState); LockSupport.park(orderState); } System.out.println(\"orderState=\"+orderState); System.out.println(\"订单准备发货...\"); } } ","date":"2018-04-02","objectID":"/juc/:1:7","tags":["并发编程","大纲"],"title":"JUC-并发编程利器","uri":"/juc/"},{"categories":["Java基础"],"content":"锁常用类ReentrantLock ReentrantLock为常用类，它是一个可重入的互斥锁 Lock，它具有与使用 synchronized 方法和语句所访问的隐式监视器锁相同的一些基本行为和语义，但功能更强大。 ","date":"2018-04-02","objectID":"/juc/:1:8","tags":["并发编程","大纲"],"title":"JUC-并发编程利器","uri":"/juc/"},{"categories":["Java基础"],"content":"锁常用类ReentrantReadWriteLock ReentrantReadWriteLock是读写锁接口ReadWriteLock的实现类，它包括Lock子类ReadLock和WriteLock。ReadLock是共享锁，WriteLock是独占锁。 基于读锁时，其他线程可以进行读操作，基于写锁时，其他线程读、写操作都禁止。 public class LockAPI03 { public static void main(String[] args) throws Exception { DataMap dataMap = new DataMap() ; Thread read = new Thread(new GetRun(dataMap)) ; Thread write = new Thread(new PutRun(dataMap)) ; write.start(); Thread.sleep(2000); read.start(); } } class GetRun implements Runnable { private DataMap dataMap ; public GetRun (DataMap dataMap){ this.dataMap = dataMap ; } @Override public void run() { System.out.println(\"GetRun：\"+dataMap.get(\"myKey\")); } } class PutRun implements Runnable { private DataMap dataMap ; public PutRun (DataMap dataMap){ this.dataMap = dataMap ; } @Override public void run() { dataMap.put(\"myKey\",\"myValue\"); } } class DataMap { Map\u003cString,String\u003e dataMap = new HashMap\u003c\u003e() ; ReadWriteLock rwLock = new ReentrantReadWriteLock() ; Lock readLock = rwLock.readLock() ; Lock writeLock = rwLock.writeLock() ; // 读取数据 public String get (String key){ readLock.lock(); try{ return dataMap.get(key) ; } finally { readLock.unlock(); } } // 写入数据 public void put (String key,String value){ writeLock.lock(); try{ dataMap.put(key,value) ; System.out.println(\"执行写入结束...\"); Thread.sleep(10000); } catch (Exception e) { System.out.println(\"Exception...\"); } finally { writeLock.unlock(); } } } ","date":"2018-04-02","objectID":"/juc/:1:9","tags":["并发编程","大纲"],"title":"JUC-并发编程利器","uri":"/juc/"},{"categories":["Java基础"],"content":"锁常用类StampedLock 它是java8在java.util.concurrent.locks新增的一个API。StampedLock控制锁有三种模式(写，读，乐观读)，一个StampedLock状态是由版本和模式两个部分组成，锁获取方法返回一个数字作为票据stamp，它用相应的锁状态表示并控制访问，数字0表示没有写锁被授权访问。在读锁上分为悲观锁和乐观锁。 ","date":"2018-04-02","objectID":"/juc/:1:10","tags":["并发编程","大纲"],"title":"JUC-并发编程利器","uri":"/juc/"},{"categories":["Java基础"],"content":"工具常用类CountDownLatch CountDownLatch为常用类，它是一个同步辅助类，在完成一组正在其他线程中执行的操作之前，它允许一个或多个线程一直等待。 ","date":"2018-04-02","objectID":"/juc/:1:11","tags":["并发编程","大纲"],"title":"JUC-并发编程利器","uri":"/juc/"},{"categories":["Java基础"],"content":"工具常用类CyclicBarrier CyclicBarrier为常用类，其是一个同步辅助类，它允许一组线程互相等待，直到到达某个公共屏障点 (common barrier point)。在涉及一组固定大小的线程的程序中，这些线程必须不时地互相等待，此时 CyclicBarrier 很有用。因为该 barrier 在释放等待线程后可以重用，所以称它为循环 的 barrier。 ","date":"2018-04-02","objectID":"/juc/:1:12","tags":["并发编程","大纲"],"title":"JUC-并发编程利器","uri":"/juc/"},{"categories":["Java基础"],"content":"工具常用类Phaser Phaser是JDK 7新增的一个同步辅助类，它可以实现CyclicBarrier和CountDownLatch类似的功能，而且它支持对任务的动态调整，并支持分层结构来达到更高的吞吐量。 ","date":"2018-04-02","objectID":"/juc/:1:13","tags":["并发编程","大纲"],"title":"JUC-并发编程利器","uri":"/juc/"},{"categories":["Java基础"],"content":"工具常用类Semaphore Semaphore为常用类，其是一个计数信号量，从概念上讲，信号量维护了一个许可集。如有必要，在许可可用前会阻塞每一个 acquire()，然后再获取该许可。每个 release() 添加一个许可，从而可能释放一个正在阻塞的获取者。但是，不使用实际的许可对象，Semaphore 只对可用许可的号码进行计数，并采取相应的行动。通常用于限制可以访问某些资源(物理或逻辑的)的线程数目。 ","date":"2018-04-02","objectID":"/juc/:1:14","tags":["并发编程","大纲"],"title":"JUC-并发编程利器","uri":"/juc/"},{"categories":["Java基础"],"content":"工具常用类Exchanger Exchanger是用于线程协作的工具类, 主要用于两个线程之间的数据交换。它提供一个同步点，在这个同步点，两个线程可以交换彼此的数据。这两个线程通过exchange()方法交换数据，当一个线程先执行exchange()方法后，它会一直等待第二个线程也执行exchange()方法，当这两个线程到达同步点时，这两个线程就可以交换数据了。 ","date":"2018-04-02","objectID":"/juc/:1:15","tags":["并发编程","大纲"],"title":"JUC-并发编程利器","uri":"/juc/"},{"categories":["Java基础"],"content":"对比 同步工具 同步工具与AQS的关联 ReentrantLock 使用AQS保存锁重复持有的次数。当一个线程获取锁时，ReentrantLock记录当前获得锁的线程标识，用于检测是否重复获取，以及错误线程试图解锁操作时异常情况的处理。 Semaphore 使用AQS同步状态来保存信号量的当前计数。tryRelease会增加计数，acquireShared会减少计数。 CountDownLatch 使用AQS同步状态来表示计数。计数为0时，所有的Acquire操作（CountDownLatch的await方法）才可以通过。 ReentrantReadWriteLock 使用AQS同步状态中的16位保存写锁持有的次数，剩下的16位用于保存读锁的持有次数。 ThreadPoolExecutor Worker利用AQS同步状态实现对独占线程变量的设置（tryAcquire和tryRelease）。 ","date":"2018-04-02","objectID":"/juc/:1:16","tags":["并发编程","大纲"],"title":"JUC-并发编程利器","uri":"/juc/"},{"categories":["Java基础"],"content":"Collections: 并发集合 并发集合\" 并发集合 ","date":"2018-04-02","objectID":"/juc/:2:0","tags":["并发编程","大纲"],"title":"JUC-并发编程利器","uri":"/juc/"},{"categories":["Java基础"],"content":"CAS,Unsafe和原子类 JUC中多数类是通过volatile和CAS来实现的，CAS本质上提供的是一种无锁方案，而Synchronized和Lock是互斥锁方案; Java原子类本质上使用的是CAS，而CAS底层是通过Unsafe类实现的。 ","date":"2018-04-02","objectID":"/juc/:3:0","tags":["并发编程","大纲"],"title":"JUC-并发编程利器","uri":"/juc/"},{"categories":["Java基础"],"content":"Atomic原子类 其基本的特性就是在多线程环境下，当有多个线程同时执行这些类的实例包含的方法时，具有排他性，即当某个线程进入方法，执行其中的指令时，不会被其他线程打断，而别的线程就像自旋锁一样，一直等到该方法执行完成，才由JVM从等待队列中选择一个另一个线程进入，这只是一种逻辑上的理解。实际上是借助硬件的相关指令来实现的，不会阻塞线程(或者说只是在硬件级别上阻塞了)。 ","date":"2018-04-02","objectID":"/juc/:3:1","tags":["并发编程","大纲"],"title":"JUC-并发编程利器","uri":"/juc/"},{"categories":["Java基础"],"content":"Executors线程池 线程池\" 线程池 ","date":"2018-04-02","objectID":"/juc/:4:0","tags":["并发编程","大纲"],"title":"JUC-并发编程利器","uri":"/juc/"},{"categories":["Java基础"],"content":"Executor Executor接口提供一种将任务提交与每个任务将如何运行的机制(包括线程使用的细节、调度等)分离开来的方法。通常使用 Executor 而不是显式地创建线程。 ","date":"2018-04-02","objectID":"/juc/:4:1","tags":["并发编程","大纲"],"title":"JUC-并发编程利器","uri":"/juc/"},{"categories":["Java基础"],"content":"ExecutorService ExecutorService继承自Executor接口，ExecutorService提供了管理终止的方法，以及可为跟踪一个或多个异步任务执行状况而生成 Future 的方法。 可以关闭 ExecutorService，这将导致其停止接受新任务。关闭后，执行程序将最后终止，这时没有任务在执行，也没有任务在等待执行，并且无法提交新任务。 ","date":"2018-04-02","objectID":"/juc/:4:2","tags":["并发编程","大纲"],"title":"JUC-并发编程利器","uri":"/juc/"},{"categories":["Java基础"],"content":"ScheduledExecutorService ScheduledExecutorService继承自ExecutorService接口，可安排在给定的延迟后运行或定期执行的命令。 ","date":"2018-04-02","objectID":"/juc/:4:3","tags":["并发编程","大纲"],"title":"JUC-并发编程利器","uri":"/juc/"},{"categories":["Java基础"],"content":"AbstractExecutorService AbstractExecutorService继承自ExecutorService接口，其提供 ExecutorService 执行方法的默认实现。此类使用 newTaskFor 返回的 RunnableFuture 实现 submit、invokeAny 和 invokeAll 方法，默认情况下，RunnableFuture 是此包中提供的 FutureTask 类。 ","date":"2018-04-02","objectID":"/juc/:4:4","tags":["并发编程","大纲"],"title":"JUC-并发编程利器","uri":"/juc/"},{"categories":["Java基础"],"content":"FutureTask FutureTask 为 Future 提供了基础实现，如获取任务执行结果(get)和取消任务(cancel)等。如果任务尚未完成，获取任务执行结果时将会阻塞。一旦执行结束，任务就不能被重启或取消(除非使用runAndReset执行计算)。FutureTask 常用来封装 Callable 和 Runnable，也可以作为一个任务提交到线程池中执行。除了作为一个独立的类之外，此类也提供了一些功能性函数供我们创建自定义 task 类使用。FutureTask 的线程安全由CAS来保证。 ","date":"2018-04-02","objectID":"/juc/:4:5","tags":["并发编程","大纲"],"title":"JUC-并发编程利器","uri":"/juc/"},{"categories":["Java基础"],"content":"核心: ThreadPoolExecutor ThreadPoolExecutor实现了AbstractExecutorService接口，也是一个 ExecutorService，它使用可能的几个池线程之一执行每个提交的任务，通常使用 Executors 工厂方法配置。 线程池可以解决两个不同问题: 由于减少了每个任务调用的开销，它们通常可以在执行大量异步任务时提供增强的性能，并且还可以提供绑定和管理资源(包括执行任务集时使用的线程)的方法。每个 ThreadPoolExecutor 还维护着一些基本的统计数据，如完成的任务数。 ","date":"2018-04-02","objectID":"/juc/:4:6","tags":["并发编程","大纲"],"title":"JUC-并发编程利器","uri":"/juc/"},{"categories":["Java基础"],"content":"核心: ScheduledThreadExecutor ScheduledThreadPoolExecutor实现ScheduledExecutorService接口，可安排在给定的延迟后运行命令，或者定期执行命令。需要多个辅助线程时，或者要求 ThreadPoolExecutor 具有额外的灵活性或功能时，此类要优于 Timer。 ","date":"2018-04-02","objectID":"/juc/:4:7","tags":["并发编程","大纲"],"title":"JUC-并发编程利器","uri":"/juc/"},{"categories":["Java基础"],"content":"核心: Fork/Join框架 ForkJoinPool 是JDK 7加入的一个线程池类。Fork/Join 技术是分治算法(Divide-and-Conquer)的并行实现，它是一项可以获得良好的并行性能的简单且高效的设计技术。目的是为了帮助我们更好地利用多处理器带来的好处，使用所有可用的运算能力来提升应用的性能。 ","date":"2018-04-02","objectID":"/juc/:4:8","tags":["并发编程","大纲"],"title":"JUC-并发编程利器","uri":"/juc/"},{"categories":["Java基础"],"content":"工具类: Executors Executors是一个工具类，用其可以创建ExecutorService、ScheduledExecutorService、ThreadFactory、Callable等对象。它的使用融入到了ThreadPoolExecutor, ScheduledThreadExecutor和ForkJoinPool中。 ","date":"2018-04-02","objectID":"/juc/:4:9","tags":["并发编程","大纲"],"title":"JUC-并发编程利器","uri":"/juc/"},{"categories":["Java基础"],"content":"Java并发编程","date":"2018-04-01","objectID":"/javacurrent/","tags":["并发编程","大纲"],"title":"Java并发编程概览","uri":"/javacurrent/"},{"categories":["Java基础"],"content":"Java并发编程概览Java并发编程概览 \" Java并发编程概览 ","date":"2018-04-01","objectID":"/javacurrent/:0:0","tags":["并发编程","大纲"],"title":"Java并发编程概览","uri":"/javacurrent/"},{"categories":["Java基础"],"content":"并发三要素 ","date":"2018-04-01","objectID":"/javacurrent/:1:0","tags":["并发编程","大纲"],"title":"Java并发编程概览","uri":"/javacurrent/"},{"categories":["Java基础"],"content":"可见性 CPU缓存引起：CPU增加了缓存，以均衡与内存的速度差异导致。 一个线程对共享变量的修改，另外一个线程能够立刻看到。 ","date":"2018-04-01","objectID":"/javacurrent/:1:1","tags":["并发编程","大纲"],"title":"Java并发编程概览","uri":"/javacurrent/"},{"categories":["Java基础"],"content":"原子性 分时复用引起：操作系统增加了进程、线程，以分时复用CPU，进而均衡CPU与I/O设备的速度差异导致。 一个操作或者多个操作 要么全部执行并且执行的过程不会被任何因素打断，要么就都不执行。 x = 10; //语句1: 直接将数值10赋值给x，也就是说线程执行这个语句的会直接将数值10写入到工作内存中 y = x; //语句2: 包含2个操作，它先要去读取x的值，再将x的值写入工作内存，虽然读取x的值以及 将x的值写入工作内存 这2个操作都是原子性操作，但是合起来就不是原子性操作了。 x++; //语句3： x++包括3个操作：读取x的值，进行加1操作，写入新的值。 x = x + 1; //语句4： 同语句3 ","date":"2018-04-01","objectID":"/javacurrent/:1:2","tags":["并发编程","大纲"],"title":"Java并发编程概览","uri":"/javacurrent/"},{"categories":["Java基础"],"content":"有序性 重排序引起：由于编译程序指令重排序优化指令执行次序，使得缓存能够得到更加合理地利用导致。 程序执行的顺序按照代码的先后顺序执行。 可参考多线程环境下初始化一个对象的过程来理解。点击查看 ","date":"2018-04-01","objectID":"/javacurrent/:1:3","tags":["并发编程","大纲"],"title":"Java并发编程概览","uri":"/javacurrent/"},{"categories":["Java基础"],"content":"线程安全的实现方法 ","date":"2018-04-01","objectID":"/javacurrent/:2:0","tags":["并发编程","大纲"],"title":"Java并发编程概览","uri":"/javacurrent/"},{"categories":["Java基础"],"content":"互斥同步(阻塞同步) synchronized(JVM实现) Lock\u0026ReentrantLock(JDK实现) 互斥同步最主要的问题就是线程阻塞和唤醒所带来的性能问题，因此这种同步也称为阻塞同步。 互斥同步属于一种悲观的并发策略，总是认为只要不去做正确的同步措施，那就肯定会出现问题。无论共享数据是否真的会出现竞争，它都要进行加锁(这里讨论的是概念模型，实际上虚拟机会优化掉很大一部分不必要的加锁)、用户态核心态转换、维护锁计数器和检查是否有被阻塞的线程需要唤醒等操作。 ","date":"2018-04-01","objectID":"/javacurrent/:2:1","tags":["并发编程","大纲"],"title":"Java并发编程概览","uri":"/javacurrent/"},{"categories":["Java基础"],"content":"非阻塞同步 CAS 随着硬件指令集的发展，我们可以使用基于冲突检测的乐观并发策略: 先进行操作，如果没有其它线程争用共享数据，那操作就成功了，否则采取补偿措施(不断地重试，直到成功为止)。 这种乐观的并发策略的许多实现都不需要将线程阻塞，因此这种同步操作称为非阻塞同步。 乐观锁需要操作和冲突检测这两个步骤具备原子性，这里就不能再使用互斥同步来保证了，只能靠硬件来完成。 硬件支持的原子性操作最典型的是: 比较并交换(Compare-and-Swap，CAS)。 CAS指令需要有3个操作数，分别是内存地址V旧的预期值A和新值B。当执行操作时，只有当V的值等于A，才将V的值更新为B。 ABA问题 如果一个变量初次读取的时候是 A 值，它的值被改成了 B，后来又被改回为 A，那 CAS 操作就会误认为它从来没有被改变过。 J.U.C 包提供了一个带有标记的原子引用类 AtomicStampedReference 来解决这个问题，它可以通过控制变量值的版本来保证 CAS 的正确性。 大部分情况下 ABA 问题不会影响程序并发的正确性，如果需要解决 ABA 问题，改用传统的互斥同步可能会比原子类更高效。 AtomicInteger J.U.C 包里面的整数原子类 AtomicInteger，其中的 compareAndSet() 和 getAndIncrement() 等方法都使用了 Unsafe 类的 CAS 操作。 public final int incrementAndGet() { return unsafe.getAndAddInt(this, valueOffset, 1) + 1; } public final int getAndAddInt(Object var1, long var2, int var4) { int var5; do { var5 = this.getIntVolatile(var1, var2); } while(!this.compareAndSwapInt(var1, var2, var5, var5 + var4)); return var5; } ","date":"2018-04-01","objectID":"/javacurrent/:2:2","tags":["并发编程","大纲"],"title":"Java并发编程概览","uri":"/javacurrent/"},{"categories":["Java基础"],"content":"无需同步方案 栈封闭 多个线程访问同一个方法的局部变量时，不会出现线程安全问题，因为局部变量存储在虚拟机栈中，属于线程私有的。 线程本地存储(ThreadLocal) 如果一段代码中所需要的数据必须与其他代码共享，那就看看这些共享数据的代码是否能保证在同一个线程中执行。如果能保证，我们就可以把共享数据的可见范围限制在同一个线程之内，这样，无须同步也能保证线程之间不出现数据争用的问题。 符合这种特点的应用并不少见，大部分使用消费队列的架构模式(如“生产者-消费者”模式)都会将产品的消费过程尽量在一个线程中消费完。 其中最重要的一个应用实例就是经典 Web 交互模型中的“一个请求对应一个服务器线程”(Thread-per-Request)的处理方式，这种处理方式的广泛应用使得很多 Web 服务端应用都可以使用线程本地存储来解决线程安全问题。 可重入代码 这种代码也叫做纯代码(Pure Code)，可以在代码执行的任何时刻中断它，转而去执行另外一段代码(包括递归调用它本身)，而在控制权返回后，原来的程序不会出现任何错误。 可重入代码有一些共同的特征，例如不依赖存储在堆上的数据和公用的系统资源、用到的状态量都由参数中传入、不调用非可重入的方法等。 ","date":"2018-04-01","objectID":"/javacurrent/:2:3","tags":["并发编程","大纲"],"title":"Java并发编程概览","uri":"/javacurrent/"},{"categories":["Java基础"],"content":"解决并发 ","date":"2018-04-01","objectID":"/javacurrent/:3:0","tags":["并发编程","大纲"],"title":"Java并发编程概览","uri":"/javacurrent/"},{"categories":["Java基础"],"content":"3个关键字 synchronized：原子性，可见性，有序性 volatile：有序性，可见性 防重排序 public class Singleton { public static volatile Singleton singleton; /** * 构造函数私有，禁止外部实例化 */ private Singleton() {}; public static Singleton getInstance() { if (singleton == null) { synchronized (singleton.class) { if (singleton == null) { singleton = new Singleton(); } } } return singleton; } } 现在我们分析一下为什么要在变量singleton之间加上volatile关键字。要理解这个问题，先要了解对象的构造过程，实例化一个对象其实可以分为三个步骤： 1. 分配内存空间。 2. 初始化对象。 3. 将内存空间的地址赋值给对应的引用。 但是由于操作系统可以对指令进行重排序，所以上面的过程也可能会变成如下过程： 分配内存空间。 将内存空间的地址赋值给对应的引用。 初始化对象 如果是这个流程，多线程环境下就可能将一个未初始化的对象引用暴露出来，从而导致不可预料的结果。因此，为了防止这个过程的重排序，我们需要将变量设置为volatile类型的变量。 实现可见性 volatile 变量的内存可见性是基于内存屏障(Memory Barrier)实现: 内存屏障，又称内存栅栏，是一个 CPU 指令。 在程序运行时，为了提高执行性能，编译器和处理器会对指令进行重排序，JMM 为了保证在不同的编译器和 CPU 上有相同的结果，通过插入特定类型的内存屏障来禁止+ 特定类型的编译器重排序和处理器重排序，插入一条内存屏障会告诉编译器和 CPU：不管什么指令都不能和这条 Memory Barrier 指令重排序。 详细见：volatile理论基础 使用 volatile 必须具备的条件 对变量的写操作不依赖于当前值。 该变量没有包含在具有其他变量的不变式中。 只有在状态真正独立于程序内其他内容时才能使用volatile。 final：有序性 写final域的重排序规则可以确保：在对象引用为任意线程可见之前，对象的final域已经被正确初始化过了，而普通域就不具有这个保障。 读final域的重排序规则可以确保：在读一个对象的final域之前，一定会先读这个包含这个final域的对象的引用。 ","date":"2018-04-01","objectID":"/javacurrent/:3:1","tags":["并发编程","大纲"],"title":"Java并发编程概览","uri":"/javacurrent/"},{"categories":["Java基础"],"content":"Happens-Before 规则 上面提到了可以用volatile和synchronized来保证有序性。除此之外，JVM 还规定了先行发生原则，让一个操作无需控制就能先于另一个操作完成。 单一线程原则（在一个线程内，在程序前面的操作先行发生于后面的操作。） 管程锁定规则（一个 unlock 操作先行发生于后面对同一个锁的 lock 操作。） volatile 变量规则（对一个 volatile 变量的写操作先行发生于后面对这个变量的读操作。） 线程启动规则（Thread 对象的 start() 方法调用先行发生于此线程的每一个动作。） 线程加入规则（Thread 对象的结束先行发生于 join() 方法返回。） 线程中断规则（对线程 interrupt()方法的调用先行发生于被中断线程的代码检测到中断事件的发生，可以通过interrupted()方法检测到是否有中断发生。） 对象终结规则 一个对象的初始化完成(构造函数执行结束)先行发生于它的 finalize() 方法的开始。 传递性（如果操作 A 先行发生于操作 B，操作 B 先行发生于操作 C，那么操作 A 先行发生于操作 C。） ","date":"2018-04-01","objectID":"/javacurrent/:3:2","tags":["并发编程","大纲"],"title":"Java并发编程概览","uri":"/javacurrent/"},{"categories":["Java基础"],"content":"锁优化及JMM 新的JDK优化锁的实现保证并发，内存模型也会保证可见性。 ","date":"2018-04-01","objectID":"/javacurrent/:3:3","tags":["并发编程","大纲"],"title":"Java并发编程概览","uri":"/javacurrent/"},{"categories":["Java基础"],"content":"J.U.C框架 ","date":"2018-04-01","objectID":"/javacurrent/:4:0","tags":["并发编程","大纲"],"title":"Java并发编程概览","uri":"/javacurrent/"},{"categories":["Java基础"],"content":"Unsafe(CAS)和原子类 ","date":"2018-04-01","objectID":"/javacurrent/:4:1","tags":["并发编程","大纲"],"title":"Java并发编程概览","uri":"/javacurrent/"},{"categories":["Java基础"],"content":"AQS框架 AQS框架借助于两个类：Unsafe(提供CAS操作)和LockSupport(提供park/unpark操作)。 ","date":"2018-04-01","objectID":"/javacurrent/:4:2","tags":["并发编程","大纲"],"title":"Java并发编程概览","uri":"/javacurrent/"},{"categories":["Java基础"],"content":"锁 LockSupport ReentrantLock ReentrantReadWriteLock ","date":"2018-04-01","objectID":"/javacurrent/:4:3","tags":["并发编程","大纲"],"title":"Java并发编程概览","uri":"/javacurrent/"},{"categories":["Java基础"],"content":"并发集合 ConcurrentHashMap CopyOnWriteArrayList ConcurrentLinkedQueue BlockingQueue ","date":"2018-04-01","objectID":"/javacurrent/:4:4","tags":["并发编程","大纲"],"title":"Java并发编程概览","uri":"/javacurrent/"},{"categories":["Java基础"],"content":"线程池 FutureTask ThreadPoolExecutor ScheduledThreadPoolExecutor Fork/Join ","date":"2018-04-01","objectID":"/javacurrent/:4:5","tags":["并发编程","大纲"],"title":"Java并发编程概览","uri":"/javacurrent/"},{"categories":["Java基础"],"content":"工具类 CountDownLatch CyclicBarrier Semaphore Phaser Exchanger ThreadLocal ","date":"2018-04-01","objectID":"/javacurrent/:4:6","tags":["并发编程","大纲"],"title":"Java并发编程概览","uri":"/javacurrent/"},{"categories":["Java基础"],"content":"参考文章 Java 并发 - 理论基础 ","date":"2018-04-01","objectID":"/javacurrent/:5:0","tags":["并发编程","大纲"],"title":"Java并发编程概览","uri":"/javacurrent/"},{"categories":["Java基础"],"content":"HashMap详解","date":"2018-03-03","objectID":"/hashmap/","tags":["数据结构"],"title":"HashMap详解","uri":"/hashmap/"},{"categories":["Java基础"],"content":"实现步骤 HashMap基于哈希散列表，数组+链表/红黑树实现。 通过key的hashCode()方法计算出hashCode。 通过HashMap类中内部hash()方法将第2步中hashCode带入得出hash值。 通过第3步中hash值和HashMap中数组长度做\u0026(位运算)得出在数组中的位置。 当第4步中位置中没有值则直接放入。 当第4步中位置中有值即产生hash冲突问题，此时通过链表(拉链法)来解决hash冲突问题。 如果第6步中第链表大小超过阈值（TREEIFY_THRESHOLD,8），链表转换为红黑树。 在转换为红黑树时，会判断数组长度大于64才转换，否则继续采用扩容策略而不转换。 ","date":"2018-03-03","objectID":"/hashmap/:1:0","tags":["数据结构"],"title":"HashMap详解","uri":"/hashmap/"},{"categories":["Java基础"],"content":"关键特性 默认初始容量值为16，负载因子为0.75，当size\u003e=threshold（ threshold等于“容量负载因子”）时，会发生扩容：newsize = oldsize2，size一定为2的n次幂 hash冲突默认采用单链表存储，当单链表节点个数大于8时且数组长度大于64，会转化为红黑树存储， 当红黑树中节点少于6时，则转化为单链表存储。 扩容针对整个Map，每次扩容时，原来数组中的元素依次重新计算存放位置，并重新插入 当Map中元素总数超过Entry数组的75%，触发扩容操作，为了减少链表长度，元素分配更均匀 ","date":"2018-03-03","objectID":"/hashmap/:2:0","tags":["数据结构"],"title":"HashMap详解","uri":"/hashmap/"},{"categories":["Java基础"],"content":"HashMap在1.7和1.8之间的变化： 1.7中是先扩容后插入新值的，1.8中是先插值再扩容 1.7中采用数组+链表，1.8采用的是数组+链表/红黑树，即在1.7中链表长度超过一定长度后就改成红黑树存储。 1.7扩容时需要重新计算哈希值和索引位置，1.8并不重新计算哈希值，巧妙地采用和扩容后容量进行\u0026操作来计算新的索引位置。 1.7是采用表头插入法插入链表，1.8采用的是尾部插入法。 在1.7中采用表头插入法，在扩容时会改变链表中元素原本的顺序，以至于在并发场景下导致链表成环的问题；在1.8中采用尾部插入法，在扩容时会保持链表元素原本的顺序，就不会出现链表成环的问题了。 ","date":"2018-03-03","objectID":"/hashmap/:3:0","tags":["数据结构"],"title":"HashMap详解","uri":"/hashmap/"},{"categories":["Java基础"],"content":"方法（JDK1.8-数组+链表/红黑树） 确定哈希桶数组索引位置 第1步计算hash 在JDK1.8的实现中，优化了高位运算的算法，通过hashCode()的高16位异或低16位实现的：(h = k.hashCode()) ^ (h »\u003e 16)，主要是从速度、功效、质量来考虑的。 目的都是在数组很小也能降低hash碰撞。 static final int hash(Object key) { int h; // key.hashCode()：返回散列值也就是hashcode // ^ ：按位异或 // \u003e\u003e\u003e:无符号右移，忽略符号位，空位都以0补齐 return (key == null) ? 0 : (h = key.hashCode()) ^ (h \u003e\u003e\u003e 16); } 第2步计算数组位置 通过(n - 1) \u0026 hash来得到该对象的保存位，而HashMap底层数组的长度总是2的n次方。 当length总是2的n次方时，h\u0026 (length-1)运算等价于对length取模，也就是h%length，但是\u0026(位运算)比%(取模运算)具有更高的效率。 (n - 1) \u0026 hash HashMap的put方法 public V put(K key, V value) { // 对key的hashCode()做hash return putVal(hash(key), key, value, false, true); } final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) { Node\u003cK,V\u003e[] tab; Node\u003cK,V\u003e p; int n, i; // 步骤①：tab为空则创建 if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; // 步骤②：计算index，并对null做处理 if ((p = tab[i = (n - 1) \u0026 hash]) == null) tab[i] = newNode(hash, key, value, null); else { Node\u003cK,V\u003e e; K k; // 步骤③：节点key存在，直接覆盖value if (p.hash == hash \u0026\u0026 ((k = p.key) == key || (key != null \u0026\u0026 key.equals(k)))) e = p; // 步骤④：判断该链为红黑树 else if (p instanceof TreeNode) e = ((TreeNode\u003cK,V\u003e)p).putTreeVal(this, tab, hash, key, value); // 步骤⑤：该链为链表 else { for (int binCount = 0; ; ++binCount) { if ((e = p.next) == null) { p.next = newNode(hash, key,value,null); //链表长度大于8转换为红黑树进行处理 if (binCount \u003e= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; } // key已经存在直接覆盖value if (e.hash == hash \u0026\u0026 ((k = e.key) == key || (key != null \u0026\u0026 key.equals(k)))) break; p = e; } } if (e != null) { // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; } } ++modCount; // 步骤⑥：超过最大容量 就扩容 if (++size \u003e threshold) resize(); afterNodeInsertion(evict); return null; } final void treeifyBin(Node\u003cK,V\u003e[] tab, int hash) { int n, index; Node\u003cK,V\u003e e; //树形化还有一个要求就是数组长度必须大于等于64，否则继续采用扩容策略 if (tab == null || (n = tab.length) \u003c MIN_TREEIFY_CAPACITY) resize(); else if ((e = tab[index = (n - 1) \u0026 hash]) != null) { TreeNode\u003cK,V\u003e hd = null, tl = null;//hd指向首节点，tl指向尾节点 do { TreeNode\u003cK,V\u003e p = replacementTreeNode(e, null);//将链表节点转化为红黑树节点 if (tl == null) // 如果尾节点为空，说明还没有首节点 hd = p; // 当前节点作为首节点 else { // 尾节点不为空，构造一个双向链表结构，将当前节点追加到双向链表的末尾 p.prev = tl; // 当前树节点的前一个节点指向尾节点 tl.next = p; // 尾节点的后一个节点指向当前节点 } tl = p; // 把当前节点设为尾节点 } while ((e = e.next) != null); // 继续遍历单链表 //将原本的单链表转化为一个节点类型为TreeNode的双向链表 if ((tab[index] = hd) != null) // 把转换后的双向链表，替换数组原来位置上的单向链表 hd.treeify(tab); // 将当前双向链表树形化 } } //将双向链表转化为红黑树的实现 final void treeify(Node\u003cK,V\u003e[] tab) { TreeNode\u003cK,V\u003e root = null; // 定义红黑树的根节点 for (TreeNode\u003cK,V\u003e x = this, next; x != null; x = next) { // 从TreeNode双向链表的头节点开始逐个遍历 next = (TreeNode\u003cK,V\u003e)x.next; // 头节点的后继节点 x.left = x.right = null; if (root == null) { x.parent = null; x.red = false; root = x; // 头节点作为红黑树的根，设置为黑色 } else { // 红黑树存在根节点 K k = x.key; int h = x.hash; Class\u003c?\u003e kc = null; for (TreeNode\u003cK,V\u003e p = root;;) { // 从根开始遍历整个红黑树 int dir, ph; K pk = p.key; if ((ph = p.hash) \u003e h) // 当前红黑树节点p的hash值大于双向链表节点x的哈希值 dir = -1; else if (ph \u003c h) // 当前红黑树节点的hash值小于双向链表节点x的哈希值 dir = 1; else if ((kc == null \u0026\u0026 (kc = comparableClassFor(k)) == null) || (dir = compareComparables(kc, k, pk)) == 0) // 当前红黑树节点的hash值等于双向链表节点x的哈希值，则如果key值采用比较器一致则比较key值 dir = tieBreakOrder(k, pk); //如果key值也一致则比较className和identityHashCode TreeNode\u003cK,V\u003e xp = p; if ((p = (dir \u003c= 0) ? p.left : p.right) == null) { // 如果当前红黑树节点p是叶子节点，那么双向链表节点x就找到了插入的位置 x.parent = xp; if (dir \u003c= 0) //根据dir的值，插入到p的左孩子或者右孩子 xp.left = x; else xp.right = x; root = balanceInsertion(root, x); //红黑树中插入元素，需要进行平衡调整(过程和TreeMap调整逻辑一模一样) break; } } } } //将TreeNode双向链表转化为红黑树结构之后，由于红黑树是基于根节点进行查找，所以必须将红黑树的根节点作为数组当前位置的元素 moveRootToFront(tab, root); } //然后将红黑树的根节点移动端数组的索引所在位置上 static \u003cK,V\u003e void moveRootToFront(Node\u003cK,V\u003e[] tab, TreeNode\u003cK,V\u003e root) { int n; if (root != null \u0026\u0026 tab != null \u0026\u0026 (n = tab.length) \u003e 0) { int index = (n - 1) \u0026 root.hash; //找到红黑树根节点在数组中的位置 TreeNode\u003cK,V\u003e first = (TreeNode\u003cK,V\u003e)tab[inde","date":"2018-03-03","objectID":"/hashmap/:4:0","tags":["数据结构"],"title":"HashMap详解","uri":"/hashmap/"},{"categories":["Java基础"],"content":"参考文章 https://www.hollischuang.com/archives/2091 https://yuanrengu.com/2020/ba184259.html https://zhuanlan.zhihu.com/p/21673805 https://mp.weixin.qq.com/s?__biz=MzIwNTI2ODY5OA==\u0026mid=2649938471\u0026idx=1\u0026sn=2964df2adc4feaf87c11b4915b9a018e ","date":"2018-03-03","objectID":"/hashmap/:5:0","tags":["数据结构"],"title":"HashMap详解","uri":"/hashmap/"},{"categories":["Java基础"],"content":"ArrayList详解","date":"2018-03-02","objectID":"/arraylist/","tags":["数据结构"],"title":"ArrayList详解","uri":"/arraylist/"},{"categories":["Java基础"],"content":"ArrayList 简介 ArrayList 的底层是数组队列，相当于动态数组。与 Java 中的数组相比，它的容量能动态增长。在添加大量元素前，应用程序可以使用ensureCapacity操作来增加 ArrayList 实例的容量。这可以减少递增式再分配的数量。 ","date":"2018-03-02","objectID":"/arraylist/:1:0","tags":["数据结构"],"title":"ArrayList详解","uri":"/arraylist/"},{"categories":["Java基础"],"content":"ArrayList 核心源码解读 package java.util; import java.util.function.Consumer; import java.util.function.Predicate; import java.util.function.UnaryOperator; public class ArrayList\u003cE\u003e extends AbstractList\u003cE\u003e implements List\u003cE\u003e, RandomAccess, Cloneable, java.io.Serializable { private static final long serialVersionUID = 8683452581122892189L; /** * 默认初始容量大小 */ private static final int DEFAULT_CAPACITY = 10; /** * 空数组（用于空实例）。 */ private static final Object[] EMPTY_ELEMENTDATA = {}; //用于默认大小空实例的共享空数组实例。 //我们把它从EMPTY_ELEMENTDATA数组中区分出来，以知道在添加第一个元素时容量需要增加多少。 private static final Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = {}; /** * 保存ArrayList数据的数组 */ transient Object[] elementData; // non-private to simplify nested class access /** * ArrayList 所包含的元素个数 */ private int size; /** * 带初始容量参数的构造函数（用户可以在创建ArrayList对象时自己指定集合的初始大小） */ public ArrayList(int initialCapacity) { if (initialCapacity \u003e 0) { //如果传入的参数大于0，创建initialCapacity大小的数组 this.elementData = new Object[initialCapacity]; } else if (initialCapacity == 0) { //如果传入的参数等于0，创建空数组 this.elementData = EMPTY_ELEMENTDATA; } else { //其他情况，抛出异常 throw new IllegalArgumentException(\"Illegal Capacity: \"+ initialCapacity); } } /** *默认无参构造函数 *DEFAULTCAPACITY_EMPTY_ELEMENTDATA 为0.初始化为10，也就是说初始其实是空数组 当添加第一个元素的时候数组容量才变成10 */ public ArrayList() { this.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA; } /** * 构造一个包含指定集合的元素的列表，按照它们由集合的迭代器返回的顺序。 */ public ArrayList(Collection\u003c? extends E\u003e c) { //将指定集合转换为数组 elementData = c.toArray(); //如果elementData数组的长度不为0 if ((size = elementData.length) != 0) { // 如果elementData不是Object类型数据（c.toArray可能返回的不是Object类型的数组所以加上下面的语句用于判断） if (elementData.getClass() != Object[].class) //将原来不是Object类型的elementData数组的内容，赋值给新的Object类型的elementData数组 elementData = Arrays.copyOf(elementData, size, Object[].class); } else { // 其他情况，用空数组代替 this.elementData = EMPTY_ELEMENTDATA; } } /** * 修改这个ArrayList实例的容量是列表的当前大小。 应用程序可以使用此操作来最小化ArrayList实例的存储。 */ public void trimToSize() { modCount++; if (size \u003c elementData.length) { elementData = (size == 0) ? EMPTY_ELEMENTDATA : Arrays.copyOf(elementData, size); } } //下面是ArrayList的扩容机制 //ArrayList的扩容机制提高了性能，如果每次只扩充一个， //那么频繁的插入会导致频繁的拷贝，降低性能，而ArrayList的扩容机制避免了这种情况。 /** * 如有必要，增加此ArrayList实例的容量，以确保它至少能容纳元素的数量 * @param minCapacity 所需的最小容量 */ public void ensureCapacity(int minCapacity) { //如果是true，minExpand的值为0，如果是false,minExpand的值为10 int minExpand = (elementData != DEFAULTCAPACITY_EMPTY_ELEMENTDATA) // any size if not default element table ? 0 // larger than default for default empty table. It's already // supposed to be at default size. : DEFAULT_CAPACITY; //如果最小容量大于已有的最大容量 if (minCapacity \u003e minExpand) { ensureExplicitCapacity(minCapacity); } } //得到最小扩容量 private void ensureCapacityInternal(int minCapacity) { if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) { // 获取“默认的容量”和“传入参数”两者之间的最大值 minCapacity = Math.max(DEFAULT_CAPACITY, minCapacity); } ensureExplicitCapacity(minCapacity); } //判断是否需要扩容 private void ensureExplicitCapacity(int minCapacity) { modCount++; // overflow-conscious code if (minCapacity - elementData.length \u003e 0) //调用grow方法进行扩容，调用此方法代表已经开始扩容了 grow(minCapacity); } /** * 要分配的最大数组大小 */ private static final int MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8; /** * ArrayList扩容的核心方法。 */ private void grow(int minCapacity) { // oldCapacity为旧容量，newCapacity为新容量 int oldCapacity = elementData.length; //将oldCapacity 右移一位，其效果相当于oldCapacity /2， //我们知道位运算的速度远远快于整除运算，整句运算式的结果就是将新容量更新为旧容量的1.5倍， int newCapacity = oldCapacity + (oldCapacity \u003e\u003e 1); //然后检查新容量是否大于最小需要容量，若还是小于最小需要容量，那么就把最小需要容量当作数组的新容量， if (newCapacity - minCapacity \u003c 0) newCapacity = minCapacity; //再检查新容量是否超出了ArrayList所定义的最大容量， //若超出了，则调用hugeCapacity()来比较minCapacity和 MAX_ARRAY_SIZE， //如果minCapacity大于MAX_ARRAY_SIZE，则新容量则为Interger.MAX_VALUE，否则，新容量大小则为 MAX_ARRAY_SIZE。 if (newCapacity - MAX_ARRAY_SIZE \u003e 0) newCapacity = hugeCapacity(minCapacity); // minCapacity is usually close to size, so this is a win: elementData = Arrays.copyOf(elementData, newCapacity); } //比较minCapacity和 MAX_ARRAY_SIZE private static int hug","date":"2018-03-02","objectID":"/arraylist/:2:0","tags":["数据结构"],"title":"ArrayList详解","uri":"/arraylist/"},{"categories":["Java基础"],"content":"Java容器","date":"2018-03-01","objectID":"/javacontainer/","tags":["数据结构","大纲"],"title":"Java容器概览","uri":"/javacontainer/"},{"categories":["Java基础"],"content":"概览 容器主要包括Collection和Map 两种，Collection是存储着对象的集合，而Map存储着键值对（两个对象）的映射表。 ","date":"2018-03-01","objectID":"/javacontainer/:1:0","tags":["数据结构","大纲"],"title":"Java容器概览","uri":"/javacontainer/"},{"categories":["Java基础"],"content":"Collection ","date":"2018-03-01","objectID":"/javacontainer/:2:0","tags":["数据结构","大纲"],"title":"Java容器概览","uri":"/javacontainer/"},{"categories":["Java基础"],"content":"List 对付顺序的好帮手： 存储的元素是有序的、可重复的。 ArrayList：基于动态数组实现，支持随机访问，适用于频繁的查找工作。 Vector：和ArrayList类似，但它是线程安全的。 LinkedList：基于双向链表实现，只能顺序访问，但是可以快速地在链表中间插入和删除元素。不仅如此，LinkedList还可以用作栈、队列和双向队列。 Arraylist与 LinkedList 区别? 是否保证线程安全： ArrayList和LinkedList都是不同步的，也就是不保证线程安全； 底层数据结构： Arraylist底层使用的是Object数组；LinkedList底层使用的是双向链表数据结构（JDK1.6 之前为循环链表，JDK1.7 取消了循环。） 插入和删除是否受元素位置的影响： ArrayList 采用数组存储，所以插入和删除元素的时间复杂度受元素位置的影响。 比如：执行add(E e)方法的时候， ArrayList 会默认在将指定的元素追加到此列表的末尾，这种情况时间复杂度就是 O(1)。但是如果要在指定位置 i 插入和删除元素的话（add(int index, E element)）时间复杂度就为 O(n-i)。因为在进行上述操作的时候集合中第 i 和第 i 个元素之后的(n-i)个元素都要执行向后位/向前移一位的操作。 LinkedList 采用链表存储，所以对于add(E e)方法的插入，删除元素时间复杂度不受元素位置的影响，近似 O(1)，如果是要在指定位置 i 插入和删除元素的话（(add(int index, E element)） 时间复杂度近似为 O(n) ，因为需要先移动到指定位置再插入。 是否支持快速随机访问： LinkedList 不支持高效的随机元素访问，而 ArrayList 支持。快速随机访问就是通过元素的序号快速获取元素对象(对应于get(int index)方法)。 内存空间占用： ArrayList的空间浪费主要体现在在list列表的结尾会预留一定的容量空间，而 LinkedList 的空间花费则体现在它的每一个元素都需要消耗比 ArrayList 更多的空间（因为要存放直接后继和直接前驱以及数据）。 ","date":"2018-03-01","objectID":"/javacontainer/:2:1","tags":["数据结构","大纲"],"title":"Java容器概览","uri":"/javacontainer/"},{"categories":["Java基础"],"content":"Set 注重独一无二的性质: 存储的元素是无序的、不可重复的。 HashSet：基于哈希表实现，支持快速查找，但不支持有序性操作。基于 HashMap 实现的，底层采用 HashMap 来保存元素。 LinkedHashSet：具有 HashSet 的查找效率，并且内部使用双向链表维护元素的插入顺序。LinkedHashSet 是 HashSet 的子类，并且其内部是通过 LinkedHashMap 来实现的。 TreeSet：基于红黑树实现（(自平衡的排序二叉树)），支持有序性操作，例如根据一个范围查找元素的操作。查找效率不如HashSet，HashSet 查找的时间复杂度为 O(1)，TreeSet 则为 O(logN)。 HashSet 如何检查重复 当你把对象加入HashSet时，HashSet 会先计算对象的hashcode值来判断对象加入的位置，同时也会与其他加入的对象的 hashcode 值作比较，如果没有相符的 hashcode，HashSet 会假设对象没有重复出现。但是如果发现有相同 hashcode 值的对象，这时会调用equals()方法来检查 hashcode 相等的对象是否真的相同。如果两者相同，HashSet 就不会让加入操作成功。 hashCode()与 equals() 的相关规定： 如果两个对象相等，则 hashcode 一定也是相同的 两个对象相等,对两个 equals() 方法返回 true 两个对象有相同的 hashcode 值，它们也不一定是相等的 综上，equals() 方法被覆盖过，则 hashCode() 方法也必须被覆盖 hashCode()的默认行为是对堆上的对象产生独特值。如果没有重写 hashCode()，则该 class 的两个对象无论如何都不会相等（即使这两个对象指向相同的数据）。 ","date":"2018-03-01","objectID":"/javacontainer/:2:2","tags":["数据结构","大纲"],"title":"Java容器概览","uri":"/javacontainer/"},{"categories":["Java基础"],"content":"Queue LinkedList：可以用它来实现双向队列。 PriorityQueue：基于堆结构实现，可以用它来实现优先队列。 ","date":"2018-03-01","objectID":"/javacontainer/:2:3","tags":["数据结构","大纲"],"title":"Java容器概览","uri":"/javacontainer/"},{"categories":["Java基础"],"content":"Map 用 Key 来搜索的专家: 使用键值对（key-value）存储，Key 是无序的、不可重复的，value 是无序的、可重复的，每个键最多映射到一个值。 TreeMap： 红黑树（自平衡的排序二叉树） HashMap： JDK1.8之前HashMap由数组+链表组成的，数组是HashMap的主体，链表则是主要为了解决哈希冲突而存在的（“拉链法”解决冲突）。JDK1.8 以后在解决哈希冲突时有了较大的变化，当链表长度大于阈值（默认为 8）（将链表转换成红黑树前会判断，如果当前数组的长度小于 64，那么会选择先进行数组扩容，而不是转换为红黑树）时，将链表转化为红黑树，以减少搜索时间 HashTable：和 HashMap 类似，但它是线程安全的，这意味着同一时刻多个线程同时写入 HashTable 不会导致数据不一致。它是遗留类，不应该去使用它，而是使用 ConcurrentHashMap 来支持线程安全，ConcurrentHashMap 的效率会更高。 LinkedHashMap：LinkedHashMap 继承自 HashMap，LinkedHashMap 在上面结构的基础上，增加了一条双向链表，使得上面的结构可以保持键值对的插入顺序，顺序为插入顺序或者最近最少使用（LRU）顺序。 ","date":"2018-03-01","objectID":"/javacontainer/:3:0","tags":["数据结构","大纲"],"title":"Java容器概览","uri":"/javacontainer/"},{"categories":["Java基础"],"content":"如何选择 主要根据集合的特点来选用，比如我们需要根据键值获取到元素值时就选用 Map 接口下的集合，需要排序时选择 TreeMap,不需要排序时就选择 HashMap,需要保证线程安全就选用 ConcurrentHashMap。 当我们只需要存放元素值时，就选择实现Collection 接口的集合，需要保证元素唯一时选择实现 Set 接口的集合比如 TreeSet 或 HashSet，不需要就选择实现 List 接口的比如 ArrayList 或 LinkedList，然后再根据实现这些接口的集合的特点来选用。 ","date":"2018-03-01","objectID":"/javacontainer/:4:0","tags":["数据结构","大纲"],"title":"Java容器概览","uri":"/javacontainer/"},{"categories":["Java基础"],"content":"为什么要使用 当我们需要保存一组类型相同的数据的时候，我们应该是用一个容器来保存，这个容器就是数组，但是，使用数组存储对象具有一定的弊端，因为我们在实际开发中，存储的数据的类型是多种多样的，于是，就出现了“集合”，集合同样也是用来存储多个数据的。 数组的缺点是一旦声明之后，长度就不可变了；同时，声明数组时的数据类型也决定了该数组存储的数据的类型；而且，数组存储的数据是有序的、可重复的，特点单一。 但是集合提高了数据存储的灵活性，Java 集合不仅可以用来存储不同类型不同数量的对象，还可以保存具有映射关系的数据。 ","date":"2018-03-01","objectID":"/javacontainer/:5:0","tags":["数据结构","大纲"],"title":"Java容器概览","uri":"/javacontainer/"},{"categories":["Java基础"],"content":"Java IO知识体系详解","date":"2018-02-05","objectID":"/javaio/","tags":["Java基础","大纲"],"title":"Java IO知识体系详解 ","uri":"/javaio/"},{"categories":["Java基础"],"content":"IO大纲\" IO大纲 ","date":"2018-02-05","objectID":"/javaio/:0:0","tags":["Java基础","大纲"],"title":"Java IO知识体系详解 ","uri":"/javaio/"},{"categories":["Java基础"],"content":"IO装饰者模式 以 InputStream 为例 InputStream 是抽象组件； FileInputStream 是 InputStream 的子类，属于具体组件，提供了字节流的输入操作； FilterInputStream 属于抽象装饰者，装饰者用于装饰组件，为组件提供额外的功能。例如 BufferedInputStream 为 FileInputStream 提供缓存的功能。 实例化一个具有缓存功能的字节流对象时，只需要在 FileInputStream 对象上再套一层 BufferedInputStream 对象即可。 FileInputStream fileInputStream = new FileInputStream(filePath); BufferedInputStream bufferedInputStream = new BufferedInputStream(fileInputStream); ","date":"2018-02-05","objectID":"/javaio/:1:0","tags":["Java基础","大纲"],"title":"Java IO知识体系详解 ","uri":"/javaio/"},{"categories":["Java基础"],"content":"IO常见类的使用 ","date":"2018-02-05","objectID":"/javaio/:2:0","tags":["Java基础","大纲"],"title":"Java IO知识体系详解 ","uri":"/javaio/"},{"categories":["Java基础"],"content":"磁盘操作 File 类可以用于表示文件和目录的信息，但是它不表示文件的内容。 //递归地列出一个目录下所有文件: public static void listAllFiles(File dir) { if (dir == null || !dir.exists()) { return; } if (dir.isFile()) { System.out.println(dir.getName()); return; } for (File file : dir.listFiles()) { listAllFiles(file); } } ","date":"2018-02-05","objectID":"/javaio/:2:1","tags":["Java基础","大纲"],"title":"Java IO知识体系详解 ","uri":"/javaio/"},{"categories":["Java基础"],"content":"字节操作（InputStream 和 OutputStream ） public static void copyFile(String src, String dist) throws IOException { FileInputStream in = new FileInputStream(src); FileOutputStream out = new FileOutputStream(dist); byte[] buffer = new byte[20 * 1024]; // read() 最多读取 buffer.length 个字节 // 返回的是实际读取的个数 // 返回 -1 的时候表示读到 eof，即文件尾 while (in.read(buffer, 0, buffer.length) != -1) { out.write(buffer); } in.close(); out.close(); } ","date":"2018-02-05","objectID":"/javaio/:2:2","tags":["Java基础","大纲"],"title":"Java IO知识体系详解 ","uri":"/javaio/"},{"categories":["Java基础"],"content":"字符操作（Reader 和 Writer ） //实现逐行输出文本文件的内容 public static void readFileContent(String filePath) throws IOException { FileReader fileReader = new FileReader(filePath); BufferedReader bufferedReader = new BufferedReader(fileReader); String line; while ((line = bufferedReader.readLine()) != null) { System.out.println(line); } // 装饰者模式使得 BufferedReader 组合了一个 Reader 对象 // 在调用 BufferedReader 的 close() 方法时会去调用 Reader 的 close() 方法 // 因此只要一个 close() 调用即可 bufferedReader.close(); } ","date":"2018-02-05","objectID":"/javaio/:2:3","tags":["Java基础","大纲"],"title":"Java IO知识体系详解 ","uri":"/javaio/"},{"categories":["Java基础"],"content":"对象操作(序列化Serializable \u0026 transient) 序列化就是将一个对象转换成字节序列，方便存储和传输。 序列化: ObjectOutputStream.writeObject() 反序列化: ObjectInputStream.readObject() 序列化的类需要实现Serializable接口，它只是一个标准，没有任何方法需要实现，但是如果不去实现它的话而进行序列化，会抛出异常。 transient 关键字可以使一些属性不会被序列化。 不会对静态变量进行序列化，因为序列化只是保存对象的状态，静态变量属于类的状态。 public static void main(String[] args) throws IOException, ClassNotFoundException { A a1 = new A(123, \"abc\"); String objectFile = \"file/a1\"; ObjectOutputStream objectOutputStream = new ObjectOutputStream(new FileOutputStream(objectFile)); objectOutputStream.writeObject(a1); objectOutputStream.close(); ObjectInputStream objectInputStream = new ObjectInputStream(new FileInputStream(objectFile)); A a2 = (A) objectInputStream.readObject(); objectInputStream.close(); System.out.println(a2); } private static class A implements Serializable { private int x; private String y; A(int x, String y) { this.x = x; this.y = y; } @Override public String toString() { return \"x = \" + x + \" \" + \"y = \" + y; } } ","date":"2018-02-05","objectID":"/javaio/:2:4","tags":["Java基础","大纲"],"title":"Java IO知识体系详解 ","uri":"/javaio/"},{"categories":["Java基础"],"content":"网络操作 InetAddress: 用于表示网络上的硬件资源，即 IP 地址； URL: 统一资源定位符； Sockets: 使用 TCP 协议实现网络通信； Datagram: 使用 UDP 协议实现网络通信。 /** * InetAddress * 没有公有的构造函数，只能通过静态方法来创建实例。 */ InetAddress.getByName(String host); InetAddress.getByAddress(byte[] address); /** * URL * 可以直接从 URL 中读取字节流数据。 */ public static void main(String[] args) throws IOException { URL url = new URL(\"http://www.baidu.com\"); /* 字节流 */ InputStream is = url.openStream(); /* 字符流 */ InputStreamReader isr = new InputStreamReader(is, \"utf-8\"); /* 提供缓存功能 */ BufferedReader br = new BufferedReader(isr); String line; while ((line = br.readLine()) != null) { System.out.println(line); } br.close(); } Sockets ServerSocket: 服务器端类 Socket: 客户端类 服务器和客户端通过 InputStream 和 OutputStream 进行输入输出。 Datagram DatagramSocket: 通信类 DatagramPacket: 数据包类 ","date":"2018-02-05","objectID":"/javaio/:2:5","tags":["Java基础","大纲"],"title":"Java IO知识体系详解 ","uri":"/javaio/"},{"categories":["Java基础"],"content":"Unix IO 模型简介 ","date":"2018-02-05","objectID":"/javaio/:3:0","tags":["Java基础","大纲"],"title":"Java IO知识体系详解 ","uri":"/javaio/"},{"categories":["Java基础"],"content":"阻塞式 I/O 应用进程被阻塞，直到数据复制到应用进程缓冲区中才返回。 应该注意到，在阻塞的过程中，其它程序还可以执行，因此阻塞不意味着整个操作系统都被阻塞。因为其他程序还可以执行，因此不消耗 CPU 时间，这种模型的执行效率会比较高。 阻塞式IO\" 阻塞式IO ","date":"2018-02-05","objectID":"/javaio/:3:1","tags":["Java基础","大纲"],"title":"Java IO知识体系详解 ","uri":"/javaio/"},{"categories":["Java基础"],"content":"非阻塞式 I/O 应用进程执行系统调用之后，内核返回一个错误码。应用进程可以继续执行，但是需要不断的执行系统调用来获知 I/O 是否完成，这种方式称为轮询(polling)。 由于 CPU 要处理更多的系统调用，因此这种模型是比较低效的。 非阻塞式IO\" 非阻塞式IO ","date":"2018-02-05","objectID":"/javaio/:3:2","tags":["Java基础","大纲"],"title":"Java IO知识体系详解 ","uri":"/javaio/"},{"categories":["Java基础"],"content":"信号驱动式 I/O(SIGIO) 应用进程使用 sigaction 系统调用，内核立即返回，应用进程可以继续执行，也就是说等待数据阶段应用进程是非阻塞的。内核在数据到达时向应用进程发送 SIGIO 信号，应用进程收到之后在信号处理程序中调用 recvfrom 将数据从内核复制到应用进程中。 相比于非阻塞式 I/O 的轮询方式，信号驱动 I/O 的 CPU 利用率更高。 信号驱动式IO\" 信号驱动式IO ","date":"2018-02-05","objectID":"/javaio/:3:3","tags":["Java基础","大纲"],"title":"Java IO知识体系详解 ","uri":"/javaio/"},{"categories":["Java基础"],"content":"异步 I/O(AIO) 进行 aio_read 系统调用会立即返回，应用进程继续执行，不会被阻塞，内核会在所有操作完成之后向应用进程发送信号。 异步 I/O 与信号驱动 I/O 的区别在于，异步 I/O 的信号是通知应用进程 I/O 完成，而信号驱动 I/O 的信号是通知应用进程可以开始 I/O。 异步IO\" 异步IO ","date":"2018-02-05","objectID":"/javaio/:3:4","tags":["Java基础","大纲"],"title":"Java IO知识体系详解 ","uri":"/javaio/"},{"categories":["Java基础"],"content":"I/O 复用(select 和 poll) 使用 select 或者 poll 等待数据，并且可以等待多个套接字中的任何一个变为可读，这一过程会被阻塞，当某一个套接字可读时返回。之后再使用 recvfrom 把数据从内核复制到进程中。 它可以让单个进程具有处理多个 I/O 事件的能力。又被称为 Event Driven I/O，即事件驱动 I/O。 如果一个 Web 服务器没有 I/O 复用，那么每一个 Socket 连接都需要创建一个线程去处理。如果同时有几万个连接，那么就需要创建相同数量的线程。并且相比于多进程和多线程技术，I/O 复用不需要进程线程创建和切换的开销，系统开销更小。 复用IO\" 复用IO IO多路复用工作模式 1. LT 模式 当 epoll_wait() 检测到描述符事件到达时，将此事件通知进程，进程可以不立即处理该事件，下次调用 epoll_wait() 会再次通知进程。是默认的一种模式，并且同时支持 Blocking 和 No-Blocking。 2. ET 模式 和 LT 模式不同的是，通知之后进程必须立即处理事件，下次再调用 epoll_wait() 时不会再得到事件到达的通知。 很大程度上减少了 epoll 事件被重复触发的次数，因此效率要比 LT 模式高。只支持 No-Blocking，以避免由于一个文件句柄的阻塞读/阻塞写操作把处理多个文件描述符的任务饿死。 ","date":"2018-02-05","objectID":"/javaio/:3:5","tags":["Java基础","大纲"],"title":"Java IO知识体系详解 ","uri":"/javaio/"},{"categories":["Java基础"],"content":"I/O模型比较 同步I/O与异步I/O 同步 I/O: 应用进程在调用 recvfrom 操作时会阻塞。 异步 I/O: 不会阻塞。 阻塞式 I/O、非阻塞式 I/O、I/O 复用和信号驱动 I/O 都是同步 I/O，虽然非阻塞式 I/O 和信号驱动 I/O 在等待数据阶段不会阻塞，但是在之后的将数据从内核复制到应用进程这个操作会阻塞。 前四种 I/O 模型的主要区别在于第一个阶段，而第二个阶段是一样的: 将数据从内核复制到应用进程过程中，应用进程会被阻塞。 IO对比\" IO对比 阻塞IO 和 非阻塞IO 这两个概念是程序级别的。主要描述的是程序请求操作系统IO操作后，如果IO资源没有准备好，那么程序该如何处理的问题: 前者等待；后者继续执行(并且使用线程一直轮询，直到有IO资源准备好了) 同步IO 和 非同步IO 这两个概念是操作系统级别的。主要描述的是操作系统在收到程序请求IO操作后，如果IO资源没有准备好，该如何响应程序的问题: 前者不响应，直到IO资源准备好以后；后者返回一个标记(好让程序和自己知道以后的数据往哪里通知)，当IO资源准备好以后，再用事件机制返回给程序。 ","date":"2018-02-05","objectID":"/javaio/:3:6","tags":["Java基础","大纲"],"title":"Java IO知识体系详解 ","uri":"/javaio/"},{"categories":["Java基础"],"content":"NIO Standard IO是对字节流的读写，在进行IO之前，首先创建一个流对象，流对象进行读写操作都是按字节，一个字节一个字节的来读或写。而NIO把IO抽象成块，类似磁盘的读写，每次IO操作的单位都是一个块，块被读入内存之后就是一个byte[]，NIO一次可以读或写多个字节。 ","date":"2018-02-05","objectID":"/javaio/:4:0","tags":["Java基础","大纲"],"title":"Java IO知识体系详解 ","uri":"/javaio/"},{"categories":["Java基础"],"content":"流与块 I/O 与 NIO 最重要的区别是数据打包和传输的方式，I/O 以流的方式处理数据，而 NIO 以块的方式处理数据。 面向流的 I/O 一次处理一个字节数据: 一个输入流产生一个字节数据，一个输出流消费一个字节数据。为流式数据创建过滤器非常容易，链接几个过滤器，以便每个过滤器只负责复杂处理机制的一部分。不利的一面是，面向流的 I/O 通常相当慢。 面向块的 I/O 一次处理一个数据块，按块处理数据比按流处理数据要快得多。但是面向块的 I/O 缺少一些面向流的 I/O 所具有的优雅性和简单性。 I/O 包和 NIO 已经很好地集成了，java.io.* 已经以 NIO 为基础重新实现了，所以现在它可以利用 NIO 的一些特性。例如，java.io.* 包中的一些类包含以块的形式读写数据的方法，这使得即使在面向流的系统中，处理速度也会更快。 ","date":"2018-02-05","objectID":"/javaio/:4:1","tags":["Java基础","大纲"],"title":"Java IO知识体系详解 ","uri":"/javaio/"},{"categories":["Java基础"],"content":"通道与缓冲区 通道 通道Channel 是对原 I/O 包中的流的模拟，可以通过它读取和写入数据。 通道与流的不同之处在于，流只能在一个方向上移动(一个流必须是 InputStream 或者 OutputStream 的子类)，而通道是双向的，可以用于读、写或者同时用于读写。 通道包括以下类型: FileChannel: 从文件中读写数据； DatagramChannel: 通过 UDP 读写网络中数据； SocketChannel: 通过 TCP 读写网络中数据； ServerSocketChannel: 可以监听新进来的 TCP 连接，对每一个新进来的连接都会创建一个 SocketChannel。 缓冲区 发送给一个通道的所有数据都必须首先放到缓冲区中，同样地，从通道中读取的任何数据都要先读到缓冲区中。也就是说，不会直接对通道进行读写数据，而是要先经过缓冲区。 缓冲区实质上是一个数组，但它不仅仅是一个数组。缓冲区提供了对数据的结构化访问，而且还可以跟踪系统的读/写进程。 缓冲区包括以下类型: ByteBuffer CharBuffer ShortBuffer IntBuffer LongBuffer FloatBuffer DoubleBuffer 使用 NIO 快速复制文件的实例 public static void fastCopy(String src, String dist) throws IOException { /* 获得源文件的输入字节流 */ FileInputStream fin = new FileInputStream(src); /* 获取输入字节流的文件通道 */ FileChannel fcin = fin.getChannel(); /* 获取目标文件的输出字节流 */ FileOutputStream fout = new FileOutputStream(dist); /* 获取输出字节流的通道 */ FileChannel fcout = fout.getChannel(); /* 为缓冲区分配 1024 个字节 */ ByteBuffer buffer = ByteBuffer.allocateDirect(1024); while (true) { /* 从输入通道中读取数据到缓冲区中 */ int r = fcin.read(buffer); /* read() 返回 -1 表示 EOF */ if (r == -1) { break; } /* 切换读写 */ buffer.flip(); /* 把缓冲区的内容写入输出文件中 */ fcout.write(buffer); /* 清空缓冲区 */ buffer.clear(); } } ","date":"2018-02-05","objectID":"/javaio/:4:2","tags":["Java基础","大纲"],"title":"Java IO知识体系详解 ","uri":"/javaio/"},{"categories":["Java基础"],"content":"选择器 Selector的英文含义是“选择器”，不过根据我们详细介绍的Selector的岗位职责，您可以把它称之为“轮询代理器”、“事件订阅器”、“channel容器管理机”都行。 NIO 常常被叫做非阻塞 IO，主要是因为 NIO 在网络通信中的非阻塞特性被广泛使用。 NIO 实现了 IO 多路复用中的 Reactor 模型，一个线程 Thread 使用一个选择器 Selector 通过轮询的方式去监听多个通道 Channel 上的事件，从而让一个线程就可以处理多个事件。 通过配置监听的通道 Channel 为非阻塞，那么当 Channel 上的 IO 事件还未到达时，就不会进入阻塞状态一直等待，而是继续轮询其它 Channel，找到 IO 事件已经到达的 Channel 执行。 因为创建和切换线程的开销很大，因此使用一个线程来处理多个事件而不是一个线程处理一个事件具有更好的性能。 应该注意的是，只有套接字 Channel 才能配置为非阻塞，而 FileChannel 不能，为 FileChannel 配置非阻塞也没有意义。 套接字 NIO 实例 public class NIOServer { public static void main(String[] args) throws IOException { Selector selector = Selector.open(); ServerSocketChannel ssChannel = ServerSocketChannel.open(); ssChannel.configureBlocking(false); ssChannel.register(selector, SelectionKey.OP_ACCEPT); ServerSocket serverSocket = ssChannel.socket(); InetSocketAddress address = new InetSocketAddress(\"127.0.0.1\", 8888); serverSocket.bind(address); while (true) { selector.select(); Set\u003cSelectionKey\u003e keys = selector.selectedKeys(); Iterator\u003cSelectionKey\u003e keyIterator = keys.iterator(); while (keyIterator.hasNext()) { SelectionKey key = keyIterator.next(); if (key.isAcceptable()) { ServerSocketChannel ssChannel1 = (ServerSocketChannel) key.channel(); // 服务器会为每个新连接创建一个 SocketChannel SocketChannel sChannel = ssChannel1.accept(); sChannel.configureBlocking(false); // 这个新连接主要用于从客户端读取数据 sChannel.register(selector, SelectionKey.OP_READ); } else if (key.isReadable()) { SocketChannel sChannel = (SocketChannel) key.channel(); System.out.println(readDataFromSocketChannel(sChannel)); sChannel.close(); } keyIterator.remove(); } } } private static String readDataFromSocketChannel(SocketChannel sChannel) throws IOException { ByteBuffer buffer = ByteBuffer.allocate(1024); StringBuilder data = new StringBuilder(); while (true) { buffer.clear(); int n = sChannel.read(buffer); if (n == -1) { break; } buffer.flip(); int limit = buffer.limit(); char[] dst = new char[limit]; for (int i = 0; i \u003c limit; i++) { dst[i] = (char) buffer.get(i); } data.append(dst); buffer.clear(); } return data.toString(); } } public class NIOClient { public static void main(String[] args) throws IOException { Socket socket = new Socket(\"127.0.0.1\", 8888); OutputStream out = socket.getOutputStream(); String s = \"hello world\"; out.write(s.getBytes()); out.close(); } } ","date":"2018-02-05","objectID":"/javaio/:4:3","tags":["Java基础","大纲"],"title":"Java IO知识体系详解 ","uri":"/javaio/"},{"categories":["Java基础"],"content":"内存映射文件 内存映射文件 I/O 是一种读和写文件数据的方法，它可以比常规的基于流或者基于通道的 I/O 快得多。 向内存映射文件写入可能是危险的，只是改变数组的单个元素这样的简单操作，就可能会直接修改磁盘上的文件。修改数据与将数据保存到磁盘是没有分开的。 NIO 与普通I/O 的区别主要有以下两点 NIO 是非阻塞的 NIO 面向块，I/O 面向流 ","date":"2018-02-05","objectID":"/javaio/:4:4","tags":["Java基础","大纲"],"title":"Java IO知识体系详解 ","uri":"/javaio/"},{"categories":["Java基础"],"content":"IO多路复用详解 https://www.pdai.tech/md/java/io/java-io-nio-select-epoll html ","date":"2018-02-05","objectID":"/javaio/:5:0","tags":["Java基础","大纲"],"title":"Java IO知识体系详解 ","uri":"/javaio/"},{"categories":["Java基础"],"content":"异步IO 阻塞式同步IO、非阻塞式同步IO、多路复用IO 这三种IO模型，以及JAVA对于这三种IO模型的支持。重点说明了IO模型是由操作系统提供支持，且这三种IO模型都是同步IO，都是采用的“应用程序不询问我，我绝不会主动通知”的方式。 异步IO则是采用“订阅-通知”模式: 即应用程序向操作系统注册IO监听，然后继续做自己的事情。当操作系统发生IO事件，并且准备好数据后，在主动通知应用程序，触发相应的函数。 ","date":"2018-02-05","objectID":"/javaio/:6:0","tags":["Java基础","大纲"],"title":"Java IO知识体系详解 ","uri":"/javaio/"},{"categories":["Java基础"],"content":"为什么还有Netty 那么有的读者可能就会问，既然JAVA NIO / JAVA AIO已经实现了各主流操作系统的底层支持，那么为什么现在主流的JAVA NIO技术会是Netty和MINA呢? 答案很简单: 因为更好用，这里举几个方面的例子: 虽然JAVA NIO 和 JAVA AIO框架提供了 多路复用IO/异步IO的支持，但是并没有提供上层“信息格式”的良好封装。例如前两者并没有提供针对 Protocol Buffer、JSON这些信息格式的封装，但是Netty框架提供了这些数据格式封装(基于责任链模式的编码和解码功能) 要编写一个可靠的、易维护的、高性能的(注意它们的排序)NIO/AIO 服务器应用。除了框架本身要兼容实现各类操作系统的实现外。更重要的是它应该还要处理很多上层特有服务，例如: 客户端的权限、还有上面提到的信息格式封装、简单的数据读取。这些Netty框架都提供了响应的支持。 JAVA NIO框架存在一个poll/epoll bug: Selector doesn’t block on Selector.select(timeout)，不能block意味着CPU的使用率会变成100%(这是底层JNI的问题，上层要处理这个异常实际上也好办)。当然这个bug只有在Linux内核上才能重现。 这个问题在JDK 1.7版本中还没有被完全解决: http://bugs.java.com/bugdatabase/view_bug.do?bug_id=2147719。虽然Netty 4.0中也是基于JAVA NIO框架进行封装的(上文中已经给出了Netty中NioServerSocketChannel类的介绍)，但是Netty已经将这个bug进行了处理。 ","date":"2018-02-05","objectID":"/javaio/:7:0","tags":["Java基础","大纲"],"title":"Java IO知识体系详解 ","uri":"/javaio/"},{"categories":["Java基础"],"content":"参考文章 https://www.pdai.tech/md/java/io/java-io-nio.html https://www.pdai.tech/md/java/io/java-io-nio-select-epoll.html ","date":"2018-02-05","objectID":"/javaio/:8:0","tags":["Java基础","大纲"],"title":"Java IO知识体系详解 ","uri":"/javaio/"},{"categories":["Java基础"],"content":"反射让一切有了可能","date":"2018-02-03","objectID":"/reflection/","tags":["Java基础"],"title":"框架的灵魂-反射","uri":"/reflection/"},{"categories":["Java基础"],"content":"什么是反射 简而言之，通过反射，我们可以在运行时获得程序中每一个类型的成员和成员的信息。 程序中一般的对象的类型都是在编译期就确定下来的，而 Java 反射机制可以动态地创建对象并调用其属性，这样的对象的类型在编译期是未知的。 所以我们可以通过反射机制直接创建对象，即使这个对象的类型在编译期是未知的。 反射的核心是 JVM 在运行时才动态加载类或调用方法/访问属性，它不需要事先（写代码的时候或编译期）知道运行对象是谁。 ","date":"2018-02-03","objectID":"/reflection/:1:0","tags":["Java基础"],"title":"框架的灵魂-反射","uri":"/reflection/"},{"categories":["Java基础"],"content":"Java 反射主要提供以下功能 在运行时构造任意一个类的对象。 在运行时调用任意一个对象的方法。 在运行时判断任意一个对象所属的类。 在运行时判断任意一个类所具有的成员变量和方法（通过反射甚至可以调用private方法）。 ","date":"2018-02-03","objectID":"/reflection/:1:1","tags":["Java基础"],"title":"框架的灵魂-反射","uri":"/reflection/"},{"categories":["Java基础"],"content":"反射的主要用途 反射最重要的用途就是开发各种通用框架。 很多框架（比如 Spring）都是配置化的（比如通过 XML 文件配置 Bean），为了保证框架的通用性，它们可能需要根据配置文件加载不同的对象或类，调用不同的方法，这个时候就必须用到反射，运行时动态加载需要加载的对象。 举一个例子，在运用 Struts 2 框架的开发中我们一般会在 struts.xml 里去配置 Action，比如： \u003caction name=\"login\" class=\"org.ScZyhSoft.test.action.SimpleLoginAction\" method=\"execute\"\u003e \u003cresult\u003e/shop/shop-index.jsp\u003c/result\u003e \u003cresult name=\"error\"\u003elogin.jsp\u003c/result\u003e \u003c/action\u003e 配置文件与 Action 建立了一种映射关系，当 View 层发出请求时，请求会被 StrutsPrepareAndExecuteFilter 拦截，然后 StrutsPrepareAndExecuteFilter 会去动态地创建 Action 实例。比如我们请求 login.action，那么 StrutsPrepareAndExecuteFilter就会去解析struts.xml文件，检索action中name为login的Action，并根据class属性创建SimpleLoginAction实例，并用invoke方法来调用execute方法，这个过程离不开反射。 对与框架开发人员来说，反射虽小但作用非常大，它是各种容器实现的核心。而对于一般的开发者来说，不深入框架开发则用反射用的就会少一点，不过了解一下框架的底层机制有助于丰富自己的编程思想，也是很有益的。 像Java中的一大利器注解的实现也用到了反射。 为什么你使用 Spring 的时候 ，一个@Component注解就声明了一个类为 Spring Bean 呢？为什么你通过一个 @Value注解就读取到配置文件中的值呢？究竟是怎么起作用的呢？ 这些都是因为你可以基于反射分析类，然后获取到类/属性/方法/方法的参数上的注解。你获取到注解之后，就可以做进一步的处理。 ","date":"2018-02-03","objectID":"/reflection/:2:0","tags":["Java基础"],"title":"框架的灵魂-反射","uri":"/reflection/"},{"categories":["Java基础"],"content":"反射的基本运用 ","date":"2018-02-03","objectID":"/reflection/:3:0","tags":["Java基础"],"title":"框架的灵魂-反射","uri":"/reflection/"},{"categories":["Java基础"],"content":"获得Class对象 使用Class类的forName 静态方法。 Class appleClass = Class.forName(\"base.reflection.Apple\"); 直接获取 Class appleClass = Apple.class; 获取某一个对象的class Apple apple = new Apple(); Class appleClass = apple.getClass(); 通过类加载器ClassLoader.loadClass()传入类路径获取 Class appleClass = ClassLoader.getSystemClassLoader().loadClass(\"base.reflection.Apple\"); ","date":"2018-02-03","objectID":"/reflection/:3:1","tags":["Java基础"],"title":"框架的灵魂-反射","uri":"/reflection/"},{"categories":["Java基础"],"content":"构造方法 Constructor[] declaredConstructors = appleClass.getDeclaredConstructors(); Constructor[] constructors = appleClass.getConstructors(); //通过无参构造来获取该类对象 newInstance() Apple apple= (Apple)appleClass.newInstance(); //通过有参构造来获取该类对象 newInstance Constructor constructor = appleClass.getConstructor(String.class,int.class,int.class); Apple apple=(Apple)constructor.newInstance(\"红色\",10,5); ","date":"2018-02-03","objectID":"/reflection/:3:2","tags":["Java基础"],"title":"框架的灵魂-反射","uri":"/reflection/"},{"categories":["Java基础"],"content":"属性 //getDeclaredFields所有已声明的成员变量，但不能得到其父类的成员变量 Field[] declaredFields = appleClass.getDeclaredFields(); //getFields访问公有的成员变量 Field[] fields = appleClass.getFields(); ","date":"2018-02-03","objectID":"/reflection/:3:3","tags":["Java基础"],"title":"框架的灵魂-反射","uri":"/reflection/"},{"categories":["Java基础"],"content":"方法 //getDeclaredMethods 方法返回类或接口声明的所有方法，包括公共、保护、默认（包）访问和私有方法，但不包括继承的方法。 Method[] declaredMethods = appleClass.getDeclaredMethods(); //getMethods方法返回某个类的所有公用（public）方法，包括其继承类的公用方法。 Method[] methods = appleClass.getMethods(); ","date":"2018-02-03","objectID":"/reflection/:3:4","tags":["Java基础"],"title":"框架的灵魂-反射","uri":"/reflection/"},{"categories":["Java基础"],"content":"调用方法 Constructor constructor = appleClass.getConstructor(String.class,int.class,int.class); Apple apple = (Apple)constructor.newInstance(\"红色\",10,5); //获取toString方法并调用 Method method = appleClass.getDeclaredMethod(\"toString\"); String str = (String)method.invoke(apple); System.out.println(str); ","date":"2018-02-03","objectID":"/reflection/:3:5","tags":["Java基础"],"title":"框架的灵魂-反射","uri":"/reflection/"},{"categories":["Java基础"],"content":"利用反射创建数组 Class\u003c?\u003e cls = Class.forName(\"java.lang.String\"); Object array = Array.newInstance(cls,5); //往数组里添加内容 Array.set(array,0,\"hello\"); Array.set(array,1,\"Java\"); Array.set(array,2,\"fuck\"); Array.set(array,3,\"Scala\"); Array.set(array,4,\"Clojure\"); //获取某一项的内容 System.out.println(Array.get(array,3)); ","date":"2018-02-03","objectID":"/reflection/:3:6","tags":["Java基础"],"title":"框架的灵魂-反射","uri":"/reflection/"},{"categories":["Java基础"],"content":"参数化类型","date":"2018-02-02","objectID":"/generic/","tags":["Java基础"],"title":"Java特性-泛型","uri":"/generic/"},{"categories":["Java基础"],"content":"泛型，即参数化类型。一提到参数，最熟悉的就是定义方法时有形参，然后调用此方法时传递实参。 那么参数化类型怎么理解呢？顾名思义，就是将类型由原来的具体的类型参数化，类似于方法中的变量参数，此时类型也定义成参数形式（类型形参），然后在使用/调用时传入具体的类型（类型实参）。 Java 语言中引入泛型是一个较大的功能增强。不仅语言、类型系统和编译器有了较大的变化，而且类库也进行了大翻修，所以许多重要的类，比如集合框架，都已经成为泛型化的了。这带来了很多好处： 类型安全。 泛型的主要目标是提高 Java 程序的类型安全。通过知道使用泛型定义的变量的类型限制，编译器可以在一个高得多的程度上验证类型假设。 消除强制类型转换。 泛型的一个附带好处是，消除源代码中的许多强制类型转换。这使得代码更加可读，并且减少了出错机会。 潜在的性能收益。 泛型为较大的优化带来可能。在泛型的初始实现中，编译器将强制类型转换（没有泛型的话，程序员会指定这些强制类型转换）插入生成的字节码中。 注意泛型的类型参数只能是类类型（包括自定义类），不能是简单类型。 ","date":"2018-02-02","objectID":"/generic/:0:0","tags":["Java基础"],"title":"Java特性-泛型","uri":"/generic/"},{"categories":["Java基础"],"content":"常用命名类型参数 K：键，比如映射的键 V：值，比如 List 和 Set 的内容，或者 Map 中的值 E：元素 T：泛型 ?：表示不确定的 java 类型 ","date":"2018-02-02","objectID":"/generic/:0:1","tags":["Java基础"],"title":"Java特性-泛型","uri":"/generic/"},{"categories":["Java基础"],"content":"通配符 Ingeter 是 Number 的一个子类，同时 Generic 与 Generic 实际上是相同的一种基本类型。那么问题来了，在使用 Generic 作为形参的方法中，能否使用Generic 的实例传入呢？在逻辑上类似于 Generic 和 Generic 是否可以看成具有父子关系的泛型类型呢？下面我们通过定义一个方法来验证。 public void show(Generic\u003cNumber\u003e obj) { System.out.println(\"key value is \" + obj.getKey()); } 进行如下的调用： Generic\u003cInteger\u003e genericInteger = new Generic\u003cInteger\u003e(123); show(genericInteger); //error Generic\u003cjava.lang.Integer\u003e cannot be applied to Generic\u003cjava.lang.Number\u003e 通过提示信息我们可以看到 Generic 不能被看作为 Generic 的子类。由此可以看出：同一种泛型可以对应多个版本（因为参数类型是不确定的），不同版本的泛型类实例是不兼容的。 我们不能因此定义一个 show(Generic obj)来处理，因此我们需要一个在逻辑上可以表示同时是Generic和Generic父类的引用类型。由此类型通配符应运而生。 T、K、V、E 等泛型字母为有类型，类型参数赋予具体的值。除了有类型，还可以用通配符来表述类型，？ 未知类型，类型参数赋予不确定值，任意类型只能用在声明类型、方法参数上，不能用在定义泛型类上。将方法改写成如下： public void show(Generic\u003c?\u003e obj) { System.out.println(\"key value is \" + obj.getKey()); } 此处 ? 是类型实参，而不是类型形参。即和 Number、String、Integer 一样都是实际的类型，可以把 ？ 看成所有类型的父类，是一种真实的类型。可以解决当具体类型不确定的时候，这个通配符就是 ?；当操作类型时，不需要使用类型的具体功能时，只使用 Object 类中的功能。那么可以用 ? 通配符来表未知类型。 ","date":"2018-02-02","objectID":"/generic/:0:2","tags":["Java基础"],"title":"Java特性-泛型","uri":"/generic/"},{"categories":["Java基础"],"content":"泛型上下边界 通配符上限为：Generic\u003c? extends Number\u003e 通配符下限为：Generic\u003c? super Number\u003e 在使用泛型的时候，我们还可以为传入的泛型类型实参进行上下边界的限制，如：类型实参只准传入某种类型的父类或某种类型的子类。为泛型添加上边界，即传入的类型实参必须是指定类型的子类型。 public void show(Generic\u003c? extends Number\u003e obj) { System.out.println(\"key value is \" + obj.getKey()); } 我们在泛型方法的入参限定参数类型为 Number 的子类。 Generic\u003cString\u003e genericString = new Generic\u003cString\u003e(\"11111\"); Generic\u003cInteger\u003e genericInteger = new Generic\u003cInteger\u003e(2222); showKeyValue1(genericString); // error showKeyValue1(genericInteger); 当我们的入参为 String 类型时，编译报错，因为 String 类型并不是 Number 类型的子类。 类型通配符上限通过形如 Generic\u003c? extends Number\u003e 形式定义；相对应的，类型通配符下限为Generic\u003c? super Number\u003e形式，其含义与类型通配符上限正好相反，在此不作过多阐述。 ","date":"2018-02-02","objectID":"/generic/:0:3","tags":["Java基础"],"title":"Java特性-泛型","uri":"/generic/"},{"categories":["Java基础"],"content":"一个泛型的增删改查Service @Transactional(readOnly = true) public abstract class CrudService\u003cD extends CrudDao\u003cT\u003e, T extends DataEntity\u003cT\u003e\u003e extends BaseService { /** * 持久层对象 */ @Autowired protected D dao; /** * 获取单条数据 * @param entity * @return */ public T get(T entity) { return dao.get(entity); } /** * 查询列表数据 * @param entity * @return */ public List\u003cT\u003e findList(T entity) { return dao.findList(entity); } /** * 查询分页数据 * @param page 分页对象 * @param entity * @return */ public Page\u003cT\u003e findPage(Page\u003cT\u003e page, T entity) { entity.setPage(page); page.setList(dao.findList(entity)); return page; } /** * 保存数据（插入或更新） * @param entity */ @Transactional(readOnly = false) public int save(T entity) { if (entity.getIsNewRecord()){ entity.preInsert(); return dao.insert(entity); }else{ entity.preUpdate(); return dao.update(entity); } } /** * 删除数据 * @param entity */ @Transactional(readOnly = false) public int delete(T entity) { return dao.delete(entity); } } ","date":"2018-02-02","objectID":"/generic/:0:4","tags":["Java基础"],"title":"Java特性-泛型","uri":"/generic/"},{"categories":["Java基础"],"content":"面向对象的三大法宝和七大戒律","date":"2018-02-01","objectID":"/objectoriented/","tags":["Java基础"],"title":"Java世界的入场券-面向对象","uri":"/objectoriented/"},{"categories":["Java基础"],"content":" 面向对象程序设计（英语：Object-oriented programming，缩写：OOP）是种具有对象概念的编程典范，同时也是一种程序开发的抽象方针。它可能包含数据、特性、代码与方法。对象则指的是类（class）的实例。它将对象作为程序的基本单元，将程序和数据封装其中，以提高软件的重用性、灵活性和扩展性，对象里的程序可以访问及经常修改对象相关连的数据。在面向对象程序编程里，计算机程序会被设计成彼此相关的对象。 面向对象就像是一张入场券，掌握了面向对象的思想，就可以在Java世界里尽情遨游，面向对象有三大法宝和七大戒律，并在其指导下萃取出了无数的锦囊妙计和绝世武器，下面我们揭开他们的神秘面纱。 ","date":"2018-02-01","objectID":"/objectoriented/:0:0","tags":["Java基础"],"title":"Java世界的入场券-面向对象","uri":"/objectoriented/"},{"categories":["Java基础"],"content":"OOP（面向对象编程）的三大法宝 封装 封装，也就是把客观事物封装成抽象的类，并且类可以把自己的属性和方法只让可信的类操作，对不可信的类进行信息隐藏。 继承 继承是指这样一种能力，它可以使用现有的类的所有功能，并在无需重新编写原来类的情况下对这些功能进行扩展。 多态 多态指一个类实例的相同方法在不同情形有不同的表现形式。具体来说就是不同实现类对公共接口有不同的实现方式，但这些操作可以通过相同的方式（公共接口）予以调用。 ","date":"2018-02-01","objectID":"/objectoriented/:0:1","tags":["Java基础"],"title":"Java世界的入场券-面向对象","uri":"/objectoriented/"},{"categories":["Java基础"],"content":"OOD（面向对象设计）七大戒律 开-闭原则 Open-Close Principle（OCP），即开-闭原则。开，指的是对扩展开放，即要支持方便地扩展；闭，指的是对修改关闭，即要严格限制对已有内容的修改。开-闭原则是最抽象也是最重要的OOD原则。简单工厂模式、工厂方法模式、抽象工厂模式中都提到了如何通过良好的设计遵循开-闭原则。 里氏替换原则 Liskov Substitution Principle（LSP），即里氏替换原则。该原则规定“子类必须能够替换其父类，否则不应当设计为其子类”。换句话说，父类出现的地方，都应该能由其子类代替。所以，子类只能去扩展基类，而不是隐藏或者覆盖基类。 依赖倒置原则 Dependence Inversion Principle（DIP），依赖倒置原则。它讲的是“设计和实现要依赖于抽象而非具体”。一方面抽象化更符合人的思维习惯；另一方面，根据里氏替换原则，可以很容易将原来的抽象替换为扩展后的具体，这样可以很好的支持开-闭原则。 接口隔离原则 Interface Segration Principle（ISP），接口隔离原则，“将大的接口打散成多个小的独立的接口”。由于Java类支持实现多个接口，可以很容易的让类具有多种接口的特征，同时每个类可以选择性地只实现目标接口。 单一职责原则 Single Responsibility Principle（SRP），单一职责原则。它讲的是，不要存在多于一个导致类变更的原因，是高内聚低耦合的一个体现。 迪米特法则/最少知道原则 Law of Demeter or Least Knowledge Principle（LoD or LKP），迪米特法则或最少知道原则。它讲的是“一个对象就尽可能少的去了解其它对象”，从而实现松耦合。如果一个类的职责过多，由于多个职责耦合在了一起，任何一个职责的变更都可能引起其它职责的问题，严重影响了代码的可维护性和可重用性。 合成/聚合复用原则 Composite/Aggregate Reuse Principle（CARP / CRP），合成/聚合复用原则。如果新对象的某些功能在别的已经创建好的对象里面已经实现，那么应当尽量使用别的对象提供的功能，使之成为新对象的一部分，而不要再重新创建。新对象可通过向这些对象的委派达到复用已有功能的效果。简而言之，要尽量使用合成/聚合，而非使用继承。《Java设计模式（九） 桥接模式》中介绍的桥接模式即是对这一原则的典型应用。 ","date":"2018-02-01","objectID":"/objectoriented/:0:2","tags":["Java基础"],"title":"Java世界的入场券-面向对象","uri":"/objectoriented/"},{"categories":["Java基础"],"content":"行走江湖的锦囊妙计和绝世武器 上面的法宝和戒律是心法，真正行走江湖还需要趁手的兵器和锦囊妙计。 而设计模式就是应用三大法宝和七大戒律下经过反复实践铸造出来锦囊妙计和武器，具体有哪些武器我们暂且不表，毕竟倚天屠龙出世，江湖必将血雨腥风，在这之前我们还需要做好准备工作。 ","date":"2018-02-01","objectID":"/objectoriented/:0:3","tags":["Java基础"],"title":"Java世界的入场券-面向对象","uri":"/objectoriented/"},{"categories":["Java基础"],"content":"Java位运算","date":"2018-01-31","objectID":"/byteopt/","tags":["Java基础"],"title":"Java位运算 ","uri":"/byteopt/"},{"categories":["Java基础"],"content":"一切的起源：二进制 位：二进制位，简称“位”。是二进制记数系统中表示小于2的整数的符号，一般用1或 0表示，是具有相等概率的两种状态中的一种。二进制位的位数可表示一个机器字的字长，一个二进制位包含的信息量称为一比特（bit）。 举个栗子： int占4个字节（byte） 1byte = 8bit 换算下来，一个int类型即占32bit int i = 88; 这里的88为十进制，转换为二进制为：1011000，使用完整的32位表示即为：00000000 00000000 00000000 01011000 上文中的00000000 00000000 00000000 01011000即为十进制88转为二进制的 原码 ，与其相关的定义还有 反码 和 补码 ","date":"2018-01-31","objectID":"/byteopt/:1:0","tags":["Java基础"],"title":"Java位运算 ","uri":"/byteopt/"},{"categories":["Java基础"],"content":"关于原码、反码和补码 在计算机内，有符号数有三种表示法：原码、反码以及补码。 原码：就是二进制定点表示法，即最高位为符号位，“0”正负“1”，其余位表示数值的大小。 反码：正数的反码与其原码相同；负数的反码是对正数逐位取反，符号位保持为1。 补码：正数的补码与其原码相同；负数的补码是在其反码的末位加1。 ","date":"2018-01-31","objectID":"/byteopt/:2:0","tags":["Java基础"],"title":"Java位运算 ","uri":"/byteopt/"},{"categories":["Java基础"],"content":"为什么要使用补码 简单来说，就是计算机计算减法时有各种不方便，于是发明了反码，结果发现反码也有缺陷（有两个零存在：“+0”和“-0”），进而发明了补码解决这个问题。 在计算机系统中，数值一律用补码来表示和存储。原因在于，使用补码，可以将符号位和数值域统一处理；同时，加法和减法也可以统一处理。此外，补码与原码相互转换，其运算过程是相同的，不需要额外的硬件电路。 有关补码的意义及作用在上面的链接里讨论的非常详尽，我这里就不班门弄斧了，理解就好～ 对原码、反码以及补码有一个初步的认知后，我们接下来再看位运算就会清晰很多。 ","date":"2018-01-31","objectID":"/byteopt/:2:1","tags":["Java基础"],"title":"Java位运算 ","uri":"/byteopt/"},{"categories":["Java基础"],"content":"位运算符的基本运算 操作符 描述 例子（A = 8, B = 9） 按位与\u0026 如果相对应位都是1，则结果为1，否则为0 A\u0026B=8，即1000 按位或 | 如果相对应位都是0，则结果为0，否则为1 A B=9，即1001 按位异或^ 如果相对应位值相同，则结果为0，否则为1 A^B=1，即0001 按位取反~ 按位取反运算符翻转操作数的每一位，即0变成1，1变成0 ~A=7，即0111 左移 « 按位左移运算符。左操作数按位左移右操作数指定的位数 A « 2 = 32，即1000 00 右移 » 按位右移运算符。左操作数按位右移右操作数指定的位数 A » 2 = 2，即0010 ","date":"2018-01-31","objectID":"/byteopt/:3:0","tags":["Java基础"],"title":"Java位运算 ","uri":"/byteopt/"},{"categories":["数据库"],"content":"分库分表","date":"2017-03-05","objectID":"/dbsharding/","tags":["数据库","性能优化","分布式"],"title":"数据切分（分库分表）总结","uri":"/dbsharding/"},{"categories":["数据库"],"content":" 关系型数据库本身比较容易成为系统瓶颈，单机存储容量、连接数、处理能力都有限。当单表的数据量达到1000W或100G以后，由于查询维度较多，即使添加从库、优化索引，做很多操作时性能仍下降严重。此时就要考虑对其进行切分了，切分的目的就在于减少数据库的负担，缩短查询时间。 数据库分布式核心内容无非就是数据切分（Sharding），以及切分后对数据的定位、整合。数据切分就是将数据分散存储到多个数据库中，使得单一数据库中的数据量变小，通过扩充主机的数量缓解单一数据库的性能问题，从而达到提升数据库操作性能的目的。 ","date":"2017-03-05","objectID":"/dbsharding/:0:0","tags":["数据库","性能优化","分布式"],"title":"数据切分（分库分表）总结","uri":"/dbsharding/"},{"categories":["数据库"],"content":"MySQL分区（可忽略） 一般情况下我们创建的表对应一组存储文件，使用MyISAM存储引擎时是一个.MYI和.MYD文件，使用Innodb存储引擎时是一个.ibd和.frm（表结构）文件。 当数据量较大时（一般千万条记录级别以上），MySQL的性能就会开始下降，这时我们就需要将数据分散到多组存储文件，保证其单个文件的执行效率。 逻辑数据分割 提高单一的写和读应用速度 提高分区范围读查询的速度 分割数据能够有多个不同的物理文件路径 高效的保存历史数据 ","date":"2017-03-05","objectID":"/dbsharding/:1:0","tags":["数据库","性能优化","分布式"],"title":"数据切分（分库分表）总结","uri":"/dbsharding/"},{"categories":["数据库"],"content":"为什么互联网公司选择自己分库分表来水平扩展 分区表，分区键设计不太灵活，如果不走分区键，很容易出现全表锁 一旦数据并发量上来，如果在分区表实施关联，就是一个灾难 自己分库分表，自己掌控业务场景与访问模式，可控。分区表，研发写了一个sql，都不确定mysql是怎么玩的，不太可控 随着业务的发展，业务越来越复杂，应用的模块越来越多，总的数据量很大，高并发读写操作均超过单个数据库服务器的处理能力怎么办？ 这个时候就出现了数据分片，数据分片指按照某个维度将存放在单一数据库中的数据分散地存放至多个数据库或表中。数据分片的有效手段就是对关系型数据库进行分库和分表。 区别于分区的是，分区一般都是放在单机里的，用的比较多的是时间范围分区，方便归档。只不过分库分表需要代码实现，分区则是mysql内部实现。分库分表和分区并不冲突，可以结合使用。 ","date":"2017-03-05","objectID":"/dbsharding/:1:1","tags":["数据库","性能优化","分布式"],"title":"数据切分（分库分表）总结","uri":"/dbsharding/"},{"categories":["数据库"],"content":"垂直（纵向）切分 垂直切分常见有垂直分库和垂直分表两种。 ","date":"2017-03-05","objectID":"/dbsharding/:2:0","tags":["数据库","性能优化","分布式"],"title":"数据切分（分库分表）总结","uri":"/dbsharding/"},{"categories":["数据库"],"content":"垂直分库 根据业务耦合性，将关联度低的不同表存储在不同的数据库。做法与大系统拆分为多个小系统类似，按业务分类进行独立划分。与\"微服务治理\"的做法相似，每个微服务使用单独的一个数据库。如图： 纵向切分库\" 纵向切分库 ","date":"2017-03-05","objectID":"/dbsharding/:2:1","tags":["数据库","性能优化","分布式"],"title":"数据切分（分库分表）总结","uri":"/dbsharding/"},{"categories":["数据库"],"content":"垂直分表 基于数据库中的\"列\"进行，某个表字段较多，可以新建一张扩展表，将不经常用或字段长度较大的字段拆分出去到扩展表中。在字段很多的情况下（例如一个大表有100多个字段），通过\"大表拆小表”，更便于开发与维护，也能避免跨页问题，MySQL底层是通过数据页存储的，一条记录占用空间过大会导致跨页，造成额外的性能开销。另外数据库以行为单位将数据加载到内存中，这样表中字段长度较短且访问频率较高，内存能加载更多的数据，命中率更高，减少了磁盘IO，从而提升了数据库性能。 纵向切分表\" 纵向切分表 ","date":"2017-03-05","objectID":"/dbsharding/:2:2","tags":["数据库","性能优化","分布式"],"title":"数据切分（分库分表）总结","uri":"/dbsharding/"},{"categories":["数据库"],"content":"垂直切分的优点： 解决业务系统层面的耦合，业务清晰 与微服务的治理类似，也能对不同业务的数据进行分级管理、维护、监控、扩展等 高并发场景下，垂直切分能一定程度的提升IO、数据库连接数、单机硬件资源的瓶颈 ","date":"2017-03-05","objectID":"/dbsharding/:2:3","tags":["数据库","性能优化","分布式"],"title":"数据切分（分库分表）总结","uri":"/dbsharding/"},{"categories":["数据库"],"content":"垂直切分的缺点： 部分表无法join，只能通过接口聚合方式解决，提升了开发的复杂度 分布式事务处理复杂 依然存在单表数据量过大的问题（需要水平切分） ","date":"2017-03-05","objectID":"/dbsharding/:2:4","tags":["数据库","性能优化","分布式"],"title":"数据切分（分库分表）总结","uri":"/dbsharding/"},{"categories":["数据库"],"content":"水平（横向）切分 当一个应用难以再细粒度的垂直切分，或切分后数据量行数巨大，存在单库读写、存储性能瓶颈，这时候就需要进行水平切分了。 水平切分分为库内分表和分库分表，是根据表内数据内在的逻辑关系，将同一个表按不同的条件分散到多个数据库或多个表中，每个表中只包含一部分数据，从而使得单个表的数据量变小，达到分布式的效果。如图所示： 横向切分库\" 横向切分库 库内分表只解决了单一表数据量过大的问题，但没有将表分布到不同机器的库上，因此对于减轻MySQL数据库的压力来说，帮助不是很大，大家还是竞争同一个物理机的CPU、内存、网络IO，最好通过分库分表来解决。 ","date":"2017-03-05","objectID":"/dbsharding/:3:0","tags":["数据库","性能优化","分布式"],"title":"数据切分（分库分表）总结","uri":"/dbsharding/"},{"categories":["数据库"],"content":"水平切分的优点： 不存在单库数据量过大、高并发的性能瓶颈，提升系统稳定性和负载能力 应用端改造较小，不需要拆分业务模块 ","date":"2017-03-05","objectID":"/dbsharding/:3:1","tags":["数据库","性能优化","分布式"],"title":"数据切分（分库分表）总结","uri":"/dbsharding/"},{"categories":["数据库"],"content":"水平切分的缺点： 跨分片的事务一致性难以保证 跨库的join关联查询性能较差 数据多次扩展难度和维护量极大 ","date":"2017-03-05","objectID":"/dbsharding/:3:2","tags":["数据库","性能优化","分布式"],"title":"数据切分（分库分表）总结","uri":"/dbsharding/"},{"categories":["数据库"],"content":"数据分片规则 水平切分后同一张表会出现在多个数据库/表中，每个库/表的内容不同。几种典型的数据分片规则为： 根据数值范围 按照时间区间或ID区间来切分。例如：按日期将不同月甚至是日的数据分散到不同的库中；将userId为1~9999的记录分到第一个库，10000~20000的分到第二个库，以此类推。某种意义上，某些系统中使用的\"冷热数据分离”，将一些使用较少的历史数据迁移到其他库中，业务功能上只提供热点数据的查询，也是类似的实践。 优点： 单表大小可控 天然便于水平扩展，后期如果想对整个分片集群扩容时，只需要添加节点即可，无需对其他分片的数据进行迁移 使用分片字段进行范围查找时，连续分片可快速定位分片进行快速查询，有效避免跨分片查询的问题。 缺点： 热点数据成为性能瓶颈。连续分片可能存在数据热点，例如按时间字段分片，有些分片存储最近时间段内的数据，可能会被频繁的读写，而有些分片存储的历史数据，则很少被查询 根据数值取模 一般采用hash取模mod的切分方式，例如：将 Customer 表根据 cusno 字段切分到4个库中，余数为0的放到第一个库，余数为1的放到第二个库，以此类推。这样同一个用户的数据会分散到同一个库中，如果查询条件带有cusno字段，则可明确定位到相应库去查询。 优点： 数据分片相对比较均匀，不容易出现热点和并发访问的瓶颈 缺点： 后期分片集群扩容时，需要迁移旧的数据（使用一致性hash算法能较好的避免这个问题） 容易面临跨分片查询的复杂问题。比如上例中，如果频繁用到的查询条件中不带cusno时，将会导致无法定位数据库，从而需要同时向4个库发起查询，再在内存中合并数据，取最小集返回给应用，分库反而成为拖累。 ","date":"2017-03-05","objectID":"/dbsharding/:3:3","tags":["数据库","性能优化","分布式"],"title":"数据切分（分库分表）总结","uri":"/dbsharding/"},{"categories":["数据库"],"content":"分库分表带来的问题 ","date":"2017-03-05","objectID":"/dbsharding/:4:0","tags":["数据库","性能优化","分布式"],"title":"数据切分（分库分表）总结","uri":"/dbsharding/"},{"categories":["数据库"],"content":"事务一致性问题 当更新内容同时分布在不同库中，不可避免会带来跨库事务问题。跨分片事务也是分布式事务，没有简单的方案，一般可使用\"XA协议\"和\"两阶段提交\"处理。 分布式事务能最大限度保证了数据库操作的原子性。但在提交事务时需要协调多个节点，推后了提交事务的时间点，延长了事务的执行时间。导致事务在访问共享资源时发生冲突或死锁的概率增高。随着数据库节点的增多，这种趋势会越来越严重，从而成为系统在数据库层面上水平扩展的枷锁。 最终一致性 对于那些性能要求很高，但对一致性要求不高的系统，往往不苛求系统的实时一致性，只要在允许的时间段内达到最终一致性即可，可采用事务补偿的方式。与事务在执行中发生错误后立即回滚的方式不同，事务补偿是一种事后检查补救的措施，一些常见的实现方法有：对数据进行对账检查，基于日志进行对比，定期同标准数据来源进行同步等等。事务补偿还要结合业务系统来考虑。 ","date":"2017-03-05","objectID":"/dbsharding/:4:1","tags":["数据库","性能优化","分布式"],"title":"数据切分（分库分表）总结","uri":"/dbsharding/"},{"categories":["数据库"],"content":"跨节点关联查询 join 问题 切分之前，系统中很多列表和详情页所需的数据可以通过sql join来完成。而切分之后，数据可能分布在不同的节点上，此时join带来的问题就比较麻烦了，考虑到性能，尽量避免使用join查询。 ","date":"2017-03-05","objectID":"/dbsharding/:4:2","tags":["数据库","性能优化","分布式"],"title":"数据切分（分库分表）总结","uri":"/dbsharding/"},{"categories":["数据库"],"content":"跨节点分页、排序、函数问题 跨节点多库进行查询时，会出现limit分页、order by排序等问题。分页需要按照指定字段进行排序，当排序字段就是分片字段时，通过分片规则就比较容易定位到指定的分片；当排序字段非分片字段时，就变得比较复杂了。需要先在不同的分片节点中将数据进行排序并返回，然后将不同分片返回的结果集进行汇总和再次排序，最终返回给用户。 ","date":"2017-03-05","objectID":"/dbsharding/:4:3","tags":["数据库","性能优化","分布式"],"title":"数据切分（分库分表）总结","uri":"/dbsharding/"},{"categories":["数据库"],"content":"全局主键避重问题 在分库分表环境中，由于表中数据同时存在不同数据库中，主键值平时使用的自增长将无用武之地，某个分区数据库自生成的ID无法保证全局唯一。因此需要单独设计全局主键，以避免跨库主键重复问题。有一些常见的主键生成策略： UUID UUID标准形式包含32个16进制数字，分为5段，形式为8-4-4-4-12的36个字符，例如：550e8400-e29b-41d4-a716-446655440000 UUID是主键是最简单的方案，本地生成，性能高，没有网络耗时。但缺点也很明显，由于UUID非常长，会占用大量的存储空间；另外，作为主键建立索引和基于索引进行查询时都会存在性能问题，在InnoDB下，UUID的无序性会引起数据位置频繁变动，导致分页。 Snowflake分布式自增ID算法 Twitter的snowflake算法解决了分布式系统生成全局ID的需求，生成64位的Long型数字，组成部分： 第一位未使用 接下来41位是毫秒级时间，41位的长度可以表示69年的时间 5位datacenterId，5位workerId。10位的长度最多支持部署1024个节点 最后12位是毫秒内的计数，12位的计数顺序号支持每个节点每毫秒产生4096个ID序列 这样的好处是：毫秒数在高位，生成的ID整体上按时间趋势递增；不依赖第三方系统，稳定性和效率较高，理论上QPS约为409.6w/s（1000*2^12），并且整个分布式系统内不会产生ID碰撞；可根据自身业务灵活分配bit位。 SnowflakeID\" SnowflakeID 不足就在于：强依赖机器时钟，如果时钟回拨，则可能导致生成ID重复。 Leaf——美团点评分布式ID生成系统 美团点评分布式ID生成 ","date":"2017-03-05","objectID":"/dbsharding/:4:4","tags":["数据库","性能优化","分布式"],"title":"数据切分（分库分表）总结","uri":"/dbsharding/"},{"categories":["数据库"],"content":"参考文章 数据库分库分表思路 大众点评订单系统分库分表实践 ShardingSphere-JDBC 分库分表技术演进\u0026最佳实践 ","date":"2017-03-05","objectID":"/dbsharding/:5:0","tags":["数据库","性能优化","分布式"],"title":"数据切分（分库分表）总结","uri":"/dbsharding/"},{"categories":["数据库"],"content":"MySQL高可用方案","date":"2017-03-04","objectID":"/mysqlhighavailability/","tags":["数据库","大纲"],"title":"MySQL高可用方案","uri":"/mysqlhighavailability/"},{"categories":["数据库"],"content":"MySQL主从复制架构 MySQL主从架构\" MySQL主从架构 ","date":"2017-03-04","objectID":"/mysqlhighavailability/:1:0","tags":["数据库","大纲"],"title":"MySQL高可用方案","uri":"/mysqlhighavailability/"},{"categories":["数据库"],"content":"基本原理 slave 会从 master 读取 binlog 来进行数据同步 ","date":"2017-03-04","objectID":"/mysqlhighavailability/:1:1","tags":["数据库","大纲"],"title":"MySQL高可用方案","uri":"/mysqlhighavailability/"},{"categories":["数据库"],"content":"三个步骤 master将改变记录到二进制日志（binary log）。这些记录过程叫做二进制日志事件，binary log events； salve 将 master 的 binary log events 拷贝到它的中继日志（relay log）; slave 重做中继日志中的事件，将改变应用到自己的数据库中。MySQL 复制是异步且是串行化的。 ","date":"2017-03-04","objectID":"/mysqlhighavailability/:1:2","tags":["数据库","大纲"],"title":"MySQL高可用方案","uri":"/mysqlhighavailability/"},{"categories":["数据库"],"content":"复制的基本原则 每个 slave只有一个 master 每个 salve只能有一个唯一的服务器 ID 每个master可以有多个salve 主从复制\" 主从复制 上图主从复制分了五个步骤进行： 步骤一：主库的更新事件(update、insert、delete)被写到binlog 步骤二：从库发起连接，连接到主库。 步骤三：此时主库创建一个binlog dump thread，把binlog的内容发送到从库。 步骤四：从库启动之后，创建一个I/O线程，读取主库传过来的binlog内容并写入到relay log 步骤五：还会创建一个SQL线程，从relay log里面读取内容，从Exec_Master_Log_Pos位置开始执行读取到的更新事件，将更新内容写入到slave的db ","date":"2017-03-04","objectID":"/mysqlhighavailability/:1:3","tags":["数据库","大纲"],"title":"MySQL高可用方案","uri":"/mysqlhighavailability/"},{"categories":["数据库"],"content":"此架构特点 成本低，布署快速、方便 读写分离 还能通过及时增加从库来减少读库压力 主库单点故障 数据一致性问题（同步延迟造成） ","date":"2017-03-04","objectID":"/mysqlhighavailability/:1:4","tags":["数据库","大纲"],"title":"MySQL高可用方案","uri":"/mysqlhighavailability/"},{"categories":["数据库"],"content":"MySQL+MHA架构 MHA目前在Mysql高可用方案中应该也是比较成熟和常见的方案，它由日本人开发出来，在mysql故障切换过程中，MHA能做到快速自动切换操作，而且还能最大限度保持数据的一致性。 MySQL+MHA架构\" MySQL+MHA架构 该软件由两部分组成：MHA Manager（管理节点）和MHA Node（数据节点）。MHA Manager可以单独部署在一台独立的机器上管理多个master-slave集群，也可以部署在一台slave节点上。MHA Node运行在每台MySQL服务器上，MHA Manager会定时探测集群中的master节点，当master出现故障时，它可以自动将最新数据的slave提升为新的master，然后将所有其他的slave重新指向新的master。整个故障转移过程对应用程序完全透明。 在MHA自动故障切换过程中，MHA试图从宕机的主服务器上保存二进制日志，最大程度的保证数据的不丢失(配合mysql半同步复制效果更佳)，但这并不总是可行的。例如，如果主服务器硬件故障或无法通过ssh访问，MHA没法保存二进制日志，只进行故障转移而丢失了最新的数据。使用MySQL 5.5的半同步复制，可以大大降低数据丢失的风险。MHA可以与半同步复制结合起来。如果只有一个slave已经收到了最新的二进制日志，MHA可以将最新的二进制日志应用于其他所有的slave服务器上，因此可以保证所有节点的数据一致性。 注意：目前MHA主要支持一主多从的架构，要搭建MHA,要求一个复制集群中必须最少有三台数据库服务器，一主二从，即一台充当master，一台充当备用master，另外一台充当从库，因为至少需要三台服务器，出于机器成本的考虑，淘宝也在该基础上进行了改造，目前淘宝TMHA已经支持一主一从。 ","date":"2017-03-04","objectID":"/mysqlhighavailability/:2:0","tags":["数据库","大纲"],"title":"MySQL高可用方案","uri":"/mysqlhighavailability/"},{"categories":["数据库"],"content":"常见问题 ","date":"2017-03-04","objectID":"/mysqlhighavailability/:3:0","tags":["数据库","大纲"],"title":"MySQL高可用方案","uri":"/mysqlhighavailability/"},{"categories":["数据库"],"content":"百万级别或以上的数据如何删除 关于索引：由于索引需要额外的维护成本，因为索引文件是单独存在的文件,所以当我们对数据的增加,修改,删除,都会产生额外的对索引文件的操作,这些操作需要消耗额外的IO,会降低增/改/删的执行效率。所以，在我们删除数据库百万级别数据的时候，查询MySQL官方手册得知删除数据的速度和创建的索引数量是成正比的。 所以我们想要删除百万数据的时候可以先删除索引（此时大概耗时三分多钟） 然后删除其中无用数据（此过程需要不到两分钟） 删除完成后重新创建索引(此时数据较少了)创建索引也非常快，约十分钟左右。 与之前的直接删除绝对是要快速很多，更别说万一删除中断,一切删除会回滚。那更是坑了。 ","date":"2017-03-04","objectID":"/mysqlhighavailability/:3:1","tags":["数据库","大纲"],"title":"MySQL高可用方案","uri":"/mysqlhighavailability/"},{"categories":["数据库"],"content":"参考文章 浅谈MySQL集群高可用架构 MySQL 同步复制及高可用方案总结 MySQL应用架构演变 Mysql高可用架构之keepalived and MHA ","date":"2017-03-04","objectID":"/mysqlhighavailability/:4:0","tags":["数据库","大纲"],"title":"MySQL高可用方案","uri":"/mysqlhighavailability/"},{"categories":["数据库"],"content":"MySQL调优","date":"2017-03-03","objectID":"/mysqltuning/","tags":["数据库","性能优化"],"title":"MySQL调优","uri":"/mysqltuning/"},{"categories":["数据库"],"content":"影响mysql的性能因素 业务需求对MySQL的影响 存储定位对MySQL的影响 不适合放进MySQL的数据 二进制多媒体数据 流水队列数据 超大文本数据 需要放进缓存的数据 系统各种配置及规则数据 活跃用户的基本信息数据 活跃用户的个性化定制信息数据 准实时的统计信息数据 其他一些访问频繁但变更较少的数据 Schema设计对系统的性能影响 尽量减少对数据库访问的请求 尽量减少无用数据的查询请求 硬件环境对系统性能的影响 ","date":"2017-03-03","objectID":"/mysqltuning/:1:0","tags":["数据库","性能优化"],"title":"MySQL调优","uri":"/mysqltuning/"},{"categories":["数据库"],"content":"性能分析 ","date":"2017-03-03","objectID":"/mysqltuning/:2:0","tags":["数据库","性能优化"],"title":"MySQL调优","uri":"/mysqltuning/"},{"categories":["数据库"],"content":"MySQL常见瓶颈 CPU：CPU在饱和的时候一般发生在数据装入内存或从磁盘上读取数据时候 IO：磁盘I/O瓶颈发生在装入数据远大于内存容量的时候 服务器硬件的性能瓶颈：top，free，iostat 和 vmstat来查看系统的性能状态 ","date":"2017-03-03","objectID":"/mysqltuning/:2:1","tags":["数据库","性能优化"],"title":"MySQL调优","uri":"/mysqltuning/"},{"categories":["数据库"],"content":"性能下降SQL慢 执行时间长 等待时间长 原因分析 查询语句写的烂 索引失效（单值、复合） 关联查询太多join（设计缺陷或不得已的需求） 服务器调优及各个参数设置（缓冲、线程数等） ","date":"2017-03-03","objectID":"/mysqltuning/:2:2","tags":["数据库","性能优化"],"title":"MySQL调优","uri":"/mysqltuning/"},{"categories":["数据库"],"content":"MySQL常见性能分析手段 在优化MySQL时，通常需要对数据库进行分析，常见的分析手段有慢查询日志，EXPLAIN 分析查询，profiling分析以及show命令查询系统状态及系统变量，通过定位分析性能的瓶颈，才能更好的优化数据库系统的性能。 性能瓶颈定位 我们可以通过 show 命令查看 MySQL 状态及变量，找到系统的瓶颈： Mysql\u003e show status ——显示状态信息（扩展show status like ‘XXX’） Mysql\u003e show variables ——显示系统变量（扩展show variables like ‘XXX’） Mysql\u003e show innodb status ——显示InnoDB存储引擎的状态 Mysql\u003e show processlist ——查看当前SQL执行，包括执行状态、是否锁表等 Shell\u003e mysqladmin variables -u username -p password——显示系统变量 Shell\u003e mysqladmin extended-status -u username -p password——显示状态信息 Explain(执行计划) 使用 Explain 关键字可以模拟优化器执行SQL查询语句，从而知道 MySQL 是如何处理你的 SQL 语句的。分析你的查询语句或是表结构的性能瓶颈 慢查询日志 MySQL 的慢查询日志是 MySQL 提供的一种日志记录，它用来记录在 MySQL 中响应时间超过阈值的语句，具体指运行时间超过 long_query_time 值的 SQL，则会被记录到慢查询日志中。 Show Profile 分析查询 通过慢日志查询可以知道哪些 SQL 语句执行效率低下，通过 explain 我们可以得知 SQL 语句的具体执行情况，索引使用等，还可以结合Show Profile命令查看执行状态。 ","date":"2017-03-03","objectID":"/mysqltuning/:2:3","tags":["数据库","性能优化"],"title":"MySQL调优","uri":"/mysqltuning/"},{"categories":["数据库"],"content":"性能优化 ","date":"2017-03-03","objectID":"/mysqltuning/:3:0","tags":["数据库","性能优化"],"title":"MySQL调优","uri":"/mysqltuning/"},{"categories":["数据库"],"content":"索引优化 全值匹配我最爱 最佳左前缀法则，比如建立了一个联合索引(a,b,c)，那么其实我们可利用的索引就有(a), (a,b), (a,b,c) 不在索引列上做任何操作（计算、函数、(自动or手动)类型转换），会导致索引失效而转向全表扫描 存储引擎不能使用索引中范围条件右边的列 尽量使用覆盖索引(只访问索引的查询(索引列和查询列一致))，减少select is null ,is not null 也无法使用索引 like “xxxx%” 是可以用到索引的，like “%xxxx” 则不行(like “%xxx%” 同理)。like以通配符开头('%abc…')索引失效会变成全表扫描的操作， 字符串不加单引号索引失效 少用or，用它来连接时会索引失效 \u003c，\u003c=，=，\u003e，\u003e=，BETWEEN，IN 可用到索引，\u003c\u003e，not in ，!= 则不行，会导致全表扫描 一般性建议 对于单键索引，尽量选择针对当前query过滤性更好的索引 在选择组合索引的时候，当前Query中过滤性最好的字段在索引字段顺序中，位置越靠前越好。 在选择组合索引的时候，尽量选择可以能够包含当前query中的where字句中更多字段的索引 尽可能通过分析统计信息和调整query的写法来达到选择合适索引的目的 少用Hint强制索引 ","date":"2017-03-03","objectID":"/mysqltuning/:3:1","tags":["数据库","性能优化"],"title":"MySQL调优","uri":"/mysqltuning/"},{"categories":["数据库"],"content":"查询优化 永远小表驱动大表（小的数据集驱动大的数据集） ORDER BY关键字优化 ORDER BY子句，尽量使用 Index 方式排序，避免使用 FileSort 方式排序 MySQL 支持两种方式的排序，FileSort 和 Index，Index效率高，它指 MySQL 扫描索引本身完成排序，FileSort 效率较低； ORDER BY 满足两种情况，会使用Index方式排序；①ORDER BY语句使用索引最左前列 ②使用where子句与ORDER BY子句条件列组合满足索引最左前列 尽可能在索引列上完成排序操作，遵照索引建的最佳左前缀 如果不在索引列上，filesort 有两种算法，mysql就要启动双路排序和单路排序 双路排序：MySQL 4.1之前是使用双路排序,字面意思就是两次扫描磁盘，最终得到数据 单路排序：从磁盘读取查询需要的所有列，按照ORDER BY 列在 buffer对它们进行排序，然后扫描排序后的列表进行输出，效率高于双路排序 优化策略 增大sort_buffer_size参数的设置 增大max_lencth_for_sort_data参数的设置 GROUP BY关键字优化 group by实质是先排序后进行分组，遵照索引建的最佳左前缀 当无法使用索引列，增大 max_length_for_sort_data 参数的设置，增大sort_buffer_size参数的设置 where高于having，能写在where限定的条件就不要去having限定了 ","date":"2017-03-03","objectID":"/mysqltuning/:3:2","tags":["数据库","性能优化"],"title":"MySQL调优","uri":"/mysqltuning/"},{"categories":["数据库"],"content":"数据类型优化 MySQL 支持的数据类型非常多，选择正确的数据类型对于获取高性能至关重要。不管存储哪种类型的数据，下面几个简单的原则都有助于做出更好的选择。 更小的通常更好：一般情况下，应该尽量使用可以正确存储数据的最小数据类型。 简单就好：简单的数据类型通常需要更少的CPU周期。例如，整数比字符操作代价更低，因为字符集和校对规则（排序规则）使字符比较比整型比较复杂。 尽量避免NULL：通常情况下最好指定列为NOT NULL ","date":"2017-03-03","objectID":"/mysqltuning/:3:3","tags":["数据库","性能优化"],"title":"MySQL调优","uri":"/mysqltuning/"},{"categories":["数据库"],"content":"参考文章 MySQL调优 ","date":"2017-03-03","objectID":"/mysqltuning/:4:0","tags":["数据库","性能优化"],"title":"MySQL调优","uri":"/mysqltuning/"},{"categories":["数据库"],"content":"MySQL总结","date":"2017-03-02","objectID":"/mysql/","tags":["数据库","大纲"],"title":"MySQL总结","uri":"/mysql/"},{"categories":["数据库"],"content":"MySQL结构\" MySQL结构 ","date":"2017-03-02","objectID":"/mysql/:0:0","tags":["数据库","大纲"],"title":"MySQL总结","uri":"/mysql/"},{"categories":["数据库"],"content":"简述一条SQL的执行流程 客户端请求 连接器（验证用户身份，给予权限） 查询缓存（存在缓存则直接返回，不存在则执行后续操作） 分析器（对SQL进行词法分析和语法分析操作） 优化器（主要对执行的sql优化选择最优的执行方案方法） 执行器（执行时会先看用户是否有执行权限，有才去使用这个引擎提供的接口） 去引擎层获取数据返回（如果开启查询缓存则会缓存查询结果） 一条SQL的执行流程\" 一条SQL的执行流程 ","date":"2017-03-02","objectID":"/mysql/:1:0","tags":["数据库","大纲"],"title":"MySQL总结","uri":"/mysql/"},{"categories":["数据库"],"content":"存储引擎 存储引擎是MySQL的组件，用于处理不同表类型的SQL操作。不同的存储引擎提供不同的存储机制、索引技巧、锁定水平等功能，使用不同的存储引擎，还可以获得特定的功能，MySQL服务器使用可插拔的存储引擎体系结构，可以从运行中的 MySQL 服务器加载或卸载存储引擎 。 ","date":"2017-03-02","objectID":"/mysql/:2:0","tags":["数据库","大纲"],"title":"MySQL总结","uri":"/mysql/"},{"categories":["数据库"],"content":"InnoDB InnoDB 现在是 MySQL 默认的存储引擎，支持事务、行级锁定和外键，只有在需要它不支持的特性时，才考虑使用其它存储引擎。 实现了四个标准的隔离级别，默认级别是可重复读(REPEATABLE READ)。在可重复读隔离级别下，通过多版本并发控制(MVCC)+ 间隙锁(Next-Key Locking)防止幻影读。 主索引是聚簇索引，在索引中保存了数据，从而避免直接读取磁盘，因此对查询性能有很大的提升。 内部做了很多优化，包括从磁盘读取数据时采用的可预测性读、能够加快读操作并且自动创建的自适应哈希索引、能够加速插入操作的插入缓冲区等。 支持真正的在线热备份。其它存储引擎不支持在线热备份，要获取一致性视图需要停止对所有表的写入，而在读写混合场景中，停止写入可能也意味着停止读取。 ","date":"2017-03-02","objectID":"/mysql/:2:1","tags":["数据库","大纲"],"title":"MySQL总结","uri":"/mysql/"},{"categories":["数据库"],"content":"MyISAM 设计简单，数据以紧密格式存储。对于只读数据，或者表比较小、可以容忍修复操作，则依然可以使用它。 不支持事务。 不支持行级锁，只能对整张表加锁，读取时会对需要读到的所有表加共享锁，写入时则对表加排它锁。但在表有读取操作的同时，也可以往表中插入新的记录，这被称为并发插入(CONCURRENT INSERT)。 ","date":"2017-03-02","objectID":"/mysql/:2:2","tags":["数据库","大纲"],"title":"MySQL总结","uri":"/mysql/"},{"categories":["数据库"],"content":"比较 对比项 MyISAM InnoDB 主外键 不支持 支持 事务 不支持 支持 行表锁 表锁，即使操作一条记录也会锁住整个表，不适合高并发的操作 行锁,操作时只锁某一行，不对其它行有影响，适合高并发的操作 缓存 只缓存索引，不缓存真实数据 不仅缓存索引还要缓存真实数据，对内存要求较高，而且内存大小对性能有决定性的影响 表空间 小 小 关注点 性能 事务 ","date":"2017-03-02","objectID":"/mysql/:2:3","tags":["数据库","大纲"],"title":"MySQL总结","uri":"/mysql/"},{"categories":["数据库"],"content":"索引 索引其实是一种数据结构，能够帮助我们快速的检索数据库中的数据，索引是在存储引擎层实现的，而不是在服务器层实现的。可以简单的理解为“排好序的快速查找数据结构”，数据本身之外，数据库还维护者一个满足特定查找算法的数据结构，这些数据结构以某种方式引用（指向）数据，这样就可以在这些数据结构上实现高级查找算法。这种数据结构，就是索引。下图是一种可能的索引方式示例。 索引\" 索引 ","date":"2017-03-02","objectID":"/mysql/:3:0","tags":["数据库","大纲"],"title":"MySQL总结","uri":"/mysql/"},{"categories":["数据库"],"content":"索引类型 数据结构角度 B+树索引 Hash索引 Full-Text全文索引 R-Tree索引 从物理存储角度 聚集索引（clustered index） 非聚集索引（non-clustered index），也叫辅助索引（secondary index） 聚集索引和非聚集索引都是B+树结构 从逻辑角度 主键索引：主键索引是一种特殊的唯一索引，不允许有空值 普通索引或者单列索引：每个索引只包含单个列，一个表可以有多个单列索引 多列索引（复合索引、联合索引）：复合索引指多个字段上创建的索引，只有在查询条件中使用了创建索引时的第一个字段，索引才会被使用。使用复合索引时遵循最左前缀集合 唯一索引或者非唯一索引 空间索引：空间索引是对空间数据类型的字段建立的索引，MYSQL中的空间数据类型有4种，分别是GEOMETRY、POINT、LINESTRING、POLYGON。 MYSQL使用SPATIAL关键字进行扩展，使得能够用于创建正规索引类型的语法创建空间索引。创建空间索引的列，必须将其声明为NOT NULL，空间索引只能在存储引擎为MYISAM的表中创建 MySQL主要有两种结构Hash索引和B+Tree索引，我们使用的是InnoDB引擎，默认的是B+树。 ","date":"2017-03-02","objectID":"/mysql/:3:1","tags":["数据库","大纲"],"title":"MySQL总结","uri":"/mysql/"},{"categories":["数据库"],"content":"B+Tree索引 所有的数据都存放在叶子节点上，且把叶子节点通过指针连接到一起，形成了一条数据链表，以加快相邻数据的检索效率。 为什么使用B+树的数据结构 B-Tree B-Tree 结构的数据可以让系统高效的找到数据所在的磁盘块。为了描述 B-Tree，首先定义一条记录为一个二元组[key, data] ，key为记录的键值，对应表中的主键值，data 为一行记录中除主键外的数据。对于不同的记录，key值互不相同。 B-Tree中的每个节点根据实际情况可以包含大量的关键字信息和分支，如下图所示为一个3阶的B-Tree: B树\" B树 B+Tree B+Tree 是在 B-Tree 基础上的一种优化，使其更适合实现外存储索引结构，InnoDB 存储引擎就是用 B+Tree 实现其索引结构。 从上一节中的B-Tree结构图中可以看到每个节点中不仅包含数据的key值，还有data值。而每一个页的存储空间是有限的，如果data数据较大时将会导致每个节点（即一个页）能存储的key的数量很小，当存储的数据量很大时同样会导致B-Tree的深度较大，增大查询时的磁盘I/O次数，进而影响查询效率。 在B+Tree中，所有数据记录节点都是按照键值大小顺序存放在同一层的叶子节点上，而非叶子节点上只存储key值信息，这样可以大大加大每个节点存储的key值数量，降低B+Tree的高度。 B+Tree相对于B-Tree有几点不同： 非叶子节点只存储键值信息； 所有叶子节点之间都有一个链指针； 数据记录都存放在叶子节点中 将上一节中的B-Tree优化，由于B+Tree的非叶子节点只存储键值信息，假设每个磁盘块能存储4个键值及指针信息，则变成B+Tree后其结构如下图所示: B+树\" B+树 因为不再需要进行全表扫描，只需要对树进行搜索即可，因此查找速度快很多。 除了用于查找，还可以用于排序和分组。 可以指定多个列作为索引列，多个索引列共同组成键。 适用于全键值、键值范围和键前缀查找，其中键前缀查找只适用于最左前缀查找。如果不是按照索引列的顺序进行查找，则无法使用索引。 InnoDB 的 B+Tree 索引分为主索引和辅助索引。 Mysql选用B+树这种数据结构作为索引，可以提高查询索引时的磁盘IO效率，并且可以提高范围查询的效率，并且B+树里的元素也是有序的。 ","date":"2017-03-02","objectID":"/mysql/:3:2","tags":["数据库","大纲"],"title":"MySQL总结","uri":"/mysql/"},{"categories":["数据库"],"content":"哈希索引 哈希索引能以 O(1) 时间进行查找，但是失去了有序性，它具有以下限制: 无法用于排序与分组； 只支持等值精确查找，无法用于部分查找和范围查找。 哈希索引没办法利用索引完成排序 哈希索引不支持多列联合索引的最左匹配规则 如果有大量重复键值得情况下，哈希索引的效率会很低，因为存在哈希碰撞问题 InnoDB 存储引擎有一个特殊的功能叫“自适应哈希索引”，当某个索引值被使用的非常频繁时，会在 B+Tree 索引之上再创建一个哈希索引，这样就让 B+Tree 索引具有哈希索引的一些优点，比如快速的哈希查找。 ","date":"2017-03-02","objectID":"/mysql/:3:3","tags":["数据库","大纲"],"title":"MySQL总结","uri":"/mysql/"},{"categories":["数据库"],"content":"B+Tree的叶子节点存储内容不同分为聚簇索引和非聚簇索引 主键索引的叶子节点 data 域记录着完整的数据记录，这种索引方式被称为聚簇索引。因为无法把数据行存放在两个不同的地方，所以一个表只能有一个聚簇索引。 聚簇索引\" 聚簇索引 辅助索引的叶子节点的 data 域记录着主键的值，因此在使用辅助索引进行查找时，需要先查找到主键值，然后使用主键在主索引上再进行对应的检索操作，这也就是所谓的“回表查询”，如果覆盖索引则无需再“回表查询” 非聚簇索引\" 非聚簇索引 ","date":"2017-03-02","objectID":"/mysql/:3:4","tags":["数据库","大纲"],"title":"MySQL总结","uri":"/mysql/"},{"categories":["数据库"],"content":"覆盖索引（covering index） 指一个查询语句的执行只用从索引中就能够取得，不必从数据表中读取。也可以称之为实现了索引覆盖。 当一条查询语句符合覆盖索引条件时，MySQL只需要通过索引就可以返回查询所需要的数据，这样避免了查到索引后再返回表操作，减少I/O提高效率。 如，表covering_index_sample中有一个普通索引 idx_key1_key2(key1,key2)。当我们通过SQL语句：select key2 from covering_index_sample where key1 = ‘keytest’;的时候，就可以通过覆盖索引查询，无需回表。 ","date":"2017-03-02","objectID":"/mysql/:3:5","tags":["数据库","大纲"],"title":"MySQL总结","uri":"/mysql/"},{"categories":["数据库"],"content":"联合索引、最左前缀匹配 创建多列索引时，我们根据业务需求，where子句中使用最频繁的一列放在最左边，因为MySQL索引查询会遵循最左前缀匹配的原则，即最左优先，在检索数据时从联合索引的最左边开始匹配。 所以当我们创建一个联合索引的时候，如(key1,key2,key3)，相当于创建了（key1）、(key1,key2)和(key1,key2,key3)三个索引，这就是最左匹配原则。 ","date":"2017-03-02","objectID":"/mysql/:3:6","tags":["数据库","大纲"],"title":"MySQL总结","uri":"/mysql/"},{"categories":["数据库"],"content":"索引下推 MySQL 5.6引入了索引下推优化，默认开启，使用SET optimizer_switch = ‘index_condition_pushdown=off’;可以将其关闭。 索引下推优化，可以在有like条件查询的情况下，减少回表次数。 ","date":"2017-03-02","objectID":"/mysql/:3:7","tags":["数据库","大纲"],"title":"MySQL总结","uri":"/mysql/"},{"categories":["数据库"],"content":"哪些情况需要创建索引 主键自动建立唯一索引 频繁作为查询条件的字段 查询中与其他表关联的字段，外键关系建立索引 单键/组合索引的选择问题，高并发下倾向创建组合索引 查询中排序的字段，排序字段通过索引访问大幅提高排序速度 查询中统计或分组字段 ","date":"2017-03-02","objectID":"/mysql/:3:8","tags":["数据库","大纲"],"title":"MySQL总结","uri":"/mysql/"},{"categories":["数据库"],"content":"哪些情况不要创建索引 表记录太少 经常增删改的表 数据重复且分布均匀的表字段，只应该为最经常查询和最经常排序的数据列建立索引（如果某个数据类包含太多的重复数据，建立索引没有太大意义） 频繁更新的字段不适合创建索引（会加重IO负担） where条件里用不到的字段不创建索引 ","date":"2017-03-02","objectID":"/mysql/:3:9","tags":["数据库","大纲"],"title":"MySQL总结","uri":"/mysql/"},{"categories":["数据库"],"content":"事务 事务指的是满足 ACID 特性的一组操作，可以通过 Commit 提交一个事务，也可以使用 Rollback 进行回滚。 ","date":"2017-03-02","objectID":"/mysql/:4:0","tags":["数据库","大纲"],"title":"MySQL总结","uri":"/mysql/"},{"categories":["数据库"],"content":"ACID特性 原子性(Atomicity) 事务被视为不可分割的最小单元，事务的所有操作要么全部提交成功，要么全部失败回滚。 回滚可以用日志来实现，日志记录着事务所执行的修改操作，在回滚时反向执行这些修改操作即可。 一致性(Consistency) 数据库在事务执行前后都保持一致性状态。在一致性状态下，所有事务对一个数据的读取结果都是相同的。 隔离性(Isolation) 一个事务所做的修改在最终提交以前，对其它事务是不可见的。 持久性(Durability) 一旦事务提交，则其所做的修改将会永远保存到数据库中。即使系统发生崩溃，事务执行的结果也不能丢失。 可以通过数据库备份和恢复来实现，在系统发生崩溃时，使用备份的数据库进行数据恢复。 ACID特性的相互关系 事务的 ACID 特性概念简单，但不是很好理解，主要是因为这几个特性不是一种平级关系: 只有满足一致性，事务的执行结果才是正确的。 在无并发的情况下，事务串行执行，隔离性一定能够满足。此时只要能满足原子性，就一定能满足一致性。 在并发的情况下，多个事务并行执行，事务不仅要满足原子性，还需要满足隔离性，才能满足一致性。 事务满足持久化是为了能应对数据库崩溃的情况。 ACID\" ACID ","date":"2017-03-02","objectID":"/mysql/:4:1","tags":["数据库","大纲"],"title":"MySQL总结","uri":"/mysql/"},{"categories":["数据库"],"content":"并发一致性问题 在并发环境下，事务的隔离性很难保证，因此会出现很多并发一致性问题。 丢失修改 T1和T2两个事务都对一个数据进行修改，T1先修改，T2随后修改，T2的修改覆盖了T1的修改。 读脏数据 T1修改一个数据，T2随后读取这个数据。如果T1撤销了这次修改，那么T2读取的数据是脏数据。 不可重复读 T2读取一个数据，T1对该数据做了修改。如果T2再次读取这个数据，此时读取的结果和第一次读取的结果不同。 幻影读 T1读取某个范围的数据，T2在这个范围内插入新的数据，T1再次读取这个范围的数据，此时读取的结果和和第一次读取的结果不同。 幻读和不可重复读的区别： 不可重复读的重点是修改：在同一事务中，同样的条件，第一次读的数据和第二次读的数据不一样。（因为中间有其他事务提交了修改） 幻读的重点在于新增或者删除：在同一事务中，同样的条件，第一次和第二次读出来的记录数不一样。（因为中间有其他事务提交了插入/删除） ","date":"2017-03-02","objectID":"/mysql/:4:2","tags":["数据库","大纲"],"title":"MySQL总结","uri":"/mysql/"},{"categories":["数据库"],"content":"并发一致性的解决方案（引出隔离级别等） 产生并发不一致性问题主要原因是破坏了事务的隔离性，解决方法是通过并发控制来保证隔离性。并发控制可以通过封锁来实现，但是封锁操作需要用户自己控制，相当复杂。 数据库管理系统提供了事务的隔离级别，让用户以一种更轻松的方式处理并发一致性问题。 ","date":"2017-03-02","objectID":"/mysql/:4:3","tags":["数据库","大纲"],"title":"MySQL总结","uri":"/mysql/"},{"categories":["数据库"],"content":"隔离级别 使用select @@tx_isolation;查询数据库的隔离级别。Mysql默认的级别是可重复读，优先考虑把数据库系统的隔离级别设为读已提交。 未提交读(READ UNCOMMITTED) 读未提交，一个事务可以读到另一个事务未提交的数据！ 提交读(READ COMMITTED) 读已提交，一个事务可以读到另一个事务已提交的数据! 一个事务只能读取已经提交的事务所做的修改。换句话说，一个事务所做的修改在提交之前对其它事务是不可见的。 可重复读(REPEATABLE READ) 可重复读，加入间隙锁保证在同一个事务中多次读取同样数据的结果是一样的。 可串行化(SERIALIZABLE) 串行化，该级别下读写串行化，且所有的select语句后都自动加上lock in share mode，即使用了共享锁。因此在该隔离级别下，使用的是当前读，而不是快照读。 多版本并发控制是MySQL的InnoDB存储引擎实现隔离级别的一种具体方式，用于实现提交读和可重复读这两种隔离级别。 而未提交读隔离级别总是读取最新的数据行，无需使用 MVCC。可串行化隔离级别需要对所有读取的行都加锁，单纯使用 MVCC 无法实现。 MySQL的InnoDB存储引擎采用两段锁协议，会根据隔离级别在需要的时候自动加锁，并且所有的锁都是在同一时刻被释放，这被称为隐式锁定。 隔离级别\" 隔离级别 ","date":"2017-03-02","objectID":"/mysql/:4:4","tags":["数据库","大纲"],"title":"MySQL总结","uri":"/mysql/"},{"categories":["数据库"],"content":"多版本并发控制 多版本并发控制(Multi-Version Concurrency Control, MVCC)是 MySQL 的 InnoDB 存储引擎实现隔离级别的一种具体方式，用于实现提交读和可重复读这两种隔离级别。而未提交读隔离级别总是读取最新的数据行，无需使用 MVCC。可串行化隔离级别需要对所有读取的行都加锁，单纯使用 MVCC 无法实现。 版本号 系统版本号: 是一个递增的数字，每开始一个新的事务，系统版本号就会自动递增。 事务版本号: 事务开始时的系统版本号。 隐藏的列 MVCC 在每行记录后面都保存着两个隐藏的列，用来存储两个版本号: 创建版本号: 指示创建一个数据行的快照时的系统版本号； 删除版本号: 如果该快照的删除版本号大于当前事务版本号表示该快照有效，否则表示该快照已经被删除了。 Undo 日志 MVCC 使用到的快照存储在 Undo 日志中，该日志通过回滚指针把一个数据行(Record)的所有快照连接起来。 实现过程 以下实现过程针对可重复读隔离级别。 当开始新一个事务时，该事务的版本号肯定会大于当前所有数据行快照的创建版本号，理解这一点很关键。 SELECT 多个事务必须读取到同一个数据行的快照，并且这个快照是距离现在最近的一个有效快照。但是也有例外，如果有一个事务正在修改该数据行，那么它可以读取事务本身所做的修改，而不用和其它事务的读取结果一致。 把没有对一个数据行做修改的事务称为 T，T 所要读取的数据行快照的创建版本号必须小于 T 的版本号，因为如果大于或者等于 T 的版本号，那么表示该数据行快照是其它事务的最新修改，因此不能去读取它。除此之外，T 所要读取的数据行快照的删除版本号必须大于 T 的版本号，因为如果小于等于 T 的版本号，那么表示该数据行快照是已经被删除的，不应该去读取它。 INSERT 将当前系统版本号作为数据行快照的创建版本号。 DELETE 将当前系统版本号作为数据行快照的删除版本号。 UPDATE 将当前系统版本号作为更新前的数据行快照的删除版本号，并将当前系统版本号作为更新后的数据行快照的创建版本号。可以理解为先执行 DELETE 后执行 INSERT。 快照读与当前读 快照读 使用 MVCC 读取的是快照中的数据，这样可以减少加锁所带来的开销。 select * from table ; 当前读 读取的是最新的数据，需要加锁。以下第一个语句需要加 S 锁，其它都需要加 X 锁。 select * from table where ? lock in share mode; //S锁 (共享锁) select * from table where ? for update; //加X锁 (排他锁) insert; update; delete; ","date":"2017-03-02","objectID":"/mysql/:4:5","tags":["数据库","大纲"],"title":"MySQL总结","uri":"/mysql/"},{"categories":["数据库"],"content":"事务的实现 事务的实现是基于数据库的存储引擎。不同的存储引擎对事务的支持程度不一样。MySQL 中支持事务的存储引擎有 InnoDB 和 NDB。 事务的实现就是如何实现ACID特性。事务的隔离性是通过锁实现，而事务的原子性、一致性和持久性则是通过事务日志实现。 InnoDB事务日志包括redo log和undo log。 redo log（重做日志） redo log通常是物理日志，记录的是数据页的物理修改，而不是某一行或某几行修改成怎样，它用来恢复提交后的物理数据页。 在InnoDB的存储引擎中，事务日志通过重做(redo)日志和InnoDB存储引擎的日志缓冲(InnoDB Log Buffer)实现。事务开启时，事务中的操作，都会先写入存储引擎的日志缓冲中，在事务提交之前，这些缓冲的日志都需要提前刷新到磁盘上持久化，这就是DBA们口中常说的“日志先行”(Write-Ahead Logging)。当事务提交之后，在Buffer Pool中映射的数据文件才会慢慢刷新到磁盘。此时如果数据库崩溃或者宕机，那么当系统重启进行恢复时，就可以根据redo log中记录的日志，把数据库恢复到崩溃前的一个状态。未完成的事务，可以继续提交，也可以选择回滚，这基于恢复的策略而定。 在系统启动的时候，就已经为redo log分配了一块连续的存储空间，以顺序追加的方式记录Redo Log，通过顺序IO来改善性能。所有的事务共享redo log的存储空间，它们的Redo Log按语句的执行顺序，依次交替的记录在一起。 undo log（回滚日志） undo log是逻辑日志，和redo log记录物理日志的不一样。可以这样认为，当delete一条记录时，undo log中会记录一条对应的insert记录，当update一条记录时，它记录一条对应相反的update记录。 undo log 主要为事务的回滚服务。在事务执行的过程中，除了记录redo log，还会记录一定量的undo log。undo log记录了数据在每个操作前的状态，如果事务执行过程中需要回滚，就可以根据undo log进行回滚操作。单个事务的回滚，只会回滚当前事务做的操作，并不会影响到其他的事务做的操作。 Undo记录的是已部分完成并且写入硬盘的未完成的事务，默认情况下回滚日志是记录在表空间中的（共享表空间或者独享表空间） 二种日志均可以视为一种恢复操作，redo_log是恢复提交事务修改的页操作，而undo_log是回滚行记录到特定版本。二者记录的内容也不同，redo_log是物理日志，记录页的物理修改操作，而undo_log是逻辑日志，根据每行记录进行记录。 事务ACID特性的实现思想 原子性：是使用 undo log来实现的，如果事务执行过程中出错或者用户执行了rollback，系统通过undo log日志返回事务开始的状态。 持久性：使用 redo log来实现，只要redo log日志持久化了，当系统崩溃，即可通过redo log把数据恢复。 隔离性：通过锁以及MVCC,使事务相互隔离开。 一致性：通过回滚日志、恢复，以及并发情况下的隔离性，从而实现一致性。 ","date":"2017-03-02","objectID":"/mysql/:4:6","tags":["数据库","大纲"],"title":"MySQL总结","uri":"/mysql/"},{"categories":["数据库"],"content":"MySQL 有多少种日志 错误日志：记录出错信息，也记录一些警告信息或者正确的信息。 查询日志：记录所有对数据库请求的信息，不论这些请求是否得到了正确的执行。 慢查询日志：设置一个阈值，将运行时间超过该值的所有SQL语句都记录到慢查询的日志文件中。 二进制日志：记录对数据库执行更改的所有操作。 中继日志：中继日志也是二进制日志，用来给slave 库恢复 事务日志：重做日志redo和回滚日志undo ","date":"2017-03-02","objectID":"/mysql/:4:7","tags":["数据库","大纲"],"title":"MySQL总结","uri":"/mysql/"},{"categories":["数据库"],"content":"MySQL对分布式事务的支持 下面是简单描述，详细请参考分布式事务。 分布式事务的实现方式有很多，既可以采用 InnoDB 提供的原生的事务支持，也可以采用消息队列来实现分布式事务的最终一致性。这里我们主要聊一下 InnoDB 对分布式事务的支持。 MySQL 从 5.0.3 InnoDB 存储引擎开始支持XA协议的分布式事务。一个分布式事务会涉及多个行动，这些行动本身是事务性的。所有行动都必须一起成功完成，或者一起被回滚。 ","date":"2017-03-02","objectID":"/mysql/:4:8","tags":["数据库","大纲"],"title":"MySQL总结","uri":"/mysql/"},{"categories":["数据库"],"content":"MySQL锁机制 ","date":"2017-03-02","objectID":"/mysql/:5:0","tags":["数据库","大纲"],"title":"MySQL总结","uri":"/mysql/"},{"categories":["数据库"],"content":"封锁 封锁粒度 MySQL 中提供了两种封锁粒度: 行级锁以及表级锁。 封锁粒度\" 封锁粒度 封锁类型 读写锁 排它锁(Exclusive)，简写为 X 锁，又称写锁。 共享锁(Shared)，简写为 S 锁，又称读锁。 有以下两个规定: 一个事务对数据对象 A 加了 X 锁，就可以对 A 进行读取和更新。加锁期间其它事务不能对 A 加任何锁。 一个事务对数据对象 A 加了 S 锁，可以对 A 进行读取操作，但是不能进行更新操作。加锁期间其它事务能对 A 加 S 锁，但是不能加 X 锁。 意向锁 使用意向锁(Intention Locks)可以更容易地支持多粒度封锁。 在存在行级锁和表级锁的情况下，事务T想要对表A加X锁，就需要先检测是否有其它事务对表A或者表A中的任意一行加了锁，那么就需要对表A的每一行都检测一次，这是非常耗时的。 意向锁在原来的 X/S 锁之上引入了 IX/IS，IX/IS 都是表锁，用来表示一个事务想要在表中的某个数据行上加 X 锁或 S 锁。 一个事务在获得某个数据行对象的 S 锁之前，必须先获得表的 IS 锁或者更强的锁； 一个事务在获得某个数据行对象的 X 锁之前，必须先获得表的 IX 锁。 任意 IS/IX 锁之间都是兼容的，因为它们只是表示想要对表加锁，而不是真正加锁； S 锁只与 S 锁和 IS 锁兼容，也就是说事务 T 想要对数据行加 S 锁，其它事务可以已经获得对表或者表中的行的 S 锁。 通过引入意向锁，事务 T 想要对表 A 加 X 锁，只需要先检测是否有其它事务对表A加了 X/IX/S/IS 锁，如果加了就表示有其它事务正在使用这个表或者表中某一行的锁，因此事务T加X锁失败。 封锁协议 三级封锁协议 一级封锁协议 事务 T 要修改数据 A 时必须加 X 锁，直到 T 结束才释放锁。 可以解决丢失修改问题，因为不能同时有两个事务对同一个数据进行修改，那么事务的修改就不会被覆盖。 二级封锁协议 在一级的基础上，要求读取数据 A 时必须加 S 锁，读取完马上释放 S 锁。 可以解决读脏数据问题，因为如果一个事务在对数据 A 进行修改，根据 1 级封锁协议，会加 X 锁，那么就不能再加 S 锁了，也就是不会读入数据。 三级封锁协议 在二级的基础上，要求读取数据 A 时必须加 S 锁，直到事务结束了才能释放 S 锁。 可以解决不可重复读的问题，因为读 A 时，其它事务不能对 A 加 X 锁，从而避免了在读的期间数据发生改变。 两段锁协议 加锁和解锁分为两个阶段进行。 可串行化调度是指，通过并发控制，使得并发执行的事务结果与某个串行执行的事务结果相同。 事务遵循两段锁协议是保证可串行化调度的充分条件。例如以下操作满足两段锁协议，它是可串行化调度。 MySQL 的 InnoDB 存储引擎采用两段锁协议，会根据隔离级别在需要的时候自动加锁，并且所有的锁都是在同一时刻被释放，这被称为隐式锁定。 ","date":"2017-03-02","objectID":"/mysql/:5:1","tags":["数据库","大纲"],"title":"MySQL总结","uri":"/mysql/"},{"categories":["数据库"],"content":"锁模式(InnoDB有三种行锁的算法) Record Locks（记录锁，行锁） 单个行记录上的锁。对索引项加锁，锁定符合条件的行。其他事务不能修改和删除加锁项。 该锁是对索引记录进行加锁！锁是在加索引上而不是行上的。注意了，InnoDB 一定存在聚簇索引，因此行锁最终都会落到聚簇索引上！ 如果表没有设置索引，InnoDB 会自动在主键上创建隐藏的聚簇索引，因此 Record Locks 依然可以使用。 Gap Locks（间隙锁） 当我们使用范围条件而不是相等条件检索数据，并请求共享或排他锁时，InnoDB会给符合条件的已有数据记录的索引项加锁。对于键值在条件范围内但并不存在的记录，叫做“间隙”，InnoDB 也会对这个“间隙”加锁，这种锁机制就是所谓的间隙锁。 锁定索引之间的间隙，但是不包含索引本身。其目的只有一个，防止其他事物插入数据。 间隙锁基于非唯一索引，它锁定一段范围内的索引记录。间隙锁基于下面将会提到的Next-Key Locking 算法，请务必牢记：使用间隙锁锁住的是一个区间，而不仅仅是这个区间中的每一条数据。 隔离级别比Read Committed低的情况下，不会使用间隙锁，如隔离级别为Read Uncommited时，也不存在间隙锁。当隔离级别为Repeatable Read和Serializable时，就会存在间隙锁。 例如当一个事务执行以下语句，其它事务就不能在 t.c 中插入 15。 SELECT c FROM t WHERE c BETWEEN 10 and 20 FOR UPDATE; Next-Key Locks（临键锁） 临键锁，是记录锁与间隙锁的组合，它的封锁范围，既包含索引记录，又包含索引区间。 MVCC不能解决幻读的问题，Next-Key Locks 就是为了解决这个问题而存在的。在可重复读(REPEATABLE READ)隔离级别下，使用 MVCC + Next-Key Locks 可以解决幻读问题。 例如一个索引包含以下值: 10, 11, 13, and 20，那么就需要锁定以下区间: (negative infinity, 10] (10, 11] (11, 13] (13, 20] (20, positive infinity) ","date":"2017-03-02","objectID":"/mysql/:5:2","tags":["数据库","大纲"],"title":"MySQL总结","uri":"/mysql/"},{"categories":["数据库"],"content":"锁行锁表 InnoDB行锁是通过给索引上的索引项加锁来实现，只有通过索引条件检索数据，InnoDB才使用行级锁，否则表锁（注意下面的解释）。 这里的表锁并不是用表锁来实现锁表的操作，而是利用了Next-Key Locks，也可以理解为是用了行锁+间隙锁来实现锁表的操作! 之所以能够锁表，是通过行锁+间隙锁来实现的。那么，RU和RC都不存在间隙锁，这种说法在RU和RC中还能成立么？ 因此，该说法只在RR和Serializable中是成立的。 如果隔离级别为RU和RC，无论条件列上是否有索引，都不会锁表，只锁行！ ","date":"2017-03-02","objectID":"/mysql/:5:3","tags":["数据库","大纲"],"title":"MySQL总结","uri":"/mysql/"},{"categories":["数据库"],"content":"参考文章 MySQL总结 数据库系统核心知识点 MySQL索引数据结构详解 select加锁分析 MySQL InnoDB的MVCC实现机制 一条SQL的执行过程详解 ","date":"2017-03-02","objectID":"/mysql/:6:0","tags":["数据库","大纲"],"title":"MySQL总结","uri":"/mysql/"},{"categories":["数据库"],"content":"关系型数据库概览","date":"2017-03-01","objectID":"/relationaldatabase/","tags":["数据库","大纲"],"title":"关系型数据库概览","uri":"/relationaldatabase/"},{"categories":["数据库"],"content":"数据库总览\" 数据库总览 SQL数据库原理\" SQL数据库原理 ","date":"2017-03-01","objectID":"/relationaldatabase/:0:0","tags":["数据库","大纲"],"title":"关系型数据库概览","uri":"/relationaldatabase/"},{"categories":["数据库"],"content":"数据库组件 SQL数据库概览\" SQL数据库概览 ","date":"2017-03-01","objectID":"/relationaldatabase/:1:0","tags":["数据库","大纲"],"title":"关系型数据库概览","uri":"/relationaldatabase/"},{"categories":["数据库"],"content":"核心组件 进程管理器（process manager）：很多数据库具备一个需要妥善管理的进程/线程池。再者，为了实现纳秒级操作，一些现代数据库使用自己的线程而不是操作系统线程。 网络管理器（network manager）：网路I/O是个大问题，尤其是对于分布式数据库。所以一些数据库具备自己的网络管理器。 文件系统管理器（File system manager）：磁盘I/O是数据库的首要瓶颈。具备一个文件系统管理器来完美地处理OS文件系统甚至取代OS文件系统，是非常重要的。 内存管理器（memory manager）：为了避免磁盘I/O带来的性能损失，需要大量的内存。但是如果你要处理大容量内存你需要高效的内存管理器，尤其是你有很多查询同时使用内存的时候。 安全管理器（Security Manager）：用于对用户的验证和授权。 客户端管理器（Client manager）：用于管理客户端连接。 ","date":"2017-03-01","objectID":"/relationaldatabase/:1:1","tags":["数据库","大纲"],"title":"关系型数据库概览","uri":"/relationaldatabase/"},{"categories":["数据库"],"content":"工具 备份管理器（Backup manager）：用于保存和恢复数据。 恢复管理器（Recovery manager）：用于崩溃后重启数据库到一个一致状态。 监控管理器（Monitor manager）：用于记录数据库活动信息和提供监控数据库的工具。 管理员管理器（Administration manager）：用于保存元数据（比如表的名称和结构），提供管理数据库、模式、表空间的工具。 ","date":"2017-03-01","objectID":"/relationaldatabase/:1:2","tags":["数据库","大纲"],"title":"关系型数据库概览","uri":"/relationaldatabase/"},{"categories":["数据库"],"content":"查询管理器 查询解析器（Query parser）：用于检查查询是否合法 查询重写器（Query rewriter）：用于预优化查询 查询优化器（Query optimizer）：用于优化查询 查询执行器（Query executor）：用于编译和执行查询 ","date":"2017-03-01","objectID":"/relationaldatabase/:1:3","tags":["数据库","大纲"],"title":"关系型数据库概览","uri":"/relationaldatabase/"},{"categories":["数据库"],"content":"数据管理器： 事务管理器（Transaction manager）：用于处理事务 缓存管理器（Cache manager）：数据被使用之前置于内存，或者数据写入磁盘之前置于内存 数据访问管理器（Data access manager）：访问磁盘中的数据 ","date":"2017-03-01","objectID":"/relationaldatabase/:1:4","tags":["数据库","大纲"],"title":"关系型数据库概览","uri":"/relationaldatabase/"},{"categories":["数据库"],"content":"数据查询的流程 本章集中探讨数据库如何通过如下进程管理SQL查询的： 客户端管理器 查询管理器 数据管理器（含恢复管理器） 客户端管理器 ","date":"2017-03-01","objectID":"/relationaldatabase/:2:0","tags":["数据库","大纲"],"title":"关系型数据库概览","uri":"/relationaldatabase/"},{"categories":["数据库"],"content":"客户端管理器 客户端管理器是处理客户端通信的。客户端可以是一个（网站）服务器或者一个最终用户或最终应用。客户端管理器通过一系列知名的API（JDBC, ODBC, OLE-DB …）提供不同的方式来访问数据库。客户端管理器也提供专有的数据库访问API。 客户端管理器\" 客户端管理器 当你连接到数据库时： 管理器首先检查你的验证信息（用户名和密码），然后检查你是否有访问数据库的授权。这些权限由DBA分配。 然后，管理器检查是否有空闲进程（或线程）来处理你对查询。 管理器还会检查数据库是否负载很重。 管理器可能会等待一会儿来获取需要的资源。如果等待时间达到超时时间，它会关闭连接并给出一个可读的错误信息。 然后管理器会把你的查询送给查询管理器来处理。 因为查询处理进程不是『不全则无』的，一旦它从查询管理器得到数据，它会把部分结果保存到一个缓冲区并且开始给你发送。 如果遇到问题，管理器关闭连接，向你发送可读的解释信息，然后释放资源。 ","date":"2017-03-01","objectID":"/relationaldatabase/:2:1","tags":["数据库","大纲"],"title":"关系型数据库概览","uri":"/relationaldatabase/"},{"categories":["数据库"],"content":"查询管理器 查询管理器\" 查询管理器 这个多步骤操作过程如下： 查询首先被解析并判断是否合法 然后被重写，去除了无用的操作并且加入预优化部分 接着被优化以便提升性能，并被转换为可执行代码和数据访问计划。 然后计划被编译 最后，被执行 ","date":"2017-03-01","objectID":"/relationaldatabase/:2:2","tags":["数据库","大纲"],"title":"关系型数据库概览","uri":"/relationaldatabase/"},{"categories":["数据库"],"content":"数据管理器 查询管理器\" 查询管理器 在这一步，查询管理器执行了查询，需要从表和索引获取数据，于是向数据管理器提出请求。 但是有 2 个问题： 关系型数据库使用事务模型，所以，当其他人在同一时刻使用或修改数据时，你无法得到这部分数据。 数据提取是数据库中速度最慢的操作，所以数据管理器需要足够聪明地获得数据并保存在内存缓冲区内。 缓冲区 缓冲池(buffer pool)是一种常见的降低磁盘访问的机制； 缓冲池通常以页(page)为单位缓存数据； 缓冲池的常见管理算法是LRU，memcache，OS，InnoDB都使用了这种算法； InnoDB对普通LRU进行了优化：将缓冲池分为老生代和新生代，入缓冲池的页，优先进入老生代，页被访问，才进入新生代，以解决预读失效的问题页被访问，且在老生代停留时间超过配置阈值的，才进入新生代，以解决批量数据访问，大量热数据淘汰的问题 缓冲区详解 ","date":"2017-03-01","objectID":"/relationaldatabase/:2:3","tags":["数据库","大纲"],"title":"关系型数据库概览","uri":"/relationaldatabase/"},{"categories":["数据库"],"content":"三个范式 第一范式（1NF）：数据库表中的字段都是单一属性的，不可再分。这个单一属性由基本类型构成，包括整型、实数、字符型、逻辑型、日期型等。 第二范式（2NF）：数据库表中不存在非关键字段对任一候选关键字段的部分函数依赖（部分函数依赖指的是存在组合关键字中的某些字段决定非关键字段的情况），也即所有非关键字段都完全依赖于任意一组候选关键字。 第三范式（3NF）：在第二范式的基础上，数据表中如果不存在非关键字段对任一候选关键字段的传递函数依赖则符合第三范式。所谓传递函数依赖，指的是如 果存在\"A → B → C\"的决定关系，则C传递函数依赖于A。因此，满足第三范式的数据库表应该不存在如下依赖关系： 关键字段 → 非关键字段 x → 非关键字段y ","date":"2017-03-01","objectID":"/relationaldatabase/:3:0","tags":["数据库","大纲"],"title":"关系型数据库概览","uri":"/relationaldatabase/"},{"categories":["数据库"],"content":"参考文章 关系型数据库是如何工作的 ","date":"2017-03-01","objectID":"/relationaldatabase/:4:0","tags":["数据库","大纲"],"title":"关系型数据库概览","uri":"/relationaldatabase/"},{"categories":["算法"],"content":"算法概览","date":"2017-02-05","objectID":"/algorithm/","tags":["算法","大纲"],"title":"算法概览","uri":"/algorithm/"},{"categories":["算法"],"content":"概览\" 概览 数据结构研究的是数据的存储方式，算法研究的是解决问题的思路。数据结构与算法是相辅相成的。 ","date":"2017-02-05","objectID":"/algorithm/:0:0","tags":["算法","大纲"],"title":"算法概览","uri":"/algorithm/"},{"categories":["算法"],"content":"排序算法 排序算法概览\" 排序算法概览 ","date":"2017-02-05","objectID":"/algorithm/:1:0","tags":["算法","大纲"],"title":"算法概览","uri":"/algorithm/"},{"categories":["算法"],"content":"冒泡排序(Bubble Sort) 它是一种较简单的排序算法。它会遍历若干次要排序的数列，每次遍历时，它都会从前往后依次的比较相邻两个数的大小；如果前者比后者大，则交换它们的位置。这样，一次遍历之后，最大的元素就在数列的末尾！ 采用相同的方法再次遍历时，第二大的元素就被排列在最大元素之前。重复此操作，直到整个数列都有序为止 ","date":"2017-02-05","objectID":"/algorithm/:1:1","tags":["算法","大纲"],"title":"算法概览","uri":"/algorithm/"},{"categories":["算法"],"content":"快速排序(Quick Sort) 它的基本思想是: 选择一个基准数，通过一趟排序将要排序的数据分割成独立的两部分；其中一部分的所有数据都比另外一部分的所有数据都要小。然后，再按此方法对这两部分数据分别进行快速排序，整个排序过程可以递归进行，以此达到整个数据变成有序序列。 ","date":"2017-02-05","objectID":"/algorithm/:1:2","tags":["算法","大纲"],"title":"算法概览","uri":"/algorithm/"},{"categories":["算法"],"content":"插入排序(Insertion Sort) 直接插入排序(Straight Insertion Sort)的基本思想是: 把n个待排序的元素看成为一个有序表和一个无序表。开始时有序表中只包含1个元素，无序表中包含有n-1个元素，排序过程中每次从无序表中取出第一个元素，将它插入到有序表中的适当位置，使之成为新的有序表，重复n-1次可完成排序过程。 ","date":"2017-02-05","objectID":"/algorithm/:1:3","tags":["算法","大纲"],"title":"算法概览","uri":"/algorithm/"},{"categories":["算法"],"content":"Shell排序(Shell Sort) 希尔排序实质上是一种分组插入方法。它的基本思想是: 对于n个待排序的数列，取一个小于n的整数gap(gap被称为步长)将待排序元素分成若干个组子序列，所有距离为gap的倍数的记录放在同一个组中；然后，对各组内的元素进行直接插入排序。 这一趟排序完成之后，每一个组的元素都是有序的。然后减小gap的值，并重复执行上述的分组和排序。重复这样的操作，当gap=1时，整个数列就是有序的。 ","date":"2017-02-05","objectID":"/algorithm/:1:4","tags":["算法","大纲"],"title":"算法概览","uri":"/algorithm/"},{"categories":["算法"],"content":"选择排序(Selection sort) 它的基本思想是: 首先在未排序的数列中找到最小(or最大)元素，然后将其存放到数列的起始位置；接着，再从剩余未排序的元素中继续寻找最小(or最大)元素，然后放到已排序序列的末尾。以此类推，直到所有元素均排序完毕。 ","date":"2017-02-05","objectID":"/algorithm/:1:5","tags":["算法","大纲"],"title":"算法概览","uri":"/algorithm/"},{"categories":["算法"],"content":"堆排序(Heap Sort) 堆排序是指利用堆这种数据结构所设计的一种排序算法。堆是一个近似完全二叉树的结构，并同时满足堆积的性质：即子结点的键值或索引总是小于（或者大于）它的父节点。 ","date":"2017-02-05","objectID":"/algorithm/:1:6","tags":["算法","大纲"],"title":"算法概览","uri":"/algorithm/"},{"categories":["算法"],"content":"归并排序(Merge Sort) 将两个的有序数列合并成一个有序数列，我们称之为\"归并”。归并排序(Merge Sort)就是利用归并思想对数列进行排序。 ","date":"2017-02-05","objectID":"/algorithm/:1:7","tags":["算法","大纲"],"title":"算法概览","uri":"/algorithm/"},{"categories":["算法"],"content":"桶排序(Bucket Sort) 桶排序(Bucket Sort)的原理很简单，将数组分到有限数量的桶子里。每个桶子再个别排序（有可能再使用别的排序算法或是以递归方式继续使用桶排序进行排序） ","date":"2017-02-05","objectID":"/algorithm/:1:8","tags":["算法","大纲"],"title":"算法概览","uri":"/algorithm/"},{"categories":["算法"],"content":"基数排序(Radix Sort) 它的基本思想是: 将整数按位数切割成不同的数字，然后按每个位数分别比较。具体做法是: 将所有待比较数值统一为同样的数位长度，数位较短的数前面补零。然后，从最低位开始，依次进行一次排序。这样从最低位排序一直到最高位排序完成以后, 数列就变成一个有序序列 ","date":"2017-02-05","objectID":"/algorithm/:1:9","tags":["算法","大纲"],"title":"算法概览","uri":"/algorithm/"},{"categories":["算法"],"content":"算法思想详解 ","date":"2017-02-05","objectID":"/algorithm/:2:0","tags":["算法","大纲"],"title":"算法概览","uri":"/algorithm/"},{"categories":["算法"],"content":"分治算法 分治算法的基本思想是将一个规模为N的问题分解为K个规模较小的子问题，这些子问题相互独立且与原问题性质相同。求出子问题的解，就可得到原问题的解 ","date":"2017-02-05","objectID":"/algorithm/:2:1","tags":["算法","大纲"],"title":"算法概览","uri":"/algorithm/"},{"categories":["算法"],"content":"动态规划算法 动态规划算法通常用于求解具有某种最优性质的问题。在这类问题中，可能会有许多可行解。每一个解都对应于一个值，我们希望找到具有最优值的解。动态规划算法与分治法类似，其基本思想也是将待求解问题分解成若干个子问题，先求解子问题，然后从这些子问题的解得到原问题的解 ","date":"2017-02-05","objectID":"/algorithm/:2:2","tags":["算法","大纲"],"title":"算法概览","uri":"/algorithm/"},{"categories":["算法"],"content":"贪心算法 本文主要介绍算法中贪心算法的思想: 保证每次操作都是局部最优的，并且最后得到的结果是全局最优的 ","date":"2017-02-05","objectID":"/algorithm/:2:3","tags":["算法","大纲"],"title":"算法概览","uri":"/algorithm/"},{"categories":["算法"],"content":"二分法 本文主要介绍算法思想中分治算法重要的二分法，比如二分查找；二分查找也称折半查找（Binary Search），它是一种效率较高的查找方法。但是，折半查找要求线性表必须采用顺序存储结构，而且表中元素按关键字有序排列。 ","date":"2017-02-05","objectID":"/algorithm/:2:4","tags":["算法","大纲"],"title":"算法概览","uri":"/algorithm/"},{"categories":["算法"],"content":"搜索算法 本文主要介绍算法中搜索算法的思想，主要包含BFS，DFS ","date":"2017-02-05","objectID":"/algorithm/:2:5","tags":["算法","大纲"],"title":"算法概览","uri":"/algorithm/"},{"categories":["算法"],"content":"回溯算法 Backtracking(回溯)属于 DFS, 本文主要介绍算法中Backtracking算法的思想。回溯算法实际上一个类似枚举的搜索尝试过程，主要是在搜索尝试过程中寻找问题的解，当发现已不满足求解条件时，就“回溯”返回，尝试别的路径。回溯法是一种选优搜索法，按选优条件向前搜索，以达到目标。但当探索到某一步时，发现原先选择并不优或达不到目标，就退回一步重新选择，这种走不通就退回再走的技术为回溯法 ","date":"2017-02-05","objectID":"/algorithm/:2:6","tags":["算法","大纲"],"title":"算法概览","uri":"/algorithm/"},{"categories":["算法"],"content":"领域算法 ","date":"2017-02-05","objectID":"/algorithm/:3:0","tags":["算法","大纲"],"title":"算法概览","uri":"/algorithm/"},{"categories":["算法"],"content":"参考文章 算法 ","date":"2017-02-05","objectID":"/algorithm/:4:0","tags":["算法","大纲"],"title":"算法概览","uri":"/algorithm/"},{"categories":["数据结构"],"content":"具有层次感的数据结构","date":"2017-02-04","objectID":"/tree/","tags":["数据结构","大纲"],"title":"树","uri":"/tree/"},{"categories":["数据结构"],"content":"树\" 树 树是一种数据结构，它是n(n\u003e=0)个节点的有限集。n=0时称为空树。n\u003e0时，有限集的元素构成一个具有层次感的数据结构。 区别于线性表一对一的元素关系，树中的节点是一对多的关系。树具有以下特点: n\u003e0时，根节点是唯一的，不可能存在多个根节点。 每个节点有零个至多个子节点；除了根节点外，每个节点有且仅有一个父节点。根节点没有父节点。 ","date":"2017-02-04","objectID":"/tree/:0:0","tags":["数据结构","大纲"],"title":"树","uri":"/tree/"},{"categories":["数据结构"],"content":"树的相关概念 树例\" 树例 子树: 除了根节点外，每个子节点都可以分为多个不相交的子树。 孩子与双亲: 若一个结点有子树，那么该结点称为子树根的\"双亲”，子树的根是该结点的\"孩子”。 在图一中，B、H是A的孩子，A是B、H的双亲。 兄弟: 具有相同双亲的节点互为兄弟，例如B与H互为兄弟。 节点的度: 一个节点拥有子树的数目。例如A的度为2，B的度为1，C的度为3. 叶子: 没有子树，也即是度为0的节点。 分支节点: 除了叶子节点之外的节点，也即是度不为0的节点。 内部节点: 除了根节点之外的分支节点。 层次: 根节点为第一层，其余节点的层次等于其双亲节点的层次加1. 树的高度: 也称为树的深度，树中节点的最大层次。 有序树: 树中节点各子树之间的次序是重要的，不可以随意交换位置。 无序树: 树种节点各子树之间的次序是不重要的。可以随意交换位置。 森林: 0或多棵互不相交的树的集合。例如图二中的两棵树为森林。 ","date":"2017-02-04","objectID":"/tree/:1:0","tags":["数据结构","大纲"],"title":"树","uri":"/tree/"},{"categories":["数据结构"],"content":"二叉树 二叉树: 最多有两棵子树的树被称为二叉树。 二叉树\" 二叉树 斜树: 所有节点都只有左子树的二叉树叫做左斜树，所有节点都只有右子树的二叉树叫做右斜树。(本质就是链表) 斜树\" 斜树 满二叉树: 二叉树中所有非叶子结点的度都是2，且叶子结点都在同一层次上 满二叉树\" 满二叉树 完全二叉树: 如果一个二叉树与满二叉树前m个节点的结构相同，这样的二叉树被称为完全二叉树 完全二叉树\" 完全二叉树 ","date":"2017-02-04","objectID":"/tree/:2:0","tags":["数据结构","大纲"],"title":"树","uri":"/tree/"},{"categories":["数据结构"],"content":"二叉查找树 - BST 二叉查找树(Binary Search Tree)是指一棵空树或者具有下列性质的二叉树: 若任意节点的左子树不空，则左子树上所有节点的值均小于它的根节点的值； 若任意节点的右子树不空，则右子树上所有节点的值均大于它的根节点的值； 任意节点的左、右子树也分别为二叉查找树； 没有键值相等的节点。 二叉查找树相比于其他数据结构的优势在于查找、插入的时间复杂度较低为 O (logn) 。二叉查找树是基础性数据结构，用于构建更为抽象的数据结构，如集合、多重集、关联数组等。 二叉查找树\" 二叉查找树 ","date":"2017-02-04","objectID":"/tree/:3:0","tags":["数据结构","大纲"],"title":"树","uri":"/tree/"},{"categories":["数据结构"],"content":"平衡二叉树 - AVL 含有相同节点的二叉查找树可以有不同的形态，而二叉查找树的平均查找长度与树的深度有关，所以需要找出一个查找平均长度最小的一棵，那就是平衡二叉树，具有以下性质: 要么是棵空树，要么其根节点左右子树的深度之差的绝对值不超过1； 其左右子树也都是平衡二叉树； 二叉树节点的平衡因子定义为该节点的左子树的深度减去右子树的深度。则平衡二叉树的所有节点的平衡因子只可能是-1,0,1。 平衡二叉树\" 平衡二叉树 ","date":"2017-02-04","objectID":"/tree/:4:0","tags":["数据结构","大纲"],"title":"树","uri":"/tree/"},{"categories":["数据结构"],"content":"红黑树 红黑树也是一种自平衡的二叉查找树。 每个结点要么是红的要么是黑的。(红或黑) 根结点是黑的。 (根黑) 每个叶结点(叶结点即指树尾端NIL指针或NULL结点)都是黑的。 (叶黑) 如果一个结点是红的，那么它的两个儿子都是黑的。 (红子黑) 对于任意结点而言，其到叶结点树尾端NIL指针的每条路径都包含相同数目的黑结点。(路径下黑相同) 红黑树\" 红黑树 用法最广: Java ConcurrentHashMap \u0026 TreeMap C++ STL: map \u0026 set linux进程调度Completely Fair Scheduler,用红黑树管理进程控制块 epoll在内核中的实现，用红黑树管理事件块 nginx中，用红黑树管理timer等 ","date":"2017-02-04","objectID":"/tree/:5:0","tags":["数据结构","大纲"],"title":"树","uri":"/tree/"},{"categories":["数据结构"],"content":"红黑树与AVL树的比较 AVL树的时间复杂度虽然优于红黑树，但是对于现在的计算机，cpu太快，可以忽略性能差异 红黑树的插入删除比AVL树更便于控制操作 红黑树整体性能略优于AVL树(红黑树旋转情况少于AVL树) ","date":"2017-02-04","objectID":"/tree/:5:1","tags":["数据结构","大纲"],"title":"树","uri":"/tree/"},{"categories":["数据结构"],"content":"哈弗曼树 哈夫曼又称最优二叉树。是一种带权路径长度最短的二叉树，一般可以按下面步骤构建: 将所有左，右子树都为空的作为根节点。 在森林中选出两棵根节点的权值最小的树作为一棵新树的左，右子树，且置新树的附加根节点的权值为其左，右子树上根节点的权值之和。 注意，左子树的权值应小于右子树的权值。 从森林中删除这两棵树，同时把新树加入到森林中。 重复2，3步骤，直到森林中只有一棵树为止，此树便是哈夫曼树。 哈弗曼树\" 哈弗曼树 ","date":"2017-02-04","objectID":"/tree/:6:0","tags":["数据结构","大纲"],"title":"树","uri":"/tree/"},{"categories":["数据结构"],"content":"B树 B树(英语: B-tree)是一种自平衡的树，能够保持数据有序。这种数据结构能够让查找数据、顺序访问、插入数据及删除的动作，都在对数时间内完成。B树，概括来说是一种自平衡的m阶树，与自平衡二叉查找树不同，B树适用于读写相对大的数据块的存储系统，例如磁盘。 根结点至少有两个子女。 每个中间节点都包含k-1个元素和k个孩子，其中 m/2 \u003c= k \u003c= m 每一个叶子节点都包含k-1个元素，其中 m/2 \u003c= k \u003c= m 所有的叶子结点都位于同一层。 每个节点中的元素从小到大排列，节点当中k-1个元素正好是k个孩子包含的元素的值域分划。 B-Tree中的每个节点根据实际情况可以包含大量的关键字信息和分支，如下图所示为一个3阶的B-Tree: B树\" B树 ","date":"2017-02-04","objectID":"/tree/:7:0","tags":["数据结构","大纲"],"title":"树","uri":"/tree/"},{"categories":["数据结构"],"content":"B+树 B+ 树是一种树数据结构，通常用于关系型数据库(如Mysql)和操作系统的文件系统中。B+ 树的特点是能够保持数据稳定有序，其插入与修改拥有较稳定的对数时间复杂度。B+ 树元素自底向上插入，这与二叉树恰好相反。 在B树基础上，为叶子结点增加链表指针(B树+叶子有序链表)，所有关键字都在叶子结点 中出现，非叶子结点作为叶子结点的索引；B+树总是到叶子结点才命中。 b+树的非叶子节点不保存数据，只保存子树的临界值(最大或者最小)，所以同样大小的节点，b+树相对于b树能够有更多的分支，使得这棵树更加矮胖，查询时做的IO操作次数也更少。 将上一节中的B-Tree优化，由于B+Tree的非叶子节点只存储键值信息，假设每个磁盘块能存储4个键值及指针信息，则变成B+Tree后其结构如下图所示: B+树\" B+树 ","date":"2017-02-04","objectID":"/tree/:8:0","tags":["数据结构","大纲"],"title":"树","uri":"/tree/"},{"categories":["数据结构"],"content":"R树 R树是用来做空间数据存储的树状数据结构。例如给地理位置，矩形和多边形这类多维数据建立索引。 R树的核心思想是聚合距离相近的节点并在树结构的上一层将其表示为这些节点的最小外接矩形(MBR)，这个最小外接矩形就成为上一层的一个节点。因为所有节点都在它们的最小外接矩形中，所以跟某个矩形不相交的查询就一定跟这个矩形中的所有节点都不相交。叶子节点上的每个矩形都代表一个对象，节点都是对象的聚合，并且越往上层聚合的对象就越多。也可以把每一层看做是对数据集的近似，叶子节点层是最细粒度的近似，与数据集相似度100%，越往上层越粗糙。 ","date":"2017-02-04","objectID":"/tree/:9:0","tags":["数据结构","大纲"],"title":"树","uri":"/tree/"},{"categories":["数据结构"],"content":"散列是数组和链表的结合体","date":"2017-02-03","objectID":"/hashtable/","tags":["数据结构"],"title":"哈希表","uri":"/hashtable/"},{"categories":["数据结构"],"content":"定义 散列Hash是和顺序、链接和索引一样，是存储集合或者线性表的一种方法。 散列的基本思想是：以集合或线性表中的每个元素的关键字K为自变量，通过一个散列函数 h(K) 得到的结果，将这个结果解释为一块连续的存储空间（如数组）的地址（如数组下标），将这个元素存储到这个空间中。 h(K) 称为散列函数或者哈希函数，它实现了关键字到存储地址的映射，散列算法，变换成固定长度的输出，该输出就是散列值。h(K)的值 称为散列地址或者哈希地址。存储空间是线性表进行散列存储的空间，所以称之为散列表或者哈希表。 ","date":"2017-02-03","objectID":"/hashtable/:1:0","tags":["数据结构"],"title":"哈希表","uri":"/hashtable/"},{"categories":["数据结构"],"content":"释义 这种转换是一种压缩映射，也就是，散列值的空间通常远小于输入的空间，不同的输入可能会散列成相同的输出，所以不可能从散列值来唯一的确定输入值。简单的说就是一种将任意长度的消息压缩到某一固定长度的消息摘要的函数。 所有散列函数都有如下一个基本特性：根据同一散列函数计算出的散列值如果不同，那么输入值肯定也不同。但是，根据同一散列函数计算出的散列值如果相同，输入值不一定相同。 两个不同的输入值，根据同一散列函数计算出的散列值相同的现象叫做碰撞，衡量一个哈希函数的好坏的重要指标就是发生碰撞的概率以及发生碰撞的解决方案。 ","date":"2017-02-03","objectID":"/hashtable/:2:0","tags":["数据结构"],"title":"哈希表","uri":"/hashtable/"},{"categories":["数据结构"],"content":"常见的Hash函数 直接定址法：直接以关键字k或者k加上某个常数（k+c）作为哈希地址。 数字分析法：提取关键字中取值比较均匀的数字作为哈希地址。 除留余数法：用关键字k除以某个不大于哈希表长度m的数p，将所得余数作为哈希表地址。 分段叠加法：按照哈希表地址位数将关键字分成位数相等的几部分，其中最后一部分可以比较短。然后将这几部分相加，舍弃最高进位后的结果就是该关键字的哈希地址。 平方取中法：如果关键字各个部分分布都不均匀的话，可以先求出它的平方值，然后按照需求取中间的几位作为哈希地址。 伪随机数法：采用一个伪随机数当作哈希函数。 ","date":"2017-02-03","objectID":"/hashtable/:3:0","tags":["数据结构"],"title":"哈希表","uri":"/hashtable/"},{"categories":["数据结构"],"content":"解决碰撞方法 开放定址法：开放定址法就是一旦发生了冲突，就去寻找下一个空的散列地址，只要散列表足够大，空的散列地址总能找到，并将记录存入。 链地址法：将哈希表的每个单元作为链表的头结点，所有哈希地址为i的元素构成一个同义词链表。即发生冲突时就把该关键字链在以该单元为头结点的链表的尾部。 再哈希法：当哈希地址发生冲突用其他的函数计算另一个哈希函数地址，直到冲突不再产生为止。 建立公共溢出区：将哈希表分为基本表和溢出表两部分，发生冲突的元素都放入溢出表中。 ","date":"2017-02-03","objectID":"/hashtable/:4:0","tags":["数据结构"],"title":"哈希表","uri":"/hashtable/"},{"categories":["数据结构"],"content":"散列存储的缺点 计算散列地址需要花费时间，关键字不是整数还先要转换为整数。 占用更多的存储空间，开放定址法的装载因子小于1，链接法则需要空间存储指针。 只能按关键字查找，无法按非关键字查找。 ","date":"2017-02-03","objectID":"/hashtable/:5:0","tags":["数据结构"],"title":"哈希表","uri":"/hashtable/"},{"categories":["数据结构"],"content":"数组是用于储存多个相同类型数据的集合","date":"2017-02-02","objectID":"/linkedlist/","tags":["数据结构"],"title":"链表","uri":"/linkedlist/"},{"categories":["数据结构"],"content":"定义 链表是一种物理存储单元上非连续、非顺序的存储结构，数据元素的逻辑顺序是通过链表中的指针链接次序实现的。 ","date":"2017-02-02","objectID":"/linkedlist/:1:0","tags":["数据结构"],"title":"链表","uri":"/linkedlist/"},{"categories":["数据结构"],"content":"详解 链表的存在就是为了解决数组的增删复杂耗时，内存占用较大的问题。它并不需要一块连续的内存空间，它通过指针将一组零散的内存块串联起来。 根据指针的不同，有单链表，双向链表，循环链表之分。 数组和链表是相互补充的一对数据结构。 ","date":"2017-02-02","objectID":"/linkedlist/:2:0","tags":["数据结构"],"title":"链表","uri":"/linkedlist/"},{"categories":["数据结构"],"content":"优点： 操作指针即可删除该元素或者插入新元素，时间复杂度 O(1)。 链表因为元素不连续，而是靠指针指向下一个元素的位置，本身没有大小的限制，不存在数组的扩容问题，所以天然地支持动态扩容。 空间没有限制 插入删除元素很快 ","date":"2017-02-02","objectID":"/linkedlist/:3:0","tags":["数据结构"],"title":"链表","uri":"/linkedlist/"},{"categories":["数据结构"],"content":"缺点： 因为存储空间不连续，你无法根据一个索引算出对应元素的地址，所以不能随机访问。 由于每个元素必须存储指向前后元素位置的指针，会消耗相对更多的储存空间。 同时内存不连续，容易造成内存碎片。 存取速度很慢 ","date":"2017-02-02","objectID":"/linkedlist/:4:0","tags":["数据结构"],"title":"链表","uri":"/linkedlist/"},{"categories":["数据结构"],"content":"对比 ","date":"2017-02-02","objectID":"/linkedlist/:5:0","tags":["数据结构"],"title":"链表","uri":"/linkedlist/"},{"categories":["数据结构"],"content":"数组 数组存储区间是连续的，占用内存严重，故空间复杂的很大。但数组的二分查找时间复杂度小，为O(1)；数组的特点是：寻址容易，插入和删除困难。 ","date":"2017-02-02","objectID":"/linkedlist/:5:1","tags":["数据结构"],"title":"链表","uri":"/linkedlist/"},{"categories":["数据结构"],"content":"链表 链表存储区间离散，占用内存比较宽松，故空间复杂度很小，但时间复杂度很大，达O（N）。链表的特点是：寻址困难，插入和删除容易。 ","date":"2017-02-02","objectID":"/linkedlist/:5:2","tags":["数据结构"],"title":"链表","uri":"/linkedlist/"},{"categories":["数据结构"],"content":"哈希表 那么我们能不能综合两者的特性，做出一种寻址容易，插入删除也容易的数据结构？这就是我们要提起的哈希表。 ","date":"2017-02-02","objectID":"/linkedlist/:5:3","tags":["数据结构"],"title":"链表","uri":"/linkedlist/"},{"categories":["数据结构"],"content":"分类 单向链表 一个节点指向下一个节点。 双向链表 一个节点有两个指针域。 循环链表 能通过任何一个节点找到其他所有的节点，将两种(双向/单向)链表的最后一个结点指向第一个结点从而实现循环。 ","date":"2017-02-02","objectID":"/linkedlist/:6:0","tags":["数据结构"],"title":"链表","uri":"/linkedlist/"},{"categories":["数据结构"],"content":"数组是用于储存多个相同类型数据的集合","date":"2017-02-01","objectID":"/array/","tags":["数据结构"],"title":"数组","uri":"/array/"},{"categories":["数据结构"],"content":"定义 有限个相同数据类型的元素按顺序排列的集合为数组。 ","date":"2017-02-01","objectID":"/array/:1:0","tags":["数据结构"],"title":"数组","uri":"/array/"},{"categories":["数据结构"],"content":"特性 数组是相同数据类型的元素的集合。 数组中的各元素的存储是有先后顺序的，它们在内存中按照这个先后顺序连续存放在一起。 ","date":"2017-02-01","objectID":"/array/:2:0","tags":["数据结构"],"title":"数组","uri":"/array/"},{"categories":["数据结构"],"content":"优点： 由于是紧凑连续存储,可以随机访问，通过索引快速找到对应元素，而且相对节约存储空间，查询修改元素的效率O(1)。 ","date":"2017-02-01","objectID":"/array/:3:0","tags":["数据结构"],"title":"数组","uri":"/array/"},{"categories":["数据结构"],"content":"缺点： 正因为连续存储，内存空间必须一次性分配够，所以说数组如果要扩容，需要重新分配一块更大的空间，再把数据全部复制过去，时间复杂度 O(N)。 想在数组中间进行插入和删除，每次必须搬移后面的所有数据以保持连续，时间复杂度 O(N) ","date":"2017-02-01","objectID":"/array/:4:0","tags":["数据结构"],"title":"数组","uri":"/array/"},{"categories":["数据结构"],"content":"二维数组 二维数组也称为矩阵，因为是二维的，所以需要两个下标才能确定一个元素，即行下标和列下标。 ","date":"2017-02-01","objectID":"/array/:5:0","tags":["数据结构"],"title":"数组","uri":"/array/"},{"categories":["数据结构"],"content":"数据结构概览","date":"2017-01-15","objectID":"/datastruct/","tags":["数据结构","大纲"],"title":"数据结构概览","uri":"/datastruct/"},{"categories":["数据结构"],"content":"概览\" 概览 数据结构研究的是数据的存储方式，算法研究的是解决问题的思路。数据结构与算法是相辅相成的。 ","date":"2017-01-15","objectID":"/datastruct/:0:0","tags":["数据结构","大纲"],"title":"数据结构概览","uri":"/datastruct/"},{"categories":["数据结构"],"content":"常用存储结构 线性表，还可细分为顺序表(数组)、链表、栈和队列。 树结构，包括普通树，二叉树，二叉查找树等。 图存储结构。 ","date":"2017-01-15","objectID":"/datastruct/:0:1","tags":["数据结构","大纲"],"title":"数据结构概览","uri":"/datastruct/"},{"categories":["数据结构"],"content":"线性表 线性表并不是一种具体的存储结构，它包含顺序存储结构和链式存储结构，是顺序表和链表的统称。 线性表是一种线性结构，它是由零个或多个数据元素构成的有限序列。 线性表的特征是在一个序列中，除了头尾元素，每个元素都有且只有一个直接前驱，有且只有一个直接后继，而序列头元素没有直接前驱，序列尾元素没有直接后继。 数据结构中常见的线性结构有数组、单链表、双链表、循环链表等。线性表中的元素为某种相同的抽象数据类型。 线性表\" 线性表 如图 3a) 所示，将数据依次存储在连续的整块物理空间中，这种存储结构称为顺序存储结构（简称顺序表，数组）； 如图 3b) 所示，数据分散的存储在物理空间中，通过一根线保存着它们之间的逻辑关系，这种存储结构称为链式存储结构（简称链表）。 ","date":"2017-01-15","objectID":"/datastruct/:1:0","tags":["数据结构","大纲"],"title":"数据结构概览","uri":"/datastruct/"},{"categories":["数据结构"],"content":"数组和矩阵(顺序表) 数组是一种连续存储线性结构，元素类型相同，大小相等，数组是多维的，通过使用整型索引值来访问他们的元素，数组尺寸不能改变。 ","date":"2017-01-15","objectID":"/datastruct/:1:1","tags":["数据结构","大纲"],"title":"数据结构概览","uri":"/datastruct/"},{"categories":["数据结构"],"content":"链表 我们知道，使用顺序表（底层实现靠数组）时，需要提前申请一定大小的存储空间，这块存储空间的物理地址是连续的，链表则完全不同，使用链表存储数据时，是随用随申请，因此数据的存储位置是相互分离的，换句话说，数据的存储位置是随机的。 n个节点离散分配，彼此通过指针相连，每个节点只有一个前驱节点，每个节点只有一个后续节点，首节点没有前驱节点，尾节点没有后续节点。确定一个链表我们只需要头指针，通过头指针就可以把整个链表都能推出来。 ","date":"2017-01-15","objectID":"/datastruct/:1:2","tags":["数据结构","大纲"],"title":"数据结构概览","uri":"/datastruct/"},{"categories":["数据结构"],"content":"哈希表(散列) 散列表（Hash table，也叫哈希表），是根据关键码值(Key value)而直接进行访问的数据结构。也就是说，它通过把关键码值映射到表中一个位置来访问记录，以加快查找的速度。这个映射函数叫做散列函数，存放记录的数组叫做散列表。 ","date":"2017-01-15","objectID":"/datastruct/:1:3","tags":["数据结构","大纲"],"title":"数据结构概览","uri":"/datastruct/"},{"categories":["数据结构"],"content":"栈和队列 数组和链表都是线性存储结构的基础，栈和队列都是线性存储结构的应用，栈和队列隶属于线性表，是特殊的线性表，因为它们对线性表中元素的进出做了明确的要求。 栈（LIFO） 使用数组实现的叫静态栈 使用链表实现的叫动态栈 栈（FIFO） 使用数组实现的叫静态队列 使用链表实现的叫动态队列 ","date":"2017-01-15","objectID":"/datastruct/:1:4","tags":["数据结构","大纲"],"title":"数据结构概览","uri":"/datastruct/"},{"categories":["数据结构"],"content":"树存储结构 树存储结构适合存储具有“一对多”关系的数据。 树\" 树 ","date":"2017-01-15","objectID":"/datastruct/:2:0","tags":["数据结构","大纲"],"title":"数据结构概览","uri":"/datastruct/"},{"categories":["数据结构"],"content":"图存储结构 图存储结构适合存储具有“多对多”关系的数据。 图\" 图 ","date":"2017-01-15","objectID":"/datastruct/:3:0","tags":["数据结构","大纲"],"title":"数据结构概览","uri":"/datastruct/"},{"categories":["数据结构"],"content":"和线性表，树的差异: 线性表中我们把数据元素叫元素，树中将数据元素叫结点，在图中数据元素，我们则称之为顶点(Vertex)。 线性表可以没有元素，称为空表；树中可以没有节点，称为空树；但是，在图中不允许没有顶点(有穷非空性)。 线性表中的各元素是线性关系，树中的各元素是层次关系，而图中各顶点的关系是用边来表示(边集可以为空)。 ","date":"2017-01-15","objectID":"/datastruct/:3:1","tags":["数据结构","大纲"],"title":"数据结构概览","uri":"/datastruct/"},{"categories":["数据结构"],"content":"总结 我们知道，实际应用当中，我们经常使用的是查找和排序操作，这在我们的各种管理系统、数据库系统、操作系统等当中，十分常用。 数组 的下标寻址十分迅速，但计算机的内存是有限的，故数组的长度也是有限的，实际应用当中的数据往往十分庞大；而且无序数组的查找最坏情况需要遍历整个数组；后来人们提出了二分查找，二分查找要求数组的构造一定有序，二分法查找解决了普通数组查找复杂度过高的问题。任和一种数组无法解决的问题就是插入、删除操作比较复杂，因此，在一个增删查改比较频繁的数据结构中，数组不会被优先考虑 普通链表 由于它的结构特点被证明根本不适合进行查找 哈希表 是数组和链表的折中，同时它的设计依赖散列函数的设计，数组不能无限长、链表也不适合查找，所以也不适合大规模的查找 二叉查找树 因为可能退化成链表，同样不适合进行查找 AVL树 是为了解决可能退化成链表问题，但是AVL树的旋转过程非常麻烦，因此插入和删除很慢，也就是构建AVL树比较麻烦 红黑树 是平衡二叉树和AVL树的折中，因此是比较合适的。集合类中的Map、关联数组具有较高的查询效率，它们的底层实现就是红黑树。 多路查找树 是大规模数据存储中，实现索引查询这样一个实际背景下，树节点存储的元素数量是有限的(如果元素数量非常多的话，查找就退化成节点内部的线性查找了)，这样导致二叉查找树结构由于树的深度过大而造成磁盘I/O读写过于频繁，进而导致查询效率低下。 B树 与自平衡二叉查找树不同，B树适用于读写相对大的数据块的存储系统，例如磁盘。它的应用是文件系统及部分非关系型数据库索引。 B+树 在B树基础上，为叶子结点增加链表指针(B树+叶子有序链表)，所有关键字都在叶子结点 中出现，非叶子结点作为叶子结点的索引；B+树总是到叶子结点才命中。通常用于关系型数据库(如Mysql)和操作系统的文件系统中。 B*树 是B+树的变体，在B+树的非根和非叶子结点再增加指向兄弟的指针, 在B+树基础上，为非叶子结点也增加链表指针，将结点的最低利用率从1/2提高到2/3。 R树是用来做空间数据存储的树状数据结构。例如给地理位置，矩形和多边形这类多维数据建立索引。 Trie树 是自然语言处理中最常用的数据结构，很多字符串处理任务都会用到。Trie树本身是一种有限状态自动机，还有很多变体。什么模式匹配、正则表达式，都与这有关。 针对大量数据，如果在内存中作业优先考虑红黑树(map,set之类多为RB-tree实现)，如果在硬盘中作业优先考虑B系列树(B+, B, B)* ","date":"2017-01-15","objectID":"/datastruct/:4:0","tags":["数据结构","大纲"],"title":"数据结构概览","uri":"/datastruct/"},{"categories":["网络"],"content":"计算机网络","date":"2017-01-05","objectID":"/network/","tags":["网络","大纲"],"title":"计算机网络","uri":"/network/"},{"categories":["网络"],"content":" 一般网线传输的模拟信号需要通过猫(调制解调器)转换成数字信号，再经由路由器把信号发给PC端，如果PC端数量超过了路由器的连接上限就需要加装交换器。因此，家里有宽带就必须有猫，有多台电脑上网就必须要路由器，假如电脑很多，超过路由器的接口数就需要交换机扩展接口。 传输示例\" 传输示例 协议对照\" 协议对照 各层协议对照\" 各层协议对照 HTTP协议\" HTTP协议 DNS协议\" DNS协议 ","date":"2017-01-05","objectID":"/network/:0:0","tags":["网络","大纲"],"title":"计算机网络","uri":"/network/"},{"categories":["网络"],"content":"参考文章 7层协议 HTTP协议 DNS协议 知识点串联：输入URL到页面加载过程详解 ","date":"2017-01-05","objectID":"/network/:1:0","tags":["网络","大纲"],"title":"计算机网络","uri":"/network/"},{"categories":["理财"],"content":"估值","date":"2016-01-02","objectID":"/appraisement/","tags":["理财"],"title":"估值","uri":"/appraisement/"},{"categories":["理财"],"content":"第一大块 蓝筹股 是以金融、地产、公用事业，还有建筑为主的蓝筹股，比较典型的特征是，估值很低，盈利质量好，盈利增速比较低。但是他不太愿意去参与蓝筹股投资，因为虽然低估值，但是并不满足盈利出现非线性变化的特征。换句话说就是，盈利无法突变。 这些行业可能十年前，甚至十年后的商业模式和盈利增速都是相对稳定，这种相对比较低的增速，它无法平抑估值上的波动。 巴菲特所说的捡烟蒂，指的就是这类股票，这类票机构看不上，但是对散户来说，拿着搏个稳定增长，还是很舒服的。 ","date":"2016-01-02","objectID":"/appraisement/:1:0","tags":["理财"],"title":"估值","uri":"/appraisement/"},{"categories":["理财"],"content":"第二大块 低估值成长 我们挑的基金，挑的都是低估值成长风格的基金。他认为，中国制造业太大了，很多细分行业是没人注意的到的，只有靠基金经理自己去挖，去走访调研，寻找小领域里别人没注意到，但是业绩即将爆发的票，先买入这种票，等市场开始关注到的时候，就会出现一个估值和业绩的双抬升，戴维斯双击。 ","date":"2016-01-02","objectID":"/appraisement/:2:0","tags":["理财"],"title":"估值","uri":"/appraisement/"},{"categories":["理财"],"content":"第三大块 顺周期行业 顺周期行业投资者参与热情并不高，因为在大家看来，顺周期是一个短久期的资产，没有量的逻辑，只有价格的逻辑，而价格的波动又过于频繁，所以个人投资者很难去判断行业盈利中枢到底在哪，容易造成永久性亏损（套几年）。讲白了就是，你摸不准这个行业在高景气度的时候，到底能赚多少钱，因为它可能十年才来一个牛市，十年前那个价格早就不具有参考性了，就像现在的煤炭、钢铁、有色、化工，你能准确说出它的历史高位在哪吗？没有一个人能够打包票。这就是顺周期的难点，他认为当前顺周期的分歧很大。 ","date":"2016-01-02","objectID":"/appraisement/:3:0","tags":["理财"],"title":"估值","uri":"/appraisement/"},{"categories":["理财"],"content":"投资纲领","date":"2016-01-01","objectID":"/investment/","tags":["理财"],"title":"投资纲领","uri":"/investment/"},{"categories":["理财"],"content":"总体策略 低估加倍 高估不买 高估卖出 好资产 + 好价格 + 长期持有 ","date":"2016-01-01","objectID":"/investment/:1:0","tags":["理财"],"title":"投资纲领","uri":"/investment/"},{"categories":["理财"],"content":"资产配置 ","date":"2016-01-01","objectID":"/investment/:2:0","tags":["理财"],"title":"投资纲领","uri":"/investment/"},{"categories":["理财"],"content":"购买标的 ","date":"2016-01-01","objectID":"/investment/:3:0","tags":["理财"],"title":"投资纲领","uri":"/investment/"},{"categories":["理财"],"content":"宽基指数（沪深300和中证500） 我们可以把沪深300和中证500这样的宽基指数作为「核心」资产，比如占整体仓位的 60% 以上，保证我们能够跟上中国经济的增长，投资到未来头部的公司。 40% 基于估值和增强型指数基金进一步提高仓位。 ","date":"2016-01-01","objectID":"/investment/:3:1","tags":["理财"],"title":"投资纲领","uri":"/investment/"},{"categories":["理财"],"content":"「卫星」资产 我们可以根据自己的判断或者市场的估值，加入一部分「卫星」资产。 主动基金（优秀基金精力管理的基金）中概互联基金 科创板（还需观看） 。 30% 分散投资给几个优秀的主动型基金经理。 ","date":"2016-01-01","objectID":"/investment/:3:2","tags":["理财"],"title":"投资纲领","uri":"/investment/"},{"categories":["理财"],"content":"债券 30% 的债券仓位，用债券基金以及有知有行未来推荐的其它「固收+」产品来进一步提高收益。 计算得出年化收益率：40% * 13% + 30% * 11% + 30% * 4% + 1% = 10.7%。 ","date":"2016-01-01","objectID":"/investment/:3:3","tags":["理财"],"title":"投资纲领","uri":"/investment/"},{"categories":["理财"],"content":"具体操作 ","date":"2016-01-01","objectID":"/investment/:4:0","tags":["理财"],"title":"投资纲领","uri":"/investment/"},{"categories":["理财"],"content":"每年一次大额买入 参考有知有行的「股市温度计」来确定自己一次性买入的仓位。 假如当年大额资金5万，当时股市温度为40处于中估状态，则先投入50%，计算得出当年大额买入资金为2.5万。 ","date":"2016-01-01","objectID":"/investment/:4:1","tags":["理财"],"title":"投资纲领","uri":"/investment/"},{"categories":["理财"],"content":"每年一次的再平衡 根据自定的家庭资产比例和当年股债实时状态，进行股债再平衡调整。 ","date":"2016-01-01","objectID":"/investment/:4:2","tags":["理财"],"title":"投资纲领","uri":"/investment/"},{"categories":["理财"],"content":"每月定投 参考有知有行的「股市温度计」，在中估时投入，低估时加倍，高估时停止买入 ","date":"2016-01-01","objectID":"/investment/:4:3","tags":["理财"],"title":"投资纲领","uri":"/investment/"},{"categories":["理财"],"content":"高估状态卖出部分锁定收益 A股的波动大，牛市之后往往出现暴跌，而浮亏越大，回本难度越大，甚至难度是呈指数级增长的。 ","date":"2016-01-01","objectID":"/investment/:4:4","tags":["理财"],"title":"投资纲领","uri":"/investment/"},{"categories":["反思"],"content":"写作促进思考","date":"2015-01-02","objectID":"/studyandthink/","tags":["反思"],"title":"学与思","uri":"/studyandthink/"},{"categories":["反思"],"content":"学而不思则罔，思而不学则殆 一味学习而不思考，就会因为不能深刻理解而不能合理有效利用学习的知识，甚至会陷入迷茫。 一味空想而不去进行实实在在地学习和钻研，则终究是沙上建塔，一无所得。 因此我们只有把学习和思考结合起来，才能学到切实有用的知识，否则就会收效甚微。 ","date":"2015-01-02","objectID":"/studyandthink/:0:1","tags":["反思"],"title":"学与思","uri":"/studyandthink/"},{"categories":["记录"],"content":"Markdown常用语法","date":"2015-01-01","objectID":"/mdgrammar/","tags":["Markdown"],"title":"Markdown语法","uri":"/mdgrammar/"},{"categories":["记录"],"content":"标题 #### 这是 H5 #### 这是 H5 ","date":"2015-01-01","objectID":"/mdgrammar/:0:1","tags":["Markdown"],"title":"Markdown语法","uri":"/mdgrammar/"},{"categories":["记录"],"content":"段落 这是一个段落。 这是另一个段落。 这是一个段落。 这是另一个段落。 ","date":"2015-01-01","objectID":"/mdgrammar/:0:2","tags":["Markdown"],"title":"Markdown语法","uri":"/mdgrammar/"},{"categories":["记录"],"content":"斜体 *这是斜体* 这是斜体 ","date":"2015-01-01","objectID":"/mdgrammar/:0:3","tags":["Markdown"],"title":"Markdown语法","uri":"/mdgrammar/"},{"categories":["记录"],"content":"粗体 **这是粗体** 这是粗体 ","date":"2015-01-01","objectID":"/mdgrammar/:0:4","tags":["Markdown"],"title":"Markdown语法","uri":"/mdgrammar/"},{"categories":["记录"],"content":"粗体+斜体 ***这是粗体+斜体*** 这是粗体+斜体 ","date":"2015-01-01","objectID":"/mdgrammar/:0:5","tags":["Markdown"],"title":"Markdown语法","uri":"/mdgrammar/"},{"categories":["记录"],"content":"删除线 ~~没有价值就会被抛弃~~ 没有价值就会被抛弃 ","date":"2015-01-01","objectID":"/mdgrammar/:0:6","tags":["Markdown"],"title":"Markdown语法","uri":"/mdgrammar/"},{"categories":["记录"],"content":"引用 \u003e Markdown是一种可以使用普通文本编辑器编写的标记语言，通过简单的标记语法，它可以使普通文本内容具有一定的格式。 Markdown是一种可以使用普通文本编辑器编写的标记语言，通过简单的标记语法，它可以使普通文本内容具有一定的格式。 ","date":"2015-01-01","objectID":"/mdgrammar/:0:7","tags":["Markdown"],"title":"Markdown语法","uri":"/mdgrammar/"},{"categories":["记录"],"content":"列表 * 学习 * 思考 * 创造 学习 思考 创造 ","date":"2015-01-01","objectID":"/mdgrammar/:0:8","tags":["Markdown"],"title":"Markdown语法","uri":"/mdgrammar/"},{"categories":["记录"],"content":"有序列表 1. 昨夜西风凋碧树。独上高楼，望尽天涯路。 2. 衣带渐宽终不悔，为伊消得人憔悴。 3. 众里寻他千百度。蓦然回首，那人却在，灯火阑珊处。 昨夜西风凋碧树。独上高楼，望尽天涯路。 衣带渐宽终不悔，为伊消得人憔悴。 众里寻他千百度。蓦然回首，那人却在，灯火阑珊处。 ","date":"2015-01-01","objectID":"/mdgrammar/:0:9","tags":["Markdown"],"title":"Markdown语法","uri":"/mdgrammar/"},{"categories":["记录"],"content":"分隔线 --------------------------------------- ","date":"2015-01-01","objectID":"/mdgrammar/:0:10","tags":["Markdown"],"title":"Markdown语法","uri":"/mdgrammar/"},{"categories":["记录"],"content":"链接 [百度](http://www.baidu.com/ \"百度一下\") 百度 ","date":"2015-01-01","objectID":"/mdgrammar/:0:11","tags":["Markdown"],"title":"Markdown语法","uri":"/mdgrammar/"},{"categories":["记录"],"content":"表格 | 账户 | 余额 | 类别 | | :--- | :--- | :--- | | 人民币 | 5百万 | 活期 | | 比特币 | 5个 | 数字资产 | | 股票基金 | 5亿 | 理财 | 账户 余额 类别 人民币 5百万 活期 比特币 5个 数字资产 股票基金 5亿 理财 ","date":"2015-01-01","objectID":"/mdgrammar/:0:12","tags":["Markdown"],"title":"Markdown语法","uri":"/mdgrammar/"},{"categories":["记录"],"content":"代码区域（四个空格） /** 这是一个Java代码区块 */ public static void main(String[] args) { System.out.println(\"Hello World\"); } ","date":"2015-01-01","objectID":"/mdgrammar/:0:13","tags":["Markdown"],"title":"Markdown语法","uri":"/mdgrammar/"},{"categories":["记录"],"content":"图像 ![](/images/star.png \"星辰大海\") 星辰大海 ","date":"2015-01-01","objectID":"/mdgrammar/:0:14","tags":["Markdown"],"title":"Markdown语法","uri":"/mdgrammar/"},{"categories":["反思"],"content":"舒缓生活","date":"2015-01-01","objectID":"/energy/","tags":["生活"],"title":"减缓焦虑，积聚生活正能量","uri":"/energy/"},{"categories":["反思"],"content":" 面对不断袭来的压力和信息，我们要做的，就是找到自己的节奏，建立一套稳定的模式，用来应对和处理种种事务。尽可能让一切「平稳」下来。 这也许需要一些取舍，一些选择、牺牲和放弃 —— 但一旦这套模式能够建立起来，一切都是值得的。 ","date":"2015-01-01","objectID":"/energy/:0:0","tags":["生活"],"title":"减缓焦虑，积聚生活正能量","uri":"/energy/"},{"categories":["反思"],"content":"思虑过载 变被动为主动，自己去决定「我要做什么」，重新找回「自主性」。 ","date":"2015-01-01","objectID":"/energy/:1:0","tags":["生活"],"title":"减缓焦虑，积聚生活正能量","uri":"/energy/"},{"categories":["反思"],"content":"前一天晚上做好安排 整理一遍任务清单，从收集/待办的池子中， 挑出5-6个最重要、最关键的任务，安排到第二天 ","date":"2015-01-01","objectID":"/energy/:1:1","tags":["生活"],"title":"减缓焦虑，积聚生活正能量","uri":"/energy/"},{"categories":["反思"],"content":"留出一定的宽裕度 做出取舍。该舍弃的，就果断舍弃。 与其把所有事情做到60分，不如把最重要的事情做到100分。 ","date":"2015-01-01","objectID":"/energy/:1:2","tags":["生活"],"title":"减缓焦虑，积聚生活正能量","uri":"/energy/"},{"categories":["反思"],"content":"聚焦在长期价值上 不妨这样问问自己：我可以做些什么，来摆脱目前这种忙碌的状态？ 无论是设计一套流程，还是把部分工作委托出去，又或者是把细碎的任务合并起来，还是优化、压缩任务步骤和时间……这些，长期来看都是更具价值的，也是你应该着重去聚焦的。 把它们作为你每天「最重要的事项」，想办法让自己能够抽身出来。 ","date":"2015-01-01","objectID":"/energy/:1:3","tags":["生活"],"title":"减缓焦虑，积聚生活正能量","uri":"/energy/"},{"categories":["反思"],"content":"被压榨感 什么是被压榨感？它是指：自己一直在劳动和付出，但却始终得不到反馈、认可和肯定，仿佛自己的付出都是无价值的。 去发现生活中微小的幸福感。 ","date":"2015-01-01","objectID":"/energy/:2:0","tags":["生活"],"title":"减缓焦虑，积聚生活正能量","uri":"/energy/"},{"categories":["反思"],"content":"决策疲劳 不要在晚上作出重要的决定。 通过给自己设立规则，让规则帮助自己作出决策。规则覆盖不到的地方，则用随机来解决。 ","date":"2015-01-01","objectID":"/energy/:3:0","tags":["生活"],"title":"减缓焦虑，积聚生活正能量","uri":"/energy/"},{"categories":["反思"],"content":"外在打扰 建立你的「第二大脑」，把思维外部化。 ","date":"2015-01-01","objectID":"/energy/:4:0","tags":["生活"],"title":"减缓焦虑，积聚生活正能量","uri":"/energy/"},{"categories":["反思"],"content":"信息过载 我们不断去追逐新信息，不断获取新鲜感的刺激，这本身是一个高耗能的行为 —— 但我们的大脑，会受到新鲜感的蛊惑，从而忽略和掩盖住这种耗能。 意识地克制自己，去做好信息的「反刍」，而非追逐新的信息。 试着把你记录的不同笔记放到一起，看看它们之间能产生什么联系，能否创造出新的火花。 在闲暇的碎片时间里，去反刍、回想自己记下的旧内容，尽量控制对新信息的摄入。 ","date":"2015-01-01","objectID":"/energy/:5:0","tags":["生活"],"title":"减缓焦虑，积聚生活正能量","uri":"/energy/"},{"categories":["反思"],"content":"tips 一定要睡好。 睡眠过程中的深度睡眠，能够有效促进腺苷到ATP的水合反应，为我们的机体储存能量、清除代谢垃圾。 请保证每天6小时以上不受干扰的睡眠，这极其重要。 多散步。 散步是最轻松有效的锻炼。不但能够促进血清素的合成，也能有效扩充大脑容量。波士顿大学的一项研究表明，每天步行1小时（约5000步），相当于大脑延缓衰老1年。 适当的运动。 每周 150 分钟一定强度的运动，能够有效提高心肺功能，从而提高每一天精力的上限。 这才是精力管理的关键 —— 上限太低，再怎么「管理」，也是无效的。 ","date":"2015-01-01","objectID":"/energy/:6:0","tags":["生活"],"title":"减缓焦虑，积聚生活正能量","uri":"/energy/"},{"categories":["区块链"],"content":"Redis","date":"0001-01-01","objectID":"/blockchain/","tags":["区块链","大纲"],"title":"区块链介绍","uri":"/blockchain/"},{"categories":["区块链"],"content":"DDC（Distributed Digital Certificate） DDC（Distributed Digital Certificate）即分布式数字凭证，其属性功能类似于 NFT。DDC/NFT 是一种区块链应用技术，本身并不带有特定业务属性。当前阶段，NFT 大多被用到数字艺术品版权领域，然而从技术上讲 NFT 就是现实或数字世界中某个事物或身份在区块链上的数字化权益证明。它的潜在使用场景是非常广泛的，任何需要提供权益证明的场景都可以用到它。 ","date":"0001-01-01","objectID":"/blockchain/:1:0","tags":["区块链","大纲"],"title":"区块链介绍","uri":"/blockchain/"},{"categories":["区块链"],"content":"参考文章 https://segmentfault.com/a/1190000041506390 ","date":"0001-01-01","objectID":"/blockchain/:2:0","tags":["区块链","大纲"],"title":"区块链介绍","uri":"/blockchain/"},{"categories":null,"content":"默哥","date":"2015-01-01","objectID":"/about/","tags":null,"title":"关于我","uri":"/about/"},{"categories":null,"content":"用写作触发思考。 ","date":"2015-01-01","objectID":"/about/:0:0","tags":null,"title":"关于我","uri":"/about/"},{"categories":null,"content":"记录点滴，反哺归真","date":"0001-01-01","objectID":"/archives/","tags":null,"title":"归档","uri":"/archives/"},{"categories":null,"content":"搜索页面","date":"0001-01-01","objectID":"/search/","tags":null,"title":"搜索","uri":"/search/"}]